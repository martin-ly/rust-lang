use anyhow::Result;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{RwLock, Semaphore};
use tokio::time::sleep;
use tracing::{info, warn, debug};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::atomic::{AtomicUsize, AtomicU64, Ordering};

/// 2025å¹´å¼‚æ­¥å†…å­˜ç®¡ç†ä¼˜åŒ–æ¼”ç¤º
/// å±•ç¤ºæœ€æ–°çš„å¼‚æ­¥å†…å­˜ç®¡ç†æŠ€æœ¯å’Œæœ€ä½³å®è·µ

/// 1. å¼‚æ­¥å†…å­˜æ± ç®¡ç†å™¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryPoolConfig {
    pub initial_size: usize,
    pub max_size: usize,
    pub chunk_size: usize,
    pub growth_factor: f64,
}

impl Default for MemoryPoolConfig {
    fn default() -> Self {
        Self {
            initial_size: 1024,
            max_size: 1024 * 1024,
            chunk_size: 64,
            growth_factor: 1.5,
        }
    }
}

#[derive(Debug, Clone)]
pub struct MemoryChunk {
    pub id: usize,
    pub size: usize,
    pub data: Vec<u8>,
    pub allocated_at: Instant,
    pub last_accessed: Instant,
}

pub struct AsyncMemoryPool {
    config: MemoryPoolConfig,
    chunks: Arc<RwLock<Vec<MemoryChunk>>>,
    available_chunks: Arc<RwLock<Vec<usize>>>,
    allocated_chunks: Arc<RwLock<HashMap<usize, usize>>>,
    stats: Arc<RwLock<MemoryPoolStats>>,
    semaphore: Arc<Semaphore>,
}

#[derive(Debug, Clone, Default)]
pub struct MemoryPoolStats {
    pub total_allocations: usize,
    pub total_deallocations: usize,
    pub peak_memory_usage: usize,
    pub current_memory_usage: usize,
    pub allocation_requests: usize,
    pub cache_hits: usize,
    pub cache_misses: usize,
}

impl AsyncMemoryPool {
    pub fn new(config: MemoryPoolConfig) -> Self {
        let semaphore = Arc::new(Semaphore::new(config.max_size / config.chunk_size));
        let pool = Self {
            config,
            chunks: Arc::new(RwLock::new(Vec::new())),
            available_chunks: Arc::new(RwLock::new(Vec::new())),
            allocated_chunks: Arc::new(RwLock::new(HashMap::new())),
            stats: Arc::new(RwLock::new(MemoryPoolStats::default())),
            semaphore,
        };
        
        // åˆå§‹åŒ–å†…å­˜æ± 
        tokio::spawn({
            let pool = pool.clone();
            async move {
                pool.initialize_pool().await;
            }
        });
        
        pool
    }

    async fn initialize_pool(&self) {
        let mut chunks = self.chunks.write().await;
        let mut available = self.available_chunks.write().await;
        
        for i in 0..(self.config.initial_size / self.config.chunk_size) {
            let chunk = MemoryChunk {
                id: i,
                size: self.config.chunk_size,
                data: vec![0u8; self.config.chunk_size],
                allocated_at: Instant::now(),
                last_accessed: Instant::now(),
            };
            
            chunks.push(chunk);
            available.push(i);
        }
        
        info!("å†…å­˜æ± åˆå§‹åŒ–å®Œæˆï¼Œåˆ›å»ºäº† {} ä¸ªå—", available.len());
    }

    pub async fn allocate(&self, size: usize) -> Result<usize> {
        let _permit = self.semaphore.acquire().await.unwrap();
        
        let mut stats = self.stats.write().await;
        stats.allocation_requests += 1;
        
        // å°è¯•ä»å¯ç”¨å—ä¸­åˆ†é…
        let mut available = self.available_chunks.write().await;
        if let Some(chunk_id) = available.pop() {
            let mut allocated = self.allocated_chunks.write().await;
            allocated.insert(chunk_id, size);
            stats.cache_hits += 1;
            stats.total_allocations += 1;
            
            let mut chunks = self.chunks.write().await;
            if let Some(chunk) = chunks.get_mut(chunk_id) {
                chunk.last_accessed = Instant::now();
            }
            
            info!("ä»å†…å­˜æ± åˆ†é…å— {}ï¼Œå¤§å°: {} å­—èŠ‚", chunk_id, size);
            return Ok(chunk_id);
        }
        
        // éœ€è¦åˆ›å»ºæ–°å—
        stats.cache_misses += 1;
        self.create_new_chunk(size).await
    }

    async fn create_new_chunk(&self, size: usize) -> Result<usize> {
        let mut chunks = self.chunks.write().await;
        let chunk_id = chunks.len();
        
        if chunk_id >= self.config.max_size / self.config.chunk_size {
            return Err(anyhow::anyhow!("å†…å­˜æ± å·²è¾¾åˆ°æœ€å¤§å¤§å°é™åˆ¶"));
        }
        
        let chunk = MemoryChunk {
            id: chunk_id,
            size: self.config.chunk_size,
            data: vec![0u8; self.config.chunk_size],
            allocated_at: Instant::now(),
            last_accessed: Instant::now(),
        };
        
        chunks.push(chunk);
        
        let mut allocated = self.allocated_chunks.write().await;
        allocated.insert(chunk_id, size);
        
        let mut stats = self.stats.write().await;
        stats.total_allocations += 1;
        stats.current_memory_usage += self.config.chunk_size;
        if stats.current_memory_usage > stats.peak_memory_usage {
            stats.peak_memory_usage = stats.current_memory_usage;
        }
        
        info!("åˆ›å»ºæ–°å†…å­˜å— {}ï¼Œå¤§å°: {} å­—èŠ‚", chunk_id, size);
        Ok(chunk_id)
    }

    pub async fn deallocate(&self, chunk_id: usize) -> Result<()> {
        let mut allocated = self.allocated_chunks.write().await;
        if allocated.remove(&chunk_id).is_some() {
            let mut available = self.available_chunks.write().await;
            available.push(chunk_id);
            
            let mut stats = self.stats.write().await;
            stats.total_deallocations += 1;
            stats.current_memory_usage = stats.current_memory_usage.saturating_sub(self.config.chunk_size);
            
            info!("é‡Šæ”¾å†…å­˜å— {}", chunk_id);
            Ok(())
        } else {
            Err(anyhow::anyhow!("å— {} æœªåˆ†é…", chunk_id))
        }
    }

    pub async fn get_stats(&self) -> MemoryPoolStats {
        self.stats.read().await.clone()
    }

    pub async fn cleanup_unused_chunks(&self, max_age: Duration) {
        let chunks = self.chunks.write().await;
        let mut available = self.available_chunks.write().await;
        let mut stats = self.stats.write().await;
        
        let now = Instant::now();
        let mut removed_count = 0;
        
        // ç§»é™¤é•¿æ—¶é—´æœªä½¿ç”¨çš„å—
        let current_len = available.len();
        available.retain(|&chunk_id| {
            if let Some(chunk) = chunks.get(chunk_id) {
                let age = now.duration_since(chunk.last_accessed);
                if age > max_age && current_len > self.config.initial_size / self.config.chunk_size {
                    removed_count += 1;
                    stats.current_memory_usage = stats.current_memory_usage.saturating_sub(chunk.size);
                    false
                } else {
                    true
                }
            } else {
                false
            }
        });
        
        if removed_count > 0 {
            info!("æ¸…ç†äº† {} ä¸ªæœªä½¿ç”¨çš„å†…å­˜å—", removed_count);
        }
    }
}

impl Clone for AsyncMemoryPool {
    fn clone(&self) -> Self {
        Self {
            config: self.config.clone(),
            chunks: self.chunks.clone(),
            available_chunks: self.available_chunks.clone(),
            allocated_chunks: self.allocated_chunks.clone(),
            stats: self.stats.clone(),
            semaphore: self.semaphore.clone(),
        }
    }
}

/// 2. å¼‚æ­¥åƒåœ¾å›æ”¶å™¨
pub struct AsyncGarbageCollector {
    objects: Arc<RwLock<HashMap<usize, GarbageCollectable>>>,
    reference_counts: Arc<RwLock<HashMap<usize, usize>>>,
    gc_stats: Arc<RwLock<GCStats>>,
    gc_interval: Duration,
}

#[derive(Debug, Clone)]
pub struct GarbageCollectable {
    pub id: usize,
    pub size: usize,
    pub created_at: Instant,
    pub last_accessed: Instant,
    pub references: Vec<usize>,
}

#[derive(Debug, Clone, Default)]
pub struct GCStats {
    pub total_objects: usize,
    pub collected_objects: usize,
    pub gc_cycles: usize,
    pub total_gc_time: Duration,
    pub memory_freed: usize,
}

impl AsyncGarbageCollector {
    pub fn new(gc_interval: Duration) -> Self {
        let gc = Self {
            objects: Arc::new(RwLock::new(HashMap::new())),
            reference_counts: Arc::new(RwLock::new(HashMap::new())),
            gc_stats: Arc::new(RwLock::new(GCStats::default())),
            gc_interval,
        };
        
        // å¯åŠ¨åƒåœ¾å›æ”¶ä»»åŠ¡
        let gc_clone = gc.clone();
        tokio::spawn(async move {
            gc_clone.gc_loop().await;
        });
        
        gc
    }

    pub async fn create_object(&self, id: usize, size: usize) -> Result<()> {
        let object = GarbageCollectable {
            id,
            size,
            created_at: Instant::now(),
            last_accessed: Instant::now(),
            references: Vec::new(),
        };
        
        self.objects.write().await.insert(id, object);
        self.reference_counts.write().await.insert(id, 1);
        
        let mut stats = self.gc_stats.write().await;
        stats.total_objects += 1;
        
        info!("åˆ›å»ºå¯¹è±¡ {}ï¼Œå¤§å°: {} å­—èŠ‚", id, size);
        Ok(())
    }

    pub async fn add_reference(&self, from_id: usize, to_id: usize) -> Result<()> {
        let mut objects = self.objects.write().await;
        if let Some(from_obj) = objects.get_mut(&from_id) {
            from_obj.references.push(to_id);
            from_obj.last_accessed = Instant::now();
        }
        
        let mut ref_counts = self.reference_counts.write().await;
        *ref_counts.entry(to_id).or_insert(0) += 1;
        
        debug!("å¯¹è±¡ {} å¼•ç”¨å¯¹è±¡ {}", from_id, to_id);
        Ok(())
    }

    pub async fn remove_reference(&self, from_id: usize, to_id: usize) -> Result<()> {
        let mut objects = self.objects.write().await;
        if let Some(from_obj) = objects.get_mut(&from_id) {
            from_obj.references.retain(|&id| id != to_id);
            from_obj.last_accessed = Instant::now();
        }
        
        let mut ref_counts = self.reference_counts.write().await;
        if let Some(count) = ref_counts.get_mut(&to_id) {
            *count = count.saturating_sub(1);
        }
        
        debug!("å¯¹è±¡ {} å–æ¶ˆå¼•ç”¨å¯¹è±¡ {}", from_id, to_id);
        Ok(())
    }

    async fn gc_loop(&self) {
        let mut interval = tokio::time::interval(self.gc_interval);
        loop {
            interval.tick().await;
            let _ = self.collect_garbage().await;
        }
    }

    pub async fn collect_garbage(&self) -> Result<()> {
        let start_time = Instant::now();
        
        let mut stats = self.gc_stats.write().await;
        stats.gc_cycles += 1;
        
        // æ ‡è®°é˜¶æ®µï¼šæ ‡è®°æ‰€æœ‰å¯è¾¾å¯¹è±¡
        let mut reachable = std::collections::HashSet::new();
        let objects = self.objects.read().await;
        let ref_counts = self.reference_counts.read().await;
        
        // ä»æ ¹å¯¹è±¡å¼€å§‹æ ‡è®°
        for (id, count) in ref_counts.iter() {
            if *count > 0 {
                self.mark_reachable(*id, &objects, &mut reachable);
            }
        }
        
        // æ¸…ç†é˜¶æ®µï¼šåˆ é™¤ä¸å¯è¾¾å¯¹è±¡
        let mut objects_write = self.objects.write().await;
        let mut ref_counts_write = self.reference_counts.write().await;
        let mut collected_count = 0;
        let mut memory_freed = 0;
        
        objects_write.retain(|id, object| {
            if reachable.contains(id) {
                true
            } else {
                collected_count += 1;
                memory_freed += object.size;
                ref_counts_write.remove(id);
                false
            }
        });
        
        stats.collected_objects += collected_count;
        stats.memory_freed += memory_freed;
        stats.total_gc_time += start_time.elapsed();
        
        if collected_count > 0 {
            info!("åƒåœ¾å›æ”¶å®Œæˆï¼Œå›æ”¶äº† {} ä¸ªå¯¹è±¡ï¼Œé‡Šæ”¾å†…å­˜: {} å­—èŠ‚", collected_count, memory_freed);
        }
        
        Ok(())
    }

    fn mark_reachable(&self, object_id: usize, objects: &HashMap<usize, GarbageCollectable>, reachable: &mut std::collections::HashSet<usize>) {
        if reachable.contains(&object_id) {
            return;
        }
        
        reachable.insert(object_id);
        
        if let Some(object) = objects.get(&object_id) {
            for &ref_id in &object.references {
                self.mark_reachable(ref_id, objects, reachable);
            }
        }
    }

    pub async fn get_stats(&self) -> GCStats {
        self.gc_stats.read().await.clone()
    }
}

impl Clone for AsyncGarbageCollector {
    fn clone(&self) -> Self {
        Self {
            objects: self.objects.clone(),
            reference_counts: self.reference_counts.clone(),
            gc_stats: self.gc_stats.clone(),
            gc_interval: self.gc_interval,
        }
    }
}

/// 3. å¼‚æ­¥å†…å­˜ç›‘æ§å™¨
pub struct AsyncMemoryMonitor {
    memory_usage: Arc<AtomicU64>,
    peak_memory: Arc<AtomicU64>,
    allocation_count: Arc<AtomicUsize>,
    deallocation_count: Arc<AtomicUsize>,
    monitor_interval: Duration,
    alert_threshold: f64,
}

impl AsyncMemoryMonitor {
    pub fn new(monitor_interval: Duration, alert_threshold: f64) -> Self {
        let monitor = Self {
            memory_usage: Arc::new(AtomicU64::new(0)),
            peak_memory: Arc::new(AtomicU64::new(0)),
            allocation_count: Arc::new(AtomicUsize::new(0)),
            deallocation_count: Arc::new(AtomicUsize::new(0)),
            monitor_interval,
            alert_threshold,
        };
        
        // å¯åŠ¨ç›‘æ§ä»»åŠ¡
        let monitor_clone = monitor.clone();
        tokio::spawn(async move {
            monitor_clone.monitor_loop().await;
        });
        
        monitor
    }

    pub fn record_allocation(&self, size: usize) {
        self.memory_usage.fetch_add(size as u64, Ordering::Relaxed);
        self.allocation_count.fetch_add(1, Ordering::Relaxed);
        
        let current = self.memory_usage.load(Ordering::Relaxed);
        let peak = self.peak_memory.load(Ordering::Relaxed);
        if current > peak {
            self.peak_memory.store(current, Ordering::Relaxed);
        }
    }

    pub fn record_deallocation(&self, size: usize) {
        self.memory_usage.fetch_sub(size as u64, Ordering::Relaxed);
        self.deallocation_count.fetch_add(1, Ordering::Relaxed);
    }

    async fn monitor_loop(&self) {
        let mut interval = tokio::time::interval(self.monitor_interval);
        loop {
            interval.tick().await;
            self.check_memory_usage().await;
        }
    }

    async fn check_memory_usage(&self) {
        let current_usage = self.memory_usage.load(Ordering::Relaxed);
        let peak_usage = self.peak_memory.load(Ordering::Relaxed);
        
        if peak_usage > 0 {
            let usage_ratio = current_usage as f64 / peak_usage as f64;
            if usage_ratio > self.alert_threshold {
                warn!("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {:.2}% ({}/{} å­—èŠ‚)", 
                      usage_ratio * 100.0, current_usage, peak_usage);
            }
        }
        
        debug!("å†…å­˜ç›‘æ§ - å½“å‰: {} å­—èŠ‚, å³°å€¼: {} å­—èŠ‚", current_usage, peak_usage);
    }

    pub fn get_stats(&self) -> MemoryMonitorStats {
        MemoryMonitorStats {
            current_memory_usage: self.memory_usage.load(Ordering::Relaxed),
            peak_memory_usage: self.peak_memory.load(Ordering::Relaxed),
            total_allocations: self.allocation_count.load(Ordering::Relaxed),
            total_deallocations: self.deallocation_count.load(Ordering::Relaxed),
        }
    }
}

#[derive(Debug, Clone)]
pub struct MemoryMonitorStats {
    pub current_memory_usage: u64,
    pub peak_memory_usage: u64,
    pub total_allocations: usize,
    pub total_deallocations: usize,
}

impl Clone for AsyncMemoryMonitor {
    fn clone(&self) -> Self {
        Self {
            memory_usage: self.memory_usage.clone(),
            peak_memory: self.peak_memory.clone(),
            allocation_count: self.allocation_count.clone(),
            deallocation_count: self.deallocation_count.clone(),
            monitor_interval: self.monitor_interval,
            alert_threshold: self.alert_threshold,
        }
    }
}

/// 4. å¼‚æ­¥å†…å­˜ä¼˜åŒ–ç®¡ç†å™¨
pub struct AsyncMemoryOptimizer {
    memory_pool: AsyncMemoryPool,
    garbage_collector: AsyncGarbageCollector,
    memory_monitor: AsyncMemoryMonitor,
    optimization_config: OptimizationConfig,
}

#[derive(Debug, Clone)]
pub struct OptimizationConfig {
    pub enable_pooling: bool,
    pub enable_gc: bool,
    pub enable_monitoring: bool,
    pub gc_interval: Duration,
    pub monitor_interval: Duration,
    pub pool_cleanup_interval: Duration,
}

impl Default for OptimizationConfig {
    fn default() -> Self {
        Self {
            enable_pooling: true,
            enable_gc: true,
            enable_monitoring: true,
            gc_interval: Duration::from_secs(30),
            monitor_interval: Duration::from_secs(10),
            pool_cleanup_interval: Duration::from_secs(60),
        }
    }
}

impl AsyncMemoryOptimizer {
    pub fn new(config: OptimizationConfig) -> Self {
        let pool_config = MemoryPoolConfig::default();
        let memory_pool = AsyncMemoryPool::new(pool_config);
        let garbage_collector = AsyncGarbageCollector::new(config.gc_interval);
        let memory_monitor = AsyncMemoryMonitor::new(config.monitor_interval, 0.8);
        
        Self {
            memory_pool,
            garbage_collector,
            memory_monitor,
            optimization_config: config,
        }
    }

    pub async fn optimize_memory_usage(&self) -> Result<()> {
        if self.optimization_config.enable_pooling {
            self.memory_pool.cleanup_unused_chunks(Duration::from_secs(300)).await;
        }
        
        if self.optimization_config.enable_gc {
            self.garbage_collector.collect_garbage().await?;
        }
        
        Ok(())
    }

    pub async fn get_comprehensive_stats(&self) -> ComprehensiveMemoryStats {
        let pool_stats = self.memory_pool.get_stats().await;
        let gc_stats = self.garbage_collector.get_stats().await;
        let monitor_stats = self.memory_monitor.get_stats();
        
        ComprehensiveMemoryStats {
            pool_stats,
            gc_stats,
            monitor_stats,
        }
    }
}

#[derive(Debug, Clone)]
pub struct ComprehensiveMemoryStats {
    pub pool_stats: MemoryPoolStats,
    pub gc_stats: GCStats,
    pub monitor_stats: MemoryMonitorStats,
}

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt::init();
    
    info!("ğŸš€ å¼€å§‹ 2025 å¹´å¼‚æ­¥å†…å­˜ç®¡ç†ä¼˜åŒ–æ¼”ç¤º");

    // 1. æ¼”ç¤ºå¼‚æ­¥å†…å­˜æ± 
    info!("ğŸ’¾ æ¼”ç¤ºå¼‚æ­¥å†…å­˜æ± ç®¡ç†");
    let pool_config = MemoryPoolConfig {
        initial_size: 2048,
        max_size: 8192,
        chunk_size: 128,
        growth_factor: 1.5,
    };
    
    let memory_pool = AsyncMemoryPool::new(pool_config);
    
    // ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
    sleep(Duration::from_millis(100)).await;
    
    // åˆ†é…ä¸€äº›å†…å­˜å—
    let mut allocated_chunks = Vec::new();
    for i in 0..10 {
        let chunk_id = memory_pool.allocate(64).await?;
        allocated_chunks.push(chunk_id);
        info!("åˆ†é…å†…å­˜å— {} ç”¨äºå¯¹è±¡ {}", chunk_id, i);
    }
    
    // é‡Šæ”¾ä¸€äº›å†…å­˜å—
    for &chunk_id in &allocated_chunks[0..5] {
        memory_pool.deallocate(chunk_id).await?;
        info!("é‡Šæ”¾å†…å­˜å— {}", chunk_id);
    }
    
    let pool_stats = memory_pool.get_stats().await;
    info!("å†…å­˜æ± ç»Ÿè®¡:");
    info!("   æ€»åˆ†é…: {}, æ€»é‡Šæ”¾: {}", pool_stats.total_allocations, pool_stats.total_deallocations);
    info!("   ç¼“å­˜å‘½ä¸­: {}, ç¼“å­˜æœªå‘½ä¸­: {}", pool_stats.cache_hits, pool_stats.cache_misses);
    info!("   å½“å‰å†…å­˜ä½¿ç”¨: {} å­—èŠ‚", pool_stats.current_memory_usage);

    // 2. æ¼”ç¤ºå¼‚æ­¥åƒåœ¾å›æ”¶å™¨
    info!("ğŸ—‘ï¸ æ¼”ç¤ºå¼‚æ­¥åƒåœ¾å›æ”¶å™¨");
    let gc = AsyncGarbageCollector::new(Duration::from_secs(5));
    
    // åˆ›å»ºä¸€äº›å¯¹è±¡
    for i in 0..20 {
        gc.create_object(i, 256).await?;
    }
    
    // å»ºç«‹ä¸€äº›å¼•ç”¨å…³ç³»
    for i in 0..10 {
        gc.add_reference(i, i + 10).await?;
    }
    
    // ç§»é™¤ä¸€äº›å¼•ç”¨ï¼Œä½¿å¯¹è±¡å˜ä¸ºåƒåœ¾
    for i in 5..10 {
        gc.remove_reference(i, i + 10).await?;
    }
    
    // æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
    gc.collect_garbage().await?;
    
    let gc_stats = gc.get_stats().await;
    info!("åƒåœ¾å›æ”¶ç»Ÿè®¡:");
    info!("   æ€»å¯¹è±¡: {}, å›æ”¶å¯¹è±¡: {}", gc_stats.total_objects, gc_stats.collected_objects);
    info!("   GCå‘¨æœŸ: {}, é‡Šæ”¾å†…å­˜: {} å­—èŠ‚", gc_stats.gc_cycles, gc_stats.memory_freed);

    // 3. æ¼”ç¤ºå¼‚æ­¥å†…å­˜ç›‘æ§å™¨
    info!("ğŸ“Š æ¼”ç¤ºå¼‚æ­¥å†…å­˜ç›‘æ§å™¨");
    let monitor = AsyncMemoryMonitor::new(Duration::from_secs(2), 0.7);
    
    // æ¨¡æ‹Ÿå†…å­˜åˆ†é…å’Œé‡Šæ”¾
    for i in 0..50 {
        monitor.record_allocation(1024);
        if i % 3 == 0 {
            monitor.record_deallocation(512);
        }
    }
    
    sleep(Duration::from_millis(100)).await;
    
    let monitor_stats = monitor.get_stats();
    info!("å†…å­˜ç›‘æ§ç»Ÿè®¡:");
    info!("   å½“å‰å†…å­˜ä½¿ç”¨: {} å­—èŠ‚", monitor_stats.current_memory_usage);
    info!("   å³°å€¼å†…å­˜ä½¿ç”¨: {} å­—èŠ‚", monitor_stats.peak_memory_usage);
    info!("   æ€»åˆ†é…: {}, æ€»é‡Šæ”¾: {}", monitor_stats.total_allocations, monitor_stats.total_deallocations);

    // 4. æ¼”ç¤ºç»¼åˆå†…å­˜ä¼˜åŒ–ç®¡ç†å™¨
    info!("âš¡ æ¼”ç¤ºç»¼åˆå¼‚æ­¥å†…å­˜ä¼˜åŒ–ç®¡ç†å™¨");
    let config = OptimizationConfig::default();
    let optimizer = AsyncMemoryOptimizer::new(config);
    
    // æ‰§è¡Œå†…å­˜ä¼˜åŒ–
    optimizer.optimize_memory_usage().await?;
    
    let comprehensive_stats = optimizer.get_comprehensive_stats().await;
    info!("ç»¼åˆå†…å­˜ç»Ÿè®¡:");
    info!("   å†…å­˜æ±  - åˆ†é…: {}, é‡Šæ”¾: {}", 
          comprehensive_stats.pool_stats.total_allocations, 
          comprehensive_stats.pool_stats.total_deallocations);
    info!("   åƒåœ¾å›æ”¶ - å¯¹è±¡: {}, å›æ”¶: {}", 
          comprehensive_stats.gc_stats.total_objects, 
          comprehensive_stats.gc_stats.collected_objects);
    info!("   å†…å­˜ç›‘æ§ - å½“å‰: {} å­—èŠ‚, å³°å€¼: {} å­—èŠ‚", 
          comprehensive_stats.monitor_stats.current_memory_usage,
          comprehensive_stats.monitor_stats.peak_memory_usage);

    info!("âœ… 2025 å¹´å¼‚æ­¥å†…å­˜ç®¡ç†ä¼˜åŒ–æ¼”ç¤ºå®Œæˆ!");
    
    Ok(())
}
