use anyhow::Result;
use std::time::{Duration, Instant};
use tokio::sync::{Semaphore, RwLock};
use tokio::time::{sleep, timeout};
use tracing::{info, warn, error, debug};
use std::sync::Arc;

/// 2025å¹´å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º
/// å±•ç¤ºæœ€æ–°çš„å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯å’Œæœ€ä½³å®è·µ

/// é«˜æ€§èƒ½å¼‚æ­¥ä»»åŠ¡æ± 
pub struct AsyncTaskPool {
    semaphore: Arc<Semaphore>,
    max_concurrent: usize,
    metrics: Arc<RwLock<TaskPoolMetrics>>,
}

#[derive(Debug, Default, Clone)]
pub struct TaskPoolMetrics {
    pub total_tasks: u64,
    pub completed_tasks: u64,
    pub failed_tasks: u64,
    pub average_execution_time: Duration,
    pub throughput_per_second: f64,
}

impl AsyncTaskPool {
    pub fn new(max_concurrent: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_concurrent)),
            max_concurrent,
            metrics: Arc::new(RwLock::new(TaskPoolMetrics::default())),
        }
    }

    /// æ‰§è¡Œä»»åŠ¡å¹¶æ”¶é›†æ€§èƒ½æŒ‡æ ‡
    pub async fn execute<F, R>(&self, task_name: &str, future: F) -> Result<R>
    where
        F: std::future::Future<Output = Result<R>> + Send + 'static,
        R: Send + 'static,
    {
        let start_time = Instant::now();
        
        // è·å–ä¿¡å·é‡è®¸å¯
        let _permit = self.semaphore.acquire().await
            .map_err(|e| anyhow::anyhow!("Failed to acquire permit: {}", e))?;

        debug!("æ‰§è¡Œä»»åŠ¡: {}", task_name);
        
        let result = timeout(Duration::from_secs(30), future).await
            .map_err(|_| anyhow::anyhow!("Task timeout"))?;

        let execution_time = start_time.elapsed();
        
        // æ›´æ–°æŒ‡æ ‡
        self.update_metrics(&result, execution_time).await;

        match &result {
            Ok(_) => {
                info!("ä»»åŠ¡å®Œæˆ: {} (è€—æ—¶: {:?})", task_name, execution_time);
            }
            Err(e) => {
                error!("ä»»åŠ¡å¤±è´¥: {} - {}", task_name, e);
            }
        }

        result
    }

    async fn update_metrics<R>(&self, result: &Result<R>, execution_time: Duration) {
        let mut metrics = self.metrics.write().await;
        metrics.total_tasks += 1;
        
        match result {
            Ok(_) => metrics.completed_tasks += 1,
            Err(_) => metrics.failed_tasks += 1,
        }

        // æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´
        let total_time = metrics.average_execution_time * (metrics.total_tasks - 1) as u32 + execution_time;
        metrics.average_execution_time = total_time / metrics.total_tasks as u32;

        // è®¡ç®—ååé‡ï¼ˆæ¯ç§’å®Œæˆçš„ä»»åŠ¡æ•°ï¼‰
        if metrics.average_execution_time.as_millis() > 0 {
            metrics.throughput_per_second = 1000.0 / metrics.average_execution_time.as_millis() as f64;
        }
    }

    pub async fn get_metrics(&self) -> TaskPoolMetrics {
        self.metrics.read().await.clone()
    }
}

/// å¼‚æ­¥ç¼“å­˜ç®¡ç†å™¨
#[allow(dead_code)]
#[derive(Debug)]
pub struct AsyncCacheManager<K, V> {
    cache: Arc<RwLock<std::collections::HashMap<K, V>>>,
    ttl: Duration,
    max_size: usize,
    hit_count: Arc<RwLock<u64>>,
    miss_count: Arc<RwLock<u64>>,
}

impl<K, V> AsyncCacheManager<K, V>
where
    K: Clone + std::hash::Hash + Eq + Send + Sync + std::fmt::Debug + 'static,
    V: Clone + Send + Sync + 'static,
{
    pub fn new(ttl: Duration, max_size: usize) -> Self {
        Self {
            cache: Arc::new(RwLock::new(std::collections::HashMap::new())),
            ttl,
            max_size,
            hit_count: Arc::new(RwLock::new(0)),
            miss_count: Arc::new(RwLock::new(0)),
        }
    }

    pub async fn get(&self, key: &K) -> Option<V> {
        let cache = self.cache.read().await;
        match cache.get(key) {
            Some(value) => {
                let mut hit_count = self.hit_count.write().await;
                *hit_count += 1;
                debug!("ç¼“å­˜å‘½ä¸­: {:?}", key);
                Some(value.clone())
            }
            None => {
                let mut miss_count = self.miss_count.write().await;
                *miss_count += 1;
                debug!("ç¼“å­˜æœªå‘½ä¸­: {:?}", key);
                None
            }
        }
    }

    pub async fn set(&self, key: K, value: V) {
        let mut cache = self.cache.write().await;
        
        // æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
        if cache.len() >= self.max_size {
            // ç®€å•çš„LRUç­–ç•¥ï¼šç§»é™¤ç¬¬ä¸€ä¸ªæ¡ç›®
            if let Some(first_key) = cache.keys().next().cloned() {
                cache.remove(&first_key);
            }
        }

        cache.insert(key.clone(), value);
        info!("ç¼“å­˜è®¾ç½®: {:?}", key);
    }

    pub async fn hit_rate(&self) -> f64 {
        let hits = *self.hit_count.read().await;
        let misses = *self.miss_count.read().await;
        
        if hits + misses == 0 {
            0.0
        } else {
            hits as f64 / (hits + misses) as f64
        }
    }
}

/// å¼‚æ­¥æ‰¹å¤„ç†å™¨
pub struct AsyncBatchProcessor<T> {
    batch_size: usize,
    flush_interval: Duration,
    buffer: Arc<RwLock<Vec<T>>>,
    processor: Arc<dyn Fn(Vec<T>) -> Result<()> + Send + Sync>,
}

impl<T> AsyncBatchProcessor<T>
where
    T: Send + Sync + 'static,
{
    pub fn new<F>(
        batch_size: usize,
        flush_interval: Duration,
        processor: F,
    ) -> Self
    where
        F: Fn(Vec<T>) -> Result<()> + Send + Sync + 'static,
    {
        Self {
            batch_size,
            flush_interval,
            buffer: Arc::new(RwLock::new(Vec::new())),
            processor: Arc::new(processor),
        }
    }

    pub async fn add(&self, item: T) -> Result<()> {
        let mut buffer = self.buffer.write().await;
        buffer.push(item);

        if buffer.len() >= self.batch_size {
            let items = buffer.drain(..).collect();
            drop(buffer); // é‡Šæ”¾é”

            self.process_batch(items).await?;
        }

        Ok(())
    }

    pub async fn flush(&self) -> Result<()> {
        let mut buffer = self.buffer.write().await;
        if !buffer.is_empty() {
            let items = buffer.drain(..).collect();
            drop(buffer); // é‡Šæ”¾é”

            self.process_batch(items).await?;
        }
        Ok(())
    }

    async fn process_batch(&self, items: Vec<T>) -> Result<()> {
        let start_time = Instant::now();
        let item_count = items.len();
        (self.processor)(items)?;
        let duration = start_time.elapsed();
        
        info!("æ‰¹å¤„ç†å®Œæˆ: {} ä¸ªé¡¹ç›®, è€—æ—¶: {:?}", item_count, duration);
        Ok(())
    }

    /// å¯åŠ¨å®šæ—¶åˆ·æ–°ä»»åŠ¡
    pub async fn start_periodic_flush(&self) -> Result<()> {
        let buffer = self.buffer.clone();
        let processor = self.processor.clone();
        let flush_interval = self.flush_interval;

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(flush_interval);
            loop {
                interval.tick().await;
                
                let mut buffer = buffer.write().await;
                if !buffer.is_empty() {
                    let items = buffer.drain(..).collect();
                    drop(buffer); // é‡Šæ”¾é”

                    if let Err(e) = (processor)(items) {
                        error!("å®šæ—¶æ‰¹å¤„ç†å¤±è´¥: {}", e);
                    }
                }
            }
        });

        Ok(())
    }
}

/// å¼‚æ­¥è¿æ¥æ± 
pub struct AsyncConnectionPool<T> {
    connections: Arc<RwLock<Vec<T>>>,
    max_size: usize,
    factory: Arc<dyn Fn() -> Result<T> + Send + Sync>,
    active_connections: Arc<RwLock<usize>>,
}

impl<T> AsyncConnectionPool<T>
where
    T: Send + Sync + 'static,
{
    pub fn new<F>(max_size: usize, factory: F) -> Self
    where
        F: Fn() -> Result<T> + Send + Sync + 'static,
    {
        Self {
            connections: Arc::new(RwLock::new(Vec::new())),
            max_size,
            factory: Arc::new(factory),
            active_connections: Arc::new(RwLock::new(0)),
        }
    }

    pub async fn acquire(&self) -> Result<PooledConnection<T>> {
        // å°è¯•ä»æ± ä¸­è·å–è¿æ¥
        {
            let mut connections = self.connections.write().await;
            if let Some(connection) = connections.pop() {
                let mut active = self.active_connections.write().await;
                *active += 1;
                debug!("ä»æ± ä¸­è·å–è¿æ¥ï¼Œæ´»è·ƒè¿æ¥æ•°: {}", *active);
                return Ok(PooledConnection::new(connection, self.clone()));
            }
        }

        // æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è¿æ¥æ•°
        {
            let active = self.active_connections.read().await;
            if *active >= self.max_size {
                return Err(anyhow::anyhow!("è¿æ¥æ± å·²æ»¡"));
            }
        }

        // åˆ›å»ºæ–°è¿æ¥
        let connection = (self.factory)()?;
        let mut active = self.active_connections.write().await;
        *active += 1;
        debug!("åˆ›å»ºæ–°è¿æ¥ï¼Œæ´»è·ƒè¿æ¥æ•°: {}", *active);

        Ok(PooledConnection::new(connection, self.clone()))
    }

    pub async fn release(&self, connection: T) {
        let mut connections = self.connections.write().await;
        if connections.len() < self.max_size {
            connections.push(connection);
        }
        
        let mut active = self.active_connections.write().await;
        *active -= 1;
        debug!("é‡Šæ”¾è¿æ¥ï¼Œæ´»è·ƒè¿æ¥æ•°: {}", *active);
    }

    pub async fn active_count(&self) -> usize {
        *self.active_connections.read().await
    }

    pub async fn available_count(&self) -> usize {
        self.connections.read().await.len()
    }
}

/// æ± åŒ–è¿æ¥åŒ…è£…å™¨
pub struct PooledConnection<T> 
where
    T: Send + Sync + 'static,
{
    connection: Option<T>,
    pool: AsyncConnectionPool<T>,
}

impl<T> PooledConnection<T> 
where
    T: Send + Sync + 'static,
{
    fn new(connection: T, pool: AsyncConnectionPool<T>) -> Self {
        Self {
            connection: Some(connection),
            pool,
        }
    }

    pub fn get(&self) -> &T {
        self.connection.as_ref().unwrap()
    }
}

impl<T> Drop for PooledConnection<T> 
where
    T: Send + Sync + 'static,
{
    fn drop(&mut self) {
        if let Some(connection) = self.connection.take() {
            let pool = self.pool.clone();
            tokio::spawn(async move {
                pool.release(connection).await;
            });
        }
    }
}

impl<T> Clone for AsyncConnectionPool<T> {
    fn clone(&self) -> Self {
        Self {
            connections: self.connections.clone(),
            max_size: self.max_size,
            factory: self.factory.clone(),
            active_connections: self.active_connections.clone(),
        }
    }
}

impl Clone for AsyncTaskPool {
    fn clone(&self) -> Self {
        Self {
            semaphore: self.semaphore.clone(),
            max_concurrent: self.max_concurrent,
            metrics: self.metrics.clone(),
        }
    }
}

/// æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º
#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_env_filter("info")
        .init();

    info!("ğŸš€ å¼€å§‹ 2025 å¹´å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º");

    // 1. å¼‚æ­¥ä»»åŠ¡æ± æ¼”ç¤º
    demo_task_pool().await?;

    // 2. å¼‚æ­¥ç¼“å­˜æ¼”ç¤º
    demo_async_cache().await?;

    // 3. å¼‚æ­¥æ‰¹å¤„ç†æ¼”ç¤º
    demo_batch_processing().await?;

    // 4. å¼‚æ­¥è¿æ¥æ± æ¼”ç¤º
    demo_connection_pool().await?;

    info!("âœ… 2025 å¹´å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–æ¼”ç¤ºå®Œæˆ!");
    Ok(())
}

async fn demo_task_pool() -> Result<()> {
    info!("ğŸ“Š æ¼”ç¤ºå¼‚æ­¥ä»»åŠ¡æ± ");

    let pool = AsyncTaskPool::new(10);

    // å¹¶å‘æ‰§è¡Œå¤šä¸ªä»»åŠ¡
    let mut handles = Vec::new();
    for i in 0..50 {
        let pool = pool.clone();
        let handle = tokio::spawn(async move {
            pool.execute(
                &format!("ä»»åŠ¡_{}", i),
                async move {
                    // æ¨¡æ‹Ÿä¸€äº›å·¥ä½œ
                    sleep(Duration::from_millis(rand::random::<u64>() % 100)).await;
                    if i % 10 == 0 {
                        Err(anyhow::anyhow!("æ¨¡æ‹Ÿé”™è¯¯"))
                    } else {
                        Ok(())
                    }
                },
            ).await
        });
        handles.push(handle);
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for handle in handles {
        handle.await??;
    }

    // æ˜¾ç¤ºæŒ‡æ ‡
    let metrics = pool.get_metrics().await;
    info!("ä»»åŠ¡æ± æŒ‡æ ‡:");
    info!("  æ€»ä»»åŠ¡æ•°: {}", metrics.total_tasks);
    info!("  å®Œæˆä»»åŠ¡æ•°: {}", metrics.completed_tasks);
    info!("  å¤±è´¥ä»»åŠ¡æ•°: {}", metrics.failed_tasks);
    info!("  å¹³å‡æ‰§è¡Œæ—¶é—´: {:?}", metrics.average_execution_time);
    info!("  ååé‡: {:.2} ä»»åŠ¡/ç§’", metrics.throughput_per_second);

    Ok(())
}

async fn demo_async_cache() -> Result<()> {
    info!("ğŸ—„ï¸ æ¼”ç¤ºå¼‚æ­¥ç¼“å­˜ç®¡ç†å™¨");

    let cache = AsyncCacheManager::new(Duration::from_secs(60), 1000);

    // å¡«å……ç¼“å­˜
    for i in 0..100 {
        cache.set(i, format!("å€¼_{}", i)).await;
    }

    // è¯»å–æµ‹è¯•
    for i in 0..200 {
        cache.get(&i).await;
    }

    let hit_rate = cache.hit_rate().await;
    info!("ç¼“å­˜å‘½ä¸­ç‡: {:.2}%", hit_rate * 100.0);
    info!("é¢„æœŸå‘½ä¸­ç‡: 50% (100/200)");

    Ok(())
}

async fn demo_batch_processing() -> Result<()> {
    info!("ğŸ“¦ æ¼”ç¤ºå¼‚æ­¥æ‰¹å¤„ç†å™¨");

    let processor = AsyncBatchProcessor::new(
        10, // æ‰¹å¤§å°
        Duration::from_secs(5), // åˆ·æ–°é—´éš”
        |items| {
            info!("å¤„ç†æ‰¹æ¬¡: {} ä¸ªé¡¹ç›®", items.len());
            Ok(())
        },
    );

    // å¯åŠ¨å®šæ—¶åˆ·æ–°
    processor.start_periodic_flush().await?;

    // æ·»åŠ ä¸€äº›æ•°æ®
    for i in 0..25 {
        processor.add(format!("æ•°æ®_{}", i)).await?;
        sleep(Duration::from_millis(100)).await;
    }

    // æ‰‹åŠ¨åˆ·æ–°å‰©ä½™æ•°æ®
    processor.flush().await?;

    Ok(())
}

async fn demo_connection_pool() -> Result<()> {
    info!("ğŸ”— æ¼”ç¤ºå¼‚æ­¥è¿æ¥æ± ");

    let pool = AsyncConnectionPool::new(
        5, // æœ€å¤§è¿æ¥æ•°
        || {
            // æ¨¡æ‹Ÿè¿æ¥åˆ›å»º
            Ok(format!("è¿æ¥_{}", rand::random::<u32>()))
        },
    );

    // è·å–ä¸€äº›è¿æ¥
    let mut connections = Vec::new();
    for i in 0..7 {
        match pool.acquire().await {
            Ok(conn) => {
                info!("è·å–è¿æ¥ {}: {}", i, conn.get());
                connections.push(conn);
            }
            Err(e) => {
                warn!("æ— æ³•è·å–è¿æ¥ {}: {}", i, e);
            }
        }
    }

    info!("æ´»è·ƒè¿æ¥æ•°: {}", pool.active_count().await);
    info!("å¯ç”¨è¿æ¥æ•°: {}", pool.available_count().await);

    // é‡Šæ”¾ä¸€äº›è¿æ¥
    connections.truncate(3);
    drop(connections);

    sleep(Duration::from_millis(100)).await; // ç­‰å¾…è¿æ¥é‡Šæ”¾

    info!("é‡Šæ”¾åæ´»è·ƒè¿æ¥æ•°: {}", pool.active_count().await);
    info!("é‡Šæ”¾åå¯ç”¨è¿æ¥æ•°: {}", pool.available_count().await);

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_task_pool() {
        let pool = AsyncTaskPool::new(2);
        let result = pool.execute("test_task", async { Ok(()) }).await;
        assert!(result.is_ok());
        
        let metrics = pool.get_metrics().await;
        assert_eq!(metrics.total_tasks, 1);
        assert_eq!(metrics.completed_tasks, 1);
    }

    #[tokio::test]
    async fn test_cache_manager() {
        let cache = AsyncCacheManager::new(Duration::from_secs(60), 10);
        
        cache.set("key1", "value1").await;
        let value = cache.get(&"key1").await;
        assert_eq!(value, Some("value1".to_string()));
        
        let hit_rate = cache.hit_rate().await;
        assert!(hit_rate > 0.0);
    }

    #[tokio::test]
    async fn test_batch_processor() {
        let processor = AsyncBatchProcessor::new(
            3,
            Duration::from_secs(1),
            |items| {
                assert_eq!(items.len(), 3);
                Ok(())
            },
        );

        for i in 0..3 {
            processor.add(i).await.unwrap();
        }
    }

    #[tokio::test]
    async fn test_connection_pool() {
        let pool = AsyncConnectionPool::new(2, || Ok("test_connection"));
        
        let conn1 = pool.acquire().await.unwrap();
        assert_eq!(conn1.get(), &"test_connection");
        
        let conn2 = pool.acquire().await.unwrap();
        assert_eq!(conn2.get(), &"test_connection");
        
        // ç¬¬ä¸‰ä¸ªè¿æ¥åº”è¯¥å¤±è´¥
        let conn3 = pool.acquire().await;
        assert!(conn3.is_err());
    }
}
