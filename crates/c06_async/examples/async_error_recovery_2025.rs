#![recursion_limit = "8192"]
use anyhow::Result;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tokio::time::{sleep, timeout};
use tracing::{info, warn, debug};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// 2025å¹´å¼‚æ­¥é”™è¯¯æ¢å¤å’Œé‡è¯•æœºåˆ¶æ¼”ç¤º
/// å±•ç¤ºæœ€æ–°çš„å¼‚æ­¥é”™è¯¯å¤„ç†å’Œæ¢å¤æœ€ä½³å®è·µ

/// 1. å¼‚æ­¥é‡è¯•ç­–ç•¥
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RetryStrategy {
    Fixed(Duration),
    Exponential(Duration, f64),
    Linear(Duration, Duration),
    Custom(Vec<Duration>),
}

#[derive(Debug, Clone)]
pub struct RetryConfig {
    pub max_attempts: u32,
    pub strategy: RetryStrategy,
    pub jitter: bool,
    pub timeout: Option<Duration>,
}

impl Default for RetryConfig {
    fn default() -> Self {
        Self {
            max_attempts: 3,
            strategy: RetryStrategy::Exponential(Duration::from_millis(100), 2.0),
            jitter: true,
            timeout: Some(Duration::from_secs(30)),
        }
    }
}

pub struct AsyncRetryManager {
    config: RetryConfig,
    metrics: Arc<RwLock<RetryMetrics>>,
}

#[derive(Debug, Default)]
pub struct RetryMetrics {
    pub total_attempts: u64,
    pub successful_attempts: u64,
    pub failed_attempts: u64,
    pub total_retry_time: Duration,
}

impl AsyncRetryManager {
    pub fn new(config: RetryConfig) -> Self {
        Self {
            config,
            metrics: Arc::new(RwLock::new(RetryMetrics::default())),
        }
    }

    #[allow(unused_variables)]
    pub async fn execute_with_retry<F, T>(&self, mut operation: F) -> Result<T>
    where
        F: FnMut() -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<T>> + Send>>,
    {
        let start_time = Instant::now();
        let mut last_error = None;
        let mut attempt = 1;

        while attempt <= self.config.max_attempts {
            let attempt_start = Instant::now();
            
            // æ‰§è¡Œæ“ä½œï¼ˆå¸¦è¶…æ—¶ï¼‰
            let result = if let Some(timeout_duration) = self.config.timeout {
                match timeout(timeout_duration, operation()).await {
                    Ok(Ok(result)) => {
                        self.update_metrics(true, attempt_start.elapsed()).await;
                        info!("æ“ä½œåœ¨ç¬¬ {} æ¬¡å°è¯•åæˆåŠŸ", attempt);
                        return Ok(result);
                    }
                    Ok(Err(e)) => {
                        last_error = Some(e);
                        debug!("æ“ä½œå¤±è´¥ï¼Œç¬¬ {} æ¬¡å°è¯•", attempt);
                    }
                    Err(_) => {
                        last_error = Some(anyhow::anyhow!("æ“ä½œè¶…æ—¶"));
                        warn!("æ“ä½œè¶…æ—¶ï¼Œç¬¬ {} æ¬¡å°è¯•", attempt);
                    }
                }
            } else {
                match operation().await {
                    Ok(result) => {
                        self.update_metrics(true, attempt_start.elapsed()).await;
                        info!("æ“ä½œåœ¨ç¬¬ {} æ¬¡å°è¯•åæˆåŠŸ", attempt);
                        return Ok(result);
                    }
                    Err(e) => {
                        last_error = Some(e);
                        debug!("æ“ä½œå¤±è´¥ï¼Œç¬¬ {} æ¬¡å°è¯•", attempt);
                    }
                }
            };

            // æ›´æ–°æŒ‡æ ‡
            self.update_metrics(false, attempt_start.elapsed()).await;

            // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè®¡ç®—å»¶è¿Ÿå¹¶ç­‰å¾…
            if attempt < self.config.max_attempts {
                let delay = self.calculate_delay(attempt);
                warn!("æ“ä½œå¤±è´¥ï¼Œç¬¬ {} æ¬¡å°è¯•ï¼Œ{}ms åé‡è¯•", attempt, delay.as_millis());
                sleep(delay).await;
            }

            attempt += 1;
        }

        let total_time = start_time.elapsed();
        self.update_total_retry_time(total_time).await;
        
        Err(last_error.unwrap())
    }

    fn calculate_delay(&self, attempt: u32) -> Duration {
        let base_delay = match &self.config.strategy {
            RetryStrategy::Fixed(delay) => *delay,
            RetryStrategy::Exponential(base, multiplier) => {
                Duration::from_millis((base.as_millis() as f64 * multiplier.powi(attempt as i32 - 1)) as u64)
            }
            RetryStrategy::Linear(base, increment) => {
                *base + *increment * (attempt - 1)
            }
            RetryStrategy::Custom(delays) => {
                let index = (attempt - 1) as usize;
                delays.get(index).copied().unwrap_or(*delays.last().unwrap())
            }
        };

        if self.config.jitter {
            let jitter_factor = 0.1; // 10% æŠ–åŠ¨
            let jitter_range = base_delay.as_nanos() as f64 * jitter_factor;
            let jitter = (rand::random::<f64>() - 0.5) * 2.0 * jitter_range;
            let jittered_nanos = (base_delay.as_nanos() as f64 + jitter).max(0.0) as u64;
            Duration::from_nanos(jittered_nanos)
        } else {
            base_delay
        }
    }

    #[allow(unused_variables)]
    async fn update_metrics(&self, success: bool, duration: Duration) {
        let mut metrics = self.metrics.write().await;
        metrics.total_attempts += 1;
        
        if success {
            metrics.successful_attempts += 1;
        } else {
            metrics.failed_attempts += 1;
        }
    }

    async fn update_total_retry_time(&self, duration: Duration) {
        let mut metrics = self.metrics.write().await;
        metrics.total_retry_time += duration;
    }

    pub async fn get_metrics(&self) -> RetryMetrics {
        self.metrics.read().await.clone()
    }
}

/// 2. å¼‚æ­¥ç†”æ–­å™¨
#[derive(Debug, Clone, PartialEq)]
pub enum CircuitState {
    Closed,    // æ­£å¸¸çŠ¶æ€
    Open,      // ç†”æ–­çŠ¶æ€
    HalfOpen,  // åŠå¼€çŠ¶æ€
}

pub struct AsyncCircuitBreaker {
    state: Arc<RwLock<CircuitState>>,
    failure_threshold: u32,
    success_threshold: u32,
    timeout: Duration,
    failure_count: Arc<RwLock<u32>>,
    success_count: Arc<RwLock<u32>>,
    last_failure_time: Arc<RwLock<Option<Instant>>>,
    metrics: Arc<RwLock<CircuitBreakerMetrics>>,
}

#[derive(Debug, Default)]
pub struct CircuitBreakerMetrics {
    pub total_requests: u64,
    pub successful_requests: u64,
    pub failed_requests: u64,
    pub circuit_open_count: u64,
    pub circuit_half_open_count: u64,
}

impl AsyncCircuitBreaker {
    pub fn new(failure_threshold: u32, success_threshold: u32, timeout: Duration) -> Self {
        Self {
            state: Arc::new(RwLock::new(CircuitState::Closed)),
            failure_threshold,
            success_threshold,
            timeout,
            failure_count: Arc::new(RwLock::new(0)),
            success_count: Arc::new(RwLock::new(0)),
            last_failure_time: Arc::new(RwLock::new(None)),
            metrics: Arc::new(RwLock::new(CircuitBreakerMetrics::default())),
        }
    }

    pub async fn execute<F, T>(&self, operation: F) -> Result<T>
    where
        F: FnOnce() -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<T>> + Send>>,
    {
        let current_state = self.state.read().await.clone();
        
        match current_state {
            CircuitState::Open => {
                if self.should_attempt_reset().await {
                    self.transition_to_half_open().await;
                } else {
                    return Err(anyhow::anyhow!("ç†”æ–­å™¨å¼€å¯ï¼Œæ‹’ç»è¯·æ±‚"));
                }
            }
            CircuitState::Closed => {
                // æ­£å¸¸çŠ¶æ€ï¼Œå…è®¸è¯·æ±‚
            }
            CircuitState::HalfOpen => {
                // åŠå¼€çŠ¶æ€ï¼Œå…è®¸å°‘é‡è¯·æ±‚æµ‹è¯•
            }
        }

        self.update_metrics_total_requests().await;

        match operation().await {
            Ok(result) => {
                self.on_success().await;
                Ok(result)
            }
            Err(e) => {
                self.on_failure().await;
                Err(e)
            }
        }
    }

    async fn should_attempt_reset(&self) -> bool {
        if let Some(last_failure) = *self.last_failure_time.read().await {
            last_failure.elapsed() >= self.timeout
        } else {
            false
        }
    }

    async fn on_success(&self) {
        self.update_metrics_successful_requests().await;
        
        let current_state = self.state.read().await.clone();
        match current_state {
            CircuitState::HalfOpen => {
                let mut success_count = self.success_count.write().await;
                *success_count += 1;
                
                if *success_count >= self.success_threshold {
                    self.transition_to_closed().await;
                }
            }
            CircuitState::Closed => {
                // é‡ç½®å¤±è´¥è®¡æ•°
                *self.failure_count.write().await = 0;
            }
            CircuitState::Open => {
                // ä¸åº”è¯¥å‘ç”Ÿ
            }
        }
    }

    async fn on_failure(&self) {
        self.update_metrics_failed_requests().await;
        
        let mut failure_count = self.failure_count.write().await;
        *failure_count += 1;
        
        *self.last_failure_time.write().await = Some(Instant::now());
        
        if *failure_count >= self.failure_threshold {
            self.transition_to_open().await;
        }
    }

    async fn transition_to_open(&self) {
        *self.state.write().await = CircuitState::Open;
        *self.success_count.write().await = 0;
        self.update_metrics_circuit_open().await;
        warn!("ç†”æ–­å™¨çŠ¶æ€è½¬æ¢ä¸º: Open");
    }

    async fn transition_to_half_open(&self) {
        *self.state.write().await = CircuitState::HalfOpen;
        *self.success_count.write().await = 0;
        self.update_metrics_circuit_half_open().await;
        info!("ç†”æ–­å™¨çŠ¶æ€è½¬æ¢ä¸º: HalfOpen");
    }

    async fn transition_to_closed(&self) {
        *self.state.write().await = CircuitState::Closed;
        *self.failure_count.write().await = 0;
        info!("ç†”æ–­å™¨çŠ¶æ€è½¬æ¢ä¸º: Closed");
    }

    async fn update_metrics_total_requests(&self) {
        self.metrics.write().await.total_requests += 1;
    }

    async fn update_metrics_successful_requests(&self) {
        self.metrics.write().await.successful_requests += 1;
    }

    async fn update_metrics_failed_requests(&self) {
        self.metrics.write().await.failed_requests += 1;
    }

    async fn update_metrics_circuit_open(&self) {
        self.metrics.write().await.circuit_open_count += 1;
    }

    async fn update_metrics_circuit_half_open(&self) {
        self.metrics.write().await.circuit_half_open_count += 1;
    }

    pub async fn get_state(&self) -> CircuitState {
        self.state.read().await.clone()
    }

    pub async fn get_metrics(&self) -> CircuitBreakerMetrics {
        self.metrics.read().await.clone()
    }
}

/// 3. å¼‚æ­¥è¶…æ—¶ç®¡ç†å™¨
pub struct AsyncTimeoutManager {
    default_timeout: Duration,
    timeouts: Arc<RwLock<HashMap<String, Duration>>>,
    metrics: Arc<RwLock<TimeoutMetrics>>,
}

#[derive(Debug, Default)]
pub struct TimeoutMetrics {
    pub total_operations: u64,
    pub timed_out_operations: u64,
    pub successful_operations: u64,
    pub average_duration: Duration,
}

impl AsyncTimeoutManager {
    pub fn new(default_timeout: Duration) -> Self {
        Self {
            default_timeout,
            timeouts: Arc::new(RwLock::new(HashMap::new())),
            metrics: Arc::new(RwLock::new(TimeoutMetrics::default())),
        }
    }

    pub async fn set_timeout(&self, operation_name: String, timeout: Duration) {
        self.timeouts.write().await.insert(operation_name, timeout);
    }

    pub async fn execute_with_timeout<F, T>(
        &self,
        operation_name: &str,
        mut operation: F,
    ) -> Result<T>
    where
        F: FnMut() -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<T>> + Send>>,
    {
        let timeout_duration = self.get_timeout_for_operation(operation_name).await;
        let start_time = Instant::now();

        self.update_metrics_total_operations().await;

        match timeout(timeout_duration, operation()).await {
            Ok(Ok(result)) => {
                let duration = start_time.elapsed();
                self.update_metrics_successful_operation(duration).await;
                Ok(result)
            }
            Ok(Err(e)) => {
                let duration = start_time.elapsed();
                self.update_metrics_successful_operation(duration).await;
                Err(e)
            }
            Err(_) => {
                let duration = start_time.elapsed();
                self.update_metrics_timed_out_operation(duration).await;
                Err(anyhow::anyhow!("æ“ä½œ '{}' è¶…æ—¶ ({:?})", operation_name, timeout_duration))
            }
        }
    }

    async fn get_timeout_for_operation(&self, operation_name: &str) -> Duration {
        self.timeouts
            .read()
            .await
            .get(operation_name)
            .copied()
            .unwrap_or(self.default_timeout)
    }

    async fn update_metrics_total_operations(&self) {
        self.metrics.write().await.total_operations += 1;
    }

    async fn update_metrics_successful_operation(&self, duration: Duration) {
        let mut metrics = self.metrics.write().await;
        metrics.successful_operations += 1;
        
        // æ›´æ–°å¹³å‡æŒç»­æ—¶é—´
        let total_ops = metrics.total_operations;
        let total_duration = metrics.average_duration.as_nanos() * (total_ops - 1) as u128 + duration.as_nanos();
        metrics.average_duration = Duration::from_nanos((total_duration / total_ops as u128) as u64);
    }

    async fn update_metrics_timed_out_operation(&self, duration: Duration) {
        let mut metrics = self.metrics.write().await;
        metrics.timed_out_operations += 1;
        
        // æ›´æ–°å¹³å‡æŒç»­æ—¶é—´ï¼ˆåŒ…æ‹¬è¶…æ—¶çš„æ“ä½œï¼‰
        let total_ops = metrics.total_operations;
        let total_duration = metrics.average_duration.as_nanos() * (total_ops - 1) as u128 + duration.as_nanos();
        metrics.average_duration = Duration::from_nanos((total_duration / total_ops as u128) as u64);
    }

    pub async fn get_metrics(&self) -> TimeoutMetrics {
        self.metrics.read().await.clone()
    }
}

/// 4. å¼‚æ­¥é”™è¯¯æ¢å¤ç­–ç•¥
#[derive(Debug, Clone)]
pub enum RecoveryStrategy {
    Retry(RetryConfig),
    CircuitBreaker(u32, u32, Duration),
    Timeout(Duration),
    Fallback(String), // ç®€åŒ–ä¸ºå­—ç¬¦ä¸²æ ‡è¯†
}

pub struct AsyncErrorRecoveryManager {
    strategies: Arc<RwLock<HashMap<String, RecoveryStrategy>>>,
    recovery_metrics: Arc<RwLock<RecoveryMetrics>>,
}

#[derive(Debug, Default)]
pub struct RecoveryMetrics {
    pub total_recoveries: u64,
    pub successful_recoveries: u64,
    pub failed_recoveries: u64,
    pub recovery_types: HashMap<String, u64>,
}

impl AsyncErrorRecoveryManager {
    pub fn new() -> Self {
        Self {
            strategies: Arc::new(RwLock::new(HashMap::new())),
            recovery_metrics: Arc::new(RwLock::new(RecoveryMetrics::default())),
        }
    }

    pub async fn add_recovery_strategy(&self, operation_name: String, strategy: RecoveryStrategy) {
        self.strategies.write().await.insert(operation_name, strategy);
    }

    pub async fn execute_with_recovery<F, T>(
        &self,
        operation_name: &str,
        mut operation: F,
    ) -> Result<T>
    where
        F: FnMut() -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<T>> + Send>>,
    {
        let strategies = self.strategies.read().await;
        
        if let Some(strategy) = strategies.get(operation_name) {
            self.apply_recovery_strategy(strategy, operation).await
        } else {
            // æ²¡æœ‰æ¢å¤ç­–ç•¥ï¼Œç›´æ¥æ‰§è¡Œ
            operation().await
        }
    }

    async fn apply_recovery_strategy<F, T>(
        &self,
        strategy: &RecoveryStrategy,
        mut operation: F,
    ) -> Result<T>
    where
        F: FnMut() -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<T>> + Send>>,
    {
        match strategy {
            RecoveryStrategy::Retry(config) => {
                let retry_manager = AsyncRetryManager::new(config.clone());
                retry_manager.execute_with_retry(|| operation()).await
            }
            RecoveryStrategy::CircuitBreaker(failure_threshold, success_threshold, timeout) => {
                let circuit_breaker = AsyncCircuitBreaker::new(*failure_threshold, *success_threshold, *timeout);
                circuit_breaker.execute(|| operation()).await
            }
            RecoveryStrategy::Timeout(duration) => {
                let timeout_manager = AsyncTimeoutManager::new(*duration);
                timeout_manager.execute_with_timeout("operation", || operation()).await
            }
            RecoveryStrategy::Fallback(fallback_msg) => {
                match operation().await {
                    Ok(result) => Ok(result),
                    Err(_) => {
                        self.update_recovery_metrics("fallback", true).await;
                        // ç®€åŒ–ï¼šç›´æ¥è¿”å›é”™è¯¯ï¼Œå› ä¸ºç±»å‹è½¬æ¢å¤æ‚
                        Err(anyhow::anyhow!("æ“ä½œå¤±è´¥ï¼Œå›é€€: {}", fallback_msg))
                    }
                }
            }
        }
    }

    async fn update_recovery_metrics(&self, recovery_type: &str, success: bool) {
        let mut metrics = self.recovery_metrics.write().await;
        metrics.total_recoveries += 1;
        
        if success {
            metrics.successful_recoveries += 1;
        } else {
            metrics.failed_recoveries += 1;
        }
        
        *metrics.recovery_types.entry(recovery_type.to_string()).or_insert(0) += 1;
    }

    pub async fn get_metrics(&self) -> RecoveryMetrics {
        self.recovery_metrics.read().await.clone()
    }
}

/// æ¼”ç¤ºå¼‚æ­¥é”™è¯¯æ¢å¤å’Œé‡è¯•æœºåˆ¶
#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_env_filter("info")
        .init();

    info!("ğŸš€ å¼€å§‹ 2025 å¹´å¼‚æ­¥é”™è¯¯æ¢å¤å’Œé‡è¯•æœºåˆ¶æ¼”ç¤º");

    // 1. å¼‚æ­¥é‡è¯•ç®¡ç†å™¨æ¼”ç¤º
    demo_async_retry_manager().await?;

    // 2. å¼‚æ­¥ç†”æ–­å™¨æ¼”ç¤º
    demo_async_circuit_breaker().await?;

    // 3. å¼‚æ­¥è¶…æ—¶ç®¡ç†å™¨æ¼”ç¤º
    demo_async_timeout_manager().await?;

    // 4. å¼‚æ­¥é”™è¯¯æ¢å¤ç®¡ç†å™¨æ¼”ç¤º
    demo_async_error_recovery_manager().await?;

    info!("âœ… 2025 å¹´å¼‚æ­¥é”™è¯¯æ¢å¤å’Œé‡è¯•æœºåˆ¶æ¼”ç¤ºå®Œæˆ!");
    Ok(())
}

async fn demo_async_retry_manager() -> Result<()> {
    info!("ğŸ”„ æ¼”ç¤ºå¼‚æ­¥é‡è¯•ç®¡ç†å™¨");

    // æŒ‡æ•°é€€é¿ç­–ç•¥
    let retry_config = RetryConfig {
        max_attempts: 5,
        strategy: RetryStrategy::Exponential(Duration::from_millis(100), 2.0),
        jitter: true,
        timeout: Some(Duration::from_secs(1)),
    };

    let retry_manager = AsyncRetryManager::new(retry_config);

    let mut attempt_count = 0;
    let result = retry_manager.execute_with_retry(|| {
        attempt_count += 1;
        Box::pin(async move {
            // æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„æ“ä½œ
            if attempt_count < 4 {
                Err(anyhow::anyhow!("æ¨¡æ‹Ÿå¤±è´¥ (å°è¯• {})", attempt_count))
            } else {
                Ok(format!("æ“ä½œæˆåŠŸ (å°è¯• {})", attempt_count))
            }
        })
    }).await?;

    info!("é‡è¯•ç»“æœ: {}", result);

    let metrics = retry_manager.get_metrics().await;
    info!("é‡è¯•æŒ‡æ ‡: æ€»å°è¯• {}, æˆåŠŸ {}, å¤±è´¥ {}", 
          metrics.total_attempts, metrics.successful_attempts, metrics.failed_attempts);

    Ok(())
}

async fn demo_async_circuit_breaker() -> Result<()> {
    info!("âš¡ æ¼”ç¤ºå¼‚æ­¥ç†”æ–­å™¨");

    let circuit_breaker = AsyncCircuitBreaker::new(3, 2, Duration::from_millis(500));

    // æ¨¡æ‹Ÿä¸€ç³»åˆ—æ“ä½œ
    for i in 1..=10 {
        let result = circuit_breaker.execute(|| {
            Box::pin(async move {
                // å‰å‡ æ¬¡æ“ä½œå¤±è´¥ï¼Œè§¦å‘ç†”æ–­
                if i <= 4 {
                    Err(anyhow::anyhow!("æ“ä½œå¤±è´¥"))
                } else {
                    Ok(format!("æ“ä½œæˆåŠŸ {}", i))
                }
            })
        }).await;

        let state = circuit_breaker.get_state().await;
        match result {
            Ok(msg) => info!("æ“ä½œ {} æˆåŠŸ: {}, ç†”æ–­å™¨çŠ¶æ€: {:?}", i, msg, state),
            Err(e) => warn!("æ“ä½œ {} å¤±è´¥: {}, ç†”æ–­å™¨çŠ¶æ€: {:?}", i, e, state),
        }

        sleep(Duration::from_millis(100)).await;
    }

    let metrics = circuit_breaker.get_metrics().await;
    info!("ç†”æ–­å™¨æŒ‡æ ‡: æ€»è¯·æ±‚ {}, æˆåŠŸ {}, å¤±è´¥ {}, å¼€å¯æ¬¡æ•° {}", 
          metrics.total_requests, metrics.successful_requests, 
          metrics.failed_requests, metrics.circuit_open_count);

    Ok(())
}

async fn demo_async_timeout_manager() -> Result<()> {
    info!("â±ï¸ æ¼”ç¤ºå¼‚æ­¥è¶…æ—¶ç®¡ç†å™¨");

    let timeout_manager = AsyncTimeoutManager::new(Duration::from_millis(200));

    // è®¾ç½®ä¸åŒæ“ä½œçš„è¶…æ—¶æ—¶é—´
    timeout_manager.set_timeout("fast_operation".to_string(), Duration::from_millis(100)).await;
    timeout_manager.set_timeout("slow_operation".to_string(), Duration::from_millis(500)).await;

    // å¿«é€Ÿæ“ä½œ
    let result = timeout_manager.execute_with_timeout("fast_operation", || {
        Box::pin(async move {
            sleep(Duration::from_millis(50)).await;
            Ok("å¿«é€Ÿæ“ä½œå®Œæˆ".to_string())
        })
    }).await?;
    info!("å¿«é€Ÿæ“ä½œç»“æœ: {}", result);

    // è¶…æ—¶æ“ä½œ
    let result = timeout_manager.execute_with_timeout("fast_operation", || {
        Box::pin(async move {
            sleep(Duration::from_millis(300)).await; // è¶…è¿‡è¶…æ—¶æ—¶é—´
            Ok("è¶…æ—¶æ“ä½œå®Œæˆ".to_string())
        })
    }).await;
    match result {
        Ok(msg) => info!("è¶…æ—¶æ“ä½œç»“æœ: {}", msg),
        Err(e) => warn!("è¶…æ—¶æ“ä½œå¤±è´¥: {}", e),
    }

    let metrics = timeout_manager.get_metrics().await;
    info!("è¶…æ—¶ç®¡ç†å™¨æŒ‡æ ‡: æ€»æ“ä½œ {}, æˆåŠŸ {}, è¶…æ—¶ {}, å¹³å‡è€—æ—¶ {:?}", 
          metrics.total_operations, metrics.successful_operations, 
          metrics.timed_out_operations, metrics.average_duration);

    Ok(())
}

async fn demo_async_error_recovery_manager() -> Result<()> {
    info!("ğŸ›¡ï¸ æ¼”ç¤ºå¼‚æ­¥é”™è¯¯æ¢å¤ç®¡ç†å™¨");

    let recovery_manager = AsyncErrorRecoveryManager::new();

    // æ·»åŠ é‡è¯•ç­–ç•¥
    let retry_config = RetryConfig {
        max_attempts: 3,
        strategy: RetryStrategy::Fixed(Duration::from_millis(100)),
        jitter: false,
        timeout: None,
    };
    recovery_manager.add_recovery_strategy(
        "retry_operation".to_string(),
        RecoveryStrategy::Retry(retry_config)
    ).await;

    // æ·»åŠ ç†”æ–­å™¨ç­–ç•¥
    recovery_manager.add_recovery_strategy(
        "circuit_breaker_operation".to_string(),
        RecoveryStrategy::CircuitBreaker(2, 1, Duration::from_millis(200))
    ).await;

    // æ·»åŠ å›é€€ç­–ç•¥
    recovery_manager.add_recovery_strategy(
        "fallback_operation".to_string(),
        RecoveryStrategy::Fallback("å›é€€æ“ä½œç»“æœ".to_string())
    ).await;

    // æµ‹è¯•é‡è¯•ç­–ç•¥
    let mut attempt_count = 0;
    let result = recovery_manager.execute_with_recovery("retry_operation", || {
        attempt_count += 1;
        Box::pin(async move {
            if attempt_count < 3 {
                Err(anyhow::anyhow!("æ¨¡æ‹Ÿå¤±è´¥"))
            } else {
                Ok("é‡è¯•æ“ä½œæˆåŠŸ".to_string())
            }
        })
    }).await?;
    info!("é‡è¯•ç­–ç•¥ç»“æœ: {}", result);

    // æµ‹è¯•å›é€€ç­–ç•¥
    let result: Result<String, _> = recovery_manager.execute_with_recovery("fallback_operation", || {
        Box::pin(async move {
            Err(anyhow::anyhow!("ä¸»è¦æ“ä½œå¤±è´¥"))
        })
    }).await;
    match result {
        Ok(msg) => info!("å›é€€ç­–ç•¥ç»“æœ: {}", msg),
        Err(e) => info!("å›é€€ç­–ç•¥ç»“æœ: {}", e),
    }

    let metrics = recovery_manager.get_metrics().await;
    info!("é”™è¯¯æ¢å¤æŒ‡æ ‡: æ€»æ¢å¤ {}, æˆåŠŸ {}, å¤±è´¥ {}", 
          metrics.total_recoveries, metrics.successful_recoveries, metrics.failed_recoveries);

    Ok(())
}

// ä¸ºæµ‹è¯•æ·»åŠ Cloneå®ç°
impl Clone for RetryMetrics {
    fn clone(&self) -> Self {
        Self {
            total_attempts: self.total_attempts,
            successful_attempts: self.successful_attempts,
            failed_attempts: self.failed_attempts,
            total_retry_time: self.total_retry_time,
        }
    }
}

impl Clone for CircuitBreakerMetrics {
    fn clone(&self) -> Self {
        Self {
            total_requests: self.total_requests,
            successful_requests: self.successful_requests,
            failed_requests: self.failed_requests,
            circuit_open_count: self.circuit_open_count,
            circuit_half_open_count: self.circuit_half_open_count,
        }
    }
}

impl Clone for TimeoutMetrics {
    fn clone(&self) -> Self {
        Self {
            total_operations: self.total_operations,
            timed_out_operations: self.timed_out_operations,
            successful_operations: self.successful_operations,
            average_duration: self.average_duration,
        }
    }
}

impl Clone for RecoveryMetrics {
    fn clone(&self) -> Self {
        Self {
            total_recoveries: self.total_recoveries,
            successful_recoveries: self.successful_recoveries,
            failed_recoveries: self.failed_recoveries,
            recovery_types: self.recovery_types.clone(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_async_retry_manager() {
        let config = RetryConfig {
            max_attempts: 3,
            strategy: RetryStrategy::Fixed(Duration::from_millis(10)),
            jitter: false,
            timeout: None,
        };
        
        let retry_manager = AsyncRetryManager::new(config);
        
        let mut attempt_count = 0;
        let result = retry_manager.execute_with_retry(|| {
            attempt_count += 1;
            Box::pin(async move {
                if attempt_count < 3 {
                    Err(anyhow::anyhow!("æ¨¡æ‹Ÿå¤±è´¥"))
                } else {
                    Ok("æˆåŠŸ".to_string())
                }
            })
        }).await;
        
        assert!(result.is_ok());
        assert_eq!(attempt_count, 3);
    }

    #[tokio::test]
    async fn test_async_circuit_breaker() {
        let circuit_breaker = AsyncCircuitBreaker::new(2, 1, Duration::from_millis(100));
        
        // è§¦å‘ç†”æ–­
        for _ in 0..3 {
            let _ = circuit_breaker.execute(|| {
                Box::pin(async move { Err::<String, _>(anyhow::anyhow!("å¤±è´¥")) })
            }).await;
        }
        
        assert_eq!(circuit_breaker.get_state().await, CircuitState::Open);
    }

    #[tokio::test]
    async fn test_async_timeout_manager() {
        let timeout_manager = AsyncTimeoutManager::new(Duration::from_millis(50));
        
        let result = timeout_manager.execute_with_timeout("test", || {
            Box::pin(async move {
                sleep(Duration::from_millis(100)).await;
                Ok("æˆåŠŸ".to_string())
            })
        }).await;
        
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("è¶…æ—¶"));
    }
}
