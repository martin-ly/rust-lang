use anyhow::Result;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{RwLock, Semaphore};
use tokio::time::sleep;
use tracing::{info, warn};
use serde::{Deserialize, Serialize};
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};

/// 2025å¹´ç®€åŒ–å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶
/// å±•ç¤ºå®ç”¨çš„å¼‚æ­¥æ€§èƒ½æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•æœ€ä½³å®è·µ

/// 1. ç®€åŒ–åŸºå‡†æµ‹è¯•é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimpleBenchmarkConfig {
    pub name: String,
    pub iterations: usize,
    pub warmup_iterations: usize,
    pub timeout: Duration,
}

impl Default for SimpleBenchmarkConfig {
    fn default() -> Self {
        Self {
            name: "default_benchmark".to_string(),
            iterations: 100,
            warmup_iterations: 10,
            timeout: Duration::from_secs(30),
        }
    }
}

/// 2. ç®€åŒ–åŸºå‡†æµ‹è¯•ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimpleBenchmarkResult {
    pub name: String,
    pub total_iterations: usize,
    pub successful_iterations: usize,
    pub failed_iterations: usize,
    pub total_duration: Duration,
    pub min_duration: Duration,
    pub max_duration: Duration,
    pub avg_duration: Duration,
    pub throughput_ops_per_sec: f64,
}

impl SimpleBenchmarkResult {
    pub fn new(name: String, total_iterations: usize) -> Self {
        Self {
            name,
            total_iterations,
            successful_iterations: 0,
            failed_iterations: 0,
            total_duration: Duration::ZERO,
            min_duration: Duration::MAX,
            max_duration: Duration::ZERO,
            avg_duration: Duration::ZERO,
            throughput_ops_per_sec: 0.0,
        }
    }
}

/// 3. ç®€åŒ–å¼‚æ­¥åŸºå‡†æµ‹è¯•è¿è¡Œå™¨
pub struct SimpleAsyncBenchmarkRunner {
    config: SimpleBenchmarkConfig,
    results: Arc<RwLock<Vec<SimpleBenchmarkResult>>>,
}

impl SimpleAsyncBenchmarkRunner {
    pub fn new(config: SimpleBenchmarkConfig) -> Self {
        Self {
            config,
            results: Arc::new(RwLock::new(Vec::new())),
        }
    }

    pub async fn run_benchmark<F, Fut>(
        &self,
        benchmark_name: &str,
        operation: F,
    ) -> Result<SimpleBenchmarkResult>
    where
        F: Fn() -> Fut + Send + Sync,
        Fut: std::future::Future<Output = Result<()>> + Send,
    {
        let mut result = SimpleBenchmarkResult::new(benchmark_name.to_string(), self.config.iterations);
        let mut durations = Vec::with_capacity(self.config.iterations);
        
        info!("ğŸš€ å¼€å§‹åŸºå‡†æµ‹è¯•: {} ({} æ¬¡è¿­ä»£)", benchmark_name, self.config.iterations);

        // é¢„çƒ­é˜¶æ®µ
        if self.config.warmup_iterations > 0 {
            println!("ğŸ”¥ é¢„çƒ­é˜¶æ®µ: {} æ¬¡è¿­ä»£", self.config.warmup_iterations);
            info!("ğŸ”¥ é¢„çƒ­é˜¶æ®µ: {} æ¬¡è¿­ä»£", self.config.warmup_iterations);
            for i in 0..self.config.warmup_iterations {
                println!("é¢„çƒ­è¿­ä»£ {}/{}", i + 1, self.config.warmup_iterations);
                let _ = operation().await;
            }
            println!("é¢„çƒ­é˜¶æ®µå®Œæˆ");
        }

        // ä¸»æµ‹è¯•é˜¶æ®µ
        println!("ğŸš€ å¼€å§‹ä¸»æµ‹è¯•é˜¶æ®µ: {} æ¬¡è¿­ä»£", self.config.iterations);
        let start_time = Instant::now();
        
        for i in 0..self.config.iterations {
            if i % 10 == 0 {
                println!("ä¸»æµ‹è¯•è¿­ä»£ {}/{}", i + 1, self.config.iterations);
            }
            let iteration_start = Instant::now();
            println!("å¼€å§‹è¿­ä»£ {} æ“ä½œ", i + 1);
            
            match operation().await {
                Ok(_) => {
                    result.successful_iterations += 1;
                    println!("è¿­ä»£ {} æˆåŠŸ", i + 1);
                }
                Err(_) => {
                    result.failed_iterations += 1;
                    warn!("åŸºå‡†æµ‹è¯• {} è¿­ä»£ {} å¤±è´¥", benchmark_name, i);
                    println!("è¿­ä»£ {} å¤±è´¥", i + 1);
                }
            }
            
            let duration = iteration_start.elapsed();
            durations.push(duration);
            
            // æ›´æ–°æœ€å°å’Œæœ€å¤§æŒç»­æ—¶é—´
            if duration < result.min_duration {
                result.min_duration = duration;
            }
            if duration > result.max_duration {
                result.max_duration = duration;
            }
        }

        result.total_duration = start_time.elapsed();
        
        // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if !durations.is_empty() {
            let total_nanos: u64 = durations.iter().map(|d| d.as_nanos() as u64).sum();
            result.avg_duration = Duration::from_nanos(total_nanos / durations.len() as u64);
        }

        // è®¡ç®—ååé‡
        result.throughput_ops_per_sec = result.successful_iterations as f64 / result.total_duration.as_secs_f64();

        info!("ğŸ“Š åŸºå‡†æµ‹è¯• {} å®Œæˆ", benchmark_name);
        info!("   æˆåŠŸ: {}, å¤±è´¥: {}, æ€»è€—æ—¶: {:?}", 
              result.successful_iterations, result.failed_iterations, result.total_duration);
        info!("   å¹³å‡è€—æ—¶: {:?}, ååé‡: {:.2} ops/sec", 
              result.avg_duration, result.throughput_ops_per_sec);

        // ä¿å­˜ç»“æœ
        self.results.write().await.push(result.clone());

        Ok(result)
    }

    pub async fn get_results(&self) -> Vec<SimpleBenchmarkResult> {
        self.results.read().await.clone()
    }
}

/// 4. ç®€åŒ–å¼‚æ­¥å¹¶å‘åŸºå‡†æµ‹è¯•
pub struct SimpleAsyncConcurrencyBenchmark {
    semaphore: Arc<Semaphore>,
    success_count: Arc<AtomicUsize>,
    failure_count: Arc<AtomicUsize>,
}

impl SimpleAsyncConcurrencyBenchmark {
    pub fn new(max_concurrency: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_concurrency)),
            success_count: Arc::new(AtomicUsize::new(0)),
            failure_count: Arc::new(AtomicUsize::new(0)),
        }
    }

    pub async fn run_concurrent_benchmark(
        &self,
        iterations: usize,
    ) -> Result<SimpleBenchmarkResult> {
        let start_time = Instant::now();
        let mut handles = Vec::new();

        for _i in 0..iterations {
            let semaphore = self.semaphore.clone();
            let success_count = self.success_count.clone();
            let failure_count = self.failure_count.clone();

            let handle = tokio::spawn(async move {
                let _permit = semaphore.acquire().await.unwrap();

                // æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ
                sleep(Duration::from_millis(5)).await;
                
                // æ¨¡æ‹Ÿå¶å°”å¤±è´¥
                let random_val = (std::time::SystemTime::now().duration_since(std::time::UNIX_EPOCH).unwrap().as_nanos() % 100) as f64 / 100.0;
                if random_val < 0.02 {
                    failure_count.fetch_add(1, Ordering::Relaxed);
                } else {
                    success_count.fetch_add(1, Ordering::Relaxed);
                }
            });

            handles.push(handle);
        }

        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for handle in handles {
            let _ = handle.await;
        }

        let total_time = start_time.elapsed();
        let successful = self.success_count.load(Ordering::Relaxed);
        let failed = self.failure_count.load(Ordering::Relaxed);

        let mut result = SimpleBenchmarkResult::new("concurrent_benchmark".to_string(), iterations);
        result.successful_iterations = successful;
        result.failed_iterations = failed;
        result.total_duration = total_time;
        result.throughput_ops_per_sec = successful as f64 / total_time.as_secs_f64();

        Ok(result)
    }
}

/// 5. ç®€åŒ–å¼‚æ­¥å†…å­˜åŸºå‡†æµ‹è¯•
pub struct SimpleAsyncMemoryBenchmark {
    allocations: Arc<AtomicUsize>,
    total_bytes: Arc<AtomicU64>,
}

impl SimpleAsyncMemoryBenchmark {
    pub fn new() -> Self {
        Self {
            allocations: Arc::new(AtomicUsize::new(0)),
            total_bytes: Arc::new(AtomicU64::new(0)),
        }
    }

    pub async fn measure_memory_usage(&self) -> Result<u64> {
        let before_allocations = self.allocations.load(Ordering::Relaxed);
        let before_bytes = self.total_bytes.load(Ordering::Relaxed);

        // æ¨¡æ‹Ÿå†…å­˜åˆ†é…æ“ä½œ
        let mut data = Vec::with_capacity(1024);
        for i in 0..1024 {
            data.push(i as u8);
        }

        let after_allocations = self.allocations.load(Ordering::Relaxed);
        let after_bytes = self.total_bytes.load(Ordering::Relaxed);

        let memory_used = after_bytes - before_bytes;
        let allocations_made = after_allocations - before_allocations;

        info!("å†…å­˜ä½¿ç”¨: {} å­—èŠ‚, åˆ†é…æ¬¡æ•°: {}", memory_used, allocations_made);

        Ok(memory_used)
    }

    pub fn track_allocation(&self, size: usize) {
        self.allocations.fetch_add(1, Ordering::Relaxed);
        self.total_bytes.fetch_add(size as u64, Ordering::Relaxed);
    }
}

/// 6. ç®€åŒ–å¼‚æ­¥ç½‘ç»œåŸºå‡†æµ‹è¯•
pub struct SimpleAsyncNetworkBenchmark {
    request_count: Arc<AtomicUsize>,
    response_times: Arc<RwLock<Vec<Duration>>>,
}

impl SimpleAsyncNetworkBenchmark {
    pub fn new() -> Self {
        Self {
            request_count: Arc::new(AtomicUsize::new(0)),
            response_times: Arc::new(RwLock::new(Vec::new())),
        }
    }

    pub async fn measure_network_latency(&self, request_id: usize) -> Result<Duration> {
        let start_time = Instant::now();
        let _request_id = self.request_count.fetch_add(1, Ordering::Relaxed);

        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        sleep(Duration::from_millis(20 + (request_id * 5) as u64)).await;
        
        let latency = start_time.elapsed();
        self.response_times.write().await.push(latency);
        info!("è¯·æ±‚ {} å»¶è¿Ÿ: {:?}", request_id, latency);
        
        Ok(latency)
    }

    pub async fn get_average_latency(&self) -> Duration {
        let response_times = self.response_times.read().await;
        if response_times.is_empty() {
            Duration::ZERO
        } else {
            let total_nanos: u64 = response_times.iter().map(|d| d.as_nanos() as u64).sum();
            Duration::from_nanos(total_nanos / response_times.len() as u64)
        }
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt::init();
    
    println!("ğŸš€ å¼€å§‹ 2025 å¹´ç®€åŒ–å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶æ¼”ç¤º");
    info!("ğŸš€ å¼€å§‹ 2025 å¹´ç®€åŒ–å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶æ¼”ç¤º");

    // 1. æ¼”ç¤ºåŸºæœ¬å¼‚æ­¥åŸºå‡†æµ‹è¯•
    println!("âš¡ æ¼”ç¤ºåŸºæœ¬å¼‚æ­¥åŸºå‡†æµ‹è¯•");
    info!("âš¡ æ¼”ç¤ºåŸºæœ¬å¼‚æ­¥åŸºå‡†æµ‹è¯•");
    let config = SimpleBenchmarkConfig {
        name: "async_operation_benchmark".to_string(),
        iterations: 10,
        warmup_iterations: 2,
        timeout: Duration::from_secs(10),
    };

    let benchmark_runner = SimpleAsyncBenchmarkRunner::new(config);
    println!("åŸºå‡†æµ‹è¯•è¿è¡Œå™¨å·²åˆ›å»º");

    // æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ
    println!("å¼€å§‹è¿è¡ŒåŸºå‡†æµ‹è¯•");
    let result = benchmark_runner.run_benchmark("async_operation", || async {
        // æ¨¡æ‹Ÿä¸€äº›å¼‚æ­¥å·¥ä½œ
        sleep(Duration::from_millis(1)).await;
        
        // ç®€åŒ–çš„æ“ä½œï¼Œæ€»æ˜¯æˆåŠŸ
        Ok(())
    }).await?;

    info!("ğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœ:");
    info!("   æ€»è¿­ä»£: {}", result.total_iterations);
    info!("   æˆåŠŸ: {}, å¤±è´¥: {}", result.successful_iterations, result.failed_iterations);
    info!("   å¹³å‡è€—æ—¶: {:?}", result.avg_duration);
    info!("   ååé‡: {:.2} ops/sec", result.throughput_ops_per_sec);

    // 2. æ¼”ç¤ºå¹¶å‘åŸºå‡†æµ‹è¯•
    info!("ğŸ”„ æ¼”ç¤ºå¼‚æ­¥å¹¶å‘åŸºå‡†æµ‹è¯•");
    let concurrency_benchmark = SimpleAsyncConcurrencyBenchmark::new(5);

    let concurrent_result = concurrency_benchmark.run_concurrent_benchmark(5).await?;

    info!("ğŸ“Š å¹¶å‘åŸºå‡†æµ‹è¯•ç»“æœ:");
    info!("   æˆåŠŸ: {}, å¤±è´¥: {}", concurrent_result.successful_iterations, concurrent_result.failed_iterations);
    info!("   ååé‡: {:.2} ops/sec", concurrent_result.throughput_ops_per_sec);

    // 3. æ¼”ç¤ºå†…å­˜åŸºå‡†æµ‹è¯•
    info!("ğŸ’¾ æ¼”ç¤ºå¼‚æ­¥å†…å­˜åŸºå‡†æµ‹è¯•");
    let memory_benchmark = SimpleAsyncMemoryBenchmark::new();

    let memory_usage = memory_benchmark.measure_memory_usage().await?;

    info!("ğŸ“Š å†…å­˜ä½¿ç”¨: {} å­—èŠ‚", memory_usage);

    // 4. æ¼”ç¤ºç½‘ç»œåŸºå‡†æµ‹è¯•
    info!("ğŸŒ æ¼”ç¤ºå¼‚æ­¥ç½‘ç»œåŸºå‡†æµ‹è¯•");
    let network_benchmark = SimpleAsyncNetworkBenchmark::new();

    // æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚
    for i in 0..3 {
        let latency = network_benchmark.measure_network_latency(i).await?;
        info!("ç½‘ç»œè¯·æ±‚ {} å»¶è¿Ÿ: {:?}", i, latency);
    }

    let avg_latency = network_benchmark.get_average_latency().await;
    info!("ğŸ“Š å¹³å‡ç½‘ç»œå»¶è¿Ÿ: {:?}", avg_latency);

    // 5. è·å–æ‰€æœ‰åŸºå‡†æµ‹è¯•ç»“æœ
    let all_results = benchmark_runner.get_results().await;

    info!("ğŸ“ˆ åŸºå‡†æµ‹è¯•æ±‡æ€»:");
    info!("   æ€»åŸºå‡†æµ‹è¯•æ•°: {}", all_results.len());

    for result in &all_results {
        info!("   {}: {:.2} ops/sec", result.name, result.throughput_ops_per_sec);
    }

    info!("âœ… 2025 å¹´ç®€åŒ–å¼‚æ­¥æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶æ¼”ç¤ºå®Œæˆ!");
    
    Ok(())
}
