# Glommio 最佳实践指南 2025

## 目录

- [Glommio 最佳实践指南 2025](#glommio-最佳实践指南-2025)
  - [目录](#目录)
  - [1. 概述](#1-概述)
    - [1.1 什么是 Glommio](#11-什么是-glommio)
    - [1.2 核心优势](#12-核心优势)
    - [1.3 适用场景](#13-适用场景)
  - [2. 快速开始](#2-快速开始)
    - [2.1 系统要求](#21-系统要求)
    - [2.2 安装配置](#22-安装配置)
    - [2.3 第一个 Glommio 程序](#23-第一个-glommio-程序)
  - [3. Thread-per-core 架构](#3-thread-per-core-架构)
    - [3.1 架构原理](#31-架构原理)
    - [3.2 与 Work-stealing 的对比](#32-与-work-stealing-的对比)
    - [3.3 最佳实践](#33-最佳实践)
  - [4. CPU 绑定与亲和性](#4-cpu-绑定与亲和性)
    - [4.1 CPU Pinning 基础](#41-cpu-pinning-基础)
    - [4.2 NUMA 优化](#42-numa-优化)
    - [4.3 最佳实践](#43-最佳实践)
  - [5. 任务调度与优先级](#5-任务调度与优先级)
    - [5.1 任务队列](#51-任务队列)
    - [5.2 优先级调度](#52-优先级调度)
    - [5.3 公平性与延迟](#53-公平性与延迟)
  - [6. 高性能 I/O](#6-高性能-io)
    - [6.1 DMA 文件 I/O](#61-dma-文件-io)
    - [6.2 网络 I/O](#62-网络-io)
    - [6.3 零拷贝技术](#63-零拷贝技术)
  - [7. 跨执行器通信](#7-跨执行器通信)
    - [7.1 Channel Mesh](#71-channel-mesh)
    - [7.2 Shared Channels](#72-shared-channels)
    - [7.3 通信模式](#73-通信模式)
  - [8. 性能优化技巧](#8-性能优化技巧)
    - [8.1 内存管理](#81-内存管理)
    - [8.2 批处理优化](#82-批处理优化)
    - [8.3 缓存友好设计](#83-缓存友好设计)
  - [9. 错误处理](#9-错误处理)
    - [9.1 错误处理策略](#91-错误处理策略)
    - [9.2 恢复机制](#92-恢复机制)
  - [10. 监控与调试](#10-监控与调试)
    - [10.1 统计信息](#101-统计信息)
    - [10.2 性能分析](#102-性能分析)
  - [11. 生产环境部署](#11-生产环境部署)
    - [11.1 配置建议](#111-配置建议)
    - [11.2 容器化部署](#112-容器化部署)
  - [12. 常见陷阱与解决方案](#12-常见陷阱与解决方案)
  - [13. 与其他运行时的对比](#13-与其他运行时的对比)
  - [14. 参考资源](#14-参考资源)

---

## 1. 概述

### 1.1 什么是 Glommio

**Glommio** 是由 DataDog 开发的基于 **io_uring** 的高性能异步运行时，专为 Linux 平台设计。它采用 **Thread-per-core** 架构，通过避免线程切换和同步开销，实现极致的性能和延迟。

```rust
use glommio::{LocalExecutor, Task};

LocalExecutor::default().run(async {
    let task = Task::local(async {
        println!("Hello from Glommio!");
        42
    });
    
    let result = task.await;
    println!("Result: {}", result);
});
```

### 1.2 核心优势

| 特性 | 描述 | 性能提升 |
|------|------|---------|
| **Thread-per-core** | 每个核心一个线程，无线程切换 | 延迟 ↓50% |
| **io_uring** | Linux 高性能异步 I/O | 吞吐量 ↑300% |
| **NUMA 感知** | 针对多 socket 系统优化 | 延迟 ↓30% |
| **零拷贝 I/O** | 最小化数据复制 | 带宽 ↑200% |
| **CPU 亲和性** | 精确控制任务调度 | 缓存命中率 ↑40% |

### 1.3 适用场景

✅ **推荐场景**:
- 高频交易系统 (HFT)
- 数据库引擎 (Storage Engine)
- 高性能网络服务 (>1M QPS)
- 实时数据处理 (Streaming)
- 游戏服务器 (Low-latency)

❌ **不推荐场景**:
- 桌面应用 (GUI)
- 简单 Web 应用
- Windows/macOS 平台
- 需要大量阻塞 I/O 的场景

---

## 2. 快速开始

### 2.1 系统要求

```bash
# 检查 Linux 版本
uname -r  # 需要 >= 5.1

# 检查 io_uring 支持
cat /proc/sys/kernel/io_uring_disabled  # 应该为 0

# 安装依赖
sudo apt-get install liburing-dev  # Debian/Ubuntu
```

### 2.2 安装配置

```toml
# Cargo.toml
[dependencies]
glommio = "0.9.0"
futures = "0.3"

[target.'cfg(target_os = "linux")'.dependencies]
glommio = "0.9.0"
```

### 2.3 第一个 Glommio 程序

```rust
use glommio::{LocalExecutor, Task, timer::sleep};
use std::time::Duration;

fn main() {
    LocalExecutor::default().run(async {
        println!("🚀 Glommio started!");
        
        // 创建任务
        let task = Task::local(async {
            sleep(Duration::from_millis(100)).await;
            println!("✅ Task completed");
            42
        });
        
        let result = task.await;
        println!("📊 Result: {}", result);
    });
}
```

---

## 3. Thread-per-core 架构

### 3.1 架构原理

Glommio 的核心设计理念是 **Thread-per-core**:

```
┌──────────────────────────────────────┐
│          应用程序                     │
└──────────────────────────────────────┘
         │         │         │
         ▼         ▼         ▼
    ┌────────┬────────┬────────┐
    │Executor│Executor│Executor│
    │ Core 0 │ Core 1 │ Core 2 │
    └────────┴────────┴────────┘
         │         │         │
         ▼         ▼         ▼
    ┌────────┬────────┬────────┐
    │  Task  │  Task  │  Task  │
    │ Queue  │ Queue  │ Queue  │
    └────────┴────────┴────────┘
```

**关键特性**:
- 每个执行器绑定到一个 CPU 核心
- 任务不会在核心之间迁移
- 最小化锁竞争和同步开销
- 充分利用 CPU 缓存

### 3.2 与 Work-stealing 的对比

| 特性 | Thread-per-core (Glommio) | Work-stealing (Tokio) |
|------|--------------------------|----------------------|
| 线程切换 | ❌ 无 | ✅ 有 |
| 缓存友好 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ |
| 负载均衡 | ⭐⭐ | ⭐⭐⭐⭐⭐ |
| 编程复杂度 | ⭐⭐⭐⭐ | ⭐⭐ |
| 延迟 | <100μs | ~200μs |
| 吞吐量 | >2M req/s | >1.2M req/s |

### 3.3 最佳实践

```rust
use glommio::{LocalExecutorBuilder, Placement};

// ✅ 好的做法: 显式绑定到特定核心
let handle = LocalExecutorBuilder::default()
    .pin_to_cpu(0)  // 绑定到核心 0
    .name("worker-0")
    .spawn(|| async move {
        // 任务代码
    })
    .unwrap();

// ❌ 不好的做法: 在执行器之间频繁通信
// 应该尽量保持任务在同一核心内完成
```

---

## 4. CPU 绑定与亲和性

### 4.1 CPU Pinning 基础

```rust
use glommio::{LocalExecutorBuilder, CpuSet, Placement};

// 方法 1: 绑定到单个核心
let handle = LocalExecutorBuilder::default()
    .pin_to_cpu(0)
    .spawn(|| async move {
        println!("Running on core 0");
    })
    .unwrap();

// 方法 2: 使用 CPU 集合
let cpu_set = CpuSet::online().unwrap();
let handle = LocalExecutorBuilder::default()
    .placement(Placement::Fixed(0))
    .spawn(|| async move {
        println!("Running with custom placement");
    })
    .unwrap();

// 方法 3: 多核心并行
let num_cores = num_cpus::get();
let mut handles = vec![];

for core_id in 0..num_cores {
    let handle = LocalExecutorBuilder::default()
        .pin_to_cpu(core_id)
        .spawn(move || async move {
            // 核心特定任务
        })
        .unwrap();
    handles.push(handle);
}
```

### 4.2 NUMA 优化

在多 socket 系统上，NUMA (Non-Uniform Memory Access) 优化非常重要:

```rust
use glommio::CpuSet;

// 检测 NUMA 拓扑
let numa_nodes = detect_numa_nodes();

for (node_id, cpus) in numa_nodes {
    for cpu in cpus {
        let handle = LocalExecutorBuilder::default()
            .pin_to_cpu(cpu)
            .spawn(move || async move {
                // 分配在本地 NUMA 节点的内存
                let local_buffer = allocate_on_numa_node(node_id);
                // 处理任务
            })
            .unwrap();
    }
}
```

### 4.3 最佳实践

```rust
// ✅ 好的做法
// 1. 将相关任务绑定到同一 NUMA 节点
// 2. 避免跨 NUMA 节点的内存访问
// 3. 使用本地内存分配

// ❌ 不好的做法
// 1. 随机分配任务到核心
// 2. 频繁跨 NUMA 节点通信
// 3. 不考虑 CPU 缓存的影响
```

---

## 5. 任务调度与优先级

### 5.1 任务队列

Glommio 支持多个任务队列，每个队列可以有不同的调度策略:

```rust
use glommio::{Shares, Latency, executor};
use std::time::Duration;

LocalExecutor::default().run(async {
    // 创建高优先级队列
    let high_priority = executor().create_task_queue(
        Shares::Static(1000),  // 更多 CPU 份额
        Latency::Matters(Duration::from_millis(1)),  // 低延迟要求
        "high-priority"
    );
    
    // 创建低优先级队列
    let low_priority = executor().create_task_queue(
        Shares::Static(100),  // 较少 CPU 份额
        Latency::NotImportant,  // 延迟不重要
        "low-priority"
    );
});
```

### 5.2 优先级调度

```rust
use glommio::Task;

LocalExecutor::default().run(async {
    let high_tq = executor().create_task_queue(
        Shares::Static(1000),
        Latency::Matters(Duration::from_millis(10)),
        "high"
    );
    
    let low_tq = executor().create_task_queue(
        Shares::Static(100),
        Latency::NotImportant,
        "low"
    );
    
    // 高优先级任务
    let high_task = Task::local_into(
        async {
            // 关键任务
            process_critical_request().await
        },
        high_tq
    ).unwrap();
    
    // 低优先级任务
    let low_task = Task::local_into(
        async {
            // 后台任务
            cleanup_old_data().await
        },
        low_tq
    ).unwrap();
    
    // 高优先级任务会优先执行
    let (high_result, low_result) = futures::join!(high_task, low_task);
});
```

### 5.3 公平性与延迟

```rust
// ✅ 好的做法: 根据任务特性选择合适的调度策略
// 延迟敏感的任务
let latency_sensitive = executor().create_task_queue(
    Shares::Static(1000),
    Latency::Matters(Duration::from_micros(100)),
    "latency-sensitive"
);

// 吞吐量优先的任务
let throughput_oriented = executor().create_task_queue(
    Shares::Static(500),
    Latency::NotImportant,
    "throughput-oriented"
);

// ❌ 不好的做法: 所有任务使用相同的队列
// 会导致延迟敏感任务被阻塞
```

---

## 6. 高性能 I/O

### 6.1 DMA 文件 I/O

Glommio 使用 **Direct Memory Access (DMA)** 实现零拷贝文件 I/O:

```rust
use glommio::io::DmaFile;

LocalExecutor::default().run(async {
    // 创建文件
    let file = DmaFile::create("/tmp/test.dat").await.unwrap();
    
    // 写入数据 (零拷贝)
    let data = vec![0u8; 4096];
    let written = file.write_at(data, 0).await.unwrap();
    println!("Written {} bytes", written);
    
    // 读取数据 (零拷贝)
    let buf = file.read_at(0, 4096).await.unwrap();
    println!("Read {} bytes", buf.len());
    
    file.close().await.unwrap();
});
```

**DMA I/O 优势**:
- 零拷贝: 避免内核到用户空间的数据复制
- 异步: 不阻塞执行器
- 高吞吐: 充分利用 I/O 带宽

### 6.2 网络 I/O

```rust
use glommio::net::{TcpListener, TcpStream};

LocalExecutor::default().run(async {
    let listener = TcpListener::bind("127.0.0.1:8080").unwrap();
    println!("Server listening on 8080");
    
    loop {
        let stream = listener.accept().await.unwrap();
        
        // 为每个连接创建任务
        Task::local(async move {
            handle_connection(stream).await;
        }).detach();
    }
});

async fn handle_connection(mut stream: TcpStream) {
    let mut buf = vec![0u8; 1024];
    loop {
        match stream.read(&mut buf).await {
            Ok(0) => break,  // EOF
            Ok(n) => {
                stream.write_all(&buf[0..n]).await.unwrap();
            }
            Err(e) => {
                eprintln!("Error: {}", e);
                break;
            }
        }
    }
}
```

### 6.3 零拷贝技术

```rust
// ✅ 好的做法: 使用 Glommio 的 DMA 接口
let file = DmaFile::open("/path/to/file").await.unwrap();
let buf = file.read_at(offset, length).await.unwrap();
// buf 是零拷贝的缓冲区

// ❌ 不好的做法: 使用标准库的同步 I/O
let data = std::fs::read("/path/to/file").unwrap();
// 涉及多次数据复制
```

---

## 7. 跨执行器通信

### 7.1 Channel Mesh

**Channel Mesh** 允许多个执行器之间高效通信:

```rust
use glommio::channels::channel_mesh::MeshBuilder;

let num_executors = 4;
let mut mesh_builder = MeshBuilder::partial();
let mut handles = vec![];

for i in 0..num_executors {
    let connection = mesh_builder.join();
    let handle = LocalExecutorBuilder::default()
        .pin_to_cpu(i)
        .spawn(move || async move {
            let mesh = connection.await;
            
            // 发送消息到其他执行器
            for peer in 0..num_executors {
                if peer != i {
                    if let Some(sender) = mesh.sender_for(peer) {
                        sender.send(format!("Hello from {}", i)).await.ok();
                    }
                }
            }
            
            // 接收消息
            while let Some(msg) = mesh.receiver().recv().await {
                println!("Executor {} received: {}", i, msg);
            }
        })
        .unwrap();
    
    handles.push(handle);
}

for handle in handles {
    handle.join().unwrap();
}
```

### 7.2 Shared Channels

```rust
use glommio::channels::shared_channel;

LocalExecutor::default().run(async {
    let (sender, receiver) = shared_channel::new_bounded(1024);
    
    // 生产者任务
    Task::local(async move {
        for i in 0..100 {
            sender.send(i).await.unwrap();
        }
    }).detach();
    
    // 消费者任务
    Task::local(async move {
        while let Ok(msg) = receiver.recv().await {
            println!("Received: {}", msg);
        }
    }).detach();
});
```

### 7.3 通信模式

```rust
// ✅ 好的做法: 最小化跨执行器通信
// 将相关任务保持在同一执行器内

// ❌ 不好的做法: 频繁的跨执行器通信
// 会导致性能下降和缓存失效
```

---

## 8. 性能优化技巧

### 8.1 内存管理

```rust
// ✅ 使用对象池减少分配
use std::sync::Arc;
use parking_lot::Mutex;

struct BufferPool {
    buffers: Vec<Vec<u8>>,
}

impl BufferPool {
    fn acquire(&mut self) -> Vec<u8> {
        self.buffers.pop().unwrap_or_else(|| vec![0u8; 4096])
    }
    
    fn release(&mut self, mut buf: Vec<u8>) {
        buf.clear();
        self.buffers.push(buf);
    }
}

// ✅ 使用栈分配而非堆分配
const SMALL_SIZE: usize = 128;
let mut stack_buf = [0u8; SMALL_SIZE];  // 栈分配

// ❌ 避免频繁的小对象分配
// let buf = vec![0u8; 16];  // 每次都堆分配
```

### 8.2 批处理优化

```rust
// ✅ 批量处理请求
async fn process_batch(requests: Vec<Request>) -> Vec<Response> {
    let mut responses = Vec::with_capacity(requests.len());
    for req in requests {
        responses.push(process_request(req).await);
    }
    responses
}

// ❌ 逐个处理
// for req in requests {
//     process_request(req).await;
// }
```

### 8.3 缓存友好设计

```rust
// ✅ 数据局部性
struct CacheFriendly {
    hot_data: [u8; 64],  // 经常访问的数据放在一起
    cold_data: Vec<u8>,  // 不常访问的数据分离
}

// ❌ 缓存不友好
// struct CacheUnfriendly {
//     data1: Box<[u8]>,
//     data2: Box<[u8]>,
//     data3: Box<[u8]>,
// }  // 数据分散在内存中
```

---

## 9. 错误处理

### 9.1 错误处理策略

```rust
use anyhow::{Result, Context};

async fn robust_operation() -> Result<()> {
    let file = DmaFile::open("/tmp/data.txt")
        .await
        .context("Failed to open file")?;
    
    let data = file.read_at(0, 1024)
        .await
        .context("Failed to read file")?;
    
    process_data(&data)
        .context("Failed to process data")?;
    
    Ok(())
}

// ✅ 使用 Result 而非 panic
// ❌ 不要使用 unwrap() 或 expect() 在生产代码中
```

### 9.2 恢复机制

```rust
// ✅ 实现重试机制
async fn retry_with_backoff<F, T>(mut f: F, max_retries: u32) -> Result<T>
where
    F: FnMut() -> futures::future::BoxFuture<'static, Result<T>>,
{
    let mut retries = 0;
    loop {
        match f().await {
            Ok(result) => return Ok(result),
            Err(e) if retries < max_retries => {
                retries += 1;
                let delay = Duration::from_millis(100 * 2u64.pow(retries));
                glommio::timer::sleep(delay).await;
            }
            Err(e) => return Err(e),
        }
    }
}
```

---

## 10. 监控与调试

### 10.1 统计信息

```rust
use glommio::executor;

LocalExecutor::default().run(async {
    // 获取执行器统计信息
    let stats = executor().stats();
    
    println!("Task queue depth: {}", stats.task_queue_depth());
    println!("Total tasks: {}", stats.total_tasks());
    println!("IO submissions: {}", stats.io_stats().submissions);
    println!("IO completions: {}", stats.io_stats().completions);
});
```

### 10.2 性能分析

```bash
# 使用 perf 分析性能
perf record -g ./your_app
perf report

# 使用 flamegraph
cargo install flamegraph
sudo flamegraph ./your_app
```

---

## 11. 生产环境部署

### 11.1 配置建议

```rust
// 生产环境配置
let executor = LocalExecutorBuilder::default()
    .pin_to_cpu(core_id)
    .name(&format!("prod-worker-{}", core_id))
    .ring_depth(1024)  // 增加 io_uring 队列深度
    .preempt_timer(Duration::from_millis(1))  // 抢占式调度
    .spawn(|| async move {
        // 工作负载
    })
    .unwrap();
```

### 11.2 容器化部署

```dockerfile
# Dockerfile
FROM rust:1.90-slim

# 安装依赖
RUN apt-get update && apt-get install -y liburing-dev

# 复制应用
COPY target/release/app /app

# 设置 CPU 亲和性
CMD ["taskset", "-c", "0-3", "/app"]
```

---

## 12. 常见陷阱与解决方案

| 陷阱 | 影响 | 解决方案 |
|------|------|---------|
| 跨执行器频繁通信 | 性能下降 50% | 保持任务在同一核心内 |
| 使用标准库 I/O | 阻塞执行器 | 使用 Glommio 的异步 I/O |
| 忘记 CPU 绑定 | 缓存失效 | 显式使用 `pin_to_cpu()` |
| 过多小任务 | 调度开销大 | 批量处理 |
| 不处理错误 | 执行器崩溃 | 使用 Result 和重试 |

---

## 13. 与其他运行时的对比

| 特性 | Glommio | Tokio | Smol | async-std |
|------|---------|-------|------|-----------|
| 架构 | Thread-per-core | Work-stealing | 单/多线程 | Work-stealing |
| 平台 | Linux only | 跨平台 | 跨平台 | 跨平台 |
| 延迟 | <100μs | ~200μs | ~150μs | ~250μs |
| 吞吐量 | >2M req/s | >1.2M req/s | >1.4M req/s | >1M req/s |
| 学习曲线 | 陡峭 | 中等 | 平缓 | 平缓 |
| 生态系统 | 小 | 大 | 中 | 中 |

**选择建议**:
- **Glommio**: 极致性能，Linux 环境
- **Tokio**: 通用场景，生态丰富
- **Smol**: 轻量级，嵌入式
- **async-std**: 标准库风格

---

## 14. 参考资源

- **官方文档**: https://docs.rs/glommio
- **GitHub**: https://github.com/DataDog/glommio
- **io_uring 文档**: https://kernel.dk/io_uring.pdf
- **性能基准**: https://github.com/DataDog/glommio/tree/master/benchmarks

---

**最后更新**: 2025年10月30日  
**Rust 版本**: 1.90+  
**Glommio 版本**: 0.9.0

---

**总结**: Glommio 是一个强大的高性能异步运行时，适合对延迟和吞吐量有极高要求的 Linux 应用。通过遵循本指南的最佳实践，你可以充分发挥 Glommio 的性能优势。

