# C12 Model - Tier 2: æ€§èƒ½ä¸é˜Ÿåˆ—æ¨¡å‹

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **æœ€åæ›´æ–°**: 2025-10-23  
> **Rust ç‰ˆæœ¬**: 1.90+  
> **é¢„è®¡é˜…è¯»**: 35 åˆ†é’Ÿ

---

## ğŸ“‹ ç›®å½•

1. [æ€§èƒ½å»ºæ¨¡åŸºç¡€](#1-æ€§èƒ½å»ºæ¨¡åŸºç¡€)
2. [æ’é˜Ÿè®º](#2-æ’é˜Ÿè®º)
3. [è´Ÿè½½æ¨¡å‹](#3-è´Ÿè½½æ¨¡å‹)
4. [å®¹é‡è§„åˆ’](#4-å®¹é‡è§„åˆ’)
5. [æ€§èƒ½ä¼˜åŒ–](#5-æ€§èƒ½ä¼˜åŒ–)
6. [å®æˆ˜æ¡ˆä¾‹](#6-å®æˆ˜æ¡ˆä¾‹)

---

## 1. æ€§èƒ½å»ºæ¨¡åŸºç¡€

### 1.1 æ€§èƒ½æŒ‡æ ‡

```rust
use std::time::{Duration, Instant};

struct PerformanceMetrics {
    latency: Duration,       // å»¶è¿Ÿ
    throughput: f64,         // ååé‡ï¼ˆè¯·æ±‚/ç§’ï¼‰
    utilization: f64,        // åˆ©ç”¨ç‡ï¼ˆ0.0-1.0ï¼‰
    queue_length: usize,     // é˜Ÿåˆ—é•¿åº¦
}

impl PerformanceMetrics {
    fn new() -> Self {
        Self {
            latency: Duration::from_secs(0),
            throughput: 0.0,
            utilization: 0.0,
            queue_length: 0,
        }
    }
    
    fn calculate_throughput(&mut self, requests: usize, duration: Duration) {
        self.throughput = requests as f64 / duration.as_secs_f64();
    }
    
    fn calculate_utilization(&mut self, busy_time: Duration, total_time: Duration) {
        self.utilization = busy_time.as_secs_f64() / total_time.as_secs_f64();
    }
    
    fn report(&self) {
        println!("=== æ€§èƒ½æŒ‡æ ‡ ===");
        println!("å»¶è¿Ÿ: {:?}", self.latency);
        println!("ååé‡: {:.2} è¯·æ±‚/ç§’", self.throughput);
        println!("åˆ©ç”¨ç‡: {:.2}%", self.utilization * 100.0);
        println!("é˜Ÿåˆ—é•¿åº¦: {}", self.queue_length);
    }
}

fn main() {
    let mut metrics = PerformanceMetrics::new();
    metrics.calculate_throughput(1000, Duration::from_secs(10));
    metrics.calculate_utilization(Duration::from_secs(8), Duration::from_secs(10));
    metrics.latency = Duration::from_millis(50);
    metrics.queue_length = 10;
    
    metrics.report();
}
```

### 1.2 Little's Law

**å…¬å¼**: `L = Î» Ã— W`

- `L`: ç³»ç»Ÿä¸­çš„å¹³å‡è¯·æ±‚æ•°
- `Î»`: è¯·æ±‚åˆ°è¾¾ç‡ï¼ˆè¯·æ±‚/ç§’ï¼‰
- `W`: å¹³å‡å“åº”æ—¶é—´ï¼ˆç§’ï¼‰

```rust
fn littles_law(arrival_rate: f64, response_time: f64) -> f64 {
    arrival_rate * response_time
}

fn main() {
    let arrival_rate = 100.0; // 100 è¯·æ±‚/ç§’
    let response_time = 0.05;  // 50ms
    
    let avg_requests = littles_law(arrival_rate, response_time);
    println!("ç³»ç»Ÿå¹³å‡è¯·æ±‚æ•°: {:.2}", avg_requests);
}
```

---

## 2. æ’é˜Ÿè®º

### 2.1 M/M/1 é˜Ÿåˆ—æ¨¡å‹

**M/M/1**: é©¬å°”å¯å¤«åˆ°è¾¾ã€é©¬å°”å¯å¤«æœåŠ¡ã€1 ä¸ªæœåŠ¡å™¨

```rust
struct MM1Queue {
    arrival_rate: f64,   // Î» (è¯·æ±‚/ç§’)
    service_rate: f64,   // Î¼ (è¯·æ±‚/ç§’)
}

impl MM1Queue {
    fn new(arrival_rate: f64, service_rate: f64) -> Self {
        assert!(arrival_rate < service_rate, "ç³»ç»Ÿä¸ç¨³å®šï¼šÎ» >= Î¼");
        Self { arrival_rate, service_rate }
    }
    
    // åˆ©ç”¨ç‡ Ï = Î»/Î¼
    fn utilization(&self) -> f64 {
        self.arrival_rate / self.service_rate
    }
    
    // å¹³å‡é˜Ÿåˆ—é•¿åº¦ L = Ï/(1-Ï)
    fn avg_queue_length(&self) -> f64 {
        let rho = self.utilization();
        rho / (1.0 - rho)
    }
    
    // å¹³å‡ç­‰å¾…æ—¶é—´ W = L/Î»
    fn avg_waiting_time(&self) -> f64 {
        self.avg_queue_length() / self.arrival_rate
    }
    
    // å¹³å‡å“åº”æ—¶é—´ R = W + 1/Î¼
    fn avg_response_time(&self) -> f64 {
        self.avg_waiting_time() + (1.0 / self.service_rate)
    }
    
    fn report(&self) {
        println!("=== M/M/1 é˜Ÿåˆ—åˆ†æ ===");
        println!("åˆ°è¾¾ç‡: {:.2} è¯·æ±‚/ç§’", self.arrival_rate);
        println!("æœåŠ¡ç‡: {:.2} è¯·æ±‚/ç§’", self.service_rate);
        println!("åˆ©ç”¨ç‡: {:.2}%", self.utilization() * 100.0);
        println!("å¹³å‡é˜Ÿåˆ—é•¿åº¦: {:.2}", self.avg_queue_length());
        println!("å¹³å‡ç­‰å¾…æ—¶é—´: {:.4} ç§’", self.avg_waiting_time());
        println!("å¹³å‡å“åº”æ—¶é—´: {:.4} ç§’", self.avg_response_time());
    }
}

fn main() {
    let queue = MM1Queue::new(80.0, 100.0);
    queue.report();
}
```

### 2.2 M/M/c é˜Ÿåˆ—æ¨¡å‹

**M/M/c**: é©¬å°”å¯å¤«åˆ°è¾¾ã€é©¬å°”å¯å¤«æœåŠ¡ã€c ä¸ªæœåŠ¡å™¨

```rust
struct MMcQueue {
    arrival_rate: f64,
    service_rate: f64,
    num_servers: usize,
}

impl MMcQueue {
    fn new(arrival_rate: f64, service_rate: f64, num_servers: usize) -> Self {
        assert!(
            arrival_rate < service_rate * num_servers as f64,
            "ç³»ç»Ÿä¸ç¨³å®š"
        );
        Self { arrival_rate, service_rate, num_servers }
    }
    
    fn utilization(&self) -> f64 {
        self.arrival_rate / (self.service_rate * self.num_servers as f64)
    }
    
    // ç®€åŒ–çš„å¹³å‡å“åº”æ—¶é—´ä¼°ç®—
    fn avg_response_time_approx(&self) -> f64 {
        let rho = self.utilization();
        let base_service_time = 1.0 / self.service_rate;
        
        // ä½¿ç”¨ Erlang C å…¬å¼çš„ç®€åŒ–ç‰ˆæœ¬
        let waiting_time = rho * base_service_time / (self.num_servers as f64 * (1.0 - rho));
        
        waiting_time + base_service_time
    }
    
    fn report(&self) {
        println!("=== M/M/{} é˜Ÿåˆ—åˆ†æ ===", self.num_servers);
        println!("åˆ°è¾¾ç‡: {:.2} è¯·æ±‚/ç§’", self.arrival_rate);
        println!("æœåŠ¡ç‡: {:.2} è¯·æ±‚/ç§’ï¼ˆæ¯æœåŠ¡å™¨ï¼‰", self.service_rate);
        println!("æœåŠ¡å™¨æ•°: {}", self.num_servers);
        println!("åˆ©ç”¨ç‡: {:.2}%", self.utilization() * 100.0);
        println!("è¿‘ä¼¼å“åº”æ—¶é—´: {:.4} ç§’", self.avg_response_time_approx());
    }
}

fn main() {
    let queue = MMcQueue::new(400.0, 100.0, 5);
    queue.report();
}
```

---

## 3. è´Ÿè½½æ¨¡å‹

### 3.1 å¼€æ”¾ç³»ç»Ÿæ¨¡å‹

```rust
struct OpenSystemModel {
    arrival_rate: f64,
    service_time: f64,
}

impl OpenSystemModel {
    fn new(arrival_rate: f64, service_time: f64) -> Self {
        Self { arrival_rate, service_time }
    }
    
    fn avg_response_time(&self) -> f64 {
        // R = S / (1 - Î»S)ï¼Œå…¶ä¸­ S æ˜¯æœåŠ¡æ—¶é—´ï¼ŒÎ» æ˜¯åˆ°è¾¾ç‡
        let utilization = self.arrival_rate * self.service_time;
        assert!(utilization < 1.0, "ç³»ç»Ÿè¿‡è½½");
        
        self.service_time / (1.0 - utilization)
    }
    
    fn max_throughput(&self) -> f64 {
        1.0 / self.service_time
    }
}

fn main() {
    let model = OpenSystemModel::new(80.0, 0.01); // 80 req/s, 10ms æœåŠ¡æ—¶é—´
    println!("å¹³å‡å“åº”æ—¶é—´: {:.4} ç§’", model.avg_response_time());
    println!("æœ€å¤§ååé‡: {:.2} è¯·æ±‚/ç§’", model.max_throughput());
}
```

### 3.2 é—­åˆç³»ç»Ÿæ¨¡å‹

```rust
struct ClosedSystemModel {
    num_users: usize,
    think_time: f64,
    service_time: f64,
}

impl ClosedSystemModel {
    fn new(num_users: usize, think_time: f64, service_time: f64) -> Self {
        Self { num_users, think_time, service_time }
    }
    
    // ä½¿ç”¨è¿‘ä¼¼å…¬å¼
    fn avg_response_time(&self) -> f64 {
        let n = self.num_users as f64;
        let z = self.think_time;
        let s = self.service_time;
        
        // R â‰ˆ S Ã— N / (1 + N Ã— S / Z)
        s * n / (1.0 + n * s / z)
    }
    
    fn throughput(&self) -> f64 {
        let r = self.avg_response_time();
        self.num_users as f64 / (r + self.think_time)
    }
}

fn main() {
    let model = ClosedSystemModel::new(100, 5.0, 0.1); // 100ç”¨æˆ·, 5sæ€è€ƒ, 0.1sæœåŠ¡
    println!("å¹³å‡å“åº”æ—¶é—´: {:.4} ç§’", model.avg_response_time());
    println!("ååé‡: {:.2} è¯·æ±‚/ç§’", model.throughput());
}
```

---

## 4. å®¹é‡è§„åˆ’

### 4.1 æ‰©å±•æ€§åˆ†æ

```rust
struct ScalabilityAnalysis {
    baseline_throughput: f64,
    baseline_servers: usize,
}

impl ScalabilityAnalysis {
    fn new(baseline_throughput: f64, baseline_servers: usize) -> Self {
        Self { baseline_throughput, baseline_servers }
    }
    
    // Amdahl's Law: åŠ é€Ÿæ¯” = 1 / (s + p/n)
    // s: ä¸²è¡Œéƒ¨åˆ†, p: å¹¶è¡Œéƒ¨åˆ†, n: å¤„ç†å™¨æ•°é‡
    fn amdahl_speedup(&self, serial_fraction: f64, num_servers: usize) -> f64 {
        let parallel_fraction = 1.0 - serial_fraction;
        1.0 / (serial_fraction + parallel_fraction / num_servers as f64)
    }
    
    // çº¿æ€§æ‰©å±•
    fn linear_scaling(&self, num_servers: usize) -> f64 {
        self.baseline_throughput * (num_servers as f64 / self.baseline_servers as f64)
    }
    
    // æ¬¡çº¿æ€§æ‰©å±•ï¼ˆè€ƒè™‘å¼€é”€ï¼‰
    fn sublinear_scaling(&self, num_servers: usize, overhead: f64) -> f64 {
        let ideal = self.linear_scaling(num_servers);
        ideal * (1.0 - overhead * (num_servers as f64 - 1.0))
    }
    
    fn report(&self, target_servers: usize) {
        println!("=== æ‰©å±•æ€§åˆ†æ ===");
        println!("åŸºå‡†ååé‡: {:.2} ({}å°æœåŠ¡å™¨)", self.baseline_throughput, self.baseline_servers);
        println!("ç›®æ ‡æœåŠ¡å™¨: {}", target_servers);
        println!("çº¿æ€§æ‰©å±•: {:.2}", self.linear_scaling(target_servers));
        println!("æ¬¡çº¿æ€§æ‰©å±• (10%å¼€é”€): {:.2}", self.sublinear_scaling(target_servers, 0.1));
        println!("Amdahl åŠ é€Ÿæ¯” (10%ä¸²è¡Œ): {:.2}x", self.amdahl_speedup(0.1, target_servers));
    }
}

fn main() {
    let analysis = ScalabilityAnalysis::new(1000.0, 2);
    analysis.report(10);
}
```

### 4.2 å®¹é‡é¢„æµ‹

```rust
struct CapacityPlanner {
    current_load: f64,
    current_capacity: f64,
    growth_rate: f64, // æœˆå¢é•¿ç‡
}

impl CapacityPlanner {
    fn new(current_load: f64, current_capacity: f64, growth_rate: f64) -> Self {
        Self { current_load, current_capacity, growth_rate }
    }
    
    fn predict_load(&self, months: usize) -> f64 {
        self.current_load * (1.0 + self.growth_rate).powi(months as i32)
    }
    
    fn months_until_capacity(&self) -> usize {
        let mut months = 0;
        let mut load = self.current_load;
        
        while load < self.current_capacity {
            load *= 1.0 + self.growth_rate;
            months += 1;
        }
        
        months
    }
    
    fn required_capacity(&self, months: usize, safety_margin: f64) -> f64 {
        self.predict_load(months) * (1.0 + safety_margin)
    }
    
    fn report(&self) {
        println!("=== å®¹é‡è§„åˆ’ ===");
        println!("å½“å‰è´Ÿè½½: {:.2}", self.current_load);
        println!("å½“å‰å®¹é‡: {:.2}", self.current_capacity);
        println!("æœˆå¢é•¿ç‡: {:.2}%", self.growth_rate * 100.0);
        
        println!("\né¢„æµ‹è´Ÿè½½:");
        for months in [3, 6, 12] {
            let load = self.predict_load(months);
            println!("  {}ä¸ªæœˆ: {:.2}", months, load);
        }
        
        println!("\nå®¹é‡ä¸è¶³é¢„è­¦: {}ä¸ªæœˆ", self.months_until_capacity());
        println!("å»ºè®®å®¹é‡ (12ä¸ªæœˆ, 20%è£•é‡): {:.2}", self.required_capacity(12, 0.2));
    }
}

fn main() {
    let planner = CapacityPlanner::new(5000.0, 10000.0, 0.05);
    planner.report();
}
```

---

## 5. æ€§èƒ½ä¼˜åŒ–

### 5.1 æ€§èƒ½ç“¶é¢ˆåˆ†æ

```rust
use std::collections::HashMap;

struct ResourceUtilization {
    cpu: f64,
    memory: f64,
    disk_io: f64,
    network_io: f64,
}

impl ResourceUtilization {
    fn identify_bottleneck(&self) -> &str {
        let mut max_util = self.cpu;
        let mut bottleneck = "CPU";
        
        if self.memory > max_util {
            max_util = self.memory;
            bottleneck = "å†…å­˜";
        }
        if self.disk_io > max_util {
            max_util = self.disk_io;
            bottleneck = "ç£ç›˜I/O";
        }
        if self.network_io > max_util {
            bottleneck = "ç½‘ç»œI/O";
        }
        
        bottleneck
    }
    
    fn report(&self) {
        println!("=== èµ„æºåˆ©ç”¨ç‡ ===");
        println!("CPU: {:.2}%", self.cpu * 100.0);
        println!("å†…å­˜: {:.2}%", self.memory * 100.0);
        println!("ç£ç›˜I/O: {:.2}%", self.disk_io * 100.0);
        println!("ç½‘ç»œI/O: {:.2}%", self.network_io * 100.0);
        println!("ç“¶é¢ˆ: {}", self.identify_bottleneck());
    }
}

fn main() {
    let utilization = ResourceUtilization {
        cpu: 0.45,
        memory: 0.60,
        disk_io: 0.85,  // ç“¶é¢ˆ
        network_io: 0.30,
    };
    
    utilization.report();
}
```

### 5.2 è´Ÿè½½å‡è¡¡ç­–ç•¥

```rust
struct LoadBalancer {
    servers: Vec<String>,
    current_index: usize,
}

impl LoadBalancer {
    fn new(servers: Vec<String>) -> Self {
        Self { servers, current_index: 0 }
    }
    
    // è½®è¯¢
    fn round_robin(&mut self) -> &str {
        let server = &self.servers[self.current_index];
        self.current_index = (self.current_index + 1) % self.servers.len();
        server
    }
    
    // åŠ æƒè½®è¯¢ï¼ˆç®€åŒ–ç‰ˆï¼‰
    fn weighted_round_robin(&mut self, weights: &[usize]) -> &str {
        // å®é™…å®ç°åº”è€ƒè™‘æƒé‡
        let total_weight: usize = weights.iter().sum();
        let index = self.current_index % total_weight;
        
        let mut cumulative = 0;
        for (i, &weight) in weights.iter().enumerate() {
            cumulative += weight;
            if index < cumulative {
                self.current_index += 1;
                return &self.servers[i];
            }
        }
        
        &self.servers[0]
    }
    
    // æœ€å°‘è¿æ¥
    fn least_connections(&self, connections: &[usize]) -> &str {
        let min_index = connections.iter()
            .enumerate()
            .min_by_key(|(_, &conn)| conn)
            .map(|(i, _)| i)
            .unwrap_or(0);
        
        &self.servers[min_index]
    }
}

fn main() {
    let mut lb = LoadBalancer::new(vec![
        "Server1".to_string(),
        "Server2".to_string(),
        "Server3".to_string(),
    ]);
    
    println!("=== è½®è¯¢ ===");
    for _ in 0..5 {
        println!("{}", lb.round_robin());
    }
    
    println!("\n=== æœ€å°‘è¿æ¥ ===");
    let connections = vec![5, 2, 8];
    println!("{}", lb.least_connections(&connections));
}
```

---

## 6. å®æˆ˜æ¡ˆä¾‹

### 6.1 Web æœåŠ¡å™¨æ€§èƒ½æ¨¡å‹

```rust
struct WebServerModel {
    num_workers: usize,
    request_rate: f64,
    avg_processing_time: f64,
}

impl WebServerModel {
    fn new(num_workers: usize, request_rate: f64, avg_processing_time: f64) -> Self {
        Self { num_workers, request_rate, avg_processing_time }
    }
    
    fn analyze(&self) -> PerformanceMetrics {
        let queue = MMcQueue::new(
            self.request_rate,
            1.0 / self.avg_processing_time,
            self.num_workers,
        );
        
        let mut metrics = PerformanceMetrics::new();
        metrics.throughput = self.request_rate;
        metrics.latency = Duration::from_secs_f64(queue.avg_response_time_approx());
        metrics.utilization = queue.utilization();
        
        metrics
    }
    
    fn recommend_workers(&self, target_response_time: f64) -> usize {
        let mut workers = 1;
        loop {
            let model = Self::new(workers, self.request_rate, self.avg_processing_time);
            let queue = MMcQueue::new(
                model.request_rate,
                1.0 / model.avg_processing_time,
                workers,
            );
            
            if queue.avg_response_time_approx() <= target_response_time {
                return workers;
            }
            
            workers += 1;
            if workers > 100 {
                break; // é˜²æ­¢æ— é™å¾ªç¯
            }
        }
        workers
    }
}

fn main() {
    let model = WebServerModel::new(4, 200.0, 0.015); // 4å·¥ä½œçº¿ç¨‹, 200req/s, 15mså¤„ç†
    let metrics = model.analyze();
    metrics.report();
    
    let recommended = model.recommend_workers(0.05); // ç›®æ ‡50mså“åº”æ—¶é—´
    println!("\nå»ºè®®å·¥ä½œçº¿ç¨‹æ•°: {}", recommended);
}
```

### 6.2 æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

```rust
struct ConnectionPoolModel {
    pool_size: usize,
    query_rate: f64,
    avg_query_time: f64,
    connection_timeout: f64,
}

impl ConnectionPoolModel {
    fn new(pool_size: usize, query_rate: f64, avg_query_time: f64) -> Self {
        Self {
            pool_size,
            query_rate,
            avg_query_time,
            connection_timeout: 1.0, // 1ç§’è¶…æ—¶
        }
    }
    
    fn analyze(&self) -> (f64, f64) {
        let queue = MMcQueue::new(
            self.query_rate,
            1.0 / self.avg_query_time,
            self.pool_size,
        );
        
        let avg_wait_time = queue.avg_response_time_approx() - self.avg_query_time;
        let timeout_probability = if avg_wait_time > self.connection_timeout {
            (avg_wait_time - self.connection_timeout) / avg_wait_time
        } else {
            0.0
        };
        
        (avg_wait_time, timeout_probability)
    }
    
    fn optimal_pool_size(&self, max_timeout_prob: f64) -> usize {
        let mut size = 1;
        loop {
            let model = Self::new(size, self.query_rate, self.avg_query_time);
            let (_, timeout_prob) = model.analyze();
            
            if timeout_prob <= max_timeout_prob {
                return size;
            }
            
            size += 1;
            if size > 1000 {
                break;
            }
        }
        size
    }
}

fn main() {
    let model = ConnectionPoolModel::new(10, 100.0, 0.05); // 10è¿æ¥, 100æŸ¥è¯¢/s, 50msæŸ¥è¯¢
    let (wait_time, timeout_prob) = model.analyze();
    
    println!("=== è¿æ¥æ± åˆ†æ ===");
    println!("è¿æ¥æ± å¤§å°: {}", model.pool_size);
    println!("å¹³å‡ç­‰å¾…æ—¶é—´: {:.4} ç§’", wait_time);
    println!("è¶…æ—¶æ¦‚ç‡: {:.2}%", timeout_prob * 100.0);
    
    let optimal = model.optimal_pool_size(0.01); // 1%è¶…æ—¶å®¹å¿åº¦
    println!("æœ€ä¼˜è¿æ¥æ± å¤§å°: {}", optimal);
}
```

---

## 7. æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

| æ¨¡å‹ | ç”¨é€” | å…³é”®æŒ‡æ ‡ |
|-----|------|---------|
| **M/M/1** | å•æœåŠ¡å™¨é˜Ÿåˆ— | åˆ©ç”¨ç‡ã€é˜Ÿåˆ—é•¿åº¦ã€å“åº”æ—¶é—´ |
| **M/M/c** | å¤šæœåŠ¡å™¨é˜Ÿåˆ— | å¹¶å‘å¤„ç†èƒ½åŠ› |
| **Little's Law** | ç³»ç»Ÿåˆ†æ | L = Î» Ã— W |
| **Amdahl's Law** | æ‰©å±•æ€§ | åŠ é€Ÿæ¯” |

### æœ€ä½³å®è·µ

1. **ç›‘æ§å…³é”®æŒ‡æ ‡**: å»¶è¿Ÿã€ååé‡ã€åˆ©ç”¨ç‡
2. **å®¹é‡è§„åˆ’**: é¢„ç•™ 20-30% è£•é‡
3. **è´Ÿè½½æµ‹è¯•**: æ¨¡æ‹Ÿå³°å€¼è´Ÿè½½
4. **ç“¶é¢ˆä¼˜åŒ–**: è¯†åˆ«å¹¶ä¼˜åŒ–æœ€æ…¢ç»„ä»¶
5. **æ°´å¹³æ‰©å±•**: ä¼˜å…ˆé€‰æ‹©æ— çŠ¶æ€æœåŠ¡

---

## ğŸ“š å‚è€ƒèµ„æº

- [Queuing Theory](https://en.wikipedia.org/wiki/Queueing_theory)
- [Performance Modeling](https://www.brendangregg.com/sysperfbook.html)
- [Little's Law](https://en.wikipedia.org/wiki/Little%27s_law)

---

**ğŸ‰ æ­å–œï¼** ä½ å·²å®Œæˆ C12 Model Tier 2 å…¨éƒ¨å®è·µæŒ‡å—çš„å­¦ä¹ ã€‚

**ä¸‹ä¸€æ­¥å»ºè®®**ï¼š

- æ·±å…¥å­¦ä¹  [Tier 3: æŠ€æœ¯å‚è€ƒ](../tier_03_references/README.md)
- æ¢ç´¢ [Tier 4: é«˜çº§ä¸»é¢˜](../tier_04_advanced/README.md)
- å®è·µåº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­
