# 第 3 章：共享状态并发与同步原语

- [第 3 章：共享状态并发与同步原语](#第-3-章共享状态并发与同步原语)
  - [1. 共享状态并发模型](#1-共享状态并发模型)
    - [1.1. 理念：通过共享内存来通信](#11-理念通过共享内存来通信)
    - [1.2. 核心挑战：数据竞争 (Data Races)](#12-核心挑战数据竞争-data-races)
  - [2. `Mutex<T>`：互斥锁](#2-mutext互斥锁)
    - [2.1. 工作原理](#21-工作原理)
    - [2.2. `MutexGuard` 与 RAII 模式](#22-mutexguard-与-raii-模式)
    - [2.3. `Mutex` 的死锁风险](#23-mutex-的死锁风险)
  - [3. `Arc<T>`：原子引用计数](#3-arct原子引用计数)
    - [3.1. 为何需要 `Arc`？](#31-为何需要-arc)
    - [3.2. `Arc<Mutex<T>>`：线程安全的内部可变性](#32-arcmutext线程安全的内部可变性)
  - [4. `RwLock<T>`：读写锁](#4-rwlockt读写锁)
    - [4.1. 优化读多写少场景](#41-优化读多写少场景)
    - [4.2. 死锁与写者饥饿](#42-死锁与写者饥饿)
  - [5. `Send` 和 `Sync` Trait 的角色](#5-send-和-sync-trait-的角色)
    - [5.1. `Send`：所有权可以被安全地送到另一个线程](#51-send所有权可以被安全地送到另一个线程)
    - [5.2. `Sync`：引用可以被安全地在多线程间共享](#52-sync引用可以被安全地在多线程间共享)
  - [6. 哲学批判性分析](#6-哲学批判性分析)
    - [6.1. 复杂性的回归](#61-复杂性的回归)
    - [6.2. 性能与权衡](#62-性能与权衡)
  - [7. 总结](#7-总结)

---

## 1. 共享状态并发模型

与消息传递模型相对，共享状态并发是更传统的一种并发范式。
在大型面向对象语言（如 Java, C#）和系统语言（C++）中，它都是主流。

### 1.1. 理念：通过共享内存来通信

这个模型的理念是，多个线程可以同时访问同一块内存区域。
为了协调这种访问，线程会使用同步原语（如锁）来确保在任何时刻，只有一个线程能够修改数据，从而避免混乱。

这种模型在某些场景下更自然或性能更高，例如：

- 当数据量巨大，在线程间移动所有权的成本很高时。
- 当多个线程需要频繁地读取同一份配置或缓存数据时。

### 1.2. 核心挑战：数据竞争 (Data Races)

共享状态并发的主要敌人是**数据竞争**。一个数据竞争在形式上精确定义为：

1. **两个或以上**的线程并发地访问同一内存位置。
2. **其中至少一个**访问是**写操作**。
3. 线程之间**没有使用任何**排他性的同步机制。

数据竞争是未定义行为 (Undefined Behavior)，会导致程序崩溃、数据损坏等一系列不可预测的问题。
Rust 的所有权和类型系统，特别是 `Send` 和 `Sync` Trait，其核心目标之一就是在**编译时**彻底消除数据竞争。

## 2. `Mutex<T>`：互斥锁

`Mutex<T>` (Mutual Exclusion) 是最基础的同步原语。
它确保在任何时间点，只有一个线程能访问 `Mutex<T>` 内部的数据 `T`。

### 2.1. 工作原理

可以把 `Mutex<T>` 想象成一个只带了一把钥匙的房间，房间里放着数据 `T`。

- 当一个线程想要访问数据时，它必须先请求获得钥匙（调用 `.lock()`）。
- 如果钥匙可用，线程拿到钥匙，进入房间，可以访问数据。
- 如果钥匙已经被其他线程持有，当前线程必须**等待（阻塞）**，直到钥匙被归还。
- 线程完成操作后，必须归还钥匙（锁被释放），这样其他等待的线程才能获得它。

### 2.2. `MutexGuard` 与 RAII 模式

Rust 的 `Mutex` 实现非常优雅，它巧妙地利用了 RAII (Resource Acquisition Is Initialization) 模式来管理锁的生命周期。

当你调用 `mutex.lock()` 时，它返回的不是数据 `T` 的直接访问权，而是一个 `Result<MutexGuard<T>, _>`。
这个 `MutexGuard<T>` 是一个智能指针，它实现了 `Deref` 和 `DerefMut`，允许你像直接持有 `T` 的引用一样操作数据。

**关键在于**：`MutexGuard<T>` 的 `Drop` Trait 实现中包含了**释放锁**的逻辑。
这意味着：

- 当 `MutexGuard` 离开其作用域时，它的 `drop` 方法被自动调用，锁也随之被自动释放。
- 这极大地避免了忘记手动释放锁而导致的死锁问题。

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // 使用 Mutex 保护一个整数
    let counter = Mutex::new(0);
    // ...
}
```

### 2.3. `Mutex` 的死锁风险

尽管 RAII 模式能防止忘记释放锁，但 `Mutex` 仍然存在逻辑上的**死锁 (Deadlock)** 风险。
当两个或多个线程各自持有一个锁，并试图获取对方持有的锁时，就会发生死锁。

```rust
// 伪代码演示死锁
// 线程 A: lock(A); lock(B);
// 线程 B: lock(B); lock(A);
// 如果线程 A 完成 lock(A) 后，线程 B 完成了 lock(B)，
// 那么线程 A 将永远等待 B 释放锁，线程 B 也将永远等待 A 释放锁。
```

避免死锁通常需要开发者保证所有线程都以相同的顺序获取锁。

## 3. `Arc<T>`：原子引用计数

直接将 `Mutex<T>` 在线程间移动是不可行的，因为 `Mutex` 本身的所有权会被转移。
我们如何让多个线程**共享**同一个 `Mutex` 的所有权呢？答案是 `Arc<T>`。

### 3.1. 为何需要 `Arc`？

- `Rc<T>` (Reference Counted) 是单线程的引用计数智能指针。它允许多个所有者，但在多线程环境下是不安全的，因为它没有对引用计数的修改进行原子化操作，会导致数据竞争。因此，`Rc<T>` 没有实现 `Send` Trait。
- `Arc<T>` (Atomically Reference Counted) 是 `Rc<T>` 的线程安全版本。它使用原子操作来增减引用计数，确保在多线程环境下修改计数是安全的。因此，`Arc<T>` 实现了 `Send` 和 `Sync`。

### 3.2. `Arc<Mutex<T>>`：线程安全的内部可变性

`Arc<Mutex<T>>` 是 Rust 中最常见、最核心的共享状态并发模式之一。

- `Arc<T>` 允许多个线程**共享**对 `Mutex<T>` 的所有权。
- `Mutex<T>` 允许在多个线程之间**同步**对内部数据 `T` 的可变访问。

它完美地体现了 Rust 的**内部可变性 (Interior Mutability)** 模式在并发领域的应用。即使你持有的是一个 `&Arc<Mutex<T>>` (一个共享引用)，你依然可以通过 `.lock()` 获取到对内部数据的可变访问权。

**代码示例**:

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // 使用 Arc<Mutex<T>> 来允许多个线程共享并修改同一个计数器
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        // 为每个线程克隆 Arc，增加引用计数
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            // 获取锁
            let mut num = counter.lock().unwrap();
            // 修改数据
            *num += 1;
        }); // 锁在这里被 `MutexGuard` 的 drop 自动释放
        handles.push(handle);
    }

    // 等待所有线程完成
    for handle in handles {
        handle.join().unwrap();
    }

    // 打印最终结果。需要先获取锁
    println!("Result: {}", *counter.lock().unwrap()); // 结果应为 10
}
```

## 4. `RwLock<T>`：读写锁

`Mutex<T>` 提供的是完全排他的访问。但在"读多写少"的场景下，允许多个线程同时读取数据是安全的，这可以显著提高并发性能。`RwLock<T>` (Read-Write Lock) 就是为此设计的。

### 4.1. 优化读多写少场景

`RwLock<T>` 遵循以下规则：

- **任意数量**的**读操作**可以**同时**进行。
- **写操作**必须是**完全排他**的。当一个线程正在写入时，其他任何线程（无论是读还是写）都必须等待。

- `.read().unwrap()`: 请求一个读锁，阻塞当前线程直到获得读权限。返回一个 `RwLockReadGuard`。
- `.write().unwrap()`: 请求一个写锁，阻塞当前线程直到获得写权限。返回一个 `RwLockWriteGuard`。

### 4.2. 死锁与写者饥饿

`RwLock<T>` 同样有死锁风险。此外，它还可能引入**写者饥饿 (Writer Starvation)** 的问题。如果在写者等待期间，不断有新的读者到来，那么写者可能永远也得不到获取锁的机会。Rust 标准库中 `RwLock` 的具体实现会尝试缓解这个问题，但开发者在设计高并发系统时仍需考虑此风险。

## 5. `Send` 和 `Sync` Trait 的角色

这两个标记 Trait 是 Rust 无畏并发的魔法核心。它们在编译时将并发规则编码到类型系统中。

### 5.1. `Send`：所有权可以被安全地送到另一个线程

一个类型 `T` 如果是 `Send` 的，意味着它的所有权可以被安全地从一个线程**转移**到另一个线程。

- 几乎所有基础类型都是 `Send` 的。
- `Rc<T>` 不是 `Send` 的。
- 如果一个复合类型的所有成员都是 `Send` 的，那么它通常也是 `Send` 的。

### 5.2. `Sync`：引用可以被安全地在多线程间共享

一个类型 `T` 如果是 `Sync` 的，意味着 `&T` 可以被安全地在多个线程之间**共享**。

- 如果 `T` 是 `Sync` 的，那么 `&T` 就是 `Send` 的。
- `Cell<T>` 和 `RefCell<T>` 都不是 `Sync` 的，这正是它们只能用于单线程内部可变性的原因。
- `Mutex<T>` 是 `Sync` 的（前提是 `T` 是 `Send` 的）。这使得 `Arc<Mutex<T>>` 可以在线程间共享。

## 6. 哲学批判性分析

### 6.1. 复杂性的回归

从消息传递切换到共享状态，意味着开发者重新承担起了管理并发复杂性的责任。

- **锁的粒度**: 锁保护的数据范围应该多大？锁太小（细粒度）可能导致需要获取多个锁，增加死锁风险；锁太大（粗粒度）则可能严重降低并发性能。
- **锁的顺序**: 必须在整个代码库中维持一个严格的锁获取顺序，以避免死锁。
- **性能瓶颈**: 高竞争的锁会成为系统的性能瓶颈。

### 6.2. 性能与权衡

共享状态模型通常被认为性能更高，因为它避免了数据在线程间的大量复制或所有权转移。然而，当锁竞争激烈时，线程阻塞和上下文切换的开销可能会抵消这一优势。选择哪种模型是一个复杂的权衡过程，取决于具体应用的访问模式和性能需求。

## 7. 总结

共享状态并发是 Rust 提供的第二种强大的并发范式。通过 `Mutex`、`RwLock` 等同步原语，以及 `Arc` 这样的原子引用计数类型，Rust 允许开发者在需要时安全地使用共享内存。RAII 模式和 `Send`/`Sync` Trait 将传统并发模型中的许多运行时风险转化为了编译时错误，但这并没有完全消除逻辑错误（如死锁）的可能性。开发者在选择此模型时，需要更谨慎地思考其并发设计。

---
**章节导航:**

- **上一章 ->** `02_message_passing.md`
- **下一章 ->** `04_parallelism_and_beyond.md`: 探讨并行计算与更高级的并发库。
- **返回目录 ->** `_index.md`
