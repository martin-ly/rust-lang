# Rust 性能优化实战手册 (2025版)

> **主题**: Rust 应用性能调优完全指南  
> **难度**: 中高级  
> **预计学习时间**: 10-15 小时  
> **更新日期**: 2025-10-20

---


## 📊 目录

- [📋 目录](#目录)
- [概述](#概述)
  - [性能优化的层次](#性能优化的层次)
  - [优化原则](#优化原则)
- [性能测量](#性能测量)
  - [基准测试 (Criterion)](#基准测试-criterion)
  - [性能分析 (Profiling)](#性能分析-profiling)
  - [火焰图 (Flamegraph)](#火焰图-flamegraph)
- [编译器优化](#编译器优化)
  - [编译选项](#编译选项)
  - [LTO (链接时优化)](#lto-链接时优化)
  - [PGO (配置文件引导优化)](#pgo-配置文件引导优化)
- [内存优化](#内存优化)
  - [避免不必要的分配](#避免不必要的分配)
  - [使用内存池](#使用内存池)
  - [栈上分配 vs 堆上分配](#栈上分配-vs-堆上分配)
  - [Copy vs Clone](#copy-vs-clone)
- [并发优化](#并发优化)
  - [Rayon 并行计算](#rayon-并行计算)
  - [Tokio 异步并发](#tokio-异步并发)
  - [无锁数据结构](#无锁数据结构)
- [算法优化](#算法优化)
  - [选择正确的数据结构](#选择正确的数据结构)
  - [迭代器优化](#迭代器优化)
  - [SIMD 优化](#simd-优化)
- [IO 优化](#io-优化)
  - [零拷贝 IO](#零拷贝-io)
  - [io_uring (Linux)](#io_uring-linux)
  - [缓冲区优化](#缓冲区优化)
- [数据库优化](#数据库优化)
  - [连接池配置](#连接池配置)
  - [批量操作](#批量操作)
  - [预编译语句](#预编译语句)
- [Web 服务优化](#web-服务优化)
  - [HTTP/2 vs HTTP/1.1](#http2-vs-http11)
  - [响应压缩](#响应压缩)
  - [静态资源优化](#静态资源优化)
- [实战案例](#实战案例)
  - [案例1: JSON 解析优化](#案例1-json-解析优化)
  - [案例2: 高性能 HTTP 服务](#案例2-高性能-http-服务)
  - [案例3: 数据处理管道](#案例3-数据处理管道)
- [性能检查清单](#性能检查清单)
- [参考资源](#参考资源)


## 📋 目录

- [Rust 性能优化实战手册 (2025版)](#rust-性能优化实战手册-2025版)
  - [📋 目录](#-目录)
  - [概述](#概述)
    - [性能优化的层次](#性能优化的层次)
    - [优化原则](#优化原则)
  - [性能测量](#性能测量)
    - [基准测试 (Criterion)](#基准测试-criterion)
    - [性能分析 (Profiling)](#性能分析-profiling)
    - [火焰图 (Flamegraph)](#火焰图-flamegraph)
  - [编译器优化](#编译器优化)
    - [编译选项](#编译选项)
    - [LTO (链接时优化)](#lto-链接时优化)
    - [PGO (配置文件引导优化)](#pgo-配置文件引导优化)
  - [内存优化](#内存优化)
    - [避免不必要的分配](#避免不必要的分配)
    - [使用内存池](#使用内存池)
    - [栈上分配 vs 堆上分配](#栈上分配-vs-堆上分配)
    - [Copy vs Clone](#copy-vs-clone)
  - [并发优化](#并发优化)
    - [Rayon 并行计算](#rayon-并行计算)
    - [Tokio 异步并发](#tokio-异步并发)
    - [无锁数据结构](#无锁数据结构)
  - [算法优化](#算法优化)
    - [选择正确的数据结构](#选择正确的数据结构)
    - [迭代器优化](#迭代器优化)
    - [SIMD 优化](#simd-优化)
  - [IO 优化](#io-优化)
    - [零拷贝 IO](#零拷贝-io)
    - [io\_uring (Linux)](#io_uring-linux)
    - [缓冲区优化](#缓冲区优化)
  - [数据库优化](#数据库优化)
    - [连接池配置](#连接池配置)
    - [批量操作](#批量操作)
    - [预编译语句](#预编译语句)
  - [Web 服务优化](#web-服务优化)
    - [HTTP/2 vs HTTP/1.1](#http2-vs-http11)
    - [响应压缩](#响应压缩)
    - [静态资源优化](#静态资源优化)
  - [实战案例](#实战案例)
    - [案例1: JSON 解析优化](#案例1-json-解析优化)
    - [案例2: 高性能 HTTP 服务](#案例2-高性能-http-服务)
    - [案例3: 数据处理管道](#案例3-数据处理管道)
  - [性能检查清单](#性能检查清单)
  - [参考资源](#参考资源)

---

## 概述

### 性能优化的层次

```text
┌──────────────────────────────────────────────────────────┐
│  Level 1: 算法和数据结构                                   │
│  影响: 🔥🔥🔥🔥🔥 (最高)                                    │
│  示例: O(n²) → O(n log n)                                │
└──────────────────────────────────────────────────────────┘
                         ↓
┌──────────────────────────────────────────────────────────┐
│  Level 2: 内存布局和分配                                   │
│  影响: 🔥🔥🔥🔥                                             │
│  示例: Vec<Box<T>> → Vec<T>                              │
└──────────────────────────────────────────────────────────┘
                         ↓
┌──────────────────────────────────────────────────────────┐
│  Level 3: 并发和异步                                       │
│  影响: 🔥🔥🔥🔥                                             │
│  示例: 单线程 → Rayon 并行                                 │
└──────────────────────────────────────────────────────────┘
                         ↓
┌──────────────────────────────────────────────────────────┐
│  Level 4: 编译器优化                                       │
│  影响: 🔥🔥🔥                                               │
│  示例: debug → release, LTO, PGO                         │
└──────────────────────────────────────────────────────────┘
                         ↓
┌──────────────────────────────────────────────────────────┐
│  Level 5: 微优化                                           │
│  影响: 🔥🔥                                                 │
│  示例: inline, SIMD, unsafe                              │
└──────────────────────────────────────────────────────────┘
```

### 优化原则

**1. 先测量，再优化**-

```bash
# 永远先建立基准
cargo bench

# 然后优化
# 优化后再次测量
```

**2. 优化最热路径**-

```text
80% 的时间花在 20% 的代码上
→ 专注优化这 20% 的代码
```

**3. 权衡可读性**-

```rust
// 可读但慢
let result: Vec<_> = items.iter().filter(|x| x > &5).map(|x| x * 2).collect();

// 快但难读
let mut result = Vec::with_capacity(items.len());
for &x in &items {
    if x > 5 {
        result.push(x * 2);
    }
}

// 只在性能关键路径使用复杂优化
```

---

## 性能测量

### 基准测试 (Criterion)

**安装**:

```toml
[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports"] }

[[bench]]
name = "my_benchmark"
harness = false
```

**基准测试**:

```rust
// benches/my_benchmark.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};

fn fibonacci_recursive(n: u64) -> u64 {
    match n {
        0 => 1,
        1 => 1,
        n => fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2),
    }
}

fn fibonacci_iterative(n: u64) -> u64 {
    let mut a = 0;
    let mut b = 1;
    for _ in 0..n {
        let temp = a;
        a = b;
        b = temp + b;
    }
    b
}

fn bench_fibonacci(c: &mut Criterion) {
    let mut group = c.benchmark_group("fibonacci");
    
    for i in [10u64, 15, 20].iter() {
        group.bench_with_input(BenchmarkId::new("recursive", i), i, |b, &i| {
            b.iter(|| fibonacci_recursive(black_box(i)));
        });
        
        group.bench_with_input(BenchmarkId::new("iterative", i), i, |b, &i| {
            b.iter(|| fibonacci_iterative(black_box(i)));
        });
    }
    
    group.finish();
}

criterion_group!(benches, bench_fibonacci);
criterion_main!(benches);
```

**运行**:

```bash
cargo bench

# 查看报告
open target/criterion/report/index.html
```

### 性能分析 (Profiling)

**Linux - perf**:

```bash
# 编译带调试信息的 release 版本
CARGO_PROFILE_RELEASE_DEBUG=true cargo build --release

# 运行 perf
perf record -g ./target/release/my-app

# 查看报告
perf report
```

**macOS - Instruments**:

```bash
# 使用 Xcode Instruments
instruments -t "Time Profiler" ./target/release/my-app
```

**跨平台 - cargo-flamegraph**:

```bash
cargo install flamegraph

# 生成火焰图
cargo flamegraph

# 查看
open flamegraph.svg
```

### 火焰图 (Flamegraph)

**示例输出**:

```text
            main() [100%]
              │
    ┌─────────┼──────────┐
    │         │          │
process()  parse()   write()
  [60%]     [30%]     [10%]
    │         │
  ┌─┴─┐     ┌─┴─┐
hash() compute()
 [40%]  [20%]   ...
```

**解读**: `process()` 占用 60% CPU，是优化重点！

---

## 编译器优化

### 编译选项

**Cargo.toml**:

```toml
[profile.release]
opt-level = 3              # 最高优化等级
lto = "fat"                # 完整 LTO
codegen-units = 1          # 单一代码生成单元 (最佳优化)
strip = true               # 移除符号 (减小体积)
panic = "abort"            # panic 时直接 abort (更小、更快)

# 针对当前CPU优化
[build]
rustflags = ["-C", "target-cpu=native"]
```

**优化等级对比**:

| Level | 优化程度 | 编译时间 | 运行时间 |
|-------|---------|---------|---------|
| `0` | 无 | 最快 | 最慢 |
| `1` | 基础 | 快 | 慢 |
| `2` | 默认 release | 中等 | 快 |
| `3` | 激进 | 慢 | 最快 |
| `s` | 体积优先 | 中等 | 中等 |
| `z` | 极致体积 | 慢 | 中等 |

### LTO (链接时优化)

```toml
[profile.release]
lto = true  # 或 "fat" / "thin"
```

**效果**: 5-15% 性能提升，编译时间增加 2-3倍

### PGO (配置文件引导优化)

**步骤1: 生成配置文件**:

```toml
[profile.release]
opt-level = 3

[build]
rustflags = ["-C", "profile-generate=/tmp/pgo-data"]
```

```bash
cargo build --release
./target/release/my-app  # 运行典型工作负载
```

**步骤2: 使用配置文件优化**:

```toml
[build]
rustflags = ["-C", "profile-use=/tmp/pgo-data/merged.profdata"]
```

```bash
cargo build --release
```

**效果**: 额外 5-10% 性能提升

---

## 内存优化

### 避免不必要的分配

**❌ 糟糕**:

```rust
fn process_data(data: &str) -> String {
    let temp = data.to_string();  // 不必要的分配
    temp.to_uppercase()           // 又一次分配
}
```

**✅ 优化**:

```rust
fn process_data(data: &str) -> String {
    data.to_uppercase()  // 只分配一次
}
```

**❌ 糟糕**:

```rust
fn concat_strings(a: &str, b: &str) -> String {
    let mut result = String::new();
    result.push_str(a);
    result.push_str(b);  // 可能需要重新分配
    result
}
```

**✅ 优化**:

```rust
fn concat_strings(a: &str, b: &str) -> String {
    let mut result = String::with_capacity(a.len() + b.len());  // 预分配
    result.push_str(a);
    result.push_str(b);
    result
}
```

### 使用内存池

```rust
use bumpalo::Bump;

fn allocate_many() {
    let bump = Bump::new();
    
    // 所有分配来自同一内存池
    let vec1 = bump.alloc_slice_fill_copy(100, 0u8);
    let vec2 = bump.alloc_slice_fill_copy(200, 0u8);
    
    // bump 销毁时，所有分配一次性释放
}
```

**效果**: 10-100x 更快的分配速度

### 栈上分配 vs 堆上分配

**栈上分配 (快)**:

```rust
let array = [0u8; 1024];  // 栈上，快
```

**堆上分配 (慢)**:

```rust
let vec = vec![0u8; 1024];  // 堆上，慢
```

**SmallVec (混合策略)**:

```rust
use smallvec::SmallVec;

// 小于 8 个元素时在栈上，大于 8 个时在堆上
let mut vec: SmallVec<[u32; 8]> = SmallVec::new();
vec.push(1);  // 栈上
vec.extend_from_slice(&[2, 3, 4, 5, 6, 7, 8, 9]);  // 自动转堆上
```

### Copy vs Clone

**❌ 糟糕**:

```rust
#[derive(Clone)]
struct Point {
    x: f64,
    y: f64,
}

let p1 = Point { x: 1.0, y: 2.0 };
let p2 = p1.clone();  // 不必要的 clone()
```

**✅ 优化**:

```rust
#[derive(Copy, Clone)]
struct Point {
    x: f64,
    y: f64,
}

let p1 = Point { x: 1.0, y: 2.0 };
let p2 = p1;  // 简单的内存拷贝，极快
```

---

## 并发优化

### Rayon 并行计算

**顺序处理 (慢)**:

```rust
let sum: i32 = (0..1_000_000)
    .map(|x| expensive_computation(x))
    .sum();
```

**并行处理 (快)**:

```rust
use rayon::prelude::*;

let sum: i32 = (0..1_000_000)
    .into_par_iter()  // 并行迭代器
    .map(|x| expensive_computation(x))
    .sum();
```

**效果**: 在 8 核 CPU 上接近 8x 加速

**并行排序**:

```rust
use rayon::prelude::*;

let mut data = vec![/* ... */];
data.par_sort_unstable();  // 并行排序
```

### Tokio 异步并发

**顺序 HTTP 请求 (慢)**:

```rust
async fn fetch_all(urls: &[String]) -> Vec<String> {
    let mut results = Vec::new();
    for url in urls {
        let response = reqwest::get(url).await.unwrap();
        results.push(response.text().await.unwrap());
    }
    results
}
```

**并发 HTTP 请求 (快)**:

```rust
use tokio::task::JoinSet;

async fn fetch_all(urls: &[String]) -> Vec<String> {
    let mut set = JoinSet::new();
    
    for url in urls {
        let url = url.clone();
        set.spawn(async move {
            reqwest::get(&url).await.unwrap().text().await.unwrap()
        });
    }
    
    let mut results = Vec::new();
    while let Some(Ok(result)) = set.join_next().await {
        results.push(result);
    }
    results
}
```

**效果**: 100 个请求从 10秒 → 1秒

### 无锁数据结构

```rust
use std::sync::atomic::{AtomicU64, Ordering};

static COUNTER: AtomicU64 = AtomicU64::new(0);

fn increment() {
    COUNTER.fetch_add(1, Ordering::Relaxed);  // 无锁，快
}
```

**对比有锁**:

```rust
use std::sync::Mutex;

static COUNTER: Mutex<u64> = Mutex::new(0);

fn increment() {
    *COUNTER.lock().unwrap() += 1;  // 需要锁，慢
}
```

---

## 算法优化

### 选择正确的数据结构

**场景1: 频繁查找**-

```rust
// ❌ 糟糕: O(n) 查找
let vec = vec![1, 2, 3, 4, 5];
vec.contains(&3);

// ✅ 优化: O(1) 查找
use std::collections::HashSet;
let set: HashSet<_> = vec![1, 2, 3, 4, 5].into_iter().collect();
set.contains(&3);
```

**场景2: 有序数据**-

```rust
// ❌ 糟糕: O(n log n) 排序 + O(n) 查找
let vec = vec![1, 5, 3, 2, 4];
vec.sort();
vec.binary_search(&3);

// ✅ 优化: 使用 BTreeSet (自动有序)
use std::collections::BTreeSet;
let set: BTreeSet<_> = vec![1, 5, 3, 2, 4].into_iter().collect();
set.contains(&3);  // O(log n)
```

### 迭代器优化

**❌ 糟糕: 多次遍历**:

```rust
let sum: i32 = vec.iter().sum();
let max = vec.iter().max().unwrap();
let min = vec.iter().min().unwrap();
```

**✅ 优化: 单次遍历**:

```rust
let (sum, max, min) = vec.iter().fold(
    (0, i32::MIN, i32::MAX),
    |(sum, max, min), &x| (sum + x, max.max(x), min.min(x))
);
```

**使用 `collect` 优化**:

```rust
// ❌ 糟糕: 链式分配
let result = vec.iter()
    .filter(|&&x| x > 5)
    .collect::<Vec<_>>()
    .iter()
    .map(|&x| x * 2)
    .collect::<Vec<_>>();

// ✅ 优化: 单次 collect
let result: Vec<_> = vec.iter()
    .filter(|&&x| x > 5)
    .map(|&x| x * 2)
    .collect();
```

### SIMD 优化

```rust
use std::simd::{f32x4, SimdFloat};

// 标量版本 (慢)
fn add_scalar(a: &[f32], b: &[f32]) -> Vec<f32> {
    a.iter().zip(b).map(|(x, y)| x + y).collect()
}

// SIMD 版本 (快)
fn add_simd(a: &[f32], b: &[f32]) -> Vec<f32> {
    let mut result = Vec::with_capacity(a.len());
    
    for i in (0..a.len()).step_by(4) {
        let va = f32x4::from_slice(&a[i..]);
        let vb = f32x4::from_slice(&b[i..]);
        let vr = va + vb;
        result.extend_from_slice(&vr.to_array());
    }
    
    result
}
```

**效果**: 4x 加速 (在支持 SIMD 的 CPU 上)

---

## IO 优化

### 零拷贝 IO

**使用 `bytes` crate**:

```rust
use bytes::{Bytes, BytesMut};

// ❌ 糟糕: 拷贝
let vec = vec![0u8; 1024];
let slice = &vec[..];  // 需要拷贝

// ✅ 优化: 零拷贝
let bytes = Bytes::from(vec![0u8; 1024]);
let slice = bytes.slice(..);  // 零拷贝
```

### io_uring (Linux)

```rust
use tokio_uring::fs::File;

async fn read_file_uring(path: &str) -> Vec<u8> {
    let file = File::open(path).await.unwrap();
    let buf = vec![0u8; 1024];
    let (res, buf) = file.read_at(buf, 0).await;
    buf
}
```

**效果**: 比传统 IO 快 2-3x

### 缓冲区优化

**❌ 糟糕: 小块读取**:

```rust
use std::io::{Read, BufReader};

let file = File::open("data.txt")?;
let mut reader = BufReader::new(file);
let mut byte = [0u8; 1];

loop {
    if reader.read(&mut byte)? == 0 {
        break;
    }
    // 处理 byte...
}
```

**✅ 优化: 大块读取**:

```rust
let file = File::open("data.txt")?;
let mut reader = BufReader::with_capacity(64 * 1024, file);  // 64KB 缓冲
let mut buffer = [0u8; 8192];

loop {
    let n = reader.read(&mut buffer)?;
    if n == 0 {
        break;
    }
    // 处理 buffer[..n]...
}
```

---

## 数据库优化

### 连接池配置

```rust
use sqlx::postgres::PgPoolOptions;

let pool = PgPoolOptions::new()
    .max_connections(20)           // 最大连接数
    .min_connections(5)            // 最小连接数
    .acquire_timeout(Duration::from_secs(30))  // 获取超时
    .idle_timeout(Duration::from_secs(600))    // 空闲超时
    .connect("postgres://...").await?;
```

### 批量操作

**❌ 糟糕: 逐条插入**:

```rust
for user in users {
    sqlx::query!("INSERT INTO users (name, email) VALUES ($1, $2)", user.name, user.email)
        .execute(&pool).await?;
}
```

**✅ 优化: 批量插入**:

```rust
let mut query_builder = sqlx::QueryBuilder::new("INSERT INTO users (name, email)");

query_builder.push_values(users, |mut b, user| {
    b.push_bind(user.name)
     .push_bind(user.email);
});

query_builder.build().execute(&pool).await?;
```

**效果**: 100 条记录从 1秒 → 0.1秒

### 预编译语句

```rust
// 预编译语句 (只解析一次)
let stmt = sqlx::query!("SELECT * FROM users WHERE id = $1")
    .persistent(true);  // 持久化

// 多次执行
for id in ids {
    let user = stmt.bind(id).fetch_one(&pool).await?;
}
```

---

## Web 服务优化

### HTTP/2 vs HTTP/1.1

```rust
use axum::Router;
use std::net::SocketAddr;

#[tokio::main]
async fn main() {
    let app = Router::new().route("/", get(handler));
    
    let addr = SocketAddr::from(([0, 0, 0, 0], 3000));
    
    // HTTP/2 自动启用
    axum::Server::bind(&addr)
        .serve(app.into_make_service())
        .await
        .unwrap();
}
```

**HTTP/2 优势**:

- 多路复用
- 头部压缩
- 服务器推送

### 响应压缩

```rust
use tower_http::compression::CompressionLayer;

let app = Router::new()
    .route("/", get(handler))
    .layer(CompressionLayer::new());  // gzip, brotli
```

**效果**: JSON 响应体积减少 70-90%

### 静态资源优化

```rust
use tower_http::services::ServeDir;

let app = Router::new()
    .nest_service("/static", ServeDir::new("static")
        .precompressed_gzip()    // 预压缩的 .gz 文件
        .precompressed_br());    // 预压缩的 .br 文件
```

---

## 实战案例

### 案例1: JSON 解析优化

**场景**: 解析大型 JSON 文件

**方案1: serde_json (通用)**:

```rust
use serde_json::Value;

let json: Value = serde_json::from_str(&data)?;
```

**方案2: simd-json (快 2-3x)**:

```rust
use simd_json;

let mut bytes = data.as_bytes().to_vec();
let json = simd_json::to_borrowed_value(&mut bytes)?;
```

**方案3: sonic-rs (最快)**:

```rust
use sonic_rs;

let json: Value = sonic_rs::from_str(&data)?;
```

**性能对比 (解析 10MB JSON)**:

| 库 | 时间 | 相对速度 |
|----|------|---------|
| serde_json | 120ms | 1x |
| simd-json | 45ms | 2.7x |
| sonic-rs | 30ms | 4x |

### 案例2: 高性能 HTTP 服务

**目标**: 100,000 QPS

```rust
use axum::{Router, routing::get, http::StatusCode};
use tower::ServiceBuilder;
use tower_http::compression::CompressionLayer;

async fn handler() -> &'static str {
    "Hello, World!"
}

#[tokio::main]
async fn main() {
    let app = Router::new()
        .route("/", get(handler))
        .layer(
            ServiceBuilder::new()
                .layer(CompressionLayer::new())
                .into_inner()
        );
    
    // 多线程 runtime
    let listener = tokio::net::TcpListener::bind("0.0.0.0:3000")
        .await
        .unwrap();
    
    axum::serve(listener, app).await.unwrap();
}
```

**配置**:

```toml
[profile.release]
opt-level = 3
lto = "fat"
codegen-units = 1

[build]
rustflags = ["-C", "target-cpu=native"]
```

**结果**: 150,000 QPS on 8-core CPU

### 案例3: 数据处理管道

**场景**: 处理 1GB CSV 文件

```rust
use rayon::prelude::*;
use csv::ReaderBuilder;

fn process_csv(path: &str) -> Result<(), Box<dyn std::error::Error>> {
    let file = std::fs::read_to_string(path)?;
    
    let results: Vec<_> = file
        .par_lines()  // 并行处理每一行
        .skip(1)      // 跳过标题
        .filter_map(|line| {
            let parts: Vec<_> = line.split(',').collect();
            if parts.len() >= 3 {
                Some(process_row(parts))
            } else {
                None
            }
        })
        .collect();
    
    Ok(())
}

fn process_row(parts: Vec<&str>) -> ProcessedData {
    // 处理逻辑
    ProcessedData {}
}
```

**性能**: 1GB 文件处理时间从 30秒 → 5秒

---

## 性能检查清单

**编译时**:

- [ ] 使用 `cargo build --release`
- [ ] 启用 LTO: `lto = "fat"`
- [ ] 单一代码生成单元: `codegen-units = 1`
- [ ] 针对本地 CPU: `target-cpu=native`

**内存**:

- [ ] 预分配容量: `Vec::with_capacity`
- [ ] 避免不必要的 clone
- [ ] 使用 `Copy` 类型
- [ ] 考虑内存池: `bumpalo`

**并发**:

- [ ] CPU 密集: 使用 `rayon`
- [ ] IO 密集: 使用 `tokio`
- [ ] 无锁原语: `Atomic*`

**算法**:

- [ ] 选择正确的数据结构
- [ ] 避免重复计算
- [ ] 使用迭代器而非索引

**IO**:

- [ ] 使用缓冲 IO
- [ ] 批量操作数据库
- [ ] 启用响应压缩

**测量**:

- [ ] 使用 `criterion` 基准测试
- [ ] 使用 `flamegraph` 分析热点
- [ ] 使用 `perf` / `instruments`

---

## 参考资源

**官方文档**:

- **Rust Performance Book**: <https://nnethercote.github.io/perf-book/>
- **Criterion.rs**: <https://bheisler.github.io/criterion.rs/book/>

**工具**:

- **cargo-flamegraph**: <https://github.com/flamegraph-rs/flamegraph>
- **cargo-llvm-lines**: <https://github.com/dtolnay/cargo-llvm-lines>

**深度文章**:

- [Optimizing Rust Programs](https://matklad.github.io/2021/09/04/fast-rust-builds.html)
- [Rust Performance Pitfalls](https://llogiq.github.io/2017/06/01/perf-pitfalls.html)

---

**文档版本**: 1.0.0  
**最后更新**: 2025-10-20  
**贡献者**: Rust 学习社区

**下一步**: [微服务架构](./RUST_MICROSERVICES_ARCHITECTURE_2025.md) | [实战项目](./RUST_FULLSTACK_PROJECT_2025.md)
