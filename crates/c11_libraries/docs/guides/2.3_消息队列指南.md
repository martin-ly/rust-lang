# 2.3 Rust 消息队列指南 (2025)

> **文档定位**: Rust 消息队列完整实战指南  
> **适用人群**: 后端开发者，分布式系统工程师  
> **关联文档**: [3.2 开源库生态全景图](../references/3.2_开源库生态全景图.md) | [2.1 数据库集成指南](./2.1_数据库集成指南.md)

## 📊 目录

- [2.3 Rust 消息队列指南 (2025)](#23-rust-消息队列指南-2025)
  - [📊 目录](#-目录)
  - [📋 目录](#-目录-1)
  - [2.3.1 概述](#231-概述)
    - [2.3.1.1 为什么需要消息队列？](#2311-为什么需要消息队列)
    - [2.3.1.2 消息队列技术栈对比](#2312-消息队列技术栈对比)
  - [2.3.2 Kafka 深度实战](#232-kafka-深度实战)
    - [2.3.2.1 项目初始化](#2321-项目初始化)
    - [2.3.2.2 生产者](#2322-生产者)
    - [2.3.2.3 消费者](#2323-消费者)
    - [2.3.2.4 高级特性](#2324-高级特性)
  - [2.3.3 RabbitMQ 实战](#233-rabbitmq-实战)
    - [2.3.3.1 项目初始化](#2331-项目初始化)
    - [2.3.3.2 基础操作](#2332-基础操作)
    - [2.3.3.3 消息模式](#2333-消息模式)
    - [2.3.3.4 高级特性](#2334-高级特性)
  - [2.3.4 NATS 实战](#234-nats-实战)
    - [2.3.4.1 项目初始化](#2341-项目初始化)
    - [2.3.4.2 基础操作](#2342-基础操作)
    - [2.3.4.3 JetStream](#2343-jetstream)
  - [2.3.5 消息模式](#235-消息模式)
    - [2.3.5.1 点对点模式](#2351-点对点模式)
    - [2.3.5.2 发布订阅模式](#2352-发布订阅模式)
    - [2.3.5.3 请求响应模式](#2353-请求响应模式)
  - [2.3.6 可靠性保证](#236-可靠性保证)
    - [2.3.6.1 消息确认](#2361-消息确认)
    - [2.3.6.2 事务支持](#2362-事务支持)
    - [2.3.6.3 死信队列](#2363-死信队列)
  - [2.3.7 性能优化](#237-性能优化)
    - [2.3.7.1 批量发送](#2371-批量发送)
    - [2.3.7.2 并发消费](#2372-并发消费)
    - [2.3.7.3 背压处理](#2373-背压处理)
  - [2.3.8 生产实践](#238-生产实践)
    - [2.3.8.1 监控告警](#2381-监控告警)
    - [2.3.8.2 容错处理](#2382-容错处理)
    - [2.3.8.3 容量规划](#2383-容量规划)
  - [2.3.9 最佳实践](#239-最佳实践)
    - [2.3.9.1 消息设计](#2391-消息设计)
    - [2.3.9.2 错误处理](#2392-错误处理)
    - [2.3.9.3 安全实践](#2393-安全实践)

**Rust 版本**: 1.90  
**文档状态**: ✅ 生产就绪  
**最后更新**: 2025-10-21

---

## 📋 目录

- [2.3 Rust 消息队列指南 (2025)](#23-rust-消息队列指南-2025)
  - [📊 目录](#-目录)
  - [📋 目录](#-目录-1)
  - [2.3.1 概述](#231-概述)
    - [2.3.1.1 为什么需要消息队列？](#2311-为什么需要消息队列)
    - [2.3.1.2 消息队列技术栈对比](#2312-消息队列技术栈对比)
  - [2.3.2 Kafka 深度实战](#232-kafka-深度实战)
    - [2.3.2.1 项目初始化](#2321-项目初始化)
    - [2.3.2.2 生产者](#2322-生产者)
    - [2.3.2.3 消费者](#2323-消费者)
    - [2.3.2.4 高级特性](#2324-高级特性)
  - [2.3.3 RabbitMQ 实战](#233-rabbitmq-实战)
    - [2.3.3.1 项目初始化](#2331-项目初始化)
    - [2.3.3.2 基础操作](#2332-基础操作)
    - [2.3.3.3 消息模式](#2333-消息模式)
    - [2.3.3.4 高级特性](#2334-高级特性)
  - [2.3.4 NATS 实战](#234-nats-实战)
    - [2.3.4.1 项目初始化](#2341-项目初始化)
    - [2.3.4.2 基础操作](#2342-基础操作)
    - [2.3.4.3 JetStream](#2343-jetstream)
  - [2.3.5 消息模式](#235-消息模式)
    - [2.3.5.1 点对点模式](#2351-点对点模式)
    - [2.3.5.2 发布订阅模式](#2352-发布订阅模式)
    - [2.3.5.3 请求响应模式](#2353-请求响应模式)
  - [2.3.6 可靠性保证](#236-可靠性保证)
    - [2.3.6.1 消息确认](#2361-消息确认)
    - [2.3.6.2 事务支持](#2362-事务支持)
    - [2.3.6.3 死信队列](#2363-死信队列)
  - [2.3.7 性能优化](#237-性能优化)
    - [2.3.7.1 批量发送](#2371-批量发送)
    - [2.3.7.2 并发消费](#2372-并发消费)
    - [2.3.7.3 背压处理](#2373-背压处理)
  - [2.3.8 生产实践](#238-生产实践)
    - [2.3.8.1 监控告警](#2381-监控告警)
    - [2.3.8.2 容错处理](#2382-容错处理)
    - [2.3.8.3 容量规划](#2383-容量规划)
  - [2.3.9 最佳实践](#239-最佳实践)
    - [2.3.9.1 消息设计](#2391-消息设计)
    - [2.3.9.2 错误处理](#2392-错误处理)
    - [2.3.9.3 安全实践](#2393-安全实践)

---

## 2.3.1 概述

### 2.3.1.1 为什么需要消息队列？

**核心价值**:

1. ✅ **解耦** - 服务间松耦合，降低依赖
2. ✅ **异步** - 非阻塞处理，提高响应速度
3. ✅ **削峰填谷** - 应对流量突发
4. ✅ **可靠性** - 消息持久化，保证不丢失
5. ✅ **扩展性** - 水平扩展，提高吞吐量

**适用场景**:

```mermaid
graph LR
    A[消息队列应用场景] --> B[异步处理]
    A --> C[服务解耦]
    A --> D[流量削峰]
    A --> E[日志收集]
    A --> F[事件驱动]
    
    B --> B1[邮件发送]
    B --> B2[图片处理]
    C --> C1[订单系统]
    C --> C2[库存系统]
    D --> D1[秒杀活动]
    D --> D2[大促活动]
```

### 2.3.1.2 消息队列技术栈对比

| 方案 | 类型 | 特点 | 吞吐量 | 延迟 | 适用场景 | 成熟度 |
|------|------|------|--------|------|----------|--------|
| **Kafka** | 日志型 | 高吞吐，持久化 | ⭐⭐⭐⭐⭐ | 10ms | 大数据，日志 | ⭐⭐⭐⭐⭐ |
| **RabbitMQ** | AMQP | 功能丰富，灵活 | ⭐⭐⭐⭐ | 1ms | 通用场景 | ⭐⭐⭐⭐⭐ |
| **NATS** | 轻量级 | 低延迟，简单 | ⭐⭐⭐⭐ | <1ms | 微服务 | ⭐⭐⭐⭐ |
| **Pulsar** | 云原生 | 多租户，地域复制 | ⭐⭐⭐⭐⭐ | 5ms | 云平台 | ⭐⭐⭐⭐ |

---

## 2.3.2 Kafka 深度实战

### 2.3.2.1 项目初始化

**依赖配置**:

```toml
[dependencies]
# Kafka 客户端
rdkafka = { version = "0.37", features = [
    "tokio",           # Tokio 异步支持
    "cmake-build",     # CMake 构建
    "ssl",             # SSL/TLS 支持
    "sasl",            # SASL 认证
] }

# 异步运行时
tokio = { version = "1.48", features = ["full"] }

# 序列化
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# 错误处理
anyhow = "1.0"
thiserror = "2.0"

# 日志
tracing = "0.1"
tracing-subscriber = "0.3"
```

**配置结构**:

```rust
use rdkafka::ClientConfig;

pub struct KafkaConfig {
    pub brokers: String,
    pub group_id: String,
    pub security_protocol: Option<String>,
    pub sasl_mechanism: Option<String>,
    pub sasl_username: Option<String>,
    pub sasl_password: Option<String>,
}

impl Default for KafkaConfig {
    fn default() -> Self {
        Self {
            brokers: "localhost:9092".to_string(),
            group_id: "my-consumer-group".to_string(),
            security_protocol: None,
            sasl_mechanism: None,
            sasl_username: None,
            sasl_password: None,
        }
    }
}

impl KafkaConfig {
    pub fn to_client_config(&self) -> ClientConfig {
        let mut config = ClientConfig::new();
        config.set("bootstrap.servers", &self.brokers);
        config.set("group.id", &self.group_id);
        
        if let Some(protocol) = &self.security_protocol {
            config.set("security.protocol", protocol);
        }
        
        if let Some(mechanism) = &self.sasl_mechanism {
            config.set("sasl.mechanism", mechanism);
        }
        
        if let Some(username) = &self.sasl_username {
            config.set("sasl.username", username);
        }
        
        if let Some(password) = &self.sasl_password {
            config.set("sasl.password", password);
        }
        
        config
    }
}
```

### 2.3.2.2 生产者

**基础生产者**:

```rust
use rdkafka::producer::{FutureProducer, FutureRecord};
use rdkafka::util::Timeout;
use std::time::Duration;

pub struct KafkaProducer {
    producer: FutureProducer,
}

impl KafkaProducer {
    pub fn new(config: &KafkaConfig) -> Result<Self, anyhow::Error> {
        let producer: FutureProducer = config
            .to_client_config()
            .set("message.timeout.ms", "5000")
            .set("compression.type", "snappy")
            .create()?;
        
        Ok(Self { producer })
    }
    
    // 发送消息
    pub async fn send_message(
        &self,
        topic: &str,
        key: Option<&str>,
        payload: &str,
    ) -> Result<(i32, i64), anyhow::Error> {
        let record = FutureRecord::to(topic)
            .key(key.unwrap_or(""))
            .payload(payload);
        
        let delivery_status = self.producer
            .send(record, Timeout::After(Duration::from_secs(5)))
            .await;
        
        match delivery_status {
            Ok((partition, offset)) => {
                tracing::info!(
                    topic = topic,
                    partition = partition,
                    offset = offset,
                    "Message sent"
                );
                Ok((partition, offset))
            }
            Err((e, _)) => {
                tracing::error!(error = ?e, "Failed to send message");
                Err(e.into())
            }
        }
    }
    
    // 发送结构化消息
    pub async fn send_json<T: serde::Serialize>(
        &self,
        topic: &str,
        key: Option<&str>,
        data: &T,
    ) -> Result<(i32, i64), anyhow::Error> {
        let payload = serde_json::to_string(data)?;
        self.send_message(topic, key, &payload).await
    }
}
```

**使用示例**:

```rust
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct OrderEvent {
    pub order_id: String,
    pub user_id: u64,
    pub amount: f64,
    pub timestamp: i64,
}

pub async fn producer_example() -> Result<(), anyhow::Error> {
    let config = KafkaConfig::default();
    let producer = KafkaProducer::new(&config)?;
    
    let event = OrderEvent {
        order_id: "ORD-12345".to_string(),
        user_id: 1001,
        amount: 99.99,
        timestamp: chrono::Utc::now().timestamp(),
    };
    
    let (partition, offset) = producer
        .send_json("orders", Some("ORD-12345"), &event)
        .await?;
    
    println!("Sent to partition {} at offset {}", partition, offset);
    
    Ok(())
}
```

### 2.3.2.3 消费者

**基础消费者**:

```rust
use rdkafka::consumer::{Consumer, StreamConsumer};
use rdkafka::Message;
use futures::StreamExt;

pub struct KafkaConsumer {
    consumer: StreamConsumer,
}

impl KafkaConsumer {
    pub fn new(config: &KafkaConfig, topics: &[&str]) -> Result<Self, anyhow::Error> {
        let consumer: StreamConsumer = config
            .to_client_config()
            .set("enable.auto.commit", "true")
            .set("auto.commit.interval.ms", "5000")
            .set("session.timeout.ms", "6000")
            .set("auto.offset.reset", "earliest")
            .create()?;
        
        consumer.subscribe(topics)?;
        
        Ok(Self { consumer })
    }
    
    // 消费消息
    pub async fn consume<F>(&self, mut handler: F) -> Result<(), anyhow::Error>
    where
        F: FnMut(&str, Option<&str>, &[u8]) -> Result<(), anyhow::Error>,
    {
        let mut stream = self.consumer.stream();
        
        while let Some(message) = stream.next().await {
            match message {
                Ok(m) => {
                    let topic = m.topic();
                    let key = m.key().map(|k| std::str::from_utf8(k).unwrap_or(""));
                    let payload = m.payload().unwrap_or(&[]);
                    
                    if let Err(e) = handler(topic, key, payload) {
                        tracing::error!(
                            error = ?e,
                            topic = topic,
                            "Failed to process message"
                        );
                    }
                }
                Err(e) => {
                    tracing::error!(error = ?e, "Kafka error");
                }
            }
        }
        
        Ok(())
    }
    
    // 消费 JSON 消息
    pub async fn consume_json<T, F>(&self, mut handler: F) -> Result<(), anyhow::Error>
    where
        T: for<'de> Deserialize<'de>,
        F: FnMut(T) -> Result<(), anyhow::Error>,
    {
        self.consume(|_topic, _key, payload| {
            let data: T = serde_json::from_slice(payload)?;
            handler(data)
        }).await
    }
}
```

**使用示例**:

```rust
pub async fn consumer_example() -> Result<(), anyhow::Error> {
    let config = KafkaConfig::default();
    let consumer = KafkaConsumer::new(&config, &["orders"])?;
    
    consumer.consume_json::<OrderEvent, _>(|event| {
        println!("Received order: {:?}", event);
        
        // 处理订单
        process_order(&event)?;
        
        Ok(())
    }).await?;
    
    Ok(())
}

fn process_order(event: &OrderEvent) -> Result<(), anyhow::Error> {
    // 业务逻辑
    println!("Processing order {}", event.order_id);
    Ok(())
}
```

### 2.3.2.4 高级特性

**手动提交偏移量**:

```rust
use rdkafka::consumer::{CommitMode, Consumer};

pub async fn manual_commit_example(
    config: &KafkaConfig,
) -> Result<(), anyhow::Error> {
    let consumer: StreamConsumer = config
        .to_client_config()
        .set("enable.auto.commit", "false")  // 禁用自动提交
        .create()?;
    
    consumer.subscribe(&["orders"])?;
    
    let mut stream = consumer.stream();
    
    while let Some(message) = stream.next().await {
        match message {
            Ok(m) => {
                // 处理消息
                let payload = m.payload().unwrap_or(&[]);
                process_message(payload)?;
                
                // 手动提交偏移量
                consumer.commit_message(&m, CommitMode::Async)?;
            }
            Err(e) => {
                tracing::error!(error = ?e, "Kafka error");
            }
        }
    }
    
    Ok(())
}

fn process_message(payload: &[u8]) -> Result<(), anyhow::Error> {
    // 处理逻辑
    Ok(())
}
```

**事务生产者**:

```rust
use rdkafka::producer::FutureProducer;

pub async fn transactional_producer_example() -> Result<(), anyhow::Error> {
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("transactional.id", "my-transactional-id")
        .create()?;
    
    // 初始化事务
    producer.init_transactions(Timeout::After(Duration::from_secs(5)))?;
    
    // 开始事务
    producer.begin_transaction()?;
    
    // 发送消息
    for i in 0..10 {
        let record = FutureRecord::to("orders")
            .key(&format!("key-{}", i))
            .payload(&format!("value-{}", i));
        
        producer.send(record, Timeout::Never).await?;
    }
    
    // 提交事务
    producer.commit_transaction(Timeout::After(Duration::from_secs(5)))?;
    
    Ok(())
}
```

**分区管理**:

```rust
use rdkafka::producer::FutureRecord;

pub async fn partition_example(
    producer: &FutureProducer,
) -> Result<(), anyhow::Error> {
    // 发送到指定分区
    let record = FutureRecord::to("orders")
        .partition(0)  // 指定分区 0
        .key("key")
        .payload("value");
    
    producer.send(record, Timeout::Never).await?;
    
    Ok(())
}
```

---

## 2.3.3 RabbitMQ 实战

### 2.3.3.1 项目初始化

**依赖配置**:

```toml
[dependencies]
# RabbitMQ 客户端
lapin = "2.5"

# 异步运行时
tokio = { version = "1.48", features = ["full"] }

# 序列化
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# 错误处理
anyhow = "1.0"
thiserror = "2.0"

# 日志
tracing = "0.1"
```

**连接配置**:

```rust
use lapin::{Connection, ConnectionProperties, Channel};

pub struct RabbitMQConfig {
    pub url: String,
}

impl Default for RabbitMQConfig {
    fn default() -> Self {
        Self {
            url: "amqp://guest:guest@localhost:5672/%2f".to_string(),
        }
    }
}

pub async fn create_connection(
    config: &RabbitMQConfig,
) -> Result<Connection, anyhow::Error> {
    let conn = Connection::connect(
        &config.url,
        ConnectionProperties::default(),
    ).await?;
    
    Ok(conn)
}

pub async fn create_channel(
    conn: &Connection,
) -> Result<Channel, anyhow::Error> {
    let channel = conn.create_channel().await?;
    Ok(channel)
}
```

### 2.3.3.2 基础操作

**声明队列和交换器**:

```rust
use lapin::{
    options::*,
    types::FieldTable,
    ExchangeKind,
};

pub async fn declare_queue(
    channel: &Channel,
    queue_name: &str,
) -> Result<(), anyhow::Error> {
    channel.queue_declare(
        queue_name,
        QueueDeclareOptions {
            durable: true,      // 持久化
            exclusive: false,   // 非独占
            auto_delete: false, // 不自动删除
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    Ok(())
}

pub async fn declare_exchange(
    channel: &Channel,
    exchange_name: &str,
    exchange_kind: ExchangeKind,
) -> Result<(), anyhow::Error> {
    channel.exchange_declare(
        exchange_name,
        exchange_kind,
        ExchangeDeclareOptions {
            durable: true,
            auto_delete: false,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    Ok(())
}

pub async fn bind_queue(
    channel: &Channel,
    queue_name: &str,
    exchange_name: &str,
    routing_key: &str,
) -> Result<(), anyhow::Error> {
    channel.queue_bind(
        queue_name,
        exchange_name,
        routing_key,
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    Ok(())
}
```

**发布消息**:

```rust
use lapin::BasicProperties;

pub async fn publish_message(
    channel: &Channel,
    exchange: &str,
    routing_key: &str,
    payload: &[u8],
) -> Result<(), anyhow::Error> {
    channel.basic_publish(
        exchange,
        routing_key,
        BasicPublishOptions::default(),
        payload,
        BasicProperties::default()
            .with_delivery_mode(2)  // 持久化消息
            .with_content_type("application/json".into()),
    ).await?;
    
    Ok(())
}

pub async fn publish_json<T: serde::Serialize>(
    channel: &Channel,
    exchange: &str,
    routing_key: &str,
    data: &T,
) -> Result<(), anyhow::Error> {
    let payload = serde_json::to_vec(data)?;
    publish_message(channel, exchange, routing_key, &payload).await
}
```

**消费消息**:

```rust
use lapin::Consumer;
use futures::StreamExt;

pub async fn consume_messages(
    channel: &Channel,
    queue_name: &str,
) -> Result<(), anyhow::Error> {
    let mut consumer = channel.basic_consume(
        queue_name,
        "my-consumer",
        BasicConsumeOptions::default(),
        FieldTable::default(),
    ).await?;
    
    while let Some(delivery) = consumer.next().await {
        match delivery {
            Ok(delivery) => {
                let payload = &delivery.data;
                
                // 处理消息
                match process_message(payload) {
                    Ok(_) => {
                        // 确认消息
                        delivery.ack(BasicAckOptions::default()).await?;
                    }
                    Err(e) => {
                        tracing::error!(error = ?e, "Failed to process message");
                        // 拒绝消息并重新入队
                        delivery.nack(BasicNackOptions {
                            requeue: true,
                            ..Default::default()
                        }).await?;
                    }
                }
            }
            Err(e) => {
                tracing::error!(error = ?e, "Consumer error");
            }
        }
    }
    
    Ok(())
}

fn process_message(payload: &[u8]) -> Result<(), anyhow::Error> {
    // 处理逻辑
    Ok(())
}
```

### 2.3.3.3 消息模式

**工作队列 (Work Queue)**:

```rust
pub async fn work_queue_pattern(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let queue = "task_queue";
    
    // 声明队列
    channel.queue_declare(
        queue,
        QueueDeclareOptions {
            durable: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // QoS 设置 (每次只消费 1 条消息)
    channel.basic_qos(
        1,
        BasicQosOptions::default(),
    ).await?;
    
    Ok(())
}
```

**发布订阅 (Pub/Sub)**:

```rust
pub async fn pubsub_pattern(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let exchange = "logs";
    
    // 声明 fanout 交换器
    channel.exchange_declare(
        exchange,
        ExchangeKind::Fanout,
        ExchangeDeclareOptions {
            durable: false,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // 声明临时队列
    let queue = channel.queue_declare(
        "",
        QueueDeclareOptions {
            exclusive: true,
            auto_delete: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // 绑定队列到交换器
    channel.queue_bind(
        queue.name().as_str(),
        exchange,
        "",
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    Ok(())
}
```

**路由模式 (Routing)**:

```rust
pub async fn routing_pattern(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let exchange = "direct_logs";
    
    // 声明 direct 交换器
    channel.exchange_declare(
        exchange,
        ExchangeKind::Direct,
        ExchangeDeclareOptions {
            durable: false,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // 根据路由键绑定
    let queue = "error_logs";
    channel.queue_bind(
        queue,
        exchange,
        "error",  // 只接收 error 级别的消息
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    Ok(())
}
```

**主题模式 (Topic)**:

```rust
pub async fn topic_pattern(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let exchange = "topic_logs";
    
    // 声明 topic 交换器
    channel.exchange_declare(
        exchange,
        ExchangeKind::Topic,
        ExchangeDeclareOptions {
            durable: false,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // 使用通配符绑定
    // * 匹配一个单词
    // # 匹配零个或多个单词
    channel.queue_bind(
        "critical_queue",
        exchange,
        "*.critical.*",  // 匹配 user.critical.login 等
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    Ok(())
}
```

### 2.3.3.4 高级特性

**死信队列 (DLX)**:

```rust
pub async fn setup_dlx(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let main_queue = "main_queue";
    let dlx_exchange = "dlx_exchange";
    let dlx_queue = "dlx_queue";
    
    // 1. 声明死信交换器
    channel.exchange_declare(
        dlx_exchange,
        ExchangeKind::Direct,
        ExchangeDeclareOptions {
            durable: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // 2. 声明死信队列
    channel.queue_declare(
        dlx_queue,
        QueueDeclareOptions {
            durable: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // 3. 绑定死信队列
    channel.queue_bind(
        dlx_queue,
        dlx_exchange,
        "",
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    // 4. 声明主队列并设置 DLX
    let mut args = FieldTable::default();
    args.insert("x-dead-letter-exchange".into(), dlx_exchange.into());
    
    channel.queue_declare(
        main_queue,
        QueueDeclareOptions {
            durable: true,
            ..Default::default()
        },
        args,
    ).await?;
    
    Ok(())
}
```

**消息 TTL**:

```rust
pub async fn message_ttl_example(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    // 发送带 TTL 的消息
    channel.basic_publish(
        "",
        "my_queue",
        BasicPublishOptions::default(),
        b"message",
        BasicProperties::default()
            .with_expiration("60000".into()),  // 60 秒过期
    ).await?;
    
    Ok(())
}
```

---

## 2.3.4 NATS 实战

### 2.3.4.1 项目初始化

**依赖配置**:

```toml
[dependencies]
# NATS 客户端
async-nats = "0.37"

# 异步运行时
tokio = { version = "1.48", features = ["full"] }

# 序列化
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# 错误处理
anyhow = "1.0"
```

**连接配置**:

```rust
use async_nats::Client;

pub async fn create_nats_client() -> Result<Client, anyhow::Error> {
    let client = async_nats::connect("nats://localhost:4222").await?;
    Ok(client)
}
```

### 2.3.4.2 基础操作

**发布订阅**:

```rust
pub async fn publish_example(
    client: &Client,
) -> Result<(), anyhow::Error> {
    // 发布消息
    client.publish("subject", "Hello, NATS!".into()).await?;
    
    Ok(())
}

pub async fn subscribe_example(
    client: &Client,
) -> Result<(), anyhow::Error> {
    let mut subscriber = client.subscribe("subject").await?;
    
    while let Some(message) = subscriber.next().await {
        let payload = String::from_utf8_lossy(&message.payload);
        println!("Received: {}", payload);
    }
    
    Ok(())
}
```

**请求响应**:

```rust
use std::time::Duration;

pub async fn request_reply_example(
    client: &Client,
) -> Result<(), anyhow::Error> {
    // 请求端
    let response = client
        .request("help", "need help".into())
        .await?;
    
    println!("Response: {:?}", response.payload);
    
    Ok(())
}

pub async fn reply_handler(
    client: &Client,
) -> Result<(), anyhow::Error> {
    // 响应端
    let mut subscriber = client.subscribe("help").await?;
    
    while let Some(message) = subscriber.next().await {
        if let Some(reply) = message.reply {
            client.publish(reply, "I can help!".into()).await?;
        }
    }
    
    Ok(())
}
```

**队列组**:

```rust
pub async fn queue_group_example(
    client: &Client,
) -> Result<(), anyhow::Error> {
    // 多个消费者共享工作负载
    let mut subscriber = client
        .queue_subscribe("tasks", "workers".to_string())
        .await?;
    
    while let Some(message) = subscriber.next().await {
        println!("Worker processing: {:?}", message.payload);
    }
    
    Ok(())
}
```

### 2.3.4.3 JetStream

**启用 JetStream**:

```rust
use async_nats::jetstream;

pub async fn jetstream_example(
    client: &Client,
) -> Result<(), anyhow::Error> {
    let jetstream = jetstream::new(client.clone());
    
    // 创建 Stream
    let _stream = jetstream
        .create_stream(jetstream::stream::Config {
            name: "ORDERS".to_string(),
            subjects: vec!["orders.*".to_string()],
            max_messages: 10_000,
            ..Default::default()
        })
        .await?;
    
    // 发布消息
    let ack = jetstream
        .publish("orders.new", "order data".into())
        .await?;
    
    println!("Published to sequence: {}", ack.await?.sequence);
    
    Ok(())
}
```

**持久化消费者**:

```rust
pub async fn durable_consumer_example(
    client: &Client,
) -> Result<(), anyhow::Error> {
    let jetstream = jetstream::new(client.clone());
    
    // 创建持久化消费者
    let consumer = jetstream
        .create_consumer_on_stream(
            jetstream::consumer::Config {
                durable_name: Some("order_processor".to_string()),
                ack_policy: jetstream::consumer::AckPolicy::Explicit,
                ..Default::default()
            },
            "ORDERS",
        )
        .await?;
    
    let mut messages = consumer.messages().await?;
    
    while let Some(message) = messages.next().await {
        let message = message?;
        
        // 处理消息
        println!("Processing: {:?}", message.payload);
        
        // 确认消息
        message.ack().await?;
    }
    
    Ok(())
}
```

---

## 2.3.5 消息模式

### 2.3.5.1 点对点模式

**特点**:

- 每条消息只被一个消费者处理
- 消费者竞争获取消息
- 适合任务分发场景

**实现** (Kafka):

```rust
pub async fn point_to_point_kafka() -> Result<(), anyhow::Error> {
    let config = KafkaConfig {
        group_id: "task-workers".to_string(),
        ..Default::default()
    };
    
    let consumer = KafkaConsumer::new(&config, &["tasks"])?;
    
    consumer.consume(|_topic, _key, payload| {
        // 只有一个消费者会处理这条消息
        process_task(payload)?;
        Ok(())
    }).await?;
    
    Ok(())
}

fn process_task(payload: &[u8]) -> Result<(), anyhow::Error> {
    // 处理任务
    Ok(())
}
```

### 2.3.5.2 发布订阅模式

**特点**:

- 每条消息被所有订阅者接收
- 订阅者独立处理
- 适合事件通知场景

**实现** (RabbitMQ):

```rust
pub async fn publish_subscribe_rabbitmq(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let exchange = "events";
    
    // 发布者
    channel.exchange_declare(
        exchange,
        ExchangeKind::Fanout,
        ExchangeDeclareOptions::default(),
        FieldTable::default(),
    ).await?;
    
    // 订阅者 1: 邮件服务
    let queue1 = channel.queue_declare(
        "",
        QueueDeclareOptions {
            exclusive: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    channel.queue_bind(
        queue1.name().as_str(),
        exchange,
        "",
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    // 订阅者 2: 短信服务
    let queue2 = channel.queue_declare(
        "",
        QueueDeclareOptions {
            exclusive: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    channel.queue_bind(
        queue2.name().as_str(),
        exchange,
        "",
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    Ok(())
}
```

### 2.3.5.3 请求响应模式

**特点**:

- 同步调用语义
- 需要响应队列
- 适合 RPC 场景

**实现** (NATS):

```rust
pub async fn request_response_nats(
    client: &Client,
) -> Result<(), anyhow::Error> {
    // 服务端
    tokio::spawn({
        let client = client.clone();
        async move {
            let mut subscriber = client.subscribe("rpc.add").await.unwrap();
            
            while let Some(message) = subscriber.next().await {
                if let Some(reply) = message.reply {
                    // 处理请求
                    let result = "result";
                    client.publish(reply, result.into()).await.unwrap();
                }
            }
        }
    });
    
    // 客户端
    let response = client
        .request("rpc.add", "1 + 1".into())
        .await?;
    
    println!("Result: {:?}", response.payload);
    
    Ok(())
}
```

---

## 2.3.6 可靠性保证

### 2.3.6.1 消息确认

**生产者确认** (Kafka):

```rust
pub async fn producer_acks_example() -> Result<(), anyhow::Error> {
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("acks", "all")  // 等待所有副本确认
        .create()?;
    
    let record = FutureRecord::to("orders")
        .key("key")
        .payload("value");
    
    // 等待确认
    let (partition, offset) = producer
        .send(record, Timeout::After(Duration::from_secs(5)))
        .await
        .map_err(|(e, _)| e)?;
    
    println!("Confirmed: partition={}, offset={}", partition, offset);
    
    Ok(())
}
```

**消费者确认** (RabbitMQ):

```rust
pub async fn consumer_acks_example(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let mut consumer = channel.basic_consume(
        "orders",
        "",
        BasicConsumeOptions {
            no_ack: false,  // 需要手动确认
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    while let Some(delivery) = consumer.next().await {
        match delivery {
            Ok(delivery) => {
                // 处理成功,确认消息
                if process_message(&delivery.data).is_ok() {
                    delivery.ack(BasicAckOptions::default()).await?;
                } else {
                    // 处理失败,拒绝并重新入队
                    delivery.nack(BasicNackOptions {
                        requeue: true,
                        ..Default::default()
                    }).await?;
                }
            }
            Err(e) => {
                tracing::error!(error = ?e, "Consumer error");
            }
        }
    }
    
    Ok(())
}
```

### 2.3.6.2 事务支持

**Kafka 事务**:

```rust
pub async fn kafka_transaction() -> Result<(), anyhow::Error> {
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("transactional.id", "txn-1")
        .create()?;
    
    producer.init_transactions(Timeout::After(Duration::from_secs(5)))?;
    producer.begin_transaction()?;
    
    // 发送多条消息
    for i in 0..10 {
        let record = FutureRecord::to("orders")
            .payload(&format!("message-{}", i));
        producer.send(record, Timeout::Never).await?;
    }
    
    // 提交事务
    producer.commit_transaction(Timeout::After(Duration::from_secs(5)))?;
    
    Ok(())
}
```

### 2.3.6.3 死信队列

**RabbitMQ DLQ**:

```rust
pub async fn setup_dlq(
    channel: &Channel,
) -> Result<(), anyhow::Error> {
    let main_queue = "orders";
    let dlq = "orders_dlq";
    let dlx = "dlx";
    
    // 1. 创建死信交换器
    channel.exchange_declare(
        dlx,
        ExchangeKind::Direct,
        ExchangeDeclareOptions {
            durable: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    // 2. 创建死信队列
    channel.queue_declare(
        dlq,
        QueueDeclareOptions {
            durable: true,
            ..Default::default()
        },
        FieldTable::default(),
    ).await?;
    
    channel.queue_bind(
        dlq,
        dlx,
        "",
        QueueBindOptions::default(),
        FieldTable::default(),
    ).await?;
    
    // 3. 创建主队列并配置 DLX
    let mut args = FieldTable::default();
    args.insert("x-dead-letter-exchange".into(), dlx.into());
    
    channel.queue_declare(
        main_queue,
        QueueDeclareOptions {
            durable: true,
            ..Default::default()
        },
        args,
    ).await?;
    
    Ok(())
}
```

---

## 2.3.7 性能优化

### 2.3.7.1 批量发送

**Kafka 批量生产**:

```rust
pub async fn batch_send_kafka(
    producer: &FutureProducer,
    messages: Vec<String>,
) -> Result<(), anyhow::Error> {
    let mut futures = Vec::new();
    
    for msg in messages {
        let record = FutureRecord::to("orders").payload(&msg);
        let future = producer.send(record, Timeout::Never);
        futures.push(future);
    }
    
    // 等待所有消息发送完成
    for future in futures {
        future.await?;
    }
    
    Ok(())
}
```

### 2.3.7.2 并发消费

**多线程消费**:

```rust
use tokio::task::JoinSet;

pub async fn concurrent_consume(
    config: &KafkaConfig,
    num_workers: usize,
) -> Result<(), anyhow::Error> {
    let mut set = JoinSet::new();
    
    for i in 0..num_workers {
        let config = config.clone();
        set.spawn(async move {
            let consumer = KafkaConsumer::new(&config, &["orders"]).unwrap();
            
            consumer.consume(|_topic, _key, payload| {
                println!("Worker {} processing message", i);
                process_message(payload)?;
                Ok(())
            }).await.unwrap();
        });
    }
    
    while let Some(res) = set.join_next().await {
        res?;
    }
    
    Ok(())
}
```

### 2.3.7.3 背压处理

**流量控制**:

```rust
use tokio::sync::Semaphore;
use std::sync::Arc;

pub async fn backpressure_example(
    consumer: &KafkaConsumer,
) -> Result<(), anyhow::Error> {
    let semaphore = Arc::new(Semaphore::new(10)); // 最多并发处理 10 条消息
    
    consumer.consume(|_topic, _key, payload| {
        let semaphore = semaphore.clone();
        
        tokio::spawn(async move {
            let _permit = semaphore.acquire().await.unwrap();
            
            // 处理消息
            process_message(payload).unwrap();
        });
        
        Ok(())
    }).await?;
    
    Ok(())
}
```

---

## 2.3.8 生产实践

### 2.3.8.1 监控告警

**Kafka 监控**:

```rust
use rdkafka::statistics::Statistics;

pub async fn kafka_monitoring(
    consumer: &StreamConsumer,
) -> Result<(), anyhow::Error> {
    // 获取统计信息
    consumer.context();
    
    // 记录指标
    tracing::info!(
        consumer_group = "my-group",
        "Consumer lag and metrics"
    );
    
    Ok(())
}
```

### 2.3.8.2 容错处理

**重试机制**:

```rust
pub async fn retry_mechanism(
    producer: &FutureProducer,
    message: &str,
    max_retries: u32,
) -> Result<(), anyhow::Error> {
    let mut retries = 0;
    
    loop {
        let record = FutureRecord::to("orders").payload(message);
        
        match producer.send(record, Timeout::After(Duration::from_secs(5))).await {
            Ok(_) => break,
            Err((e, _)) => {
                retries += 1;
                if retries >= max_retries {
                    return Err(e.into());
                }
                
                tracing::warn!(retries = retries, "Retrying send");
                tokio::time::sleep(Duration::from_secs(2_u64.pow(retries))).await;
            }
        }
    }
    
    Ok(())
}
```

### 2.3.8.3 容量规划

**吞吐量估算**:

```rust
pub fn estimate_throughput(
    msg_size_kb: f64,
    msg_per_sec: f64,
) -> f64 {
    // 估算带宽需求 (MB/s)
    msg_size_kb * msg_per_sec / 1024.0
}

pub fn estimate_storage(
    msg_size_kb: f64,
    msg_per_sec: f64,
    retention_days: u32,
) -> f64 {
    // 估算存储需求 (GB)
    let daily_volume = msg_size_kb * msg_per_sec * 86400.0 / (1024.0 * 1024.0);
    daily_volume * retention_days as f64
}
```

---

## 2.3.9 最佳实践

### 2.3.9.1 消息设计

**消息结构**:

```rust
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct Message<T> {
    pub id: String,
    pub timestamp: i64,
    pub version: String,
    pub event_type: String,
    pub data: T,
}

impl<T> Message<T> {
    pub fn new(event_type: String, data: T) -> Self {
        Self {
            id: uuid::Uuid::new_v4().to_string(),
            timestamp: chrono::Utc::now().timestamp(),
            version: "1.0".to_string(),
            event_type,
            data,
        }
    }
}
```

### 2.3.9.2 错误处理

**自定义错误类型**:

```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum MessagingError {
    #[error("Failed to send message: {0}")]
    SendError(String),
    
    #[error("Failed to consume message: {0}")]
    ConsumeError(String),
    
    #[error("Serialization error: {0}")]
    SerializationError(#[from] serde_json::Error),
    
    #[error("Kafka error: {0}")]
    KafkaError(#[from] rdkafka::error::KafkaError),
}
```

### 2.3.9.3 安全实践

1. ✅ **使用 TLS 加密**
2. ✅ **启用 SASL 认证**
3. ✅ **限制网络访问**
4. ✅ **消息加密**
5. ✅ **审计日志**
6. ✅ **访问控制**

```rust
// TLS 配置示例
pub fn create_secure_config() -> ClientConfig {
    let mut config = ClientConfig::new();
    config.set("bootstrap.servers", "localhost:9092");
    config.set("security.protocol", "SASL_SSL");
    config.set("sasl.mechanism", "PLAIN");
    config.set("sasl.username", "user");
    config.set("sasl.password", "password");
    config
}
```

---

**文档版本**: v1.0  
**最后更新**: 2025-10-21  
**维护团队**: Rust 学习社区

---

**✅ Rust 消息队列指南完成！** 🎉
