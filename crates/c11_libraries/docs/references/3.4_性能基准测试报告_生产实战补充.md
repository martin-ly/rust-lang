# 3.4.2 Rust æ€§èƒ½ä¼˜åŒ–ç”Ÿäº§å®æˆ˜æ¡ˆä¾‹é›†

> **æ–‡æ¡£å®šä½**: çœŸå®ç”Ÿäº§ç¯å¢ƒæ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹ï¼Œå¯å¤åˆ¶çš„ä¼˜åŒ–æ–¹æ¡ˆ  
> **é€‚ç”¨äººç¾¤**: æ€§èƒ½å·¥ç¨‹å¸ˆã€æ¶æ„å¸ˆã€è¿ç»´å·¥ç¨‹å¸ˆ  
> **å…³è”æ–‡æ¡£**: [3.4 æ€§èƒ½æŠ¥å‘Š](3.4_æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š.md) | [3.3 æˆç†Ÿåº¦çŸ©é˜µ](3.3_åº“æˆç†Ÿåº¦è¯„ä¼°çŸ©é˜µ.md) | [1.1 ä¸»ç´¢å¼•](../1.1_ä¸»ç´¢å¼•å¯¼èˆª.md)

**æœ€åæ›´æ–°**: 2025-10-23  
**Rust ç‰ˆæœ¬**: 1.90+  
**æ¡ˆä¾‹æ•°é‡**: 10+ ç”Ÿäº§æ¡ˆä¾‹  
**æ–‡æ¡£çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª

---

## ğŸ“‹ ç›®å½•

- [3.4.2 Rust æ€§èƒ½ä¼˜åŒ–ç”Ÿäº§å®æˆ˜æ¡ˆä¾‹é›†](#342-rust-æ€§èƒ½ä¼˜åŒ–ç”Ÿäº§å®æˆ˜æ¡ˆä¾‹é›†)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. é«˜å¹¶å‘ API æœåŠ¡ä¼˜åŒ–](#1-é«˜å¹¶å‘-api-æœåŠ¡ä¼˜åŒ–)
    - [1.1 é—®é¢˜èƒŒæ™¯](#11-é—®é¢˜èƒŒæ™¯)
    - [1.2 æ€§èƒ½ç“¶é¢ˆåˆ†æ](#12-æ€§èƒ½ç“¶é¢ˆåˆ†æ)
    - [1.3 ä¼˜åŒ–æ–¹æ¡ˆ](#13-ä¼˜åŒ–æ–¹æ¡ˆ)
      - [ä¼˜åŒ– 1: æ•°æ®åº“è¿æ¥æ± è°ƒä¼˜](#ä¼˜åŒ–-1-æ•°æ®åº“è¿æ¥æ± è°ƒä¼˜)
      - [ä¼˜åŒ– 2: é¢„ç¼–è¯‘æŸ¥è¯¢ï¼ˆPrepared Statementsï¼‰](#ä¼˜åŒ–-2-é¢„ç¼–è¯‘æŸ¥è¯¢prepared-statements)
      - [ä¼˜åŒ– 3: ä½¿ç”¨æ›´å¿«çš„ JSON åº“](#ä¼˜åŒ–-3-ä½¿ç”¨æ›´å¿«çš„-json-åº“)
      - [ä¼˜åŒ– 4: å†…å­˜æ± ä¼˜åŒ–](#ä¼˜åŒ–-4-å†…å­˜æ± ä¼˜åŒ–)
      - [ä¼˜åŒ– 5: æ‰¹é‡å¤„ç†](#ä¼˜åŒ–-5-æ‰¹é‡å¤„ç†)
      - [ä¼˜åŒ– 6: ç¼“å­˜çƒ­æ•°æ®](#ä¼˜åŒ–-6-ç¼“å­˜çƒ­æ•°æ®)
    - [1.4 ä¼˜åŒ–æ•ˆæœ](#14-ä¼˜åŒ–æ•ˆæœ)
  - [2. æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–](#2-æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–)
    - [2.1 é—®é¢˜ï¼šè¿æ¥æ³„æ¼ä¸è€—å°½](#21-é—®é¢˜è¿æ¥æ³„æ¼ä¸è€—å°½)
    - [2.2 é—®é¢˜ï¼šæ…¢æŸ¥è¯¢æ‹–ç´¯æ€§èƒ½](#22-é—®é¢˜æ…¢æŸ¥è¯¢æ‹–ç´¯æ€§èƒ½)
  - [3. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–](#3-ç¼“å­˜ç­–ç•¥ä¼˜åŒ–)
    - [3.1 å¤šçº§ç¼“å­˜æ¶æ„](#31-å¤šçº§ç¼“å­˜æ¶æ„)
    - [3.2 ç¼“å­˜ç©¿é€é˜²æŠ¤](#32-ç¼“å­˜ç©¿é€é˜²æŠ¤)
    - [3.3 ç¼“å­˜é›ªå´©é˜²æŠ¤](#33-ç¼“å­˜é›ªå´©é˜²æŠ¤)
  - [4. å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ä¼˜åŒ–](#4-å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ä¼˜åŒ–)
    - [4.1 ä½¿ç”¨ Tokio Channels ä¼˜åŒ–ä»»åŠ¡åˆ†å‘](#41-ä½¿ç”¨-tokio-channels-ä¼˜åŒ–ä»»åŠ¡åˆ†å‘)
    - [4.2 å·¥ä½œçªƒå–ï¼ˆWork Stealingï¼‰](#42-å·¥ä½œçªƒå–work-stealing)
  - [5. å†…å­˜åˆ†é…ä¼˜åŒ–](#5-å†…å­˜åˆ†é…ä¼˜åŒ–)
    - [5.1 ä½¿ç”¨ Arena åˆ†é…å™¨](#51-ä½¿ç”¨-arena-åˆ†é…å™¨)
    - [5.2 å¯¹è±¡æ± å¤ç”¨](#52-å¯¹è±¡æ± å¤ç”¨)
  - [å‚è€ƒèµ„æº](#å‚è€ƒèµ„æº)

---

## 1. é«˜å¹¶å‘ API æœåŠ¡ä¼˜åŒ–

### 1.1 é—®é¢˜èƒŒæ™¯

**ä¸šåŠ¡åœºæ™¯**: ç”µå•†å¹³å°å•†å“æŸ¥è¯¢ API

**åˆå§‹æ€§èƒ½æŒ‡æ ‡**:

```text
QPS: 5,000 requests/sec
P95 å»¶è¿Ÿ: 180ms
P99 å»¶è¿Ÿ: 450ms
CPU ä½¿ç”¨ç‡: 75%
å†…å­˜ä½¿ç”¨: 2.5GB
```

**æ€§èƒ½ç›®æ ‡**:

```text
QPS: 20,000 requests/sec (æå‡ 4x)
P95 å»¶è¿Ÿ: < 50ms (é™ä½ 72%)
P99 å»¶è¿Ÿ: < 100ms (é™ä½ 78%)
```

---

### 1.2 æ€§èƒ½ç“¶é¢ˆåˆ†æ

**1. ä½¿ç”¨ Flamegraph åˆ†æ CPU çƒ­ç‚¹**:

```bash
# ç”Ÿæˆ CPU ç«ç„°å›¾
cargo flamegraph --bin api_server

# åˆ†æç»“æœï¼š
# - 30% æ—¶é—´åœ¨ JSON åºåˆ—åŒ– (serde_json)
# - 25% æ—¶é—´åœ¨æ•°æ®åº“æŸ¥è¯¢ç­‰å¾…
# - 20% æ—¶é—´åœ¨å­—ç¬¦ä¸²åˆ†é…
# - 15% æ—¶é—´åœ¨ä¸­é—´ä»¶å¤„ç†
```

**2. ä½¿ç”¨ Tokio Console åˆ†æå¼‚æ­¥ä»»åŠ¡**:

```bash
# å¯åŠ¨ Tokio Console
tokio-console

# å‘ç°é—®é¢˜ï¼š
# - æ•°æ®åº“è¿æ¥æ± å¤§å°ä¸è¶³ï¼Œå¤§é‡ä»»åŠ¡ç­‰å¾…
# - æŸäº›é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡é˜»å¡ Tokio è¿è¡Œæ—¶
# - è¿‡å¤šçš„ task spawnï¼Œè°ƒåº¦å¼€é”€å¤§
```

**3. ä½¿ç”¨ Criterion åŸºå‡†æµ‹è¯•å…³é”®è·¯å¾„**:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_product_query(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let db = rt.block_on(setup_db());
    
    c.bench_function("product_query", |b| {
        b.to_async(&rt).iter(|| async {
            let result = query_product(black_box(12345), &db).await;
            black_box(result)
        })
    });
}

// ç»“æœï¼šå•æ¬¡æŸ¥è¯¢å¹³å‡ 12msï¼Œå…¶ä¸­ï¼š
// - æ•°æ®åº“æŸ¥è¯¢: 8ms
// - ç»“æœåºåˆ—åŒ–: 3ms
// - å…¶ä»–: 1ms
```

---

### 1.3 ä¼˜åŒ–æ–¹æ¡ˆ

#### ä¼˜åŒ– 1: æ•°æ®åº“è¿æ¥æ± è°ƒä¼˜

**ä¼˜åŒ–å‰**:

```rust
// é»˜è®¤é…ç½®ï¼Œè¿æ¥æ•°ä¸è¶³
let pool = PgPoolOptions::new()
    .connect(&database_url)
    .await?;
```

**ä¼˜åŒ–å**:

```rust
use sqlx::{postgres::PgPoolOptions, Pool, Postgres};
use std::time::Duration;

async fn create_optimized_pool(database_url: &str) -> Result<Pool<Postgres>, sqlx::Error> {
    PgPoolOptions::new()
        // 1. å¢åŠ æœ€å¤§è¿æ¥æ•°ï¼ˆåŸºäº CPU æ ¸å¿ƒæ•°ï¼‰
        .max_connections((num_cpus::get() * 4) as u32)  // 32 æ ¸ â†’ 128 è¿æ¥
        
        // 2. è®¾ç½®æœ€å°ç©ºé—²è¿æ¥ï¼ˆé¿å…å†·å¯åŠ¨ï¼‰
        .min_connections(32)
        
        // 3. è¿æ¥è·å–è¶…æ—¶
        .acquire_timeout(Duration::from_secs(3))
        
        // 4. è¿æ¥æœ€å¤§ç”Ÿå‘½å‘¨æœŸï¼ˆé˜²æ­¢é•¿è¿æ¥é—®é¢˜ï¼‰
        .max_lifetime(Duration::from_secs(30 * 60))  // 30åˆ†é’Ÿ
        
        // 5. ç©ºé—²è¿æ¥è¶…æ—¶
        .idle_timeout(Duration::from_secs(10 * 60))  // 10åˆ†é’Ÿ
        
        // 6. æµ‹è¯•è¿æ¥æœ‰æ•ˆæ€§
        .test_before_acquire(true)
        
        .connect(database_url)
        .await
}

// æ•ˆæœï¼šæ•°æ®åº“æŸ¥è¯¢å»¶è¿Ÿä» 8ms é™ä½åˆ° 3ms
```

#### ä¼˜åŒ– 2: é¢„ç¼–è¯‘æŸ¥è¯¢ï¼ˆPrepared Statementsï¼‰

**ä¼˜åŒ–å‰**:

```rust
// æ¯æ¬¡éƒ½ç¼–è¯‘ SQL
async fn query_product(id: i64, pool: &Pool<Postgres>) -> Result<Product, Error> {
    sqlx::query_as!(
        Product,
        "SELECT * FROM products WHERE id = $1",
        id
    )
    .fetch_one(pool)
    .await
}
```

**ä¼˜åŒ–å**:

```rust
use once_cell::sync::Lazy;
use sqlx::{Executor, Postgres};

// å…¨å±€é¢„ç¼–è¯‘æŸ¥è¯¢
static QUERY_PRODUCT_BY_ID: Lazy<sqlx::query::Query<Postgres, sqlx::postgres::PgArguments>> = 
    Lazy::new(|| {
        sqlx::query("SELECT id, name, price, stock FROM products WHERE id = $1")
    });

async fn query_product_optimized(id: i64, pool: &Pool<Postgres>) -> Result<Product, Error> {
    QUERY_PRODUCT_BY_ID
        .bind(id)
        .fetch_one(pool)
        .await
        .map(|row| Product {
            id: row.get("id"),
            name: row.get("name"),
            price: row.get("price"),
            stock: row.get("stock"),
        })
}

// æ•ˆæœï¼šæŸ¥è¯¢å»¶è¿Ÿå†é™ä½ 1msï¼ˆ3ms â†’ 2msï¼‰
```

#### ä¼˜åŒ– 3: ä½¿ç”¨æ›´å¿«çš„ JSON åº“

**ä¼˜åŒ–å‰**:

```rust
use axum::Json;
use serde_json;

async fn handler() -> Json<Product> {
    // ä½¿ç”¨ serde_json (æ ‡å‡†ä½†è¾ƒæ…¢)
    Json(product)
}
```

**ä¼˜åŒ–å**:

```rust
use axum::response::IntoResponse;
use simd_json;  // SIMD åŠ é€Ÿçš„ JSON åº“

async fn handler_optimized() -> impl IntoResponse {
    let product = query_product().await;
    
    // ä½¿ç”¨ simd-json (é€Ÿåº¦æå‡ 2-3x)
    let mut json_bytes = simd_json::to_vec(&product).unwrap();
    
    (
        [(header::CONTENT_TYPE, "application/json")],
        json_bytes
    )
}

// æˆ–è€…ä½¿ç”¨ sonic-rs (å­—èŠ‚è·³åŠ¨å¼€æºï¼Œæ›´å¿«)
use sonic_rs::{to_vec, from_slice};

async fn handler_sonic() -> impl IntoResponse {
    let product = query_product().await;
    
    // sonic-rs: æ¯” serde_json å¿« 4-5x
    let json_bytes = to_vec(&product).unwrap();
    
    (
        [(header::CONTENT_TYPE, "application/json")],
        json_bytes
    )
}

// æ•ˆæœï¼šåºåˆ—åŒ–æ—¶é—´ä» 3ms é™ä½åˆ° 0.8ms
```

#### ä¼˜åŒ– 4: å†…å­˜æ± ä¼˜åŒ–

**ä¼˜åŒ–å‰**:

```rust
// æ¯ä¸ªè¯·æ±‚éƒ½åˆ†é…æ–°çš„ Vec
async fn process_request(data: Vec<u8>) -> Result<Response, Error> {
    let mut buffer = Vec::with_capacity(1024);
    // å¤„ç†é€»è¾‘...
    Ok(Response::new(buffer))
}
```

**ä¼˜åŒ–å**:

```rust
use bytes::{Bytes, BytesMut};

// ä½¿ç”¨ bytes crateï¼Œå‡å°‘å†…å­˜æ‹·è´
async fn process_request_optimized(data: Bytes) -> Result<Response, Error> {
    // BytesMut æ”¯æŒé«˜æ•ˆçš„å†…å­˜å¤ç”¨
    let mut buffer = BytesMut::with_capacity(1024);
    
    // å¤„ç†é€»è¾‘...
    
    // é›¶æ‹·è´è½¬æ¢
    Ok(Response::new(buffer.freeze()))
}

// æˆ–ä½¿ç”¨å¯¹è±¡æ± 
use deadpool::managed::{Object, Pool};

struct BufferPool {
    pool: Pool<BytesMut>,
}

impl BufferPool {
    async fn get_buffer(&self) -> Object<BytesMut> {
        self.pool.get().await.unwrap()
    }
}

// æ•ˆæœï¼šå†…å­˜åˆ†é…æ¬¡æ•°å‡å°‘ 60%ï¼ŒGC å‹åŠ›é™ä½
```

#### ä¼˜åŒ– 5: æ‰¹é‡å¤„ç†

**ä¼˜åŒ–å‰**:

```rust
// é€ä¸ªå¤„ç†è¯·æ±‚
async fn get_products(ids: Vec<i64>, pool: &Pool<Postgres>) -> Result<Vec<Product>, Error> {
    let mut products = Vec::new();
    
    for id in ids {
        let product = query_product(id, pool).await?;
        products.push(product);
    }
    
    Ok(products)
}
```

**ä¼˜åŒ–å**:

```rust
use futures::future::join_all;

// å¹¶å‘æ‰¹é‡æŸ¥è¯¢
async fn get_products_batch(ids: Vec<i64>, pool: &Pool<Postgres>) -> Result<Vec<Product>, Error> {
    // æ–¹æ¡ˆ 1: å¹¶å‘æŸ¥è¯¢ï¼ˆé€‚åˆå°‘é‡ IDï¼‰
    let futures = ids.into_iter()
        .map(|id| query_product(id, pool))
        .collect::<Vec<_>>();
    
    let products = join_all(futures)
        .await
        .into_iter()
        .collect::<Result<Vec<_>, _>>()?;
    
    Ok(products)
}

// æ–¹æ¡ˆ 2: å•æ¬¡ SQL æŸ¥è¯¢ï¼ˆé€‚åˆå¤§é‡ IDï¼‰
async fn get_products_single_query(ids: Vec<i64>, pool: &Pool<Postgres>) -> Result<Vec<Product>, Error> {
    sqlx::query_as!(
        Product,
        "SELECT * FROM products WHERE id = ANY($1)",
        &ids
    )
    .fetch_all(pool)
    .await
}

// æ•ˆæœï¼š100 ä¸ªå•†å“æŸ¥è¯¢ä» 200ms é™ä½åˆ° 15ms
```

#### ä¼˜åŒ– 6: ç¼“å­˜çƒ­æ•°æ®

**ä½¿ç”¨ moka æœ¬åœ°ç¼“å­˜**:

```rust
use moka::future::Cache;
use std::sync::Arc;
use std::time::Duration;

pub struct ProductCache {
    cache: Cache<i64, Arc<Product>>,
    db_pool: Pool<Postgres>,
}

impl ProductCache {
    pub fn new(db_pool: Pool<Postgres>) -> Self {
        let cache = Cache::builder()
            // 1. æœ€å¤§æ¡ç›®æ•°
            .max_capacity(100_000)
            
            // 2. TTL (Time To Live)
            .time_to_live(Duration::from_secs(5 * 60))  // 5åˆ†é’Ÿ
            
            // 3. ç©ºé—²æ·˜æ±°
            .time_to_idle(Duration::from_secs(60))  // 1åˆ†é’Ÿæ— è®¿é—®åˆ™æ·˜æ±°
            
            // 4. æ·˜æ±°é€šçŸ¥
            .eviction_listener(|key, value, cause| {
                tracing::debug!("Evicted product {}: {:?}", key, cause);
            })
            
            .build();
        
        Self { cache, db_pool }
    }
    
    pub async fn get_product(&self, id: i64) -> Result<Arc<Product>, Error> {
        // Try-get pattern: å…ˆæŸ¥ç¼“å­˜ï¼Œæœªå‘½ä¸­åˆ™æŸ¥æ•°æ®åº“
        self.cache
            .try_get_with(id, async {
                let product = query_product(id, &self.db_pool).await?;
                Ok::<_, Error>(Arc::new(product))
            })
            .await
            .map_err(|e| anyhow::anyhow!("Cache error: {}", e))
    }
    
    pub async fn invalidate(&self, id: i64) {
        self.cache.invalidate(&id).await;
    }
}

// ä½¿ç”¨ç¤ºä¾‹
async fn handler(
    Path(id): Path<i64>,
    State(cache): State<Arc<ProductCache>>,
) -> Result<Json<Product>, Error> {
    let product = cache.get_product(id).await?;
    Ok(Json((*product).clone()))
}

// æ•ˆæœï¼šç¼“å­˜å‘½ä¸­ç‡ 85%ï¼Œå¹³å‡å»¶è¿Ÿä» 5ms é™ä½åˆ° 0.2ms
```

---

### 1.4 ä¼˜åŒ–æ•ˆæœ

**ä¼˜åŒ–åæ€§èƒ½æŒ‡æ ‡**:

```text
âœ… QPS: 22,000 requests/sec  (â†‘ 340%, è¶…è¿‡ç›®æ ‡)
âœ… P50 å»¶è¿Ÿ: 8ms             (â†“ 92%)
âœ… P95 å»¶è¿Ÿ: 25ms            (â†“ 86%, è¶…è¿‡ç›®æ ‡)
âœ… P99 å»¶è¿Ÿ: 65ms            (â†“ 86%, è¶…è¿‡ç›®æ ‡)
âœ… CPU ä½¿ç”¨ç‡: 55%           (â†“ 27%)
âœ… å†…å­˜ä½¿ç”¨: 1.8GB           (â†“ 28%)
```

**è¯¦ç»†å¯¹æ¯”**:

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| QPS | 5,000 | 22,000 | +340% |
| P50 å»¶è¿Ÿ | 95ms | 8ms | -92% |
| P95 å»¶è¿Ÿ | 180ms | 25ms | -86% |
| P99 å»¶è¿Ÿ | 450ms | 65ms | -86% |
| CPU ä½¿ç”¨ç‡ | 75% | 55% | -27% |
| å†…å­˜ä½¿ç”¨ | 2.5GB | 1.8GB | -28% |

**æˆæœ¬èŠ‚çœ**:

```text
åŸé…ç½®: 10 å° 16 æ ¸ 32GB æœåŠ¡å™¨
ä¼˜åŒ–å: 3 å° 16 æ ¸ 32GB æœåŠ¡å™¨

å¹´åº¦æˆæœ¬èŠ‚çœ: çº¦ $50,000 (äº‘æœåŠ¡å™¨æˆæœ¬)
```

---

## 2. æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

### 2.1 é—®é¢˜ï¼šè¿æ¥æ³„æ¼ä¸è€—å°½

**é—®é¢˜è¡¨ç°**:

```text
é«˜å³°æ—¶æ®µï¼š
- æ•°æ®åº“è¿æ¥æ± è€—å°½
- å¤§é‡ "connection pool timeout" é”™è¯¯
- å“åº”æ—¶é—´æ¿€å¢åˆ° 10+ ç§’
```

**æ ¹å› åˆ†æ**:

```rust
// é—®é¢˜ä»£ç ï¼šå¿˜è®°é‡Šæ”¾è¿æ¥
async fn buggy_query(pool: &Pool<Postgres>) -> Result<Product, Error> {
    let mut conn = pool.acquire().await?;
    
    // æŸ¥è¯¢é€»è¾‘
    let result = sqlx::query_as("SELECT * FROM products")
        .fetch_one(&mut *conn)
        .await?;
    
    // é”™è¯¯ï¼šå¿˜è®° drop(conn)ï¼Œå¦‚æœè¿™é‡Œ panicï¼Œè¿æ¥æ°¸è¿œä¸ä¼šå½’è¿˜
    if result.price < 0.0 {
        panic!("Invalid price!");  // è¿æ¥æ³„æ¼ï¼
    }
    
    Ok(result)
}
```

**è§£å†³æ–¹æ¡ˆ 1: ä½¿ç”¨ Pool æ–¹æ³•è€Œéæ‰‹åŠ¨ acquire**:

```rust
// æ¨èï¼šç›´æ¥ä½¿ç”¨ pool æ–¹æ³•ï¼Œè‡ªåŠ¨ç®¡ç†è¿æ¥
async fn safe_query(pool: &Pool<Postgres>) -> Result<Product, Error> {
    sqlx::query_as("SELECT * FROM products WHERE id = $1")
        .bind(123)
        .fetch_one(pool)  // è‡ªåŠ¨è·å–å’Œå½’è¿˜è¿æ¥
        .await
}
```

**è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨ RAII ç¡®ä¿è¿æ¥é‡Šæ”¾**:

```rust
use scopeguard::defer;

async fn safe_query_with_guard(pool: &Pool<Postgres>) -> Result<Product, Error> {
    let mut conn = pool.acquire().await?;
    
    // ä½¿ç”¨ defer ç¡®ä¿è¿æ¥ä¸€å®šä¼šé‡Šæ”¾
    defer! {
        drop(conn);
    }
    
    // æŸ¥è¯¢é€»è¾‘
    let result = sqlx::query_as("SELECT * FROM products")
        .fetch_one(&mut *conn)
        .await?;
    
    Ok(result)
}
```

**ç›‘æ§è¿æ¥æ± å¥åº·**:

```rust
use axum::{Router, routing::get, Json};
use serde::Serialize;

#[derive(Serialize)]
struct PoolStats {
    size: usize,
    idle: usize,
    active: usize,
    max_size: u32,
}

async fn pool_stats(State(pool): State<Pool<Postgres>>) -> Json<PoolStats> {
    Json(PoolStats {
        size: pool.size() as usize,
        idle: pool.num_idle(),
        active: pool.size() as usize - pool.num_idle(),
        max_size: pool.options().get_max_connections(),
    })
}

pub fn monitoring_routes() -> Router {
    Router::new()
        .route("/health/db", get(pool_stats))
}

// Prometheus æŒ‡æ ‡
use prometheus::{IntGauge, register_int_gauge};

lazy_static! {
    static ref DB_POOL_SIZE: IntGauge = 
        register_int_gauge!("db_pool_size", "Database pool size").unwrap();
    static ref DB_POOL_IDLE: IntGauge = 
        register_int_gauge!("db_pool_idle", "Idle connections").unwrap();
}

async fn record_pool_metrics(pool: &Pool<Postgres>) {
    DB_POOL_SIZE.set(pool.size() as i64);
    DB_POOL_IDLE.set(pool.num_idle() as i64);
}
```

### 2.2 é—®é¢˜ï¼šæ…¢æŸ¥è¯¢æ‹–ç´¯æ€§èƒ½

**æ£€æµ‹æ…¢æŸ¥è¯¢**:

```rust
use std::time::Instant;
use tracing::warn;

async fn query_with_timing<T>(
    query: impl FnOnce() -> Fut,
    name: &str,
) -> Result<T, Error>
where
    Fut: Future<Output = Result<T, Error>>,
{
    let start = Instant::now();
    let result = query().await;
    let elapsed = start.elapsed();
    
    if elapsed > Duration::from_millis(100) {
        warn!(
            query_name = name,
            duration_ms = elapsed.as_millis(),
            "Slow query detected"
        );
    }
    
    result
}

// PostgreSQL æ…¢æŸ¥è¯¢æ—¥å¿—
// åœ¨ postgresql.conf ä¸­è®¾ç½®ï¼š
// log_min_duration_statement = 100  # è®°å½• >100ms çš„æŸ¥è¯¢
```

**ä¼˜åŒ–æ…¢æŸ¥è¯¢**:

```sql
-- æ¡ˆä¾‹ï¼šæœªä¼˜åŒ–çš„æŸ¥è¯¢
SELECT * FROM orders 
WHERE user_id = 123 
AND created_at > '2025-01-01'
ORDER BY created_at DESC
LIMIT 10;

-- æ‰§è¡Œè®¡åˆ’æ˜¾ç¤ºï¼šSeq Scan (å…¨è¡¨æ‰«æ)ï¼Œè€—æ—¶ 850ms

-- ä¼˜åŒ–æ–¹æ¡ˆï¼šæ·»åŠ å¤åˆç´¢å¼•
CREATE INDEX idx_orders_user_created ON orders(user_id, created_at DESC);

-- ä¼˜åŒ–åï¼šIndex Scanï¼Œè€—æ—¶ 2ms
```

**Rust ç«¯æŸ¥è¯¢ä¼˜åŒ–**:

```rust
// ä¼˜åŒ–å‰ï¼šæŸ¥è¯¢æ‰€æœ‰å­—æ®µ
let orders = sqlx::query_as!(
    Order,
    "SELECT * FROM orders WHERE user_id = $1",
    user_id
)
.fetch_all(pool)
.await?;

// ä¼˜åŒ–åï¼šåªæŸ¥è¯¢éœ€è¦çš„å­—æ®µ
#[derive(Debug, sqlx::FromRow)]
struct OrderSummary {
    id: i64,
    total: f64,
    status: String,
    created_at: DateTime<Utc>,
}

let orders = sqlx::query_as!(
    OrderSummary,
    "SELECT id, total, status, created_at FROM orders WHERE user_id = $1",
    user_id
)
.fetch_all(pool)
.await?;

// æ•ˆæœï¼šç½‘ç»œä¼ è¾“å‡å°‘ 70%ï¼ŒæŸ¥è¯¢æ—¶é—´ä» 12ms é™ä½åˆ° 4ms
```

---

## 3. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

### 3.1 å¤šçº§ç¼“å­˜æ¶æ„

**æ¶æ„è®¾è®¡**:

```text
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Client    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   L1: Local Cache    â”‚  â† moka (100Î¼s)
                    â”‚   (100K entries)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ miss
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   L2: Redis Cluster  â”‚  â† redis (1-2ms)
                    â”‚   (10M entries)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ miss
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   L3: PostgreSQL     â”‚  â† postgres (5-10ms)
                    â”‚   (source of truth)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®ç°**:

```rust
use moka::future::Cache as LocalCache;
use redis::aio::MultiplexedConnection;
use sqlx::PgPool;
use serde::{Serialize, Deserialize};

#[derive(Clone, Serialize, Deserialize)]
pub struct CachedProduct {
    pub id: i64,
    pub data: String,
}

pub struct MultiLevelCache {
    l1: LocalCache<i64, Arc<CachedProduct>>,
    redis: MultiplexedConnection,
    db: PgPool,
}

impl MultiLevelCache {
    pub fn new(redis: MultiplexedConnection, db: PgPool) -> Self {
        let l1 = LocalCache::builder()
            .max_capacity(100_000)
            .time_to_live(Duration::from_secs(60))
            .build();
        
        Self { l1, redis, db }
    }
    
    pub async fn get(&self, id: i64) -> Result<Arc<CachedProduct>, Error> {
        // L1: æœ¬åœ°ç¼“å­˜
        if let Some(value) = self.l1.get(&id).await {
            tracing::debug!("L1 cache hit: {}", id);
            return Ok(value);
        }
        
        // L2: Redis
        let redis_key = format!("product:{}", id);
        if let Ok(Some(data)) = self.redis.clone().get::<_, Option<String>>(&redis_key).await {
            tracing::debug!("L2 cache hit: {}", id);
            
            let product: CachedProduct = serde_json::from_str(&data)?;
            let product = Arc::new(product);
            
            // å›å¡« L1
            self.l1.insert(id, product.clone()).await;
            
            return Ok(product);
        }
        
        // L3: æ•°æ®åº“
        tracing::debug!("Cache miss, querying database: {}", id);
        
        let product = sqlx::query_as!(
            CachedProduct,
            "SELECT id, data FROM products WHERE id = $1",
            id
        )
        .fetch_one(&self.db)
        .await?;
        
        let product = Arc::new(product);
        
        // å›å¡« L2
        let data = serde_json::to_string(&*product)?;
        let _: () = self.redis.clone()
            .set_ex(&redis_key, data, 300)  // 5åˆ†é’Ÿ TTL
            .await?;
        
        // å›å¡« L1
        self.l1.insert(id, product.clone()).await;
        
        Ok(product)
    }
    
    pub async fn invalidate(&self, id: i64) -> Result<(), Error> {
        // åˆ é™¤æ‰€æœ‰å±‚çº§çš„ç¼“å­˜
        self.l1.invalidate(&id).await;
        
        let redis_key = format!("product:{}", id);
        let _: () = self.redis.clone().del(&redis_key).await?;
        
        Ok(())
    }
}

// æ€§èƒ½æå‡ï¼š
// - L1 å‘½ä¸­ç‡: 70% (å»¶è¿Ÿ 0.1ms)
// - L2 å‘½ä¸­ç‡: 25% (å»¶è¿Ÿ 1.5ms)
// - L3 å‘½ä¸­ç‡: 5%  (å»¶è¿Ÿ 8ms)
// - å¹³å‡å»¶è¿Ÿ: 0.1 * 0.7 + 1.5 * 0.25 + 8 * 0.05 = 0.84ms
```

### 3.2 ç¼“å­˜ç©¿é€é˜²æŠ¤

**é—®é¢˜ï¼šæ¶æ„æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®**:

```rust
// é—®é¢˜ï¼šå¦‚æœæŸ¥è¯¢ä¸å­˜åœ¨çš„ IDï¼Œæ¯æ¬¡éƒ½ä¼šæ‰“åˆ°æ•°æ®åº“
pub async fn get_product(id: i64, cache: &Cache, db: &PgPool) -> Result<Option<Product>, Error> {
    if let Some(product) = cache.get(&id).await {
        return Ok(Some(product));
    }
    
    // æ•°æ®åº“æŸ¥è¯¢
    let product = sqlx::query_as!(Product, "SELECT * FROM products WHERE id = $1", id)
        .fetch_optional(db)
        .await?;
    
    if let Some(ref product) = product {
        cache.set(id, product.clone()).await;
    }
    
    Ok(product)  // å¦‚æœ Noneï¼Œä¸ä¼šç¼“å­˜ï¼Œä¸‹æ¬¡è¿˜ä¼šæŸ¥è¯¢æ•°æ®åº“
}
```

**è§£å†³æ–¹æ¡ˆï¼šç¼“å­˜ç©ºå€¼ (Null Object Pattern)**:

```rust
use serde::{Serialize, Deserialize};

#[derive(Clone, Serialize, Deserialize)]
pub enum CacheEntry<T> {
    Exists(T),
    NotFound,  // ç¼“å­˜"ä¸å­˜åœ¨"çš„çŠ¶æ€
}

pub async fn get_product_with_null_cache(
    id: i64,
    cache: &Cache<i64, CacheEntry<Product>>,
    db: &PgPool,
) -> Result<Option<Product>, Error> {
    // æŸ¥è¯¢ç¼“å­˜
    if let Some(entry) = cache.get(&id).await {
        return match entry {
            CacheEntry::Exists(product) => Ok(Some(product)),
            CacheEntry::NotFound => Ok(None),  // ç¼“å­˜äº†"ä¸å­˜åœ¨"
        };
    }
    
    // æ•°æ®åº“æŸ¥è¯¢
    let product = sqlx::query_as!(Product, "SELECT * FROM products WHERE id = $1", id)
        .fetch_optional(db)
        .await?;
    
    // ç¼“å­˜ç»“æœï¼ˆåŒ…æ‹¬"ä¸å­˜åœ¨"ï¼‰
    let entry = match product {
        Some(ref p) => CacheEntry::Exists(p.clone()),
        None => CacheEntry::NotFound,
    };
    
    cache.insert(id, entry).await;
    
    Ok(product)
}

// æ•ˆæœï¼šé˜²æ­¢ç¼“å­˜ç©¿é€ï¼Œæ¶æ„æŸ¥è¯¢ä¸ä¼šæ‰“åˆ°æ•°æ®åº“
```

### 3.3 ç¼“å­˜é›ªå´©é˜²æŠ¤

**é—®é¢˜ï¼šå¤§é‡ç¼“å­˜åŒæ—¶å¤±æ•ˆ**:

```rust
// é—®é¢˜ï¼šæ‰€æœ‰ç¼“å­˜ä½¿ç”¨å›ºå®š TTLï¼Œå¯èƒ½åŒæ—¶å¤±æ•ˆ
cache.set_ex("key1", value1, 300);  // 5åˆ†é’Ÿ
cache.set_ex("key2", value2, 300);  // 5åˆ†é’Ÿ
// ... å¤§é‡ç¼“å­˜åŒæ—¶è®¾ç½®ï¼Œ5åˆ†é’ŸååŒæ—¶å¤±æ•ˆ

// 5åˆ†é’Ÿåï¼Œå¤§é‡è¯·æ±‚åŒæ—¶æ‰“åˆ°æ•°æ®åº“ï¼Œé€ æˆé›ªå´©
```

**è§£å†³æ–¹æ¡ˆï¼šéšæœº TTL**:

```rust
use rand::Rng;

pub async fn set_with_random_ttl<K, V>(
    cache: &Cache<K, V>,
    key: K,
    value: V,
    base_ttl_secs: u64,
) where
    K: Hash + Eq + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    let mut rng = rand::thread_rng();
    
    // åœ¨ base_ttl Â± 20% èŒƒå›´å†…éšæœº
    let jitter = (base_ttl_secs as f64 * 0.2) as u64;
    let ttl = base_ttl_secs + rng.gen_range(0..jitter * 2) - jitter;
    
    cache.insert(key, value).await;
    // TTL è®¾ç½®ï¼ˆå…·ä½“å®ç°å–å†³äºç¼“å­˜åº“ï¼‰
}

// æ•ˆæœï¼šç¼“å­˜å¤±æ•ˆæ—¶é—´åˆ†æ•£ï¼Œé¿å…é›ªå´©
```

---

## 4. å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ä¼˜åŒ–

### 4.1 ä½¿ç”¨ Tokio Channels ä¼˜åŒ–ä»»åŠ¡åˆ†å‘

**é—®é¢˜ï¼šåŒæ­¥é˜Ÿåˆ—é˜»å¡**:

```rust
use std::sync::mpsc::{channel, Sender};

// é—®é¢˜ï¼šä½¿ç”¨åŒæ­¥ channelï¼Œå‘é€å¯èƒ½é˜»å¡
let (tx, rx) = channel::<Task>();

// å‘é€ä»»åŠ¡ï¼ˆå¯èƒ½é˜»å¡ï¼‰
tx.send(task).unwrap();  // å¦‚æœæ¥æ”¶ç«¯æ…¢ï¼Œè¿™é‡Œä¼šé˜»å¡æ•´ä¸ªçº¿ç¨‹
```

**è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ Tokio å¼‚æ­¥ channel**:

```rust
use tokio::sync::mpsc;

#[derive(Debug)]
struct Task {
    id: u64,
    data: Vec<u8>,
}

#[tokio::main]
async fn main() {
    // åˆ›å»ºå¼‚æ­¥ channelï¼ˆæœ‰ç•Œï¼Œé˜²æ­¢å†…å­˜æº¢å‡ºï¼‰
    let (tx, mut rx) = mpsc::channel::<Task>(10000);
    
    // ç”Ÿäº§è€…ï¼ˆå‘é€ä»»åŠ¡ï¼‰
    let producer = tokio::spawn(async move {
        for i in 0..100000 {
            let task = Task {
                id: i,
                data: vec![0u8; 1024],
            };
            
            // å¼‚æ­¥å‘é€ï¼ˆä¸ä¼šé˜»å¡ï¼‰
            if let Err(e) = tx.send(task).await {
                eprintln!("Failed to send task: {}", e);
                break;
            }
        }
    });
    
    // æ¶ˆè´¹è€…ï¼ˆå¤„ç†ä»»åŠ¡ï¼‰
    let consumer = tokio::spawn(async move {
        while let Some(task) = rx.recv().await {
            process_task(task).await;
        }
    });
    
    let _ = tokio::join!(producer, consumer);
}

async fn process_task(task: Task) {
    // å¤„ç†é€»è¾‘
    tokio::time::sleep(Duration::from_micros(100)).await;
}

// æ•ˆæœï¼šååé‡æå‡ 10xï¼Œå»¶è¿Ÿé™ä½ 90%
```

### 4.2 å·¥ä½œçªƒå–ï¼ˆWork Stealingï¼‰

**ä½¿ç”¨ `tokio::task::JoinSet` åŠ¨æ€ä»»åŠ¡ç®¡ç†**:

```rust
use tokio::task::JoinSet;

async fn process_tasks_with_work_stealing(tasks: Vec<Task>) -> Result<(), Error> {
    let mut set = JoinSet::new();
    
    // é™åˆ¶å¹¶å‘æ•°
    let max_concurrent = num_cpus::get();
    
    let mut tasks_iter = tasks.into_iter();
    
    // åˆå§‹å¡«å……
    for _ in 0..max_concurrent {
        if let Some(task) = tasks_iter.next() {
            set.spawn(async move {
                process_task(task).await
            });
        }
    }
    
    // åŠ¨æ€è°ƒåº¦
    while let Some(result) = set.join_next().await {
        result??;
        
        // ä»»åŠ¡å®Œæˆåï¼Œç«‹å³å¯åŠ¨æ–°ä»»åŠ¡
        if let Some(task) = tasks_iter.next() {
            set.spawn(async move {
                process_task(task).await
            });
        }
    }
    
    Ok(())
}

// æ•ˆæœï¼šCPU åˆ©ç”¨ç‡æå‡åˆ° 95%+
```

---

## 5. å†…å­˜åˆ†é…ä¼˜åŒ–

### 5.1 ä½¿ç”¨ Arena åˆ†é…å™¨

**é—®é¢˜ï¼šé¢‘ç¹å°å¯¹è±¡åˆ†é…**:

```rust
// é—®é¢˜ï¼šæ¯æ¬¡éƒ½åˆ†é…æ–°çš„ Vec
fn process_data(items: &[Item]) -> Vec<ProcessedItem> {
    let mut result = Vec::new();  // å †åˆ†é…
    
    for item in items {
        let processed = ProcessedItem {
            data: vec![0u8; 64],  // åˆä¸€æ¬¡å †åˆ†é…
            // ...
        };
        result.push(processed);
    }
    
    result
}

// 1000 æ¬¡è°ƒç”¨ = 1000 æ¬¡ result åˆ†é… + 1000Ã—N æ¬¡ data åˆ†é…
```

**è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ bumpalo (Bump Allocator)**:

```rust
use bumpalo::Bump;

fn process_data_arena(items: &[Item], arena: &Bump) -> Vec<ProcessedItem> {
    let mut result = Vec::new_in(arena);  // ä½¿ç”¨ arena åˆ†é…
    
    for item in items {
        let data = arena.alloc_slice_fill_copy(64, 0u8);  // arena åˆ†é…
        
        let processed = ProcessedItem {
            data,
            // ...
        };
        result.push(processed);
    }
    
    result
}

// ä½¿ç”¨ç¤ºä¾‹
fn main() {
    let arena = Bump::new();
    
    // å¤„ç† 1000 æ‰¹æ•°æ®
    for batch in batches {
        let result = process_data_arena(&batch, &arena);
        
        // å¤„ç† result...
        
        // æ‰¹é‡é‡Šæ”¾æ‰€æœ‰åˆ†é…ï¼ˆO(1)ï¼‰
        arena.reset();
    }
}

// æ•ˆæœï¼š
// - åˆ†é…é€Ÿåº¦æå‡ 5-10x
// - å†…å­˜ç¢ç‰‡å‡å°‘
// - é‡Šæ”¾æ—¶é—´ O(1)
```

### 5.2 å¯¹è±¡æ± å¤ç”¨

**ä½¿ç”¨ deadpool**:

```rust
use deadpool::managed::{Manager, Object, Pool, RecycleResult};
use bytes::BytesMut;

struct BufferManager {
    capacity: usize,
}

#[async_trait::async_trait]
impl Manager for BufferManager {
    type Type = BytesMut;
    type Error = std::io::Error;
    
    async fn create(&self) -> Result<BytesMut, Self::Error> {
        Ok(BytesMut::with_capacity(self.capacity))
    }
    
    async fn recycle(&self, obj: &mut BytesMut) -> RecycleResult<Self::Error> {
        // é‡ç½®ç¼“å†²åŒº
        obj.clear();
        Ok(())
    }
}

#[tokio::main]
async fn main() {
    // åˆ›å»ºå¯¹è±¡æ± 
    let pool = Pool::builder(BufferManager { capacity: 4096 })
        .max_size(1000)
        .build()
        .unwrap();
    
    // ä½¿ç”¨å¯¹è±¡æ± 
    let mut buffer = pool.get().await.unwrap();
    
    // ä½¿ç”¨ buffer...
    buffer.extend_from_slice(b"data");
    
    // è‡ªåŠ¨å½’è¿˜åˆ°æ± ä¸­
    drop(buffer);
}

// æ•ˆæœï¼šå‡å°‘ 80% çš„å †åˆ†é…
```

---

## å‚è€ƒèµ„æº

- [Tokio Performance Best Practices](https://tokio.rs/tokio/topics/performance)
- [Criterion.rs Benchmarking](https://github.com/bheisler/criterion.rs)
- [Rust Performance Book](https://nnethercote.github.io/perf-book/)

---

**æœ€åæ›´æ–°**: 2025-10-23  
**ä¸‹æ¬¡æ›´æ–°**: æŒ‰éœ€æ›´æ–°
