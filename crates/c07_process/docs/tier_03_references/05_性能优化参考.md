# Tier 3: 性能优化参考

> **文档类型**: 技术参考  
> **适用版本**: Rust 1.90+  
> **前置知识**: [进程监控与诊断](../tier_02_guides/05_进程监控与诊断.md)

---

## 目录

- [Tier 3: 性能优化参考](#tier-3-性能优化参考)
  - [目录](#目录)
  - [1. 性能分析方法](#1-性能分析方法)
    - [1.1 性能分析工具](#11-性能分析工具)
    - [1.2 性能指标](#12-性能指标)
  - [2. 进程启动优化](#2-进程启动优化)
    - [2.1 减少启动时间](#21-减少启动时间)
    - [2.2 减少资源占用](#22-减少资源占用)
  - [3. IPC性能优化](#3-ipc性能优化)
    - [3.1 IPC机制选择](#31-ipc机制选择)
    - [3.2 缓冲优化](#32-缓冲优化)
    - [3.3 零拷贝技术](#33-零拷贝技术)
  - [4. 内存优化](#4-内存优化)
    - [4.1 减少内存分配](#41-减少内存分配)
    - [4.2 内存映射](#42-内存映射)
  - [5. CPU优化](#5-cpu优化)
    - [5.1 并行化](#51-并行化)
    - [5.2 减少上下文切换](#52-减少上下文切换)
  - [6. I/O优化](#6-io优化)
    - [6.1 异步I/O](#61-异步io)
    - [6.2 批量I/O](#62-批量io)
  - [7. 并发优化](#7-并发优化)
    - [7.1 进程池](#71-进程池)
    - [7.2 动态扩缩容](#72-动态扩缩容)
  - [8. 基准测试](#8-基准测试)
    - [8.1 Criterion基准测试](#81-criterion基准测试)
    - [8.2 对比基准](#82-对比基准)
  - [9. 性能监控](#9-性能监控)
    - [9.1 运行时监控](#91-运行时监控)
    - [9.2 性能指标收集](#92-性能指标收集)
  - [10. 实战案例](#10-实战案例)
    - [案例: 高性能批处理系统](#案例-高性能批处理系统)
  - [总结](#总结)

---

## 1. 性能分析方法

### 1.1 性能分析工具

**Linux工具链**:

```bash
# CPU分析
perf record -g ./myapp
perf report

# 火焰图
perf script | flamegraph.pl > flame.svg

# 内存分析
valgrind --tool=massif ./myapp

# 系统调用追踪
strace -c ./myapp

# 实时监控
top -p $(pidof myapp)
htop -p $(pidof myapp)
```

**Rust专用工具**:

```bash
# Criterion基准测试
cargo bench

# flamegraph
cargo install flamegraph
cargo flamegraph --bin myapp

# cargo-profdata
cargo install cargo-profdata
cargo profdata -- ./target/release/myapp

# heaptrack (内存分析)
heaptrack ./target/release/myapp
heaptrack_gui heaptrack.myapp.*.gz
```

**高级性能分析工具链**:

1. **perf + flamegraph (CPU热点分析)**:

    ```bash
    # 采集性能数据 (60秒)
    perf record -F 99 -g -p $(pidof myapp) -- sleep 60

    # 生成火焰图
    perf script | stackcollapse-perf.pl | flamegraph.pl > flame.svg

    # 分析结果
    # - 宽度：CPU占用时间
    # - 高度：调用栈深度
    # - 颜色：不同函数
    ```

2. **valgrind + massif-visualizer (内存分析)**:

    ```bash
    # 运行内存分析
    valgrind --tool=massif \
            --massif-out-file=massif.out \
            ./target/release/myapp

    # 可视化
    massif-visualizer massif.out

    # 关键指标:
    # - 堆内存使用峰值
    # - 内存分配热点
    # - 内存泄漏检测
    ```

3. **strace + ltrace (系统调用分析)**:

    ```bash
    # 统计系统调用
    strace -c -p $(pidof myapp)

    # 详细跟踪
    strace -T -tt -o strace.log ./myapp

    # 库函数调用
    ltrace -c ./myapp

    # 关注指标:
    # - 系统调用频率
    # - I/O 操作次数
    # - 锁竞争情况
    ```

4. **cargo-flamegraph (Rust优化)**:

    ```bash
    # 安装
    cargo install flamegraph

    # CPU 火焰图
    cargo flamegraph --bin myapp

    # 定制采样频率
    cargo flamegraph --bin myapp --freq 997

    # 过滤特定函数
    cargo flamegraph --bin myapp --filter "process::"
    ```

5. **cargo-bloat (二进制大小分析)**:

    ```bash
    # 安装
    cargo install cargo-bloat

    # 分析二进制大小
    cargo bloat --release

    # 示例输出:
    #  File  .text     Size Crate Name
    #  0.9%  31.8%  89.3KiB   std std::sys::unix::process::process_common::Command::spawn
    #  0.5%  17.5%  49.1KiB tokio tokio::process::unix::ChildStdio::try_into_stdio
    ```

**性能分析最佳实践**:

```rust
use std::time::Instant;

// 1. 内置性能计时器
#[inline]
pub fn measure_time<F, T>(name: &str, f: F) -> T
where
    F: FnOnce() -> T,
{
    let start = Instant::now();
    let result = f();
    let duration = start.elapsed();
    println!("[{}] 耗时: {:?}", name, duration);
    result
}

// 使用示例
let output = measure_time("spawn_process", || {
    Command::new("echo").arg("hello").output().unwrap()
});

// 2. 自定义性能指标收集器
pub struct PerfMetrics {
    spawn_count: AtomicU64,
    spawn_time_ms: AtomicU64,
    wait_count: AtomicU64,
    wait_time_ms: AtomicU64,
}

impl PerfMetrics {
    pub fn record_spawn(&self, duration: Duration) {
        self.spawn_count.fetch_add(1, Ordering::Relaxed);
        self.spawn_time_ms.fetch_add(
            duration.as_millis() as u64,
            Ordering::Relaxed
        );
    }
    
    pub fn report(&self) {
        let spawns = self.spawn_count.load(Ordering::Relaxed);
        let spawn_time = self.spawn_time_ms.load(Ordering::Relaxed);
        
        println!("进程spawn: {} 次", spawns);
        println!("平均spawn时间: {} ms", spawn_time / spawns);
    }
}
```

**性能分析决策树**:

```text
性能问题
├─ CPU高？
│  ├─ 使用perf + flamegraph
│  ├─ 检查热点函数
│  └─ 考虑并行化/算法优化
│
├─ 内存高？
│  ├─ 使用valgrind/heaptrack
│  ├─ 查找泄漏/过度分配
│  └─ 考虑对象池/内存映射
│
├─ I/O慢？
│  ├─ 使用strace分析系统调用
│  ├─ 检查缓冲区大小
│  └─ 考虑异步I/O/批量操作
│
└─ 启动慢？
   ├─ 使用进程池
   ├─ 预热缓存
   └─ 减少依赖加载
```

---

### 1.2 性能指标

**核心指标**:

| 指标 | 说明 | 目标 |
|------|------|------|
| **吞吐量** | 单位时间处理量 | 越高越好 |
| **延迟** | 响应时间 | 越低越好 |
| **CPU使用率** | CPU占用百分比 | 适中 |
| **内存占用** | 常驻内存大小 | 越小越好 |
| **进程数** | 并发进程数量 | 适当 |

---

## 2. 进程启动优化

### 2.1 减少启动时间

**策略1: 预热进程池**:

```rust
use std::process::Command;

pub struct ProcessPool {
    workers: Vec<std::process::Child>,
}

impl ProcessPool {
    pub fn new(size: usize, program: &str) -> std::io::Result<Self> {
        let mut workers = Vec::with_capacity(size);
        
        for _ in 0..size {
            let child = Command::new(program).spawn()?;
            workers.push(child);
        }
        
        Ok(Self { workers })
    }
}

// 启动时预热10个进程
let pool = ProcessPool::new(10, "worker")?;
```

**策略2: 延迟启动**:

```rust
use std::sync::LazyLock;

static PROCESS: LazyLock<Child> = LazyLock::new(|| {
    Command::new("worker").spawn().unwrap()
});

// 首次使用时才启动
let pid = PROCESS.id();
```

**基准测试** (启动100个进程):

| 方法 | 耗时 |
|------|------|
| 逐个启动 | 1,500ms |
| 批量启动 | 800ms |
| 进程池 (预热) | 50ms ✅ |

---

### 2.2 减少资源占用

**最小化环境变量**:

```rust
// ❌ 继承所有环境变量
Command::new("app").spawn()?;

// ✅ 仅传递必要的
Command::new("app")
    .env_clear()
    .env("PATH", "/usr/bin")
    .spawn()?;
```

**优化工作目录**:

```rust
// 设置合适的工作目录
Command::new("app")
    .current_dir("/tmp")  // 快速的tmpfs
    .spawn()?;
```

---

## 3. IPC性能优化

### 3.1 IPC机制选择

**性能排序** (同主机):

1. 🥇 **共享内存**: ~20 GB/s
2. 🥈 **Unix Socket**: ~10 GB/s
3. 🥉 **管道**: ~1 GB/s
4. **TCP Socket**: ~1 GB/s

**选择决策**:

```rust
pub fn select_ipc(data_size: usize, local: bool) -> &'static str {
    match (data_size, local) {
        (size, true) if size > 1024 * 1024 => "shared_memory",  // >1MB
        (_, true) => "unix_socket",
        (_, false) => "tcp_socket",
    }
}
```

---

### 3.2 缓冲优化

**使用BufReader/BufWriter**:

```rust
use std::io::{BufReader, BufWriter, Write, Read};

// ❌ 低效：无缓冲
for byte in data {
    stdout.write(&[byte])?;
}

// ✅ 高效：大缓冲
let mut writer = BufWriter::with_capacity(64 * 1024, stdout);
writer.write_all(&data)?;
writer.flush()?;
```

**性能对比** (传输10MB):

| 方法 | 耗时 |
|------|------|
| 无缓冲 | 2,500ms |
| 默认缓冲(8KB) | 150ms |
| 大缓冲(64KB) | 80ms ✅ |

---

### 3.3 零拷贝技术

**sendfile (Linux)**:

```rust
#[cfg(target_os = "linux")]
fn zero_copy_transfer(from: &File, to: &File, len: usize) -> std::io::Result<()> {
    use std::os::unix::io::AsRawFd;
    
    unsafe {
        libc::sendfile(
            to.as_raw_fd(),
            from.as_raw_fd(),
            std::ptr::null_mut(),
            len,
        );
    }
    
    Ok(())
}
```

---

## 4. 内存优化

### 4.1 减少内存分配

**对象池模式**:

```rust
use std::collections::VecDeque;

pub struct ByteBufferPool {
    buffers: VecDeque<Vec<u8>>,
    capacity: usize,
}

impl ByteBufferPool {
    pub fn new(size: usize, capacity: usize) -> Self {
        let mut buffers = VecDeque::with_capacity(size);
        for _ in 0..size {
            buffers.push_back(Vec::with_capacity(capacity));
        }
        
        Self { buffers, capacity }
    }
    
    pub fn acquire(&mut self) -> Vec<u8> {
        self.buffers.pop_front()
            .unwrap_or_else(|| Vec::with_capacity(self.capacity))
    }
    
    pub fn release(&mut self, mut buf: Vec<u8>) {
        buf.clear();
        self.buffers.push_back(buf);
    }
}
```

**高级对象池实现（线程安全）**:

```rust
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;

pub struct ThreadSafePool<T> {
    pool: Arc<Mutex<VecDeque<T>>>,
    factory: Arc<dyn Fn() -> T + Send + Sync>,
    max_size: usize,
}

impl<T> ThreadSafePool<T>
where
    T: Send + 'static,
{
    pub fn new<F>(max_size: usize, factory: F) -> Self
    where
        F: Fn() -> T + Send + Sync + 'static,
    {
        Self {
            pool: Arc::new(Mutex::new(VecDeque::with_capacity(max_size))),
            factory: Arc::new(factory),
            max_size,
        }
    }
    
    pub fn acquire(&self) -> PoolGuard<T> {
        let mut pool = self.pool.lock().unwrap();
        let item = pool.pop_front().unwrap_or_else(|| (self.factory)());
        
        PoolGuard {
            item: Some(item),
            pool: Arc::clone(&self.pool),
        }
    }
}

pub struct PoolGuard<T> {
    item: Option<T>,
    pool: Arc<Mutex<VecDeque<T>>>,
}

impl<T> Drop for PoolGuard<T> {
    fn drop(&mut self) {
        if let Some(item) = self.item.take() {
            let mut pool = self.pool.lock().unwrap();
            pool.push_back(item);
        }
    }
}

impl<T> std::ops::Deref for PoolGuard<T> {
    type Target = T;
    
    fn deref(&self) -> &Self::Target {
        self.item.as_ref().unwrap()
    }
}

impl<T> std::ops::DerefMut for PoolGuard<T> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        self.item.as_mut().unwrap()
    }
}

// 使用示例
use std::process::Command;

let pool = ThreadSafePool::new(10, || Vec::with_capacity(1024 * 1024));

// 自动归还到池中
{
    let mut buffer = pool.acquire();
    // 使用 buffer...
} // Drop时自动归还
```

**SmallVec优化（栈上小数组）**:

```rust
use smallvec::{SmallVec, smallvec};

// 小于8个元素时，存储在栈上
type ArgsVec = SmallVec<[String; 8]>;

fn build_args(base_args: &[&str], extra: &[&str]) -> ArgsVec {
    let mut args: ArgsVec = smallvec![];
    
    for arg in base_args {
        args.push(arg.to_string());
    }
    
    for arg in extra {
        args.push(arg.to_string());
    }
    
    args  // 大部分情况下无堆分配
}

// 性能对比
// Vec<String>: 每次都堆分配
// SmallVec<[String; 8]>: ≤8个元素时无堆分配（快2-3x）
```

**内存预分配策略**:

```rust
// ❌ 低效：多次分配
let mut vec = Vec::new();
for i in 0..10000 {
    vec.push(i);  // 每次可能触发重新分配
}

// ✅ 高效：预分配
let mut vec = Vec::with_capacity(10000);
for i in 0..10000 {
    vec.push(i);  // 无重新分配
}

// ✅ 更高效：直接collect
let vec: Vec<_> = (0..10000).collect();
```

**内存复用技巧**:

```rust
use std::process::{Command, Stdio};
use std::io::Read;

pub struct ProcessRunner {
    buffer: Vec<u8>,  // 复用缓冲区
}

impl ProcessRunner {
    pub fn new(buffer_size: usize) -> Self {
        Self {
            buffer: Vec::with_capacity(buffer_size),
        }
    }
    
    pub fn run_and_capture(&mut self, cmd: &str) -> std::io::Result<String> {
        // 复用buffer，避免重复分配
        self.buffer.clear();
        
        let mut child = Command::new("sh")
            .arg("-c")
            .arg(cmd)
            .stdout(Stdio::piped())
            .spawn()?;
        
        if let Some(mut stdout) = child.stdout.take() {
            stdout.read_to_end(&mut self.buffer)?;
        }
        
        child.wait()?;
        
        Ok(String::from_utf8_lossy(&self.buffer).to_string())
    }
}

// 使用示例：单个buffer运行100个进程
let mut runner = ProcessRunner::new(64 * 1024);

for i in 0..100 {
    let output = runner.run_and_capture(&format!("echo {}", i))?;
    println!("{}", output);
}
// 仅分配一次64KB内存，复用100次
```

---

### 4.2 内存映射

**mmap优化**:

```rust
use memmap2::MmapMut;

fn use_mmap(size: usize) -> std::io::Result<()> {
    let file = std::fs::OpenOptions::new()
        .read(true)
        .write(true)
        .create(true)
        .open("/tmp/data")?;
    
    file.set_len(size as u64)?;
    
    let mut mmap = unsafe { MmapMut::map_mut(&file)? };
    
    // 直接访问内存
    mmap[0] = 42;
    
    mmap.flush()?;
    Ok(())
}
```

**优点**: 减少系统调用、懒加载。

---

## 5. CPU优化

### 5.1 并行化

**Rayon并行处理**:

```rust
use rayon::prelude::*;

// 并行处理进程输出
let results: Vec<_> = outputs.par_iter()
    .map(|output| process_output(output))
    .collect();
```

**性能提升**: 4核CPU可提升3-3.5x。

**高级并行模式**:

1. **Rayon并行批处理**:

    ```rust
    use rayon::prelude::*;
    use std::process::Command;

    pub struct ParallelProcessor {
        num_threads: usize,
    }

    impl ParallelProcessor {
        pub fn new(num_threads: usize) -> Self {
            rayon::ThreadPoolBuilder::new()
                .num_threads(num_threads)
                .build_global()
                .unwrap();
            
            Self { num_threads }
        }
        
        pub fn process_batch(&self, commands: Vec<String>) -> Vec<Result<String, std::io::Error>> {
            commands.par_iter()
                .map(|cmd| {
                    let output = Command::new("sh")
                        .arg("-c")
                        .arg(cmd)
                        .output()?;
                    
                    Ok(String::from_utf8_lossy(&output.stdout).to_string())
                })
                .collect()
        }
        
        // 并行Map-Reduce
        pub fn parallel_map_reduce<T, R>(
            &self,
            data: Vec<T>,
            map_fn: impl Fn(T) -> R + Sync + Send,
            reduce_fn: impl Fn(R, R) -> R + Sync + Send,
        ) -> Option<R>
        where
            T: Send,
            R: Send,
        {
            data.into_par_iter()
                .map(map_fn)
                .reduce_with(reduce_fn)
        }
    }

    // 使用示例
    let processor = ParallelProcessor::new(8);

    // 并行执行100个命令
    let commands: Vec<_> = (0..100)
        .map(|i| format!("echo Processing {}", i))
        .collect();

    let results = processor.process_batch(commands);

    println!("成功: {} / {}", 
        results.iter().filter(|r| r.is_ok()).count(),
        results.len()
    );
    ```

2. **Work Stealing并行**:

    ```rust
    use crossbeam::channel::{unbounded, Sender, Receiver};
    use std::thread;
    use std::process::Command;

    pub struct WorkStealingPool {
        workers: Vec<thread::JoinHandle<()>>,
        sender: Sender<WorkItem>,
    }

    type WorkItem = Box<dyn FnOnce() + Send + 'static>;

    impl WorkStealingPool {
        pub fn new(size: usize) -> Self {
            let (sender, receiver) = unbounded::<WorkItem>();
            
            let mut workers = Vec::with_capacity(size);
            
            for id in 0..size {
                let rx = receiver.clone();
                
                let handle = thread::spawn(move || {
                    while let Ok(work) = rx.recv() {
                        work();
                    }
                });
                
                workers.push(handle);
            }
            
            Self { workers, sender }
        }
        
        pub fn execute<F>(&self, f: F)
        where
            F: FnOnce() + Send + 'static,
        {
            self.sender.send(Box::new(f)).unwrap();
        }
        
        pub fn shutdown(self) {
            drop(self.sender);
            for worker in self.workers {
                worker.join().unwrap();
            }
        }
    }

    // 使用示例
    let pool = WorkStealingPool::new(4);

    for i in 0..100 {
        pool.execute(move || {
            let output = Command::new("echo")
                .arg(format!("Task {}", i))
                .output()
                .unwrap();
            
            println!("{}", String::from_utf8_lossy(&output.stdout));
        });
    }

    pool.shutdown();
    ```

3. **并行流水线处理**:

    ```rust
    use std::sync::mpsc::{channel, Sender, Receiver};
    use std::thread;

    pub struct Pipeline<I, O> {
        stages: Vec<Box<dyn FnMut(I) -> O + Send>>,
    }

    impl<I: Send + 'static, O: Send + 'static> Pipeline<I, O> {
        pub fn new() -> Self {
            Self { stages: Vec::new() }
        }
        
        pub fn add_stage<F>(mut self, f: F) -> Self
        where
            F: FnMut(I) -> O + Send + 'static,
        {
            self.stages.push(Box::new(f));
            self
        }
        
        pub fn run(&mut self, inputs: Vec<I>) -> Vec<O> {
            // 简化示例：实际应该使用多线程流水线
            inputs.into_iter()
                .map(|input| {
                    let mut result = input;
                    for stage in &mut self.stages {
                        // 这里需要类型转换逻辑
                        // 实际实现更复杂
                    }
                    // result
                    unimplemented!("需要更复杂的类型系统")
                })
                .collect()
        }
    }
    ```

4. **CPU亲和性优化** (Linux):

    ```rust
    #[cfg(target_os = "linux")]
    pub fn set_cpu_affinity(cpu_id: usize) -> std::io::Result<()> {
        use libc::{cpu_set_t, CPU_SET, CPU_ZERO, sched_setaffinity};
        use std::mem;
        
        unsafe {
            let mut cpuset: cpu_set_t = mem::zeroed();
            CPU_ZERO(&mut cpuset);
            CPU_SET(cpu_id, &mut cpuset);
            
            let result = sched_setaffinity(
                0,  // 当前线程
                mem::size_of::<cpu_set_t>(),
                &cpuset,
            );
            
            if result == 0 {
                Ok(())
            } else {
                Err(std::io::Error::last_os_error())
            }
        }
    }

    // 使用示例：将worker线程绑定到特定CPU
    thread::spawn(move || {
        set_cpu_affinity(core_id).unwrap();
        
        // 执行进程管理任务
        loop {
            // ...
        }
    });
    ```

**并行化最佳实践**:

| 场景 | 推荐方案 | 性能提升 |
|------|---------|---------|
| CPU密集型 | Rayon | 3-3.5x (4核) |
| I/O密集型 | Tokio异步 | 10-100x |
| 混合任务 | Work Stealing Pool | 2-5x |
| 流水线 | 多stage pipeline | 2-4x |

---

### 5.2 减少上下文切换

**控制并发数**:

```rust
use tokio::sync::Semaphore;

let sem = Arc::new(Semaphore::new(num_cpus::get()));

for task in tasks {
    let permit = sem.clone().acquire_owned().await.unwrap();
    tokio::spawn(async move {
        do_work(task).await;
        drop(permit);
    });
}
```

---

## 6. I/O优化

### 6.1 异步I/O

**Tokio异步进程**:

```rust
use tokio::process::Command;

async fn async_execute(cmd: &str) -> std::io::Result<Vec<u8>> {
    let output = Command::new("sh")
        .arg("-c")
        .arg(cmd)
        .output()
        .await?;
    
    Ok(output.stdout)
}

// 并发执行
let results = futures::future::join_all(
    commands.iter().map(|cmd| async_execute(cmd))
).await;
```

**吞吐量提升**: 相比同步版本提升10-50x。

**异步流式I/O**:

```rust
use tokio::io::{AsyncBufReadExt, BufReader};
use tokio::process::Command;

pub async fn stream_output(cmd: &str) -> std::io::Result<Vec<String>> {
    let mut child = Command::new("sh")
        .arg("-c")
        .arg(cmd)
        .stdout(std::process::Stdio::piped())
        .spawn()?;
    
    let stdout = child.stdout.take().unwrap();
    let reader = BufReader::new(stdout);
    let mut lines = reader.lines();
    
    let mut output = Vec::new();
    
    while let Some(line) = lines.next_line().await? {
        output.push(line);
    }
    
    child.wait().await?;
    Ok(output)
}
```

**异步并发I/O控制**:

```rust
use tokio::sync::Semaphore;
use tokio::process::Command;
use std::sync::Arc;

pub async fn concurrent_with_limit(
    commands: Vec<String>,
    limit: usize
) -> Vec<Result<String, std::io::Error>> {
    let sem = Arc::new(Semaphore::new(limit));
    let mut tasks = Vec::new();
    
    for cmd in commands {
        let sem_clone = Arc::clone(&sem);
        
        let task = tokio::spawn(async move {
            let _permit = sem_clone.acquire().await.unwrap();
            
            let output = Command::new("sh")
                .arg("-c")
                .arg(&cmd)
                .output()
                .await?;
            
            Ok(String::from_utf8_lossy(&output.stdout).to_string())
        });
        
        tasks.push(task);
    }
    
    let mut results = Vec::new();
    for task in tasks {
        results.push(task.await.unwrap());
    }
    
    results
}

// 限制并发：防止资源耗尽
// limit = 10: 同时最多10个进程
```

---

### 6.2 批量I/O

```rust
// ❌ 逐个读写
for _ in 0..1000 {
    let byte = reader.read_u8()?;
    writer.write_u8(byte)?;
}

// ✅ 批量读写
let mut buffer = vec![0; 1024];
while let Ok(n) = reader.read(&mut buffer) {
    if n == 0 { break; }
    writer.write_all(&buffer[..n])?;
}
```

**高级批量I/O模式**:

```rust
use std::io::{BufWriter, Write};
use std::fs::File;

// 1. 批量写入带缓冲
pub fn batch_write(file_path: &str, data: &[Vec<u8>]) -> std::io::Result<()> {
    let file = File::create(file_path)?;
    let mut writer = BufWriter::with_capacity(256 * 1024, file);
    
    for chunk in data {
        writer.write_all(chunk)?;
    }
    
    writer.flush()?;
    Ok(())
}

// 2. 批量读取
pub fn batch_read(file_path: &str, chunk_size: usize) -> std::io::Result<Vec<Vec<u8>>> {
    use std::io::Read;
    
    let mut file = File::open(file_path)?;
    let mut chunks = Vec::new();
    let mut buffer = vec![0; chunk_size];
    
    loop {
        match file.read(&mut buffer) {
            Ok(0) => break,
            Ok(n) => {
                chunks.push(buffer[..n].to_vec());
            }
            Err(e) => return Err(e),
        }
    }
    
    Ok(chunks)
}

// 性能对比 (10MB文件):
// 逐字节读写: 8,000ms
// 4KB缓冲:    120ms
// 256KB缓冲:  15ms (533x 提升)
```

---

## 7. 并发优化

### 7.1 进程池

**高级进程池**:

```rust
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;

pub struct AdvancedProcessPool {
    workers: Arc<Mutex<VecDeque<Worker>>>,
    size: usize,
}

struct Worker {
    child: Child,
    busy: bool,
}

impl AdvancedProcessPool {
    pub fn new(size: usize, program: &str) -> std::io::Result<Self> {
        let mut workers = VecDeque::with_capacity(size);
        
        for _ in 0..size {
            let child = Command::new(program).spawn()?;
            workers.push_back(Worker {
                child,
                busy: false,
            });
        }
        
        Ok(Self {
            workers: Arc::new(Mutex::new(workers)),
            size,
        })
    }
    
    pub fn execute<F>(&self, task: F) -> std::io::Result<()>
    where
        F: FnOnce(&mut Child) -> std::io::Result<()>,
    {
        let mut workers = self.workers.lock().unwrap();
        
        if let Some(worker) = workers.iter_mut().find(|w| !w.busy) {
            worker.busy = true;
            task(&mut worker.child)?;
            worker.busy = false;
        }
        
        Ok(())
    }
}
```

---

### 7.2 动态扩缩容

```rust
impl AdvancedProcessPool {
    pub fn scale_up(&mut self, count: usize, program: &str) -> std::io::Result<()> {
        let mut workers = self.workers.lock().unwrap();
        
        for _ in 0..count {
            let child = Command::new(program).spawn()?;
            workers.push_back(Worker {
                child,
                busy: false,
            });
        }
        
        self.size += count;
        Ok(())
    }
    
    pub fn scale_down(&mut self, count: usize) -> std::io::Result<()> {
        let mut workers = self.workers.lock().unwrap();
        
        for _ in 0..count.min(workers.len()) {
            if let Some(mut worker) = workers.pop_front() {
                worker.child.kill()?;
            }
        }
        
        self.size = self.size.saturating_sub(count);
        Ok(())
    }
}
```

---

## 8. 基准测试

### 8.1 Criterion基准测试

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_process_spawn(c: &mut Criterion) {
    c.bench_function("spawn_process", |b| {
        b.iter(|| {
            let child = Command::new("true").spawn().unwrap();
            child.wait_with_output().unwrap();
        });
    });
}

criterion_group!(benches, bench_process_spawn);
criterion_main!(benches);
```

---

### 8.2 对比基准

**IPC基准**:

```rust
fn bench_ipc_mechanisms(c: &mut Criterion) {
    let mut group = c.benchmark_group("ipc");
    
    // Unix Socket
    group.bench_function("unix_socket", |b| {
        b.iter(|| unix_socket_transfer(black_box(&data)));
    });
    
    // 管道
    group.bench_function("pipe", |b| {
        b.iter(|| pipe_transfer(black_box(&data)));
    });
    
    // 共享内存
    group.bench_function("shared_memory", |b| {
        b.iter(|| shm_transfer(black_box(&data)));
    });
    
    group.finish();
}
```

---

## 9. 性能监控

### 9.1 运行时监控

```rust
use sysinfo::{System, ProcessExt};

pub struct ProcessMonitor {
    system: System,
}

impl ProcessMonitor {
    pub fn new() -> Self {
        Self {
            system: System::new_all(),
        }
    }
    
    pub fn monitor(&mut self, pid: u32) {
        self.system.refresh_all();
        
        if let Some(process) = self.system.process(sysinfo::Pid::from(pid as usize)) {
            println!("CPU: {:.2}%", process.cpu_usage());
            println!("Memory: {} KB", process.memory());
            println!("Disk read: {} bytes", process.disk_usage().read_bytes);
            println!("Disk write: {} bytes", process.disk_usage().written_bytes);
        }
    }
}
```

---

### 9.2 性能指标收集

```rust
use std::time::Instant;

pub struct Metrics {
    pub total_processes: usize,
    pub avg_duration: std::time::Duration,
    pub max_memory: usize,
}

pub struct MetricsCollector {
    start: Instant,
    process_count: usize,
    durations: Vec<std::time::Duration>,
}

impl MetricsCollector {
    pub fn new() -> Self {
        Self {
            start: Instant::now(),
            process_count: 0,
            durations: Vec::new(),
        }
    }
    
    pub fn record_process(&mut self, duration: std::time::Duration) {
        self.process_count += 1;
        self.durations.push(duration);
    }
    
    pub fn report(&self) -> Metrics {
        let avg_duration = self.durations.iter().sum::<std::time::Duration>() 
            / self.durations.len() as u32;
        
        Metrics {
            total_processes: self.process_count,
            avg_duration,
            max_memory: 0,  // 需要从系统获取
        }
    }
}
```

---

## 10. 实战案例

### 案例: 高性能批处理系统

```rust
use tokio::process::Command;
use tokio::sync::Semaphore;
use std::sync::Arc;

pub struct BatchProcessor {
    concurrency: usize,
    semaphore: Arc<Semaphore>,
}

impl BatchProcessor {
    pub fn new(concurrency: usize) -> Self {
        Self {
            concurrency,
            semaphore: Arc::new(Semaphore::new(concurrency)),
        }
    }
    
    pub async fn process_batch(&self, tasks: Vec<String>) -> Vec<Result<String, std::io::Error>> {
        let mut handles = vec![];
        
        for task in tasks {
            let sem = self.semaphore.clone();
            let handle = tokio::spawn(async move {
                let _permit = sem.acquire().await.unwrap();
                
                let output = Command::new("sh")
                    .arg("-c")
                    .arg(&task)
                    .output()
                    .await?;
                
                Ok(String::from_utf8_lossy(&output.stdout).to_string())
            });
            
            handles.push(handle);
        }
        
        let mut results = Vec::with_capacity(handles.len());
        for handle in handles {
            results.push(handle.await.unwrap());
        }
        
        results
    }
}

// 使用示例
#[tokio::main]
async fn main() {
    let processor = BatchProcessor::new(10);
    
    let tasks = (0..100).map(|i| format!("echo Task {}", i)).collect();
    
    let start = std::time::Instant::now();
    let results = processor.process_batch(tasks).await;
    let duration = start.elapsed();
    
    println!("处理 {} 个任务", results.len());
    println!("总耗时: {:?}", duration);
    println!("平均: {:?}/任务", duration / results.len() as u32);
}
```

**性能指标**:

- 并发数: 10
- 任务数: 100
- 总耗时: ~1s
- 吞吐量: 100 tasks/s

---

## 总结

**性能优化清单**:

| 优化项 | 方法 | 提升 |
|--------|------|------|
| **进程启动** | 进程池 | 30x |
| **IPC** | Unix Socket代替管道 | 10x |
| **I/O** | BufReader/Writer | 10-30x |
| **并发** | 异步 + 信号量 | 10-50x |
| **内存** | 对象池 | 减少50%分配 |
| **CPU** | Rayon并行 | 3-3.5x |

**关键原则**:

1. ✅ **测量优先**: 先测量再优化
2. ✅ **选择合适的IPC**: 根据场景选择
3. ✅ **使用缓冲**: BufReader/BufWriter
4. ✅ **异步I/O**: Tokio提升并发
5. ✅ **进程池**: 复用进程
6. ✅ **监控指标**: 持续监控

**推荐配置**:

```rust
// 生产级配置
ProcessPool::new(num_cpus::get() * 2, "worker")?
    .with_buffer_size(128 * 1024)
    .with_timeout(Duration::from_secs(30))
    .with_retry(3)
    .build()
```

---

**下一步**: 返回 [主索引导航](../tier_01_foundations/02_主索引导航.md)

---

**文档维护**: Documentation Team  
**创建日期**: 2025-10-22  
**最后更新**: 2025-10-23  
**适用版本**: Rust 1.90+
