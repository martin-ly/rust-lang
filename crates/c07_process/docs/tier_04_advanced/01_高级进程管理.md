# Tier 4: é«˜çº§è¿›ç¨‹ç®¡ç†

> **æ–‡æ¡£ç±»å‹**: é«˜çº§ä¸»é¢˜
> **éš¾åº¦**: â­â­â­â­
> **é€‚ç”¨ç‰ˆæœ¬**: Rust 1.92.0+
> **å‰ç½®çŸ¥è¯†**: [æ€§èƒ½ä¼˜åŒ–å‚è€ƒ](../tier_03_references/05_æ€§èƒ½ä¼˜åŒ–å‚è€ƒ.md)

---

## ç›®å½•

- [Tier 4: é«˜çº§è¿›ç¨‹ç®¡ç†](#tier-4-é«˜çº§è¿›ç¨‹ç®¡ç†)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“ çŸ¥è¯†ç»“æ„](#-çŸ¥è¯†ç»“æ„)
  - [1. è¿›ç¨‹æ± æ¶æ„è®¾è®¡](#1-è¿›ç¨‹æ± æ¶æ„è®¾è®¡)
    - [1.1 åŸºç¡€è¿›ç¨‹æ± ](#11-åŸºç¡€è¿›ç¨‹æ± )
    - [1.2 å¼‚æ­¥è¿›ç¨‹æ± ](#12-å¼‚æ­¥è¿›ç¨‹æ± )
    - [1.3 åŠ¨æ€æ‰©ç¼©å®¹æ± ](#13-åŠ¨æ€æ‰©ç¼©å®¹æ± )
    - [1.4 ä¼˜å…ˆçº§æ± ](#14-ä¼˜å…ˆçº§æ± )
  - [2. è¿›ç¨‹è°ƒåº¦ç­–ç•¥](#2-è¿›ç¨‹è°ƒåº¦ç­–ç•¥)
    - [2.1 FIFOè°ƒåº¦](#21-fifoè°ƒåº¦)
    - [2.2 ä¼˜å…ˆçº§è°ƒåº¦](#22-ä¼˜å…ˆçº§è°ƒåº¦)
    - [2.3 å…¬å¹³è°ƒåº¦](#23-å…¬å¹³è°ƒåº¦)
    - [2.4 å®æ—¶è°ƒåº¦](#24-å®æ—¶è°ƒåº¦)
  - [3. è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†](#3-è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†)
    - [3.1 å¥åº·æ£€æŸ¥](#31-å¥åº·æ£€æŸ¥)
    - [3.2 è‡ªåŠ¨é‡å¯](#32-è‡ªåŠ¨é‡å¯)
    - [3.3 ä¼˜é›…å…³é—­](#33-ä¼˜é›…å…³é—­)
    - [3.4 èµ„æºæ¸…ç†](#34-èµ„æºæ¸…ç†)
  - [4. è¿›ç¨‹ç›‘æ§ä¸è¯Šæ–­](#4-è¿›ç¨‹ç›‘æ§ä¸è¯Šæ–­)
    - [4.1 å®æ—¶ç›‘æ§ç³»ç»Ÿ](#41-å®æ—¶ç›‘æ§ç³»ç»Ÿ)
    - [4.2 æ€§èƒ½æŒ‡æ ‡æ”¶é›†](#42-æ€§èƒ½æŒ‡æ ‡æ”¶é›†)
    - [4.3 å‘Šè­¦ç³»ç»Ÿ](#43-å‘Šè­¦ç³»ç»Ÿ)
    - [4.4 è¯Šæ–­å·¥å…·](#44-è¯Šæ–­å·¥å…·)
  - [5. è¿›ç¨‹é—´åè°ƒ](#5-è¿›ç¨‹é—´åè°ƒ)
    - [5.1 åˆ†å¸ƒå¼é”](#51-åˆ†å¸ƒå¼é”)
    - [5.2 é€‰ä¸»ç®—æ³•](#52-é€‰ä¸»ç®—æ³•)
    - [5.3 ä»»åŠ¡åˆ†é…](#53-ä»»åŠ¡åˆ†é…)
  - [6. å®¹é”™ä¸æ¢å¤](#6-å®¹é”™ä¸æ¢å¤)
  - [7. å®æˆ˜æ¡ˆä¾‹](#7-å®æˆ˜æ¡ˆä¾‹)
    - [æ¡ˆä¾‹: ç”Ÿäº§çº§è¿›ç¨‹ç®¡ç†ç³»ç»Ÿ](#æ¡ˆä¾‹-ç”Ÿäº§çº§è¿›ç¨‹ç®¡ç†ç³»ç»Ÿ)
  - [8. æœ€ä½³å®è·µ](#8-æœ€ä½³å®è·µ)
  - [æ€»ç»“](#æ€»ç»“)

---

## ğŸ“ çŸ¥è¯†ç»“æ„

### æ¦‚å¿µå®šä¹‰

**é«˜çº§è¿›ç¨‹ç®¡ç† (Advanced Process Management)**:

- **å®šä¹‰**: Rust 1.92.0 é«˜çº§è¿›ç¨‹ç®¡ç†ï¼ŒåŒ…æ‹¬è¿›ç¨‹æ± æ¶æ„è®¾è®¡ã€è¿›ç¨‹è°ƒåº¦ç­–ç•¥ã€è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€è¿›ç¨‹ç›‘æ§ä¸è¯Šæ–­ã€è¿›ç¨‹é—´åè°ƒã€å®¹é”™ä¸æ¢å¤ã€å®æˆ˜æ¡ˆä¾‹ã€æœ€ä½³å®è·µç­‰
- **ç±»å‹**: é«˜çº§ä¸»é¢˜æ–‡æ¡£
- **èŒƒç•´**: è¿›ç¨‹ç®¡ç†ã€ç³»ç»Ÿç¼–ç¨‹
- **ç‰ˆæœ¬**: Rust 1.92.0+ (Edition 2024)
- **ç›¸å…³æ¦‚å¿µ**: è¿›ç¨‹æ± ã€è¿›ç¨‹è°ƒåº¦ã€ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€è¿›ç¨‹ç›‘æ§ã€è¿›ç¨‹é—´åè°ƒã€å®¹é”™

### å±æ€§ç‰¹å¾

**æ ¸å¿ƒå±æ€§**:

- **è¿›ç¨‹æ± æ¶æ„è®¾è®¡**: åŸºç¡€è¿›ç¨‹æ± ã€å¼‚æ­¥è¿›ç¨‹æ± ã€åŠ¨æ€æ‰©ç¼©å®¹æ± ã€ä¼˜å…ˆçº§æ± 
- **è¿›ç¨‹è°ƒåº¦ç­–ç•¥**: FIFO è°ƒåº¦ã€ä¼˜å…ˆçº§è°ƒåº¦ã€å…¬å¹³è°ƒåº¦ã€å®æ—¶è°ƒåº¦
- **è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†**: å¥åº·æ£€æŸ¥ã€è‡ªåŠ¨é‡å¯ã€ä¼˜é›…å…³é—­ã€èµ„æºæ¸…ç†
- **è¿›ç¨‹ç›‘æ§ä¸è¯Šæ–­**: å®æ—¶ç›‘æ§ç³»ç»Ÿã€æ€§èƒ½æŒ‡æ ‡æ”¶é›†ã€å‘Šè­¦ç³»ç»Ÿã€è¯Šæ–­å·¥å…·
- **è¿›ç¨‹é—´åè°ƒ**: åˆ†å¸ƒå¼é”ã€é€‰ä¸»ç®—æ³•ã€ä»»åŠ¡åˆ†é…
- **å®¹é”™ä¸æ¢å¤**: å®¹é”™æœºåˆ¶ã€æ¢å¤ç­–ç•¥

**Rust 1.92.0 æ–°ç‰¹æ€§**:

- **æ”¹è¿›çš„è¿›ç¨‹ç®¡ç†**: æ›´é«˜æ•ˆçš„è¿›ç¨‹ç®¡ç†æ”¯æŒ
- **å¢å¼ºçš„å¼‚æ­¥è¿›ç¨‹**: æ›´å¥½çš„å¼‚æ­¥è¿›ç¨‹æ”¯æŒ
- **ä¼˜åŒ–çš„æ€§èƒ½**: æ›´é«˜æ•ˆçš„è¿›ç¨‹æ€§èƒ½

**æ€§èƒ½ç‰¹å¾**:

- **é«˜å¹¶å‘**: æ”¯æŒå¤§è§„æ¨¡å¹¶å‘è¿›ç¨‹
- **é«˜æ€§èƒ½**: é«˜æ•ˆçš„è¿›ç¨‹ç®¡ç†
- **é€‚ç”¨åœºæ™¯**: å¤§è§„æ¨¡ç³»ç»Ÿã€é«˜æ€§èƒ½åº”ç”¨ã€äº‘åŸç”Ÿåº”ç”¨

### å…³ç³»è¿æ¥

**ç»„åˆå…³ç³»**:

- é«˜çº§è¿›ç¨‹ç®¡ç† --[covers]--> è¿›ç¨‹ç®¡ç†å®Œæ•´å†…å®¹
- å¤§è§„æ¨¡ç³»ç»Ÿ --[uses]--> é«˜çº§è¿›ç¨‹ç®¡ç†

**ä¾èµ–å…³ç³»**:

- é«˜çº§è¿›ç¨‹ç®¡ç† --[depends-on]--> è¿›ç¨‹ç®¡ç†åŸºç¡€
- å¤§è§„æ¨¡åº”ç”¨ --[depends-on]--> é«˜çº§è¿›ç¨‹ç®¡ç†

### æ€ç»´å¯¼å›¾

```text
é«˜çº§è¿›ç¨‹ç®¡ç†
â”‚
â”œâ”€â”€ è¿›ç¨‹æ± æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ åŸºç¡€è¿›ç¨‹æ± 
â”‚   â”œâ”€â”€ å¼‚æ­¥è¿›ç¨‹æ± 
â”‚   â””â”€â”€ åŠ¨æ€æ‰©ç¼©å®¹æ± 
â”œâ”€â”€ è¿›ç¨‹è°ƒåº¦ç­–ç•¥
â”‚   â”œâ”€â”€ FIFO è°ƒåº¦
â”‚   â””â”€â”€ ä¼˜å…ˆçº§è°ƒåº¦
â”œâ”€â”€ è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
â”‚   â”œâ”€â”€ å¥åº·æ£€æŸ¥
â”‚   â””â”€â”€ è‡ªåŠ¨é‡å¯
â”œâ”€â”€ è¿›ç¨‹ç›‘æ§ä¸è¯Šæ–­
â”‚   â”œâ”€â”€ å®æ—¶ç›‘æ§ç³»ç»Ÿ
â”‚   â””â”€â”€ æ€§èƒ½æŒ‡æ ‡æ”¶é›†
â”œâ”€â”€ è¿›ç¨‹é—´åè°ƒ
â”‚   â”œâ”€â”€ åˆ†å¸ƒå¼é”
â”‚   â””â”€â”€ é€‰ä¸»ç®—æ³•
â””â”€â”€ å®¹é”™ä¸æ¢å¤
    â””â”€â”€ å®¹é”™æœºåˆ¶
```

### å¤šç»´æ¦‚å¿µå¯¹æ¯”çŸ©é˜µ

| è¿›ç¨‹ç®¡ç†æŠ€æœ¯ | æ€§èƒ½ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ | Rust 1.92.0 |
| --- | --- | --- | --- | --- |
| **åŸºç¡€è¿›ç¨‹æ± ** | ä¸­ | ä½ | ç®€å•åœºæ™¯ | âœ… |
| **å¼‚æ­¥è¿›ç¨‹æ± ** | é«˜ | ä¸­ | å¼‚æ­¥åœºæ™¯ | âœ… |
| **åŠ¨æ€æ‰©ç¼©å®¹æ± ** | é«˜ | é«˜ | åŠ¨æ€è´Ÿè½½ | âœ… |
| **ä¼˜å…ˆçº§æ± ** | ä¸­ | ä¸­ | ä¼˜å…ˆçº§åœºæ™¯ | âœ… |
| **FIFO è°ƒåº¦** | ä¸­ | ä½ | ç®€å•åœºæ™¯ | âœ… |
| **ä¼˜å…ˆçº§è°ƒåº¦** | ä¸­ | ä¸­ | ä¼˜å…ˆçº§åœºæ™¯ | âœ… |
| **å…¬å¹³è°ƒåº¦** | ä¸­ | ä¸­ | å…¬å¹³åœºæ™¯ | âœ… |
| **å®æ—¶è°ƒåº¦** | é«˜ | é«˜ | å®æ—¶åœºæ™¯ | âœ… |

### å†³ç­–æ ‘å›¾

```text
é€‰æ‹©è¿›ç¨‹ç®¡ç†æŠ€æœ¯
â”‚
â”œâ”€â”€ æ˜¯å¦éœ€è¦è¿›ç¨‹æ± ï¼Ÿ
â”‚   â”œâ”€â”€ æ˜¯ â†’ åŸºç¡€è¿›ç¨‹æ±  / å¼‚æ­¥è¿›ç¨‹æ±  / åŠ¨æ€æ‰©ç¼©å®¹æ± 
â”‚   â””â”€â”€ å¦ â†’ ç»§ç»­åˆ¤æ–­
â”‚       â”œâ”€â”€ æ˜¯å¦éœ€è¦è°ƒåº¦ç­–ç•¥ï¼Ÿ
â”‚       â”‚   â”œâ”€â”€ æ˜¯ â†’ FIFO / ä¼˜å…ˆçº§ / å…¬å¹³ / å®æ—¶è°ƒåº¦
â”‚       â”‚   â””â”€â”€ å¦ â†’ ç»§ç»­åˆ¤æ–­
â”‚       â”‚       â”œâ”€â”€ æ˜¯å¦éœ€è¦ç›‘æ§ï¼Ÿ
â”‚       â”‚       â”‚   â”œâ”€â”€ æ˜¯ â†’ å®æ—¶ç›‘æ§ç³»ç»Ÿ / æ€§èƒ½æŒ‡æ ‡æ”¶é›†
â”‚       â”‚       â”‚   â””â”€â”€ å¦ â†’ è¿›ç¨‹é—´åè°ƒ / å®¹é”™ä¸æ¢å¤
```

---

## 1. è¿›ç¨‹æ± æ¶æ„è®¾è®¡

### 1.1 åŸºç¡€è¿›ç¨‹æ± 

**è®¾è®¡åŸåˆ™**:

1. **å›ºå®šå®¹é‡**: é¢„å…ˆåˆ›å»ºå›ºå®šæ•°é‡çš„worker
2. **ä»»åŠ¡é˜Ÿåˆ—**: FIFOé˜Ÿåˆ—ç®¡ç†å¾…å¤„ç†ä»»åŠ¡
3. **åŒæ­¥ç®¡ç†**: ä½¿ç”¨Mutex/Condvaråè°ƒ
4. **èµ„æºå¤ç”¨**: é¿å…é¢‘ç¹åˆ›å»ºé”€æ¯è¿›ç¨‹

**å®Œæ•´å®ç°**:

```rust
use std::sync::{Arc, Mutex, Condvar};
use std::collections::VecDeque;
use std::process::{Child, Command};
use std::time::Duration;

pub struct ProcessPool {
    workers: Arc<Mutex<VecDeque<Worker>>>,
    tasks: Arc<(Mutex<VecDeque<Task>>, Condvar)>,
    size: usize,
}

struct Worker {
    id: usize,
    child: Option<Child>,
    busy: bool,
}

struct Task {
    command: String,
    args: Vec<String>,
}

impl ProcessPool {
    pub fn new(size: usize, program: &str) -> std::io::Result<Self> {
        let mut workers = VecDeque::with_capacity(size);

        for id in 0..size {
            let child = Command::new(program).spawn()?;
            workers.push_back(Worker {
                id,
                child: Some(child),
                busy: false,
            });
        }

        Ok(Self {
            workers: Arc::new(Mutex::new(workers)),
            tasks: Arc::new((Mutex::new(VecDeque::new()), Condvar::new())),
            size,
        })
    }

    pub fn submit(&self, command: String, args: Vec<String>) {
        let (lock, cvar) = &*self.tasks;
        let mut tasks = lock.lock().unwrap();
        tasks.push_back(Task { command, args });
        cvar.notify_one();
    }

    pub fn execute(&self) -> std::io::Result<()> {
        let (lock, cvar) = &*self.tasks;
        let mut tasks = lock.lock().unwrap();

        while tasks.is_empty() {
            tasks = cvar.wait(tasks).unwrap();
        }

        if let Some(task) = tasks.pop_front() {
            let mut workers = self.workers.lock().unwrap();

            if let Some(worker) = workers.iter_mut().find(|w| !w.busy) {
                worker.busy = true;

                // æ‰§è¡Œä»»åŠ¡
                if let Some(ref mut child) = worker.child {
                    child.wait()?;
                }

                // é‡æ–°å¯åŠ¨worker
                worker.child = Some(Command::new(&task.command)
                    .args(&task.args)
                    .spawn()?);

                worker.busy = false;
            }
        }

        Ok(())
    }

    pub fn shutdown(self) -> std::io::Result<()> {
        let mut workers = self.workers.lock().unwrap();

        for worker in workers.iter_mut() {
            if let Some(mut child) = worker.child.take() {
                child.kill()?;
                child.wait()?;
            }
        }

        Ok(())
    }
}
```

---

### 1.2 å¼‚æ­¥è¿›ç¨‹æ± 

**Tokioå¼‚æ­¥ç‰ˆæœ¬**:

```rust
use tokio::process::Command;
use tokio::sync::{Semaphore, Mutex};
use std::sync::Arc;

pub struct AsyncProcessPool {
    semaphore: Arc<Semaphore>,
    max_workers: usize,
    active: Arc<Mutex<usize>>,
}

impl AsyncProcessPool {
    pub fn new(max_workers: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_workers)),
            max_workers,
            active: Arc::new(Mutex::new(0)),
        }
    }

    pub async fn execute<F, Fut>(&self, task: F) -> std::io::Result<()>
    where
        F: FnOnce() -> Fut + Send + 'static,
        Fut: std::future::Future<Output = std::io::Result<()>> + Send,
    {
        let permit = self.semaphore.clone().acquire_owned().await.unwrap();

        {
            let mut active = self.active.lock().await;
            *active += 1;
            println!("æ´»åŠ¨è¿›ç¨‹æ•°: {}", *active);
        }

        tokio::spawn(async move {
            let _permit = permit;
            task().await.ok();
        });

        Ok(())
    }

    pub async fn wait_all(&self) {
        // è·å–æ‰€æœ‰permitsï¼Œç¡®ä¿æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        let permits: Vec<_> = (0..self.max_workers)
            .map(|_| self.semaphore.clone().try_acquire_owned())
            .collect();

        // é‡Šæ”¾æ‰€æœ‰permits
        drop(permits);
    }
}
```

---

### 1.3 åŠ¨æ€æ‰©ç¼©å®¹æ± 

**è‡ªé€‚åº”å®¹é‡è°ƒæ•´**:

```rust
use std::sync::atomic::{AtomicUsize, Ordering};

pub struct DynamicProcessPool {
    min_workers: usize,
    max_workers: usize,
    current_workers: AtomicUsize,
    pending_tasks: Arc<Mutex<VecDeque<Task>>>,
    workers: Arc<Mutex<Vec<WorkerHandle>>>,
}

impl DynamicProcessPool {
    pub fn new(min: usize, max: usize) -> Self {
        Self {
            min_workers: min,
            max_workers: max,
            current_workers: AtomicUsize::new(min),
            pending_tasks: Arc::new(Mutex::new(VecDeque::new())),
            workers: Arc::new(Mutex::new(Vec::with_capacity(max))),
        }
    }

    pub fn scale_up(&self, count: usize) -> std::io::Result<()> {
        let current = self.current_workers.load(Ordering::SeqCst);
        let new_count = (current + count).min(self.max_workers);

        if new_count > current {
            let mut workers = self.workers.lock().unwrap();

            for _ in 0..(new_count - current) {
                workers.push(self.spawn_worker()?);
            }

            self.current_workers.store(new_count, Ordering::SeqCst);
            println!("æ‰©å®¹åˆ° {} ä¸ªworker", new_count);
        }

        Ok(())
    }

    pub fn scale_down(&self, count: usize) -> std::io::Result<()> {
        let current = self.current_workers.load(Ordering::SeqCst);
        let new_count = (current.saturating_sub(count)).max(self.min_workers);

        if new_count < current {
            let mut workers = self.workers.lock().unwrap();

            for _ in 0..(current - new_count) {
                if let Some(worker) = workers.pop() {
                    worker.terminate()?;
                }
            }

            self.current_workers.store(new_count, Ordering::SeqCst);
            println!("ç¼©å®¹åˆ° {} ä¸ªworker", new_count);
        }

        Ok(())
    }

    fn spawn_worker(&self) -> std::io::Result<WorkerHandle> {
        // Workerå®ç°ç»†èŠ‚
        unimplemented!()
    }
}

struct WorkerHandle {
    child: Child,
}

impl WorkerHandle {
    fn terminate(mut self) -> std::io::Result<()> {
        self.child.kill()?;
        self.child.wait()?;
        Ok(())
    }
}
```

**è‡ªåŠ¨æ‰©ç¼©å®¹ç­–ç•¥**:

```rust
impl DynamicProcessPool {
    pub fn auto_scale(&self) {
        let tasks = self.pending_tasks.lock().unwrap();
        let task_count = tasks.len();
        let current = self.current_workers.load(Ordering::SeqCst);

        // æ‰©å®¹ï¼šå¾…å¤„ç†ä»»åŠ¡ > å½“å‰workeræ•° * 2
        if task_count > current * 2 {
            let scale_up_count = (task_count / 2).min(self.max_workers - current);
            drop(tasks);
            self.scale_up(scale_up_count).ok();
        }
        // ç¼©å®¹ï¼šå¾…å¤„ç†ä»»åŠ¡ < å½“å‰workeræ•° / 2
        else if task_count < current / 2 && current > self.min_workers {
            let scale_down_count = (current / 2).min(current - self.min_workers);
            drop(tasks);
            self.scale_down(scale_down_count).ok();
        }
    }
}
```

---

### 1.4 ä¼˜å…ˆçº§æ± 

**å¤šçº§ä¼˜å…ˆçº§é˜Ÿåˆ—**:

```rust
use std::collections::BinaryHeap;
use std::cmp::Ordering;

#[derive(Eq, PartialEq)]
struct PriorityTask {
    priority: u8,  // 0-255, è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜
    task: Task,
    timestamp: std::time::Instant,
}

impl Ord for PriorityTask {
    fn cmp(&self, other: &Self) -> Ordering {
        // å…ˆæ¯”è¾ƒä¼˜å…ˆçº§ï¼Œå†æ¯”è¾ƒæ—¶é—´æˆ³ï¼ˆFIFOï¼‰
        self.priority.cmp(&other.priority)
            .then_with(|| other.timestamp.cmp(&self.timestamp))
    }
}

impl PartialOrd for PriorityTask {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

pub struct PriorityProcessPool {
    high_priority: Arc<Mutex<BinaryHeap<PriorityTask>>>,
    normal_priority: Arc<Mutex<VecDeque<Task>>>,
    low_priority: Arc<Mutex<VecDeque<Task>>>,
    workers: Arc<Mutex<Vec<Worker>>>,
}

impl PriorityProcessPool {
    pub fn submit_with_priority(&self, task: Task, priority: u8) {
        let ptask = PriorityTask {
            priority,
            task,
            timestamp: std::time::Instant::now(),
        };

        if priority >= 200 {
            self.high_priority.lock().unwrap().push(ptask);
        } else if priority >= 100 {
            self.normal_priority.lock().unwrap().push_back(ptask.task);
        } else {
            self.low_priority.lock().unwrap().push_back(ptask.task);
        }
    }

    fn next_task(&self) -> Option<Task> {
        // 1. é«˜ä¼˜å…ˆçº§
        if let Some(ptask) = self.high_priority.lock().unwrap().pop() {
            return Some(ptask.task);
        }

        // 2. æ™®é€šä¼˜å…ˆçº§
        if let Some(task) = self.normal_priority.lock().unwrap().pop_front() {
            return Some(task);
        }

        // 3. ä½ä¼˜å…ˆçº§
        self.low_priority.lock().unwrap().pop_front()
    }
}
```

---

## 2. è¿›ç¨‹è°ƒåº¦ç­–ç•¥

### 2.1 FIFOè°ƒåº¦

**å…ˆè¿›å…ˆå‡º**:

```rust
pub struct FIFOScheduler {
    queue: Arc<Mutex<VecDeque<Task>>>,
}

impl FIFOScheduler {
    pub fn new() -> Self {
        Self {
            queue: Arc::new(Mutex::new(VecDeque::new())),
        }
    }

    pub fn schedule(&self, task: Task) {
        self.queue.lock().unwrap().push_back(task);
    }

    pub fn next(&self) -> Option<Task> {
        self.queue.lock().unwrap().pop_front()
    }
}
```

---

### 2.2 ä¼˜å…ˆçº§è°ƒåº¦

**å¤šçº§åé¦ˆé˜Ÿåˆ—**:

```rust
pub struct MultiLevelFeedbackScheduler {
    queues: Vec<Arc<Mutex<VecDeque<Task>>>>,
    levels: usize,
}

impl MultiLevelFeedbackScheduler {
    pub fn new(levels: usize) -> Self {
        let queues = (0..levels)
            .map(|_| Arc::new(Mutex::new(VecDeque::new())))
            .collect();

        Self { queues, levels }
    }

    pub fn schedule(&self, task: Task, level: usize) {
        if level < self.levels {
            self.queues[level].lock().unwrap().push_back(task);
        }
    }

    pub fn next(&self) -> Option<(Task, usize)> {
        for (level, queue) in self.queues.iter().enumerate() {
            if let Some(task) = queue.lock().unwrap().pop_front() {
                return Some((task, level));
            }
        }
        None
    }
}
```

---

### 2.3 å…¬å¹³è°ƒåº¦

**æ—¶é—´ç‰‡è½®è½¬**:

```rust
pub struct FairScheduler {
    tasks: Arc<Mutex<Vec<(Task, Duration)>>>,
    time_slice: Duration,
}

impl FairScheduler {
    pub fn new(time_slice: Duration) -> Self {
        Self {
            tasks: Arc::new(Mutex::new(Vec::new())),
            time_slice,
        }
    }

    pub fn schedule(&self, task: Task) {
        self.tasks.lock().unwrap().push((task, Duration::ZERO));
    }

    pub fn next(&self) -> Option<Task> {
        let mut tasks = self.tasks.lock().unwrap();

        // æ‰¾åˆ°è¿è¡Œæ—¶é—´æœ€çŸ­çš„ä»»åŠ¡
        tasks.iter_mut()
            .enumerate()
            .min_by_key(|(_, (_, time))| *time)
            .map(|(idx, (task, time))| {
                *time += self.time_slice;
                tasks.remove(idx).0
            })
    }
}
```

---

### 2.4 å®æ—¶è°ƒåº¦

**æˆªæ­¢æ—¶é—´ä¼˜å…ˆï¼ˆEDFï¼‰**:

```rust
use std::time::{Instant, Duration};

pub struct RealtimeScheduler {
    tasks: Arc<Mutex<BinaryHeap<DeadlineTask>>>,
}

#[derive(Eq, PartialEq)]
struct DeadlineTask {
    task: Task,
    deadline: Instant,
}

impl Ord for DeadlineTask {
    fn cmp(&self, other: &Self) -> Ordering {
        // åå‘æ’åºï¼šdeadlineè¶Šæ—©ä¼˜å…ˆçº§è¶Šé«˜
        other.deadline.cmp(&self.deadline)
    }
}

impl PartialOrd for DeadlineTask {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl RealtimeScheduler {
    pub fn schedule_with_deadline(&self, task: Task, deadline: Duration) {
        let dtask = DeadlineTask {
            task,
            deadline: Instant::now() + deadline,
        };

        self.tasks.lock().unwrap().push(dtask);
    }

    pub fn next(&self) -> Option<Task> {
        let mut tasks = self.tasks.lock().unwrap();

        // ç§»é™¤è¿‡æœŸä»»åŠ¡
        while let Some(dtask) = tasks.peek() {
            if dtask.deadline < Instant::now() {
                tasks.pop();
                println!("ä»»åŠ¡å·²è¿‡æœŸï¼Œä¸¢å¼ƒ");
            } else {
                break;
            }
        }

        tasks.pop().map(|dt| dt.task)
    }
}
```

---

## 3. è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†

### 3.1 å¥åº·æ£€æŸ¥

**å‘¨æœŸæ€§å¥åº·æ£€æŸ¥**:

```rust
use std::time::{Duration, Instant};

pub struct HealthChecker {
    check_interval: Duration,
    timeout: Duration,
}

impl HealthChecker {
    pub fn new(check_interval: Duration, timeout: Duration) -> Self {
        Self {
            check_interval,
            timeout,
        }
    }

    pub async fn monitor(&self, pid: u32) -> bool {
        let start = Instant::now();

        loop {
            tokio::time::sleep(self.check_interval).await;

            // æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
            if !self.is_alive(pid) {
                println!("è¿›ç¨‹ {} ä¸å“åº”", pid);
                return false;
            }

            // æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if start.elapsed() > self.timeout {
                println!("å¥åº·æ£€æŸ¥è¶…æ—¶");
                return false;
            }
        }
    }

    fn is_alive(&self, pid: u32) -> bool {
        #[cfg(unix)]
        {
            use nix::sys::signal::{kill, Signal};
            use nix::unistd::Pid;

            kill(Pid::from_raw(pid as i32), Signal::SIGKILL).is_ok()
        }

        #[cfg(windows)]
        {
            // Windowså®ç°
            true
        }
    }
}
```

---

### 3.2 è‡ªåŠ¨é‡å¯

**é‡å¯ç­–ç•¥**:

```rust
pub struct RestartPolicy {
    max_retries: usize,
    backoff: Duration,
    max_backoff: Duration,
}

impl RestartPolicy {
    pub fn exponential_backoff() -> Self {
        Self {
            max_retries: 5,
            backoff: Duration::from_secs(1),
            max_backoff: Duration::from_secs(60),
        }
    }

    pub async fn restart_with_backoff<F, Fut>(
        &self,
        spawn_fn: F,
    ) -> std::io::Result<Child>
    where
        F: Fn() -> Fut,
        Fut: std::future::Future<Output = std::io::Result<Child>>,
    {
        let mut current_backoff = self.backoff;

        for attempt in 0..self.max_retries {
            match spawn_fn().await {
                Ok(child) => {
                    println!("é‡å¯æˆåŠŸï¼ˆå°è¯• {}ï¼‰", attempt + 1);
                    return Ok(child);
                }
                Err(e) => {
                    println!("é‡å¯å¤±è´¥: {}, ç­‰å¾… {:?}", e, current_backoff);
                    tokio::time::sleep(current_backoff).await;

                    // æŒ‡æ•°é€€é¿
                    current_backoff = (current_backoff * 2).min(self.max_backoff);
                }
            }
        }

        Err(std::io::Error::new(
            std::io::ErrorKind::Other,
            "è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°",
        ))
    }
}
```

---

### 3.3 ä¼˜é›…å…³é—­

**ä¿¡å·å¤„ç†**:

```rust
#[cfg(unix)]
use nix::sys::signal::{kill, Signal};
#[cfg(unix)]
use nix::unistd::Pid;

pub struct GracefulShutdown {
    grace_period: Duration,
}

impl GracefulShutdown {
    pub fn new(grace_period: Duration) -> Self {
        Self { grace_period }
    }

    #[cfg(unix)]
    pub async fn shutdown(&self, mut child: Child) -> std::io::Result<()> {
        let pid = child.id();

        // 1. å‘é€SIGTERM
        println!("å‘é€SIGTERMåˆ°è¿›ç¨‹ {}", pid);
        kill(Pid::from_raw(pid as i32), Signal::SIGTERM)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;

        // 2. ç­‰å¾…ä¼˜é›…å…³é—­
        let start = Instant::now();
        loop {
            if let Ok(Some(_)) = child.try_wait() {
                println!("è¿›ç¨‹ {} å·²ä¼˜é›…å…³é—­", pid);
                return Ok(());
            }

            if start.elapsed() > self.grace_period {
                break;
            }

            tokio::time::sleep(Duration::from_millis(100)).await;
        }

        // 3. å¼ºåˆ¶ç»ˆæ­¢
        println!("å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ {}", pid);
        kill(Pid::from_raw(pid as i32), Signal::SIGKILL)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;

        child.wait()?;
        Ok(())
    }
}
```

---

### 3.4 èµ„æºæ¸…ç†

**è‡ªåŠ¨èµ„æºç®¡ç†**:

```rust
pub struct ResourceManager {
    temp_files: Vec<PathBuf>,
    file_handles: Vec<std::fs::File>,
}

impl ResourceManager {
    pub fn new() -> Self {
        Self {
            temp_files: Vec::new(),
            file_handles: Vec::new(),
        }
    }

    pub fn track_temp_file(&mut self, path: PathBuf) {
        self.temp_files.push(path);
    }

    pub fn track_file_handle(&mut self, file: std::fs::File) {
        self.file_handles.push(file);
    }
}

impl Drop for ResourceManager {
    fn drop(&mut self) {
        // å…³é—­æ–‡ä»¶å¥æŸ„
        self.file_handles.clear();

        // åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        for path in &self.temp_files {
            if let Err(e) = std::fs::remove_file(path) {
                eprintln!("æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {} - {}", path.display(), e);
            }
        }
    }
}
```

---

## 4. è¿›ç¨‹ç›‘æ§ä¸è¯Šæ–­

### 4.1 å®æ—¶ç›‘æ§ç³»ç»Ÿ

**ç»¼åˆç›‘æ§**:

```rust
use sysinfo::{System, SystemExt, ProcessExt, Pid};

pub struct ProcessMonitor {
    system: System,
    watched_pids: Vec<Pid>,
    metrics_history: Vec<MetricsSnapshot>,
}

#[derive(Clone)]
pub struct MetricsSnapshot {
    timestamp: Instant,
    cpu: f32,
    memory: u64,
    threads: usize,
}

impl ProcessMonitor {
    pub fn new() -> Self {
        Self {
            system: System::new_all(),
            watched_pids: Vec::new(),
            metrics_history: Vec::new(),
        }
    }

    pub fn watch(&mut self, pid: Pid) {
        self.watched_pids.push(pid);
    }

    pub fn collect_metrics(&mut self) -> Vec<ProcessMetrics> {
        self.system.refresh_all();

        let metrics: Vec<_> = self.watched_pids.iter()
            .filter_map(|&pid| {
                self.system.process(pid).map(|p| ProcessMetrics {
                    pid: pid.as_u32(),
                    cpu: p.cpu_usage(),
                    memory: p.memory(),
                    virtual_memory: p.virtual_memory(),
                    threads: p.thread_count() as usize,
                    status: format!("{:?}", p.status()),
                })
            })
            .collect();

        // è®°å½•å†å²
        for m in &metrics {
            self.metrics_history.push(MetricsSnapshot {
                timestamp: Instant::now(),
                cpu: m.cpu,
                memory: m.memory,
                threads: m.threads,
            });
        }

        metrics
    }

    pub fn analyze_trend(&self) -> TrendAnalysis {
        if self.metrics_history.is_empty() {
            return TrendAnalysis::default();
        }

        let recent = &self.metrics_history[self.metrics_history.len().saturating_sub(100)..];

        let avg_cpu: f32 = recent.iter().map(|m| m.cpu).sum::<f32>() / recent.len() as f32;
        let avg_memory: u64 = recent.iter().map(|m| m.memory).sum::<u64>() / recent.len() as u64;

        TrendAnalysis {
            avg_cpu,
            avg_memory,
            max_cpu: recent.iter().map(|m| m.cpu).fold(0.0f32, f32::max),
            max_memory: recent.iter().map(|m| m.memory).max().unwrap_or(0),
        }
    }
}

#[derive(Debug)]
pub struct ProcessMetrics {
    pub pid: u32,
    pub cpu: f32,
    pub memory: u64,
    pub virtual_memory: u64,
    pub threads: usize,
    pub status: String,
}

#[derive(Debug, Default)]
pub struct TrendAnalysis {
    pub avg_cpu: f32,
    pub avg_memory: u64,
    pub max_cpu: f32,
    pub max_memory: u64,
}
```

---

### 4.2 æ€§èƒ½æŒ‡æ ‡æ”¶é›†

**Prometheusé›†æˆ**:

```rust
use prometheus::{IntGauge, IntCounter, Histogram, Registry};

pub struct ProcessMetrics {
    pub active_processes: IntGauge,
    pub completed_processes: IntCounter,
    pub process_duration: Histogram,
    registry: Registry,
}

impl ProcessMetrics {
    pub fn new() -> Self {
        let registry = Registry::new();

        let active_processes = IntGauge::new(
            "process_active_total",
            "å½“å‰æ´»åŠ¨è¿›ç¨‹æ•°",
        ).unwrap();

        let completed_processes = IntCounter::new(
            "process_completed_total",
            "å·²å®Œæˆè¿›ç¨‹æ€»æ•°",
        ).unwrap();

        let process_duration = Histogram::new(
            prometheus::HistogramOpts::new(
                "process_duration_seconds",
                "è¿›ç¨‹æ‰§è¡Œæ—¶é—´",
            )
        ).unwrap();

        registry.register(Box::new(active_processes.clone())).unwrap();
        registry.register(Box::new(completed_processes.clone())).unwrap();
        registry.register(Box::new(process_duration.clone())).unwrap();

        Self {
            active_processes,
            completed_processes,
            process_duration,
            registry,
        }
    }

    pub fn process_started(&self) {
        self.active_processes.inc();
    }

    pub fn process_completed(&self, duration: Duration) {
        self.active_processes.dec();
        self.completed_processes.inc();
        self.process_duration.observe(duration.as_secs_f64());
    }
}
```

---

### 4.3 å‘Šè­¦ç³»ç»Ÿ

**è§„åˆ™å¼•æ“**:

```rust
pub struct AlertRule {
    name: String,
    condition: Box<dyn Fn(&ProcessMetrics) -> bool + Send + Sync>,
    threshold_count: usize,
}

pub struct AlertManager {
    rules: Vec<AlertRule>,
    violations: HashMap<String, usize>,
}

impl AlertManager {
    pub fn new() -> Self {
        Self {
            rules: Vec::new(),
            violations: HashMap::new(),
        }
    }

    pub fn add_rule(&mut self, rule: AlertRule) {
        self.rules.push(rule);
    }

    pub fn check(&mut self, metrics: &ProcessMetrics) -> Vec<Alert> {
        let mut alerts = Vec::new();

        for rule in &self.rules {
            if (rule.condition)(metrics) {
                let count = self.violations.entry(rule.name.clone())
                    .or_insert(0);
                *count += 1;

                if *count >= rule.threshold_count {
                    alerts.push(Alert {
                        rule_name: rule.name.clone(),
                        message: format!(
                            "è§„åˆ™ {} è§¦å‘ï¼ˆè¿ç»­{}æ¬¡ï¼‰",
                            rule.name, count
                        ),
                        severity: Severity::Warning,
                    });
                    *count = 0;  // é‡ç½®è®¡æ•°
                }
            } else {
                self.violations.insert(rule.name.clone(), 0);
            }
        }

        alerts
    }
}

pub struct Alert {
    pub rule_name: String,
    pub message: String,
    pub severity: Severity,
}

pub enum Severity {
    Info,
    Warning,
    Critical,
}

// ä½¿ç”¨ç¤ºä¾‹
fn setup_alerts() -> AlertManager {
    let mut manager = AlertManager::new();

    // CPUä½¿ç”¨ç‡è¿‡é«˜
    manager.add_rule(AlertRule {
        name: "high_cpu".to_string(),
        condition: Box::new(|m| m.cpu > 80.0),
        threshold_count: 3,
    });

    // å†…å­˜æ³„æ¼
    manager.add_rule(AlertRule {
        name: "memory_leak".to_string(),
        condition: Box::new(|m| m.memory > 1024 * 1024 * 1024),  // >1GB
        threshold_count: 5,
    });

    manager
}
```

---

### 4.4 è¯Šæ–­å·¥å…·

**è¿›ç¨‹å¿«ç…§**:

```rust
pub struct ProcessSnapshot {
    pub pid: u32,
    pub command: String,
    pub cpu: f32,
    pub memory: u64,
    pub threads: Vec<ThreadInfo>,
    pub open_files: Vec<FileDescriptor>,
}

pub struct ThreadInfo {
    pub tid: u32,
    pub cpu: f32,
    pub state: String,
}

pub struct FileDescriptor {
    pub fd: i32,
    pub path: PathBuf,
    pub flags: String,
}

impl ProcessSnapshot {
    #[cfg(target_os = "linux")]
    pub fn capture(pid: u32) -> std::io::Result<Self> {
        use std::fs;

        // è¯»å– /proc/[pid]/stat
        let stat = fs::read_to_string(format!("/proc/{}/stat", pid))?;

        // è¯»å– /proc/[pid]/status
        let status = fs::read_to_string(format!("/proc/{}/status", pid))?;

        // è¯»å– /proc/[pid]/cmdline
        let cmdline = fs::read_to_string(format!("/proc/{}/cmdline", pid))?;

        // è§£æçº¿ç¨‹ä¿¡æ¯
        let threads = fs::read_dir(format!("/proc/{}/task", pid))?
            .filter_map(|e| e.ok())
            .map(|entry| {
                let tid = entry.file_name()
                    .to_string_lossy()
                    .parse::<u32>()
                    .unwrap_or(0);

                ThreadInfo {
                    tid,
                    cpu: 0.0,  // éœ€è¦è¿›ä¸€æ­¥è§£æ
                    state: "Running".to_string(),
                }
            })
            .collect();

        Ok(Self {
            pid,
            command: cmdline.replace('\0', " "),
            cpu: 0.0,  // ä»statè§£æ
            memory: 0,  // ä»statusè§£æ
            threads,
            open_files: Vec::new(),
        })
    }
}
```

---

## 5. è¿›ç¨‹é—´åè°ƒ

### 5.1 åˆ†å¸ƒå¼é”

**åŸºäºæ–‡ä»¶çš„åˆ†å¸ƒå¼é”**:

```rust
use std::fs::{File, OpenOptions};
use std::io::Write;

pub struct DistributedLock {
    file: File,
    lock_path: PathBuf,
}

impl DistributedLock {
    pub fn try_acquire(lock_path: PathBuf) -> std::io::Result<Self> {
        let file = OpenOptions::new()
            .write(true)
            .create_new(true)
            .open(&lock_path)?;

        // å†™å…¥å½“å‰è¿›ç¨‹PID
        let mut f = &file;
        write!(f, "{}", std::process::id())?;

        Ok(Self {
            file,
            lock_path,
        })
    }

    pub fn acquire_with_timeout(
        lock_path: PathBuf,
        timeout: Duration,
    ) -> std::io::Result<Self> {
        let start = Instant::now();

        loop {
            match Self::try_acquire(lock_path.clone()) {
                Ok(lock) => return Ok(lock),
                Err(e) if e.kind() == std::io::ErrorKind::AlreadyExists => {
                    if start.elapsed() > timeout {
                        return Err(std::io::Error::new(
                            std::io::ErrorKind::TimedOut,
                            "è·å–é”è¶…æ—¶",
                        ));
                    }
                    std::thread::sleep(Duration::from_millis(100));
                }
                Err(e) => return Err(e),
            }
        }
    }
}

impl Drop for DistributedLock {
    fn drop(&mut self) {
        let _ = std::fs::remove_file(&self.lock_path);
    }
}
```

---

### 5.2 é€‰ä¸»ç®—æ³•

**Bullyç®—æ³•**:

```rust
use std::collections::HashMap;

pub struct BullyElection {
    my_id: u32,
    peers: HashMap<u32, PeerStatus>,
    leader: Option<u32>,
}

enum PeerStatus {
    Alive,
    Dead,
}

impl BullyElection {
    pub fn new(my_id: u32, peer_ids: Vec<u32>) -> Self {
        let peers = peer_ids.into_iter()
            .map(|id| (id, PeerStatus::Alive))
            .collect();

        Self {
            my_id,
            peers,
            leader: None,
        }
    }

    pub fn start_election(&mut self) -> u32 {
        println!("è¿›ç¨‹ {} å‘èµ·é€‰ä¸¾", self.my_id);

        // å‘æ‰€æœ‰IDæ›´å¤§çš„è¿›ç¨‹å‘é€ELECTIONæ¶ˆæ¯
        let higher_peers: Vec<_> = self.peers.keys()
            .filter(|&&id| id > self.my_id)
            .copied()
            .collect();

        if higher_peers.is_empty() {
            // æˆ‘æ˜¯æœ€å¤§çš„ï¼Œå®£å¸ƒè‡ªå·±ä¸ºleader
            self.become_leader();
            return self.my_id;
        }

        // ç­‰å¾…å“åº”
        // ï¼ˆå®é™…å®ç°éœ€è¦ç½‘ç»œé€šä¿¡ï¼‰

        // å¦‚æœæ²¡æœ‰å“åº”ï¼Œæˆä¸ºleader
        self.become_leader();
        self.my_id
    }

    fn become_leader(&mut self) {
        println!("è¿›ç¨‹ {} æˆä¸ºleader", self.my_id);
        self.leader = Some(self.my_id);

        // å¹¿æ’­COORDINATORæ¶ˆæ¯
        for &peer_id in self.peers.keys() {
            println!("é€šçŸ¥è¿›ç¨‹ {}: æ–°leaderæ˜¯ {}", peer_id, self.my_id);
        }
    }
}
```

---

### 5.3 ä»»åŠ¡åˆ†é…

**ä¸€è‡´æ€§å“ˆå¸Œåˆ†é…**:

```rust
use std::collections::BTreeMap;

pub struct ConsistentHash {
    ring: BTreeMap<u64, u32>,  // hash -> worker_id
    replicas: usize,
}

impl ConsistentHash {
    pub fn new(replicas: usize) -> Self {
        Self {
            ring: BTreeMap::new(),
            replicas,
        }
    }

    pub fn add_worker(&mut self, worker_id: u32) {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        for i in 0..self.replicas {
            let mut hasher = DefaultHasher::new();
            format!("{}:{}", worker_id, i).hash(&mut hasher);
            let hash = hasher.finish();

            self.ring.insert(hash, worker_id);
        }
    }

    pub fn remove_worker(&mut self, worker_id: u32) {
        self.ring.retain(|_, &mut id| id != worker_id);
    }

    pub fn assign_task(&self, task_id: &str) -> Option<u32> {
        if self.ring.is_empty() {
            return None;
        }

        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        task_id.hash(&mut hasher);
        let hash = hasher.finish();

        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªhashå€¼å¤§äºç­‰äºtask hashçš„worker
        self.ring.range(hash..)
            .next()
            .or_else(|| self.ring.iter().next())
            .map(|(_, &worker_id)| worker_id)
    }
}
```

---

## 6. å®¹é”™ä¸æ¢å¤

**æ£€æŸ¥ç‚¹æœºåˆ¶**:

```rust
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize)]
pub struct Checkpoint {
    timestamp: u64,
    state: ProcessState,
}

#[derive(Serialize, Deserialize)]
pub struct ProcessState {
    completed_tasks: Vec<String>,
    pending_tasks: Vec<String>,
    metrics: MetricsSnapshot,
}

pub struct CheckpointManager {
    checkpoint_dir: PathBuf,
}

impl CheckpointManager {
    pub fn save(&self, pid: u32, state: &ProcessState) -> std::io::Result<()> {
        let checkpoint = Checkpoint {
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
            state: state.clone(),
        };

        let path = self.checkpoint_dir.join(format!("{}.json", pid));
        let json = serde_json::to_string_pretty(&checkpoint)?;
        std::fs::write(path, json)?;

        Ok(())
    }

    pub fn restore(&self, pid: u32) -> std::io::Result<ProcessState> {
        let path = self.checkpoint_dir.join(format!("{}.json", pid));
        let json = std::fs::read_to_string(path)?;
        let checkpoint: Checkpoint = serde_json::from_str(&json)?;

        Ok(checkpoint.state)
    }
}
```

---

## 7. å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹: ç”Ÿäº§çº§è¿›ç¨‹ç®¡ç†ç³»ç»Ÿ

```rust
pub struct ProductionProcessManager {
    pool: DynamicProcessPool,
    scheduler: PriorityProcessPool,
    monitor: ProcessMonitor,
    health_checker: HealthChecker,
    alert_manager: AlertManager,
    checkpoint_manager: CheckpointManager,
}

impl ProductionProcessManager {
    pub fn new() -> Self {
        Self {
            pool: DynamicProcessPool::new(4, 64),
            scheduler: PriorityProcessPool::new(),
            monitor: ProcessMonitor::new(),
            health_checker: HealthChecker::new(
                Duration::from_secs(10),
                Duration::from_secs(60),
            ),
            alert_manager: setup_alerts(),
            checkpoint_manager: CheckpointManager::new(PathBuf::from("/var/checkpoints")),
        }
    }

    pub async fn run(&mut self) {
        // å¯åŠ¨ç›‘æ§
        let monitor_task = tokio::spawn(async move {
            loop {
                let metrics = self.monitor.collect_metrics();

                for m in metrics {
                    let alerts = self.alert_manager.check(&m);
                    for alert in alerts {
                        self.handle_alert(alert).await;
                    }
                }

                tokio::time::sleep(Duration::from_secs(10)).await;
            }
        });

        // å¤„ç†ä»»åŠ¡
        loop {
            if let Some(task) = self.scheduler.next_task() {
                self.pool.execute(task).await.ok();
            }

            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    }

    async fn handle_alert(&self, alert: Alert) {
        println!("å‘Šè­¦: {} - {}", alert.rule_name, alert.message);

        // å‘é€é€šçŸ¥ï¼ˆé‚®ä»¶/Slack/PagerDutyï¼‰
        // self.notification_service.send(alert).await;
    }
}
```

---

## 8. æœ€ä½³å®è·µ

**1. è¿›ç¨‹æ± å¤§å°**:

- CPUå¯†é›†å‹: `pool_size = CPUæ ¸å¿ƒæ•°`
- I/Oå¯†é›†å‹: `pool_size = CPUæ ¸å¿ƒæ•° * 2-4`
- æ··åˆå‹: åŠ¨æ€è°ƒæ•´

**2. ç›‘æ§æŒ‡æ ‡**:

- âœ… CPUä½¿ç”¨ç‡ < 80%
- âœ… å†…å­˜å¢é•¿ç‡ < 10% /å°æ—¶
- âœ… å¹³å‡å“åº”æ—¶é—´ < 100ms
- âœ… æˆåŠŸç‡ > 99.9%

**3. é”™è¯¯å¤„ç†**:

```rust
// âœ… æ¨èï¼šè¯¦ç»†çš„é”™è¯¯ç±»å‹
#[derive(Debug)]
pub enum ProcessError {
    SpawnFailed(std::io::Error),
    ExecutionTimeout,
    UnexpectedExit(i32),
    ResourceExhausted,
}

// âŒ é¿å…ï¼šåå™¬é”™è¯¯
let _ = child.wait();
```

**4. èµ„æºæ¸…ç†**:

```rust
// âœ… ä½¿ç”¨RAII
struct ProcessGuard {
    child: Child,
}

impl Drop for ProcessGuard {
    fn drop(&mut self) {
        self.child.kill().ok();
        self.child.wait().ok();
    }
}
```

**5. æ€§èƒ½ä¼˜åŒ–**:

- é¢„çƒ­è¿›ç¨‹æ± 
- æ‰¹é‡å¤„ç†ä»»åŠ¡
- ä½¿ç”¨å¼‚æ­¥I/O
- é¿å…é¢‘ç¹åˆ›å»ºé”€æ¯è¿›ç¨‹

---

## æ€»ç»“

**é«˜çº§è¿›ç¨‹ç®¡ç†æ ¸å¿ƒè¦ç´ **:

1. âœ… **è¿›ç¨‹æ± **: å›ºå®š/åŠ¨æ€/ä¼˜å…ˆçº§
2. âœ… **è°ƒåº¦ç­–ç•¥**: FIFO/ä¼˜å…ˆçº§/å…¬å¹³/å®æ—¶
3. âœ… **ç”Ÿå‘½å‘¨æœŸ**: å¥åº·æ£€æŸ¥/è‡ªåŠ¨é‡å¯/ä¼˜é›…å…³é—­
4. âœ… **ç›‘æ§è¯Šæ–­**: å®æ—¶ç›‘æ§/æŒ‡æ ‡æ”¶é›†/å‘Šè­¦
5. âœ… **è¿›ç¨‹åè°ƒ**: åˆ†å¸ƒå¼é”/é€‰ä¸»/ä»»åŠ¡åˆ†é…
6. âœ… **å®¹é”™æ¢å¤**: æ£€æŸ¥ç‚¹/è‡ªåŠ¨æ¢å¤

**å…³é”®æŒ‡æ ‡**:

- ååé‡: 1000+ tasks/s
- å»¶è¿Ÿ: P99 < 100ms
- å¯ç”¨æ€§: 99.99%
- èµ„æºåˆ©ç”¨ç‡: CPU 60-80%

---

**ä¸‹ä¸€æ­¥**: [02_å®‰å…¨ä¸æ²™ç®±.md](./02_å®‰å…¨ä¸æ²™ç®±.md)

---

**æ–‡æ¡£ç»´æŠ¤**: Documentation Team
**åˆ›å»ºæ—¥æœŸ**: 2025-10-22
**æœ€åæ›´æ–°**: 2025-12-11
**é€‚ç”¨ç‰ˆæœ¬**: Rust 1.92.0+
