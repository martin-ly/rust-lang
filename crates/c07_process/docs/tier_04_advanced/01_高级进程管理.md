# Tier 4: 高级进程管理

> **文档类型**: 高级主题
> **难度**: ⭐⭐⭐⭐
> **适用版本**: Rust 1.92.0+
> **前置知识**: [性能优化参考](../tier_03_references/05_性能优化参考.md)

---

## 目录

- [Tier 4: 高级进程管理](#tier-4-高级进程管理)
  - [目录](#目录)
  - [1. 进程池架构设计](#1-进程池架构设计)
    - [1.1 基础进程池](#11-基础进程池)
    - [1.2 异步进程池](#12-异步进程池)
    - [1.3 动态扩缩容池](#13-动态扩缩容池)
    - [1.4 优先级池](#14-优先级池)
  - [2. 进程调度策略](#2-进程调度策略)
    - [2.1 FIFO调度](#21-fifo调度)
    - [2.2 优先级调度](#22-优先级调度)
    - [2.3 公平调度](#23-公平调度)
    - [2.4 实时调度](#24-实时调度)
  - [3. 进程生命周期管理](#3-进程生命周期管理)
    - [3.1 健康检查](#31-健康检查)
    - [3.2 自动重启](#32-自动重启)
    - [3.3 优雅关闭](#33-优雅关闭)
    - [3.4 资源清理](#34-资源清理)
  - [4. 进程监控与诊断](#4-进程监控与诊断)
    - [4.1 实时监控系统](#41-实时监控系统)
    - [4.2 性能指标收集](#42-性能指标收集)
    - [4.3 告警系统](#43-告警系统)
    - [4.4 诊断工具](#44-诊断工具)
  - [5. 进程间协调](#5-进程间协调)
    - [5.1 分布式锁](#51-分布式锁)
    - [5.2 选主算法](#52-选主算法)
    - [5.3 任务分配](#53-任务分配)
  - [6. 容错与恢复](#6-容错与恢复)
  - [7. 实战案例](#7-实战案例)
    - [案例: 生产级进程管理系统](#案例-生产级进程管理系统)
  - [8. 最佳实践](#8-最佳实践)
  - [总结](#总结)

---

## 1. 进程池架构设计

### 1.1 基础进程池

**设计原则**:

1. **固定容量**: 预先创建固定数量的worker
2. **任务队列**: FIFO队列管理待处理任务
3. **同步管理**: 使用Mutex/Condvar协调
4. **资源复用**: 避免频繁创建销毁进程

**完整实现**:

```rust
use std::sync::{Arc, Mutex, Condvar};
use std::collections::VecDeque;
use std::process::{Child, Command};
use std::time::Duration;

pub struct ProcessPool {
    workers: Arc<Mutex<VecDeque<Worker>>>,
    tasks: Arc<(Mutex<VecDeque<Task>>, Condvar)>,
    size: usize,
}

struct Worker {
    id: usize,
    child: Option<Child>,
    busy: bool,
}

struct Task {
    command: String,
    args: Vec<String>,
}

impl ProcessPool {
    pub fn new(size: usize, program: &str) -> std::io::Result<Self> {
        let mut workers = VecDeque::with_capacity(size);

        for id in 0..size {
            let child = Command::new(program).spawn()?;
            workers.push_back(Worker {
                id,
                child: Some(child),
                busy: false,
            });
        }

        Ok(Self {
            workers: Arc::new(Mutex::new(workers)),
            tasks: Arc::new((Mutex::new(VecDeque::new()), Condvar::new())),
            size,
        })
    }

    pub fn submit(&self, command: String, args: Vec<String>) {
        let (lock, cvar) = &*self.tasks;
        let mut tasks = lock.lock().unwrap();
        tasks.push_back(Task { command, args });
        cvar.notify_one();
    }

    pub fn execute(&self) -> std::io::Result<()> {
        let (lock, cvar) = &*self.tasks;
        let mut tasks = lock.lock().unwrap();

        while tasks.is_empty() {
            tasks = cvar.wait(tasks).unwrap();
        }

        if let Some(task) = tasks.pop_front() {
            let mut workers = self.workers.lock().unwrap();

            if let Some(worker) = workers.iter_mut().find(|w| !w.busy) {
                worker.busy = true;

                // 执行任务
                if let Some(ref mut child) = worker.child {
                    child.wait()?;
                }

                // 重新启动worker
                worker.child = Some(Command::new(&task.command)
                    .args(&task.args)
                    .spawn()?);

                worker.busy = false;
            }
        }

        Ok(())
    }

    pub fn shutdown(self) -> std::io::Result<()> {
        let mut workers = self.workers.lock().unwrap();

        for worker in workers.iter_mut() {
            if let Some(mut child) = worker.child.take() {
                child.kill()?;
                child.wait()?;
            }
        }

        Ok(())
    }
}
```

---

### 1.2 异步进程池

**Tokio异步版本**:

```rust
use tokio::process::Command;
use tokio::sync::{Semaphore, Mutex};
use std::sync::Arc;

pub struct AsyncProcessPool {
    semaphore: Arc<Semaphore>,
    max_workers: usize,
    active: Arc<Mutex<usize>>,
}

impl AsyncProcessPool {
    pub fn new(max_workers: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_workers)),
            max_workers,
            active: Arc::new(Mutex::new(0)),
        }
    }

    pub async fn execute<F, Fut>(&self, task: F) -> std::io::Result<()>
    where
        F: FnOnce() -> Fut + Send + 'static,
        Fut: std::future::Future<Output = std::io::Result<()>> + Send,
    {
        let permit = self.semaphore.clone().acquire_owned().await.unwrap();

        {
            let mut active = self.active.lock().await;
            *active += 1;
            println!("活动进程数: {}", *active);
        }

        tokio::spawn(async move {
            let _permit = permit;
            task().await.ok();
        });

        Ok(())
    }

    pub async fn wait_all(&self) {
        // 获取所有permits，确保所有任务完成
        let permits: Vec<_> = (0..self.max_workers)
            .map(|_| self.semaphore.clone().try_acquire_owned())
            .collect();

        // 释放所有permits
        drop(permits);
    }
}
```

---

### 1.3 动态扩缩容池

**自适应容量调整**:

```rust
use std::sync::atomic::{AtomicUsize, Ordering};

pub struct DynamicProcessPool {
    min_workers: usize,
    max_workers: usize,
    current_workers: AtomicUsize,
    pending_tasks: Arc<Mutex<VecDeque<Task>>>,
    workers: Arc<Mutex<Vec<WorkerHandle>>>,
}

impl DynamicProcessPool {
    pub fn new(min: usize, max: usize) -> Self {
        Self {
            min_workers: min,
            max_workers: max,
            current_workers: AtomicUsize::new(min),
            pending_tasks: Arc::new(Mutex::new(VecDeque::new())),
            workers: Arc::new(Mutex::new(Vec::with_capacity(max))),
        }
    }

    pub fn scale_up(&self, count: usize) -> std::io::Result<()> {
        let current = self.current_workers.load(Ordering::SeqCst);
        let new_count = (current + count).min(self.max_workers);

        if new_count > current {
            let mut workers = self.workers.lock().unwrap();

            for _ in 0..(new_count - current) {
                workers.push(self.spawn_worker()?);
            }

            self.current_workers.store(new_count, Ordering::SeqCst);
            println!("扩容到 {} 个worker", new_count);
        }

        Ok(())
    }

    pub fn scale_down(&self, count: usize) -> std::io::Result<()> {
        let current = self.current_workers.load(Ordering::SeqCst);
        let new_count = (current.saturating_sub(count)).max(self.min_workers);

        if new_count < current {
            let mut workers = self.workers.lock().unwrap();

            for _ in 0..(current - new_count) {
                if let Some(worker) = workers.pop() {
                    worker.terminate()?;
                }
            }

            self.current_workers.store(new_count, Ordering::SeqCst);
            println!("缩容到 {} 个worker", new_count);
        }

        Ok(())
    }

    fn spawn_worker(&self) -> std::io::Result<WorkerHandle> {
        // Worker实现细节
        unimplemented!()
    }
}

struct WorkerHandle {
    child: Child,
}

impl WorkerHandle {
    fn terminate(mut self) -> std::io::Result<()> {
        self.child.kill()?;
        self.child.wait()?;
        Ok(())
    }
}
```

**自动扩缩容策略**:

```rust
impl DynamicProcessPool {
    pub fn auto_scale(&self) {
        let tasks = self.pending_tasks.lock().unwrap();
        let task_count = tasks.len();
        let current = self.current_workers.load(Ordering::SeqCst);

        // 扩容：待处理任务 > 当前worker数 * 2
        if task_count > current * 2 {
            let scale_up_count = (task_count / 2).min(self.max_workers - current);
            drop(tasks);
            self.scale_up(scale_up_count).ok();
        }
        // 缩容：待处理任务 < 当前worker数 / 2
        else if task_count < current / 2 && current > self.min_workers {
            let scale_down_count = (current / 2).min(current - self.min_workers);
            drop(tasks);
            self.scale_down(scale_down_count).ok();
        }
    }
}
```

---

### 1.4 优先级池

**多级优先级队列**:

```rust
use std::collections::BinaryHeap;
use std::cmp::Ordering;

#[derive(Eq, PartialEq)]
struct PriorityTask {
    priority: u8,  // 0-255, 越大优先级越高
    task: Task,
    timestamp: std::time::Instant,
}

impl Ord for PriorityTask {
    fn cmp(&self, other: &Self) -> Ordering {
        // 先比较优先级，再比较时间戳（FIFO）
        self.priority.cmp(&other.priority)
            .then_with(|| other.timestamp.cmp(&self.timestamp))
    }
}

impl PartialOrd for PriorityTask {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

pub struct PriorityProcessPool {
    high_priority: Arc<Mutex<BinaryHeap<PriorityTask>>>,
    normal_priority: Arc<Mutex<VecDeque<Task>>>,
    low_priority: Arc<Mutex<VecDeque<Task>>>,
    workers: Arc<Mutex<Vec<Worker>>>,
}

impl PriorityProcessPool {
    pub fn submit_with_priority(&self, task: Task, priority: u8) {
        let ptask = PriorityTask {
            priority,
            task,
            timestamp: std::time::Instant::now(),
        };

        if priority >= 200 {
            self.high_priority.lock().unwrap().push(ptask);
        } else if priority >= 100 {
            self.normal_priority.lock().unwrap().push_back(ptask.task);
        } else {
            self.low_priority.lock().unwrap().push_back(ptask.task);
        }
    }

    fn next_task(&self) -> Option<Task> {
        // 1. 高优先级
        if let Some(ptask) = self.high_priority.lock().unwrap().pop() {
            return Some(ptask.task);
        }

        // 2. 普通优先级
        if let Some(task) = self.normal_priority.lock().unwrap().pop_front() {
            return Some(task);
        }

        // 3. 低优先级
        self.low_priority.lock().unwrap().pop_front()
    }
}
```

---

## 2. 进程调度策略

### 2.1 FIFO调度

**先进先出**:

```rust
pub struct FIFOScheduler {
    queue: Arc<Mutex<VecDeque<Task>>>,
}

impl FIFOScheduler {
    pub fn new() -> Self {
        Self {
            queue: Arc::new(Mutex::new(VecDeque::new())),
        }
    }

    pub fn schedule(&self, task: Task) {
        self.queue.lock().unwrap().push_back(task);
    }

    pub fn next(&self) -> Option<Task> {
        self.queue.lock().unwrap().pop_front()
    }
}
```

---

### 2.2 优先级调度

**多级反馈队列**:

```rust
pub struct MultiLevelFeedbackScheduler {
    queues: Vec<Arc<Mutex<VecDeque<Task>>>>,
    levels: usize,
}

impl MultiLevelFeedbackScheduler {
    pub fn new(levels: usize) -> Self {
        let queues = (0..levels)
            .map(|_| Arc::new(Mutex::new(VecDeque::new())))
            .collect();

        Self { queues, levels }
    }

    pub fn schedule(&self, task: Task, level: usize) {
        if level < self.levels {
            self.queues[level].lock().unwrap().push_back(task);
        }
    }

    pub fn next(&self) -> Option<(Task, usize)> {
        for (level, queue) in self.queues.iter().enumerate() {
            if let Some(task) = queue.lock().unwrap().pop_front() {
                return Some((task, level));
            }
        }
        None
    }
}
```

---

### 2.3 公平调度

**时间片轮转**:

```rust
pub struct FairScheduler {
    tasks: Arc<Mutex<Vec<(Task, Duration)>>>,
    time_slice: Duration,
}

impl FairScheduler {
    pub fn new(time_slice: Duration) -> Self {
        Self {
            tasks: Arc::new(Mutex::new(Vec::new())),
            time_slice,
        }
    }

    pub fn schedule(&self, task: Task) {
        self.tasks.lock().unwrap().push((task, Duration::ZERO));
    }

    pub fn next(&self) -> Option<Task> {
        let mut tasks = self.tasks.lock().unwrap();

        // 找到运行时间最短的任务
        tasks.iter_mut()
            .enumerate()
            .min_by_key(|(_, (_, time))| *time)
            .map(|(idx, (task, time))| {
                *time += self.time_slice;
                tasks.remove(idx).0
            })
    }
}
```

---

### 2.4 实时调度

**截止时间优先（EDF）**:

```rust
use std::time::{Instant, Duration};

pub struct RealtimeScheduler {
    tasks: Arc<Mutex<BinaryHeap<DeadlineTask>>>,
}

#[derive(Eq, PartialEq)]
struct DeadlineTask {
    task: Task,
    deadline: Instant,
}

impl Ord for DeadlineTask {
    fn cmp(&self, other: &Self) -> Ordering {
        // 反向排序：deadline越早优先级越高
        other.deadline.cmp(&self.deadline)
    }
}

impl PartialOrd for DeadlineTask {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl RealtimeScheduler {
    pub fn schedule_with_deadline(&self, task: Task, deadline: Duration) {
        let dtask = DeadlineTask {
            task,
            deadline: Instant::now() + deadline,
        };

        self.tasks.lock().unwrap().push(dtask);
    }

    pub fn next(&self) -> Option<Task> {
        let mut tasks = self.tasks.lock().unwrap();

        // 移除过期任务
        while let Some(dtask) = tasks.peek() {
            if dtask.deadline < Instant::now() {
                tasks.pop();
                println!("任务已过期，丢弃");
            } else {
                break;
            }
        }

        tasks.pop().map(|dt| dt.task)
    }
}
```

---

## 3. 进程生命周期管理

### 3.1 健康检查

**周期性健康检查**:

```rust
use std::time::{Duration, Instant};

pub struct HealthChecker {
    check_interval: Duration,
    timeout: Duration,
}

impl HealthChecker {
    pub fn new(check_interval: Duration, timeout: Duration) -> Self {
        Self {
            check_interval,
            timeout,
        }
    }

    pub async fn monitor(&self, pid: u32) -> bool {
        let start = Instant::now();

        loop {
            tokio::time::sleep(self.check_interval).await;

            // 检查进程是否存活
            if !self.is_alive(pid) {
                println!("进程 {} 不响应", pid);
                return false;
            }

            // 检查是否超时
            if start.elapsed() > self.timeout {
                println!("健康检查超时");
                return false;
            }
        }
    }

    fn is_alive(&self, pid: u32) -> bool {
        #[cfg(unix)]
        {
            use nix::sys::signal::{kill, Signal};
            use nix::unistd::Pid;

            kill(Pid::from_raw(pid as i32), Signal::SIGKILL).is_ok()
        }

        #[cfg(windows)]
        {
            // Windows实现
            true
        }
    }
}
```

---

### 3.2 自动重启

**重启策略**:

```rust
pub struct RestartPolicy {
    max_retries: usize,
    backoff: Duration,
    max_backoff: Duration,
}

impl RestartPolicy {
    pub fn exponential_backoff() -> Self {
        Self {
            max_retries: 5,
            backoff: Duration::from_secs(1),
            max_backoff: Duration::from_secs(60),
        }
    }

    pub async fn restart_with_backoff<F, Fut>(
        &self,
        spawn_fn: F,
    ) -> std::io::Result<Child>
    where
        F: Fn() -> Fut,
        Fut: std::future::Future<Output = std::io::Result<Child>>,
    {
        let mut current_backoff = self.backoff;

        for attempt in 0..self.max_retries {
            match spawn_fn().await {
                Ok(child) => {
                    println!("重启成功（尝试 {}）", attempt + 1);
                    return Ok(child);
                }
                Err(e) => {
                    println!("重启失败: {}, 等待 {:?}", e, current_backoff);
                    tokio::time::sleep(current_backoff).await;

                    // 指数退避
                    current_backoff = (current_backoff * 2).min(self.max_backoff);
                }
            }
        }

        Err(std::io::Error::new(
            std::io::ErrorKind::Other,
            "达到最大重试次数",
        ))
    }
}
```

---

### 3.3 优雅关闭

**信号处理**:

```rust
#[cfg(unix)]
use nix::sys::signal::{kill, Signal};
#[cfg(unix)]
use nix::unistd::Pid;

pub struct GracefulShutdown {
    grace_period: Duration,
}

impl GracefulShutdown {
    pub fn new(grace_period: Duration) -> Self {
        Self { grace_period }
    }

    #[cfg(unix)]
    pub async fn shutdown(&self, mut child: Child) -> std::io::Result<()> {
        let pid = child.id();

        // 1. 发送SIGTERM
        println!("发送SIGTERM到进程 {}", pid);
        kill(Pid::from_raw(pid as i32), Signal::SIGTERM)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;

        // 2. 等待优雅关闭
        let start = Instant::now();
        loop {
            if let Ok(Some(_)) = child.try_wait() {
                println!("进程 {} 已优雅关闭", pid);
                return Ok(());
            }

            if start.elapsed() > self.grace_period {
                break;
            }

            tokio::time::sleep(Duration::from_millis(100)).await;
        }

        // 3. 强制终止
        println!("强制终止进程 {}", pid);
        kill(Pid::from_raw(pid as i32), Signal::SIGKILL)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;

        child.wait()?;
        Ok(())
    }
}
```

---

### 3.4 资源清理

**自动资源管理**:

```rust
pub struct ResourceManager {
    temp_files: Vec<PathBuf>,
    file_handles: Vec<std::fs::File>,
}

impl ResourceManager {
    pub fn new() -> Self {
        Self {
            temp_files: Vec::new(),
            file_handles: Vec::new(),
        }
    }

    pub fn track_temp_file(&mut self, path: PathBuf) {
        self.temp_files.push(path);
    }

    pub fn track_file_handle(&mut self, file: std::fs::File) {
        self.file_handles.push(file);
    }
}

impl Drop for ResourceManager {
    fn drop(&mut self) {
        // 关闭文件句柄
        self.file_handles.clear();

        // 删除临时文件
        for path in &self.temp_files {
            if let Err(e) = std::fs::remove_file(path) {
                eprintln!("清理临时文件失败: {} - {}", path.display(), e);
            }
        }
    }
}
```

---

## 4. 进程监控与诊断

### 4.1 实时监控系统

**综合监控**:

```rust
use sysinfo::{System, SystemExt, ProcessExt, Pid};

pub struct ProcessMonitor {
    system: System,
    watched_pids: Vec<Pid>,
    metrics_history: Vec<MetricsSnapshot>,
}

#[derive(Clone)]
pub struct MetricsSnapshot {
    timestamp: Instant,
    cpu: f32,
    memory: u64,
    threads: usize,
}

impl ProcessMonitor {
    pub fn new() -> Self {
        Self {
            system: System::new_all(),
            watched_pids: Vec::new(),
            metrics_history: Vec::new(),
        }
    }

    pub fn watch(&mut self, pid: Pid) {
        self.watched_pids.push(pid);
    }

    pub fn collect_metrics(&mut self) -> Vec<ProcessMetrics> {
        self.system.refresh_all();

        let metrics: Vec<_> = self.watched_pids.iter()
            .filter_map(|&pid| {
                self.system.process(pid).map(|p| ProcessMetrics {
                    pid: pid.as_u32(),
                    cpu: p.cpu_usage(),
                    memory: p.memory(),
                    virtual_memory: p.virtual_memory(),
                    threads: p.thread_count() as usize,
                    status: format!("{:?}", p.status()),
                })
            })
            .collect();

        // 记录历史
        for m in &metrics {
            self.metrics_history.push(MetricsSnapshot {
                timestamp: Instant::now(),
                cpu: m.cpu,
                memory: m.memory,
                threads: m.threads,
            });
        }

        metrics
    }

    pub fn analyze_trend(&self) -> TrendAnalysis {
        if self.metrics_history.is_empty() {
            return TrendAnalysis::default();
        }

        let recent = &self.metrics_history[self.metrics_history.len().saturating_sub(100)..];

        let avg_cpu: f32 = recent.iter().map(|m| m.cpu).sum::<f32>() / recent.len() as f32;
        let avg_memory: u64 = recent.iter().map(|m| m.memory).sum::<u64>() / recent.len() as u64;

        TrendAnalysis {
            avg_cpu,
            avg_memory,
            max_cpu: recent.iter().map(|m| m.cpu).fold(0.0f32, f32::max),
            max_memory: recent.iter().map(|m| m.memory).max().unwrap_or(0),
        }
    }
}

#[derive(Debug)]
pub struct ProcessMetrics {
    pub pid: u32,
    pub cpu: f32,
    pub memory: u64,
    pub virtual_memory: u64,
    pub threads: usize,
    pub status: String,
}

#[derive(Debug, Default)]
pub struct TrendAnalysis {
    pub avg_cpu: f32,
    pub avg_memory: u64,
    pub max_cpu: f32,
    pub max_memory: u64,
}
```

---

### 4.2 性能指标收集

**Prometheus集成**:

```rust
use prometheus::{IntGauge, IntCounter, Histogram, Registry};

pub struct ProcessMetrics {
    pub active_processes: IntGauge,
    pub completed_processes: IntCounter,
    pub process_duration: Histogram,
    registry: Registry,
}

impl ProcessMetrics {
    pub fn new() -> Self {
        let registry = Registry::new();

        let active_processes = IntGauge::new(
            "process_active_total",
            "当前活动进程数",
        ).unwrap();

        let completed_processes = IntCounter::new(
            "process_completed_total",
            "已完成进程总数",
        ).unwrap();

        let process_duration = Histogram::new(
            prometheus::HistogramOpts::new(
                "process_duration_seconds",
                "进程执行时间",
            )
        ).unwrap();

        registry.register(Box::new(active_processes.clone())).unwrap();
        registry.register(Box::new(completed_processes.clone())).unwrap();
        registry.register(Box::new(process_duration.clone())).unwrap();

        Self {
            active_processes,
            completed_processes,
            process_duration,
            registry,
        }
    }

    pub fn process_started(&self) {
        self.active_processes.inc();
    }

    pub fn process_completed(&self, duration: Duration) {
        self.active_processes.dec();
        self.completed_processes.inc();
        self.process_duration.observe(duration.as_secs_f64());
    }
}
```

---

### 4.3 告警系统

**规则引擎**:

```rust
pub struct AlertRule {
    name: String,
    condition: Box<dyn Fn(&ProcessMetrics) -> bool + Send + Sync>,
    threshold_count: usize,
}

pub struct AlertManager {
    rules: Vec<AlertRule>,
    violations: HashMap<String, usize>,
}

impl AlertManager {
    pub fn new() -> Self {
        Self {
            rules: Vec::new(),
            violations: HashMap::new(),
        }
    }

    pub fn add_rule(&mut self, rule: AlertRule) {
        self.rules.push(rule);
    }

    pub fn check(&mut self, metrics: &ProcessMetrics) -> Vec<Alert> {
        let mut alerts = Vec::new();

        for rule in &self.rules {
            if (rule.condition)(metrics) {
                let count = self.violations.entry(rule.name.clone())
                    .or_insert(0);
                *count += 1;

                if *count >= rule.threshold_count {
                    alerts.push(Alert {
                        rule_name: rule.name.clone(),
                        message: format!(
                            "规则 {} 触发（连续{}次）",
                            rule.name, count
                        ),
                        severity: Severity::Warning,
                    });
                    *count = 0;  // 重置计数
                }
            } else {
                self.violations.insert(rule.name.clone(), 0);
            }
        }

        alerts
    }
}

pub struct Alert {
    pub rule_name: String,
    pub message: String,
    pub severity: Severity,
}

pub enum Severity {
    Info,
    Warning,
    Critical,
}

// 使用示例
fn setup_alerts() -> AlertManager {
    let mut manager = AlertManager::new();

    // CPU使用率过高
    manager.add_rule(AlertRule {
        name: "high_cpu".to_string(),
        condition: Box::new(|m| m.cpu > 80.0),
        threshold_count: 3,
    });

    // 内存泄漏
    manager.add_rule(AlertRule {
        name: "memory_leak".to_string(),
        condition: Box::new(|m| m.memory > 1024 * 1024 * 1024),  // >1GB
        threshold_count: 5,
    });

    manager
}
```

---

### 4.4 诊断工具

**进程快照**:

```rust
pub struct ProcessSnapshot {
    pub pid: u32,
    pub command: String,
    pub cpu: f32,
    pub memory: u64,
    pub threads: Vec<ThreadInfo>,
    pub open_files: Vec<FileDescriptor>,
}

pub struct ThreadInfo {
    pub tid: u32,
    pub cpu: f32,
    pub state: String,
}

pub struct FileDescriptor {
    pub fd: i32,
    pub path: PathBuf,
    pub flags: String,
}

impl ProcessSnapshot {
    #[cfg(target_os = "linux")]
    pub fn capture(pid: u32) -> std::io::Result<Self> {
        use std::fs;

        // 读取 /proc/[pid]/stat
        let stat = fs::read_to_string(format!("/proc/{}/stat", pid))?;

        // 读取 /proc/[pid]/status
        let status = fs::read_to_string(format!("/proc/{}/status", pid))?;

        // 读取 /proc/[pid]/cmdline
        let cmdline = fs::read_to_string(format!("/proc/{}/cmdline", pid))?;

        // 解析线程信息
        let threads = fs::read_dir(format!("/proc/{}/task", pid))?
            .filter_map(|e| e.ok())
            .map(|entry| {
                let tid = entry.file_name()
                    .to_string_lossy()
                    .parse::<u32>()
                    .unwrap_or(0);

                ThreadInfo {
                    tid,
                    cpu: 0.0,  // 需要进一步解析
                    state: "Running".to_string(),
                }
            })
            .collect();

        Ok(Self {
            pid,
            command: cmdline.replace('\0', " "),
            cpu: 0.0,  // 从stat解析
            memory: 0,  // 从status解析
            threads,
            open_files: Vec::new(),
        })
    }
}
```

---

## 5. 进程间协调

### 5.1 分布式锁

**基于文件的分布式锁**:

```rust
use std::fs::{File, OpenOptions};
use std::io::Write;

pub struct DistributedLock {
    file: File,
    lock_path: PathBuf,
}

impl DistributedLock {
    pub fn try_acquire(lock_path: PathBuf) -> std::io::Result<Self> {
        let file = OpenOptions::new()
            .write(true)
            .create_new(true)
            .open(&lock_path)?;

        // 写入当前进程PID
        let mut f = &file;
        write!(f, "{}", std::process::id())?;

        Ok(Self {
            file,
            lock_path,
        })
    }

    pub fn acquire_with_timeout(
        lock_path: PathBuf,
        timeout: Duration,
    ) -> std::io::Result<Self> {
        let start = Instant::now();

        loop {
            match Self::try_acquire(lock_path.clone()) {
                Ok(lock) => return Ok(lock),
                Err(e) if e.kind() == std::io::ErrorKind::AlreadyExists => {
                    if start.elapsed() > timeout {
                        return Err(std::io::Error::new(
                            std::io::ErrorKind::TimedOut,
                            "获取锁超时",
                        ));
                    }
                    std::thread::sleep(Duration::from_millis(100));
                }
                Err(e) => return Err(e),
            }
        }
    }
}

impl Drop for DistributedLock {
    fn drop(&mut self) {
        let _ = std::fs::remove_file(&self.lock_path);
    }
}
```

---

### 5.2 选主算法

**Bully算法**:

```rust
use std::collections::HashMap;

pub struct BullyElection {
    my_id: u32,
    peers: HashMap<u32, PeerStatus>,
    leader: Option<u32>,
}

enum PeerStatus {
    Alive,
    Dead,
}

impl BullyElection {
    pub fn new(my_id: u32, peer_ids: Vec<u32>) -> Self {
        let peers = peer_ids.into_iter()
            .map(|id| (id, PeerStatus::Alive))
            .collect();

        Self {
            my_id,
            peers,
            leader: None,
        }
    }

    pub fn start_election(&mut self) -> u32 {
        println!("进程 {} 发起选举", self.my_id);

        // 向所有ID更大的进程发送ELECTION消息
        let higher_peers: Vec<_> = self.peers.keys()
            .filter(|&&id| id > self.my_id)
            .copied()
            .collect();

        if higher_peers.is_empty() {
            // 我是最大的，宣布自己为leader
            self.become_leader();
            return self.my_id;
        }

        // 等待响应
        // （实际实现需要网络通信）

        // 如果没有响应，成为leader
        self.become_leader();
        self.my_id
    }

    fn become_leader(&mut self) {
        println!("进程 {} 成为leader", self.my_id);
        self.leader = Some(self.my_id);

        // 广播COORDINATOR消息
        for &peer_id in self.peers.keys() {
            println!("通知进程 {}: 新leader是 {}", peer_id, self.my_id);
        }
    }
}
```

---

### 5.3 任务分配

**一致性哈希分配**:

```rust
use std::collections::BTreeMap;

pub struct ConsistentHash {
    ring: BTreeMap<u64, u32>,  // hash -> worker_id
    replicas: usize,
}

impl ConsistentHash {
    pub fn new(replicas: usize) -> Self {
        Self {
            ring: BTreeMap::new(),
            replicas,
        }
    }

    pub fn add_worker(&mut self, worker_id: u32) {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        for i in 0..self.replicas {
            let mut hasher = DefaultHasher::new();
            format!("{}:{}", worker_id, i).hash(&mut hasher);
            let hash = hasher.finish();

            self.ring.insert(hash, worker_id);
        }
    }

    pub fn remove_worker(&mut self, worker_id: u32) {
        self.ring.retain(|_, &mut id| id != worker_id);
    }

    pub fn assign_task(&self, task_id: &str) -> Option<u32> {
        if self.ring.is_empty() {
            return None;
        }

        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        task_id.hash(&mut hasher);
        let hash = hasher.finish();

        // 找到第一个hash值大于等于task hash的worker
        self.ring.range(hash..)
            .next()
            .or_else(|| self.ring.iter().next())
            .map(|(_, &worker_id)| worker_id)
    }
}
```

---

## 6. 容错与恢复

**检查点机制**:

```rust
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize)]
pub struct Checkpoint {
    timestamp: u64,
    state: ProcessState,
}

#[derive(Serialize, Deserialize)]
pub struct ProcessState {
    completed_tasks: Vec<String>,
    pending_tasks: Vec<String>,
    metrics: MetricsSnapshot,
}

pub struct CheckpointManager {
    checkpoint_dir: PathBuf,
}

impl CheckpointManager {
    pub fn save(&self, pid: u32, state: &ProcessState) -> std::io::Result<()> {
        let checkpoint = Checkpoint {
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
            state: state.clone(),
        };

        let path = self.checkpoint_dir.join(format!("{}.json", pid));
        let json = serde_json::to_string_pretty(&checkpoint)?;
        std::fs::write(path, json)?;

        Ok(())
    }

    pub fn restore(&self, pid: u32) -> std::io::Result<ProcessState> {
        let path = self.checkpoint_dir.join(format!("{}.json", pid));
        let json = std::fs::read_to_string(path)?;
        let checkpoint: Checkpoint = serde_json::from_str(&json)?;

        Ok(checkpoint.state)
    }
}
```

---

## 7. 实战案例

### 案例: 生产级进程管理系统

```rust
pub struct ProductionProcessManager {
    pool: DynamicProcessPool,
    scheduler: PriorityProcessPool,
    monitor: ProcessMonitor,
    health_checker: HealthChecker,
    alert_manager: AlertManager,
    checkpoint_manager: CheckpointManager,
}

impl ProductionProcessManager {
    pub fn new() -> Self {
        Self {
            pool: DynamicProcessPool::new(4, 64),
            scheduler: PriorityProcessPool::new(),
            monitor: ProcessMonitor::new(),
            health_checker: HealthChecker::new(
                Duration::from_secs(10),
                Duration::from_secs(60),
            ),
            alert_manager: setup_alerts(),
            checkpoint_manager: CheckpointManager::new(PathBuf::from("/var/checkpoints")),
        }
    }

    pub async fn run(&mut self) {
        // 启动监控
        let monitor_task = tokio::spawn(async move {
            loop {
                let metrics = self.monitor.collect_metrics();

                for m in metrics {
                    let alerts = self.alert_manager.check(&m);
                    for alert in alerts {
                        self.handle_alert(alert).await;
                    }
                }

                tokio::time::sleep(Duration::from_secs(10)).await;
            }
        });

        // 处理任务
        loop {
            if let Some(task) = self.scheduler.next_task() {
                self.pool.execute(task).await.ok();
            }

            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    }

    async fn handle_alert(&self, alert: Alert) {
        println!("告警: {} - {}", alert.rule_name, alert.message);

        // 发送通知（邮件/Slack/PagerDuty）
        // self.notification_service.send(alert).await;
    }
}
```

---

## 8. 最佳实践

**1. 进程池大小**:

- CPU密集型: `pool_size = CPU核心数`
- I/O密集型: `pool_size = CPU核心数 * 2-4`
- 混合型: 动态调整

**2. 监控指标**:

- ✅ CPU使用率 < 80%
- ✅ 内存增长率 < 10% /小时
- ✅ 平均响应时间 < 100ms
- ✅ 成功率 > 99.9%

**3. 错误处理**:

```rust
// ✅ 推荐：详细的错误类型
#[derive(Debug)]
pub enum ProcessError {
    SpawnFailed(std::io::Error),
    ExecutionTimeout,
    UnexpectedExit(i32),
    ResourceExhausted,
}

// ❌ 避免：吞噬错误
let _ = child.wait();
```

**4. 资源清理**:

```rust
// ✅ 使用RAII
struct ProcessGuard {
    child: Child,
}

impl Drop for ProcessGuard {
    fn drop(&mut self) {
        self.child.kill().ok();
        self.child.wait().ok();
    }
}
```

**5. 性能优化**:

- 预热进程池
- 批量处理任务
- 使用异步I/O
- 避免频繁创建销毁进程

---

## 总结

**高级进程管理核心要素**:

1. ✅ **进程池**: 固定/动态/优先级
2. ✅ **调度策略**: FIFO/优先级/公平/实时
3. ✅ **生命周期**: 健康检查/自动重启/优雅关闭
4. ✅ **监控诊断**: 实时监控/指标收集/告警
5. ✅ **进程协调**: 分布式锁/选主/任务分配
6. ✅ **容错恢复**: 检查点/自动恢复

**关键指标**:

- 吞吐量: 1000+ tasks/s
- 延迟: P99 < 100ms
- 可用性: 99.99%
- 资源利用率: CPU 60-80%

---

**下一步**: [02_安全与沙箱.md](./02_安全与沙箱.md)

---

**文档维护**: Documentation Team
**创建日期**: 2025-10-22
**最后更新**: 2025-12-11
**适用版本**: Rust 1.92.0+
