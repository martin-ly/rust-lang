# C10 Networks æ•°å­¦åŸºç¡€

> é€‚ç”¨èŒƒå›´ï¼šRust 1.90+ï¼ŒTokio 1.35+ã€‚æ–‡æ¡£é£æ ¼éµå¾ª [`STYLE.md`](STYLE.md)ã€‚

## ğŸ“‹ ç›®å½•

- [C10 Networks æ•°å­¦åŸºç¡€](#c10-networks-æ•°å­¦åŸºç¡€)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ¯ æ¦‚è¿°](#-æ¦‚è¿°)
    - [ğŸ“š æ•°å­¦åŸºç¡€çš„é‡è¦æ€§](#-æ•°å­¦åŸºç¡€çš„é‡è¦æ€§)
    - [ğŸ”¬ æ•°å­¦å·¥å…·çš„åº”ç”¨](#-æ•°å­¦å·¥å…·çš„åº”ç”¨)
    - [ğŸ“Š ç¬¦å·çº¦å®š](#-ç¬¦å·çº¦å®š)
  - [ğŸ“Š æ¦‚ç‡è®ºåŸºç¡€](#-æ¦‚ç‡è®ºåŸºç¡€)
    - [éšæœºè¿‡ç¨‹](#éšæœºè¿‡ç¨‹)
      - [éšæœºè¿‡ç¨‹å®šä¹‰](#éšæœºè¿‡ç¨‹å®šä¹‰)
      - [éšæœºè¿‡ç¨‹åˆ†ç±»](#éšæœºè¿‡ç¨‹åˆ†ç±»)
      - [ç½‘ç»œæµé‡å»ºæ¨¡](#ç½‘ç»œæµé‡å»ºæ¨¡)
    - [é©¬å°”å¯å¤«é“¾](#é©¬å°”å¯å¤«é“¾)
      - [å®šä¹‰2](#å®šä¹‰2)
      - [TCPçŠ¶æ€æœºé©¬å°”å¯å¤«é“¾](#tcpçŠ¶æ€æœºé©¬å°”å¯å¤«é“¾)
    - [æ³Šæ¾è¿‡ç¨‹](#æ³Šæ¾è¿‡ç¨‹)
      - [å®šä¹‰3](#å®šä¹‰3)
      - [å®ç°](#å®ç°)
  - [ğŸ”¢ æ•°è®ºåŸºç¡€](#-æ•°è®ºåŸºç¡€)
    - [æ¨¡è¿ç®—](#æ¨¡è¿ç®—)
      - [å®šä¹‰4](#å®šä¹‰4)
      - [å®ç°1](#å®ç°1)
    - [æ¬§å‡ é‡Œå¾—ç®—æ³•](#æ¬§å‡ é‡Œå¾—ç®—æ³•)
      - [ç®—æ³•](#ç®—æ³•)
    - [è´¹é©¬å°å®šç†](#è´¹é©¬å°å®šç†)
      - [å®šç†](#å®šç†)
      - [åº”ç”¨](#åº”ç”¨)
  - [ğŸ“ˆ å›¾è®ºåŸºç¡€](#-å›¾è®ºåŸºç¡€)
    - [ç½‘ç»œæ‹“æ‰‘](#ç½‘ç»œæ‹“æ‰‘)
      - [å›¾è®ºå®šä¹‰](#å›¾è®ºå®šä¹‰)
      - [å›¾è®ºå®ç°](#å›¾è®ºå®ç°)
    - [æœ€çŸ­è·¯å¾„ç®—æ³•](#æœ€çŸ­è·¯å¾„ç®—æ³•)
      - [Dijkstraç®—æ³•](#dijkstraç®—æ³•)
    - [æœ€å°ç”Ÿæˆæ ‘](#æœ€å°ç”Ÿæˆæ ‘)
      - [Kruskalç®—æ³•](#kruskalç®—æ³•)
  - [âš¡ ä¿¡æ¯è®ºåŸºç¡€](#-ä¿¡æ¯è®ºåŸºç¡€)
    - [ç†µå’Œä¿¡æ¯é‡](#ç†µå’Œä¿¡æ¯é‡)
      - [ç†µå’Œä¿¡æ¯é‡å®šä¹‰](#ç†µå’Œä¿¡æ¯é‡å®šä¹‰)
      - [ä¿¡æ¯è®ºå®ç°](#ä¿¡æ¯è®ºå®ç°)
    - [ä¿¡é“å®¹é‡](#ä¿¡é“å®¹é‡)
      - [ä¿¡é“å®¹é‡å®šä¹‰](#ä¿¡é“å®¹é‡å®šä¹‰)
      - [ä¿¡é“å®¹é‡å®ç°](#ä¿¡é“å®¹é‡å®ç°)
    - [ç¼–ç ç†è®º](#ç¼–ç ç†è®º)
      - [éœå¤«æ›¼ç¼–ç ](#éœå¤«æ›¼ç¼–ç )
  - [ğŸ§® çº¿æ€§ä»£æ•°åŸºç¡€](#-çº¿æ€§ä»£æ•°åŸºç¡€)
    - [çŸ©é˜µè¿ç®—](#çŸ©é˜µè¿ç®—)
      - [çŸ©é˜µä¹˜æ³•](#çŸ©é˜µä¹˜æ³•)
    - [ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡](#ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡)
      - [å¹‚è¿­ä»£æ³•](#å¹‚è¿­ä»£æ³•)
    - [å¥‡å¼‚å€¼åˆ†è§£](#å¥‡å¼‚å€¼åˆ†è§£)
      - [SVDç®—æ³•](#svdç®—æ³•)
  - [ğŸ“Š ç»Ÿè®¡å­¦åŸºç¡€](#-ç»Ÿè®¡å­¦åŸºç¡€)
    - [æè¿°æ€§ç»Ÿè®¡](#æè¿°æ€§ç»Ÿè®¡)
      - [ç»Ÿè®¡é‡è®¡ç®—](#ç»Ÿè®¡é‡è®¡ç®—)
    - [å‡è®¾æ£€éªŒ](#å‡è®¾æ£€éªŒ)
      - [tæ£€éªŒ](#tæ£€éªŒ)
    - [å›å½’åˆ†æ](#å›å½’åˆ†æ)
      - [çº¿æ€§å›å½’](#çº¿æ€§å›å½’)
  - [ğŸ” å¯†ç å­¦æ•°å­¦åŸºç¡€](#-å¯†ç å­¦æ•°å­¦åŸºç¡€)
    - [ç¾¤è®º](#ç¾¤è®º)
      - [ç¾¤çš„å®šä¹‰å’Œæ€§è´¨](#ç¾¤çš„å®šä¹‰å’Œæ€§è´¨)
    - [æ¤­åœ†æ›²çº¿](#æ¤­åœ†æ›²çº¿)
      - [æ¤­åœ†æ›²çº¿å¯†ç å­¦](#æ¤­åœ†æ›²çº¿å¯†ç å­¦)
    - [ç¦»æ•£å¯¹æ•°](#ç¦»æ•£å¯¹æ•°)
      - [ç¦»æ•£å¯¹æ•°é—®é¢˜](#ç¦»æ•£å¯¹æ•°é—®é¢˜)
  - [ğŸ¯ ä¼˜åŒ–ç†è®º](#-ä¼˜åŒ–ç†è®º)
    - [çº¿æ€§è§„åˆ’](#çº¿æ€§è§„åˆ’)
      - [å•çº¯å½¢æ³•](#å•çº¯å½¢æ³•)
    - [åŠ¨æ€è§„åˆ’](#åŠ¨æ€è§„åˆ’)
      - [ç½‘ç»œæµé—®é¢˜](#ç½‘ç»œæµé—®é¢˜)
    - [å¯å‘å¼ç®—æ³•](#å¯å‘å¼ç®—æ³•)
      - [é—ä¼ ç®—æ³•](#é—ä¼ ç®—æ³•)
  - [ğŸ“š å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº†C10 Networksé¡¹ç›®æ‰€éœ€çš„æ•°å­¦ç†è®ºåŸºç¡€ï¼Œæ¶µç›–æ¦‚ç‡è®ºã€æ•°è®ºã€å›¾è®ºã€ä¿¡æ¯è®ºã€çº¿æ€§ä»£æ•°ã€ç»Ÿè®¡å­¦ã€å¯†ç å­¦å’Œä¼˜åŒ–ç†è®ºç­‰æ ¸å¿ƒæ•°å­¦æ¦‚å¿µã€‚è¿™äº›æ•°å­¦å·¥å…·ä¸ºç½‘ç»œåè®®è®¾è®¡ã€æ€§èƒ½åˆ†æã€å®‰å…¨éªŒè¯å’Œç³»ç»Ÿä¼˜åŒ–æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚

### ğŸ“š æ•°å­¦åŸºç¡€çš„é‡è¦æ€§

åœ¨ç½‘ç»œç¼–ç¨‹ä¸­ï¼Œæ•°å­¦åŸºç¡€å‘æŒ¥ç€å…³é”®ä½œç”¨ï¼š

1. **åè®®è®¾è®¡**: ä½¿ç”¨å½¢å¼åŒ–æ–¹æ³•æè¿°åè®®è¡Œä¸º
2. **æ€§èƒ½åˆ†æ**: é€šè¿‡æ•°å­¦æ¨¡å‹é¢„æµ‹ç³»ç»Ÿæ€§èƒ½
3. **å®‰å…¨éªŒè¯**: ä½¿ç”¨å¯†ç å­¦ç†è®ºä¿è¯é€šä¿¡å®‰å…¨
4. **ä¼˜åŒ–ç®—æ³•**: åº”ç”¨ä¼˜åŒ–ç†è®ºæé«˜ç³»ç»Ÿæ•ˆç‡
5. **æ•…éšœåˆ†æ**: ä½¿ç”¨æ¦‚ç‡è®ºåˆ†æç³»ç»Ÿå¯é æ€§

### ğŸ”¬ æ•°å­¦å·¥å…·çš„åº”ç”¨

| æ•°å­¦é¢†åŸŸ | åº”ç”¨åœºæ™¯ | å…·ä½“ç”¨é€” |
|---------|---------|---------|
| æ¦‚ç‡è®º | ç½‘ç»œæµé‡å»ºæ¨¡ | æ³Šæ¾è¿‡ç¨‹ã€é©¬å°”å¯å¤«é“¾ |
| æ•°è®º | å¯†ç å­¦ç®—æ³• | RSAã€æ¤­åœ†æ›²çº¿å¯†ç  |
| å›¾è®º | ç½‘ç»œæ‹“æ‰‘åˆ†æ | æœ€çŸ­è·¯å¾„ã€æœ€å°ç”Ÿæˆæ ‘ |
| ä¿¡æ¯è®º | æ•°æ®å‹ç¼© | éœå¤«æ›¼ç¼–ç ã€ç†µè®¡ç®— |
| çº¿æ€§ä»£æ•° | ä¿¡å·å¤„ç† | çŸ©é˜µè¿ç®—ã€ç‰¹å¾å€¼åˆ†æ |
| ç»Ÿè®¡å­¦ | æ€§èƒ½åˆ†æ | å‡è®¾æ£€éªŒã€å›å½’åˆ†æ |
| ä¼˜åŒ–ç†è®º | èµ„æºåˆ†é… | çº¿æ€§è§„åˆ’ã€åŠ¨æ€è§„åˆ’ |

### ğŸ“Š ç¬¦å·çº¦å®š

æœ¬æ–‡æ¡£ä½¿ç”¨ä»¥ä¸‹æ•°å­¦ç¬¦å·ï¼š

- $\mathbb{N}$: è‡ªç„¶æ•°é›†åˆ
- $\mathbb{Z}$: æ•´æ•°é›†åˆ
- $\mathbb{R}$: å®æ•°é›†åˆ
- $\mathbb{C}$: å¤æ•°é›†åˆ
- $\mathcal{P}(S)$: é›†åˆSçš„å¹‚é›†
- $|S|$: é›†åˆSçš„åŸºæ•°
- $\emptyset$: ç©ºé›†
- $\in$: å±äºå…³ç³»
- $\subseteq$: å­é›†å…³ç³»
- $\cup$: å¹¶é›†
- $\cap$: äº¤é›†
- $\setminus$: å·®é›†
- $\times$: ç¬›å¡å°”ç§¯
- $\rightarrow$: å‡½æ•°æ˜ å°„
- $\forall$: å…¨ç§°é‡è¯
- $\exists$: å­˜åœ¨é‡è¯
- $\Rightarrow$: è•´å«
- $\Leftrightarrow$: ç­‰ä»·
- $\neg$: å¦å®š
- $\land$: é€»è¾‘ä¸
- $\lor$: é€»è¾‘æˆ–

## ğŸ“Š æ¦‚ç‡è®ºåŸºç¡€

### éšæœºè¿‡ç¨‹

ç½‘ç»œç³»ç»Ÿä¸­çš„è®¸å¤šç°è±¡å¯ä»¥ç”¨éšæœºè¿‡ç¨‹æ¥å»ºæ¨¡ï¼š

#### éšæœºè¿‡ç¨‹å®šä¹‰

è®¾ $(\Omega, \mathcal{F}, P)$ æ˜¯æ¦‚ç‡ç©ºé—´ï¼Œ$T$ æ˜¯æŒ‡æ ‡é›†ï¼Œ$\{X_t\}_{t \in T}$ æ˜¯éšæœºå˜é‡æ—ï¼Œåˆ™ç§° $\{X_t\}_{t \in T}$ ä¸ºéšæœºè¿‡ç¨‹ã€‚

#### éšæœºè¿‡ç¨‹åˆ†ç±»

1. **æŒ‰æ—¶é—´å‚æ•°åˆ†ç±»**:
   - ç¦»æ•£æ—¶é—´éšæœºè¿‡ç¨‹: $T = \mathbb{N}$ æˆ– $T = \mathbb{Z}$
   - è¿ç»­æ—¶é—´éšæœºè¿‡ç¨‹: $T = \mathbb{R}$ æˆ– $T = [0, \infty)$

2. **æŒ‰çŠ¶æ€ç©ºé—´åˆ†ç±»**:
   - ç¦»æ•£çŠ¶æ€éšæœºè¿‡ç¨‹: çŠ¶æ€ç©ºé—´ä¸ºæœ‰é™æˆ–å¯æ•°é›†åˆ
   - è¿ç»­çŠ¶æ€éšæœºè¿‡ç¨‹: çŠ¶æ€ç©ºé—´ä¸ºè¿ç»­é›†åˆ

3. **æŒ‰ç»Ÿè®¡ç‰¹æ€§åˆ†ç±»**:
   - å¹³ç¨³éšæœºè¿‡ç¨‹: ç»Ÿè®¡ç‰¹æ€§ä¸éšæ—¶é—´å˜åŒ–
   - éå¹³ç¨³éšæœºè¿‡ç¨‹: ç»Ÿè®¡ç‰¹æ€§éšæ—¶é—´å˜åŒ–

#### ç½‘ç»œæµé‡å»ºæ¨¡

ç½‘ç»œæµé‡å¯ä»¥ç”¨å¤šç§éšæœºè¿‡ç¨‹æ¨¡å‹æ¥æè¿°ï¼š

```rust
// ç½‘ç»œæµé‡éšæœºè¿‡ç¨‹
pub struct NetworkTrafficProcess {
    // åˆ°è¾¾è¿‡ç¨‹
    arrival_process: PoissonProcess,
    // æœåŠ¡è¿‡ç¨‹
    service_process: ExponentialProcess,
    // é˜Ÿåˆ—é•¿åº¦è¿‡ç¨‹
    queue_length_process: MarkovChain,
}

impl NetworkTrafficProcess {
    // è®¡ç®—ç¨³æ€æ¦‚ç‡
    pub fn steady_state_probability(&self, state: usize) -> f64 {
        let lambda = self.arrival_process.rate();
        let mu = self.service_process.rate();
        let rho = lambda / mu;
        
        if rho < 1.0 {
            (1.0 - rho) * rho.powi(state as i32)
        } else {
            0.0
        }
    }
    
    // è®¡ç®—å¹³å‡é˜Ÿåˆ—é•¿åº¦
    pub fn average_queue_length(&self) -> f64 {
        let lambda = self.arrival_process.rate();
        let mu = self.service_process.rate();
        let rho = lambda / mu;
        
        if rho < 1.0 {
            rho / (1.0 - rho)
        } else {
            f64::INFINITY
        }
    }
}
```

### é©¬å°”å¯å¤«é“¾

ç½‘ç»œçŠ¶æ€è½¬æ¢å¯ä»¥ç”¨é©¬å°”å¯å¤«é“¾å»ºæ¨¡ï¼š

#### å®šä¹‰2

è®¾ $\{X_n\}_{n \geq 0}$ æ˜¯éšæœºè¿‡ç¨‹ï¼Œå¦‚æœå¯¹äºä»»æ„ $n \geq 0$ å’ŒçŠ¶æ€ $i_0, i_1, \ldots, i_{n-1}, i, j$ï¼Œæœ‰ï¼š

$$P(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i)$$

åˆ™ç§° $\{X_n\}_{n \geq 0}$ ä¸ºé©¬å°”å¯å¤«é“¾ã€‚

#### TCPçŠ¶æ€æœºé©¬å°”å¯å¤«é“¾

```rust
// TCPçŠ¶æ€æœºé©¬å°”å¯å¤«é“¾
pub struct TcpMarkovChain {
    // çŠ¶æ€ç©ºé—´
    states: Vec<TcpState>,
    // è½¬ç§»æ¦‚ç‡çŸ©é˜µ
    transition_matrix: Vec<Vec<f64>>,
    // åˆå§‹åˆ†å¸ƒ
    initial_distribution: Vec<f64>,
}

impl TcpMarkovChain {
    // è®¡ç®—næ­¥è½¬ç§»æ¦‚ç‡
    pub fn n_step_transition_probability(&self, from: TcpState, to: TcpState, n: usize) -> f64 {
        let from_idx = self.state_index(from);
        let to_idx = self.state_index(to);
        
        // è®¡ç®—è½¬ç§»çŸ©é˜µçš„næ¬¡å¹‚
        let matrix_power = self.matrix_power(&self.transition_matrix, n);
        matrix_power[from_idx][to_idx]
    }
    
    // è®¡ç®—ç¨³æ€åˆ†å¸ƒ
    pub fn steady_state_distribution(&self) -> Vec<f64> {
        // æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„ Ï€ = Ï€P
        let n = self.states.len();
        let mut system = vec![vec![0.0; n + 1]; n];
        
        // æ·»åŠ çº¦æŸæ¡ä»¶
        for i in 0..n {
            for j in 0..n {
                system[i][j] = self.transition_matrix[j][i] - if i == j { 1.0 } else { 0.0 };
            }
            system[i][n] = 0.0;
        }
        
        // æ·»åŠ å½’ä¸€åŒ–æ¡ä»¶
        for j in 0..n {
            system[n-1][j] = 1.0;
        }
        system[n-1][n] = 1.0;
        
        self.solve_linear_system(&system)
    }
}
```

### æ³Šæ¾è¿‡ç¨‹

ç½‘ç»œæ•°æ®åŒ…åˆ°è¾¾é€šå¸¸å¯ä»¥ç”¨æ³Šæ¾è¿‡ç¨‹å»ºæ¨¡ï¼š

#### å®šä¹‰3

è®¡æ•°è¿‡ç¨‹ $\{N(t), t \geq 0\}$ ç§°ä¸ºå¼ºåº¦ä¸º $\lambda$ çš„æ³Šæ¾è¿‡ç¨‹ï¼Œå¦‚æœï¼š

1. $N(0) = 0$
2. è¿‡ç¨‹æœ‰ç‹¬ç«‹å¢é‡
3. å¯¹äºä»»æ„ $s, t \geq 0$ï¼Œ$N(t+s) - N(s)$ æœä»å‚æ•°ä¸º $\lambda t$ çš„æ³Šæ¾åˆ†å¸ƒ

#### å®ç°

```rust
// æ³Šæ¾è¿‡ç¨‹
pub struct PoissonProcess {
    rate: f64, // Î»
}

impl PoissonProcess {
    // ç”Ÿæˆåˆ°è¾¾æ—¶é—´é—´éš”
    pub fn generate_interarrival_times(&self, count: usize) -> Vec<f64> {
        (0..count)
            .map(|_| -self.rate.ln() * rand::random::<f64>())
            .collect()
    }
    
    // è®¡ç®—åœ¨æ—¶é—´tå†…åˆ°è¾¾nä¸ªäº‹ä»¶çš„æ¦‚ç‡
    pub fn probability(&self, n: usize, t: f64) -> f64 {
        let lambda_t = self.rate * t;
        (lambda_t.powi(n as i32) * (-lambda_t).exp()) / factorial(n)
    }
    
    // è®¡ç®—å¹³å‡åˆ°è¾¾æ—¶é—´
    pub fn mean_interarrival_time(&self) -> f64 {
        1.0 / self.rate
    }
}

fn factorial(n: usize) -> f64 {
    (1..=n).fold(1.0, |acc, x| acc * x as f64)
}
```

## ğŸ”¢ æ•°è®ºåŸºç¡€

### æ¨¡è¿ç®—

å¯†ç å­¦å’Œç½‘ç»œåè®®ä¸­å¹¿æ³›ä½¿ç”¨æ¨¡è¿ç®—ï¼š

#### å®šä¹‰4

å¯¹äºæ•´æ•° $a, b, n$ï¼Œå¦‚æœ $n \neq 0$ï¼Œåˆ™ $a \equiv b \pmod{n}$ å½“ä¸”ä»…å½“ $n | (a - b)$ã€‚

#### å®ç°1

```rust
// æ¨¡è¿ç®—å·¥å…·
pub struct ModularArithmetic {
    modulus: u64,
}

impl ModularArithmetic {
    // æ¨¡åŠ æ³•
    pub fn add(&self, a: u64, b: u64) -> u64 {
        (a + b) % self.modulus
    }
    
    // æ¨¡ä¹˜æ³•
    pub fn multiply(&self, a: u64, b: u64) -> u64 {
        (a * b) % self.modulus
    }
    
    // æ¨¡å¹‚è¿ç®—
    pub fn power(&self, base: u64, exponent: u64) -> u64 {
        let mut result = 1;
        let mut base = base % self.modulus;
        let mut exp = exponent;
        
        while exp > 0 {
            if exp % 2 == 1 {
                result = (result * base) % self.modulus;
            }
            exp >>= 1;
            base = (base * base) % self.modulus;
        }
        
        result
    }
    
    // æ¨¡é€†å…ƒ
    pub fn inverse(&self, a: u64) -> Option<u64> {
        let (gcd, x, _) = self.extended_gcd(a, self.modulus);
        if gcd == 1 {
            Some((x % self.modulus as i64 + self.modulus as i64) as u64 % self.modulus)
        } else {
            None
        }
    }
    
    // æ‰©å±•æ¬§å‡ é‡Œå¾—ç®—æ³•
    fn extended_gcd(&self, a: u64, b: u64) -> (u64, i64, i64) {
        if a == 0 {
            (b, 0, 1)
        } else {
            let (gcd, x1, y1) = self.extended_gcd(b % a, a);
            let x = y1 - (b / a) as i64 * x1;
            let y = x1;
            (gcd, x, y)
        }
    }
}
```

### æ¬§å‡ é‡Œå¾—ç®—æ³•

ç”¨äºè®¡ç®—æœ€å¤§å…¬çº¦æ•°ï¼š

#### ç®—æ³•

```rust
// æ¬§å‡ é‡Œå¾—ç®—æ³•
pub fn gcd(a: u64, b: u64) -> u64 {
    if b == 0 {
        a
    } else {
        gcd(b, a % b)
    }
}

// æ‰©å±•æ¬§å‡ é‡Œå¾—ç®—æ³•
pub fn extended_gcd(a: u64, b: u64) -> (u64, i64, i64) {
    if a == 0 {
        (b, 0, 1)
    } else {
        let (gcd, x1, y1) = extended_gcd(b % a, a);
        let x = y1 - (b / a) as i64 * x1;
        let y = x1;
        (gcd, x, y)
    }
}
```

### è´¹é©¬å°å®šç†

å¯†ç å­¦ä¸­çš„é‡è¦å®šç†ï¼š

#### å®šç†

å¦‚æœ $p$ æ˜¯ç´ æ•°ï¼Œ$a$ æ˜¯æ•´æ•°ä¸” $p \nmid a$ï¼Œåˆ™ï¼š

$$a^{p-1} \equiv 1 \pmod{p}$$

#### åº”ç”¨

```rust
// è´¹é©¬ç´ æ€§æµ‹è¯•
pub fn fermat_primality_test(n: u64, k: usize) -> bool {
    if n <= 1 || n == 4 {
        return false;
    }
    if n <= 3 {
        return true;
    }
    
    for _ in 0..k {
        let a = 2 + rand::random::<u64>() % (n - 4);
        if modular_power(a, n - 1, n) != 1 {
            return false;
        }
    }
    
    true
}

fn modular_power(base: u64, exponent: u64, modulus: u64) -> u64 {
    let mut result = 1;
    let mut base = base % modulus;
    let mut exp = exponent;
    
    while exp > 0 {
        if exp % 2 == 1 {
            result = (result * base) % modulus;
        }
        exp >>= 1;
        base = (base * base) % modulus;
    }
    
    result
}
```

## ğŸ“ˆ å›¾è®ºåŸºç¡€

### ç½‘ç»œæ‹“æ‰‘

ç½‘ç»œå¯ä»¥ç”¨å›¾æ¥è¡¨ç¤ºï¼š

#### å›¾è®ºå®šä¹‰

å›¾ $G = (V, E)$ ç”±é¡¶ç‚¹é›† $V$ å’Œè¾¹é›† $E$ ç»„æˆï¼Œå…¶ä¸­ $E \subseteq V \times V$ã€‚

#### å›¾è®ºå®ç°

```rust
// ç½‘ç»œå›¾è¡¨ç¤º
pub struct NetworkGraph {
    vertices: Vec<Vertex>,
    edges: Vec<Edge>,
    adjacency_matrix: Vec<Vec<f64>>,
}

#[derive(Debug, Clone)]
pub struct Vertex {
    pub id: usize,
    pub label: String,
    pub position: (f64, f64),
}

#[derive(Debug, Clone)]
pub struct Edge {
    pub from: usize,
    pub to: usize,
    pub weight: f64,
    pub capacity: f64,
}

impl NetworkGraph {
    // æ·»åŠ é¡¶ç‚¹
    pub fn add_vertex(&mut self, vertex: Vertex) {
        self.vertices.push(vertex);
        self.expand_adjacency_matrix();
    }
    
    // æ·»åŠ è¾¹
    pub fn add_edge(&mut self, edge: Edge) {
        self.edges.push(edge.clone());
        self.adjacency_matrix[edge.from][edge.to] = edge.weight;
    }
    
    // è®¡ç®—é¡¶ç‚¹åº¦æ•°
    pub fn vertex_degree(&self, vertex_id: usize) -> usize {
        self.adjacency_matrix[vertex_id]
            .iter()
            .filter(|&&weight| weight > 0.0)
            .count()
    }
    
    // æ£€æŸ¥è¿é€šæ€§
    pub fn is_connected(&self) -> bool {
        if self.vertices.is_empty() {
            return true;
        }
        
        let mut visited = vec![false; self.vertices.len()];
        self.dfs(0, &mut visited);
        visited.iter().all(|&v| v)
    }
    
    // æ·±åº¦ä¼˜å…ˆæœç´¢
    fn dfs(&self, vertex: usize, visited: &mut Vec<bool>) {
        visited[vertex] = true;
        for (neighbor, &weight) in self.adjacency_matrix[vertex].iter().enumerate() {
            if weight > 0.0 && !visited[neighbor] {
                self.dfs(neighbor, visited);
            }
        }
    }
}
```

### æœ€çŸ­è·¯å¾„ç®—æ³•

#### Dijkstraç®—æ³•

```rust
// Dijkstraæœ€çŸ­è·¯å¾„ç®—æ³•
pub fn dijkstra(graph: &NetworkGraph, start: usize) -> Vec<f64> {
    let n = graph.vertices.len();
    let mut distances = vec![f64::INFINITY; n];
    let mut visited = vec![false; n];
    
    distances[start] = 0.0;
    
    for _ in 0..n {
        let u = find_min_distance_vertex(&distances, &visited);
        visited[u] = true;
        
        for v in 0..n {
            if !visited[v] && graph.adjacency_matrix[u][v] > 0.0 {
                let new_distance = distances[u] + graph.adjacency_matrix[u][v];
                if new_distance < distances[v] {
                    distances[v] = new_distance;
                }
            }
        }
    }
    
    distances
}

fn find_min_distance_vertex(distances: &[f64], visited: &[bool]) -> usize {
    let mut min_distance = f64::INFINITY;
    let mut min_vertex = 0;
    
    for (i, &distance) in distances.iter().enumerate() {
        if !visited[i] && distance < min_distance {
            min_distance = distance;
            min_vertex = i;
        }
    }
    
    min_vertex
}
```

### æœ€å°ç”Ÿæˆæ ‘

#### Kruskalç®—æ³•

```rust
// Kruskalæœ€å°ç”Ÿæˆæ ‘ç®—æ³•
pub fn kruskal_mst(graph: &NetworkGraph) -> Vec<Edge> {
    let mut edges = graph.edges.clone();
    edges.sort_by(|a, b| a.weight.partial_cmp(&b.weight).unwrap());
    
    let mut mst = Vec::new();
    let mut union_find = UnionFind::new(graph.vertices.len());
    
    for edge in edges {
        if union_find.find(edge.from) != union_find.find(edge.to) {
            mst.push(edge.clone());
            union_find.union(edge.from, edge.to);
        }
    }
    
    mst
}

// å¹¶æŸ¥é›†æ•°æ®ç»“æ„
pub struct UnionFind {
    parent: Vec<usize>,
    rank: Vec<usize>,
}

impl UnionFind {
    pub fn new(n: usize) -> Self {
        Self {
            parent: (0..n).collect(),
            rank: vec![0; n],
        }
    }
    
    pub fn find(&mut self, x: usize) -> usize {
        if self.parent[x] != x {
            self.parent[x] = self.find(self.parent[x]);
        }
        self.parent[x]
    }
    
    pub fn union(&mut self, x: usize, y: usize) {
        let px = self.find(x);
        let py = self.find(y);
        
        if px != py {
            if self.rank[px] < self.rank[py] {
                self.parent[px] = py;
            } else if self.rank[px] > self.rank[py] {
                self.parent[py] = px;
            } else {
                self.parent[py] = px;
                self.rank[px] += 1;
            }
        }
    }
}
```

## âš¡ ä¿¡æ¯è®ºåŸºç¡€

### ç†µå’Œä¿¡æ¯é‡

#### ç†µå’Œä¿¡æ¯é‡å®šä¹‰

ç¦»æ•£éšæœºå˜é‡ $X$ çš„ç†µå®šä¹‰ä¸ºï¼š

$$H(X) = -\sum_{i} p(x_i) \log_2 p(x_i)$$

#### ä¿¡æ¯è®ºå®ç°

```rust
// ä¿¡æ¯è®ºå·¥å…·
pub struct InformationTheory {
    // æ¦‚ç‡åˆ†å¸ƒ
    probabilities: Vec<f64>,
}

impl InformationTheory {
    // è®¡ç®—ç†µ
    pub fn entropy(&self) -> f64 {
        self.probabilities
            .iter()
            .filter(|&&p| p > 0.0)
            .map(|&p| -p * p.log2())
            .sum()
    }
    
    // è®¡ç®—äº’ä¿¡æ¯
    pub fn mutual_information(&self, joint_prob: &[Vec<f64>]) -> f64 {
        let mut mi = 0.0;
        
        for i in 0..joint_prob.len() {
            for j in 0..joint_prob[i].len() {
                let p_xy = joint_prob[i][j];
                if p_xy > 0.0 {
                    let p_x = joint_prob[i].iter().sum::<f64>();
                    let p_y = joint_prob.iter().map(|row| row[j]).sum::<f64>();
                    
                    if p_x > 0.0 && p_y > 0.0 {
                        mi += p_xy * (p_xy / (p_x * p_y)).log2();
                    }
                }
            }
        }
        
        mi
    }
    
    // è®¡ç®—æ¡ä»¶ç†µ
    pub fn conditional_entropy(&self, joint_prob: &[Vec<f64>]) -> f64 {
        let mut ce = 0.0;
        
        for i in 0..joint_prob.len() {
            let p_x = joint_prob[i].iter().sum::<f64>();
            if p_x > 0.0 {
                for j in 0..joint_prob[i].len() {
                    let p_xy = joint_prob[i][j];
                    if p_xy > 0.0 {
                        ce -= p_xy * (p_xy / p_x).log2();
                    }
                }
            }
        }
        
        ce
    }
}
```

### ä¿¡é“å®¹é‡

#### ä¿¡é“å®¹é‡å®šä¹‰

ç¦»æ•£æ— è®°å¿†ä¿¡é“çš„å®¹é‡å®šä¹‰ä¸ºï¼š

$$C = \max_{p(x)} I(X; Y)$$

å…¶ä¸­ $I(X; Y)$ æ˜¯äº’ä¿¡æ¯ã€‚

#### ä¿¡é“å®¹é‡å®ç°

```rust
// ä¿¡é“å®¹é‡è®¡ç®—
pub struct ChannelCapacity {
    // è½¬ç§»æ¦‚ç‡çŸ©é˜µ
    transition_matrix: Vec<Vec<f64>>,
}

impl ChannelCapacity {
    // è®¡ç®—ä¿¡é“å®¹é‡
    pub fn calculate_capacity(&self) -> f64 {
        // ä½¿ç”¨è¿­ä»£ç®—æ³•æ±‚è§£
        let mut input_dist = vec![1.0 / self.transition_matrix.len() as f64; self.transition_matrix.len()];
        let mut prev_capacity = 0.0;
        let mut capacity = 1.0;
        let epsilon = 1e-6;
        
        while (capacity - prev_capacity).abs() > epsilon {
            prev_capacity = capacity;
            
            // æ›´æ–°è¾“å…¥åˆ†å¸ƒ
            input_dist = self.update_input_distribution(&input_dist);
            
            // è®¡ç®—äº’ä¿¡æ¯
            capacity = self.mutual_information(&input_dist);
        }
        
        capacity
    }
    
    // æ›´æ–°è¾“å…¥åˆ†å¸ƒ
    fn update_input_distribution(&self, input_dist: &[f64]) -> Vec<f64> {
        let mut new_dist = vec![0.0; input_dist.len()];
        let mut sum = 0.0;
        
        for i in 0..input_dist.len() {
            let mut product = 1.0;
            for j in 0..self.transition_matrix[i].len() {
                if self.transition_matrix[i][j] > 0.0 {
                    let output_prob = self.output_probability(j, input_dist);
                    if output_prob > 0.0 {
                        product *= (self.transition_matrix[i][j] / output_prob).powf(self.transition_matrix[i][j]);
                    }
                }
            }
            new_dist[i] = product;
            sum += product;
        }
        
        // å½’ä¸€åŒ–
        for i in 0..new_dist.len() {
            new_dist[i] /= sum;
        }
        
        new_dist
    }
    
    // è®¡ç®—è¾“å‡ºæ¦‚ç‡
    fn output_probability(&self, output: usize, input_dist: &[f64]) -> f64 {
        input_dist.iter()
            .enumerate()
            .map(|(i, &p)| p * self.transition_matrix[i][output])
            .sum()
    }
    
    // è®¡ç®—äº’ä¿¡æ¯
    fn mutual_information(&self, input_dist: &[f64]) -> f64 {
        let mut mi = 0.0;
        
        for i in 0..input_dist.len() {
            for j in 0..self.transition_matrix[i].len() {
                let p_xy = input_dist[i] * self.transition_matrix[i][j];
                if p_xy > 0.0 {
                    let p_y = self.output_probability(j, input_dist);
                    if p_y > 0.0 {
                        mi += p_xy * (self.transition_matrix[i][j] / p_y).log2();
                    }
                }
            }
        }
        
        mi
    }
}
```

### ç¼–ç ç†è®º

#### éœå¤«æ›¼ç¼–ç 

```rust
// éœå¤«æ›¼ç¼–ç 
pub struct HuffmanEncoder {
    codes: HashMap<u8, Vec<bool>>,
}

impl HuffmanEncoder {
    pub fn new(frequencies: &HashMap<u8, usize>) -> Self {
        let codes = Self::build_codes(frequencies);
        Self { codes }
    }
    
    fn build_codes(frequencies: &HashMap<u8, usize>) -> HashMap<u8, Vec<bool>> {
        let mut heap = BinaryHeap::new();
        
        // åˆ›å»ºå¶å­èŠ‚ç‚¹
        for (symbol, freq) in frequencies {
            heap.push(Node::Leaf(*symbol, *freq));
        }
        
        // æ„å»ºéœå¤«æ›¼æ ‘
        while heap.len() > 1 {
            let left = heap.pop().unwrap();
            let right = heap.pop().unwrap();
            let merged = Node::Internal(
                Box::new(left),
                Box::new(right),
                left.frequency() + right.frequency()
            );
            heap.push(merged);
        }
        
        // ç”Ÿæˆç¼–ç 
        let root = heap.pop().unwrap();
        Self::generate_codes(&root, Vec::new())
    }
    
    fn generate_codes(node: &Node, mut code: Vec<bool>) -> HashMap<u8, Vec<bool>> {
        match node {
            Node::Leaf(symbol, _) => {
                let mut codes = HashMap::new();
                codes.insert(*symbol, code);
                codes
            }
            Node::Internal(left, right, _) => {
                let mut left_code = code.clone();
                left_code.push(false);
                let mut right_code = code;
                right_code.push(true);
                
                let mut left_codes = Self::generate_codes(left, left_code);
                let right_codes = Self::generate_codes(right, right_code);
                
                left_codes.extend(right_codes);
                left_codes
            }
        }
    }
    
    // ç¼–ç 
    pub fn encode(&self, data: &[u8]) -> Vec<bool> {
        let mut result = Vec::new();
        for &byte in data {
            if let Some(code) = self.codes.get(&byte) {
                result.extend(code);
            }
        }
        result
    }
    
    // è®¡ç®—å‹ç¼©æ¯”
    pub fn compression_ratio(&self, original_size: usize, compressed_size: usize) -> f64 {
        original_size as f64 / compressed_size as f64
    }
}

#[derive(Debug, PartialEq, Eq)]
enum Node {
    Leaf(u8, usize),
    Internal(Box<Node>, Box<Node>, usize),
}

impl Node {
    fn frequency(&self) -> usize {
        match self {
            Node::Leaf(_, freq) => *freq,
            Node::Internal(_, _, freq) => *freq,
        }
    }
}

impl PartialOrd for Node {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for Node {
    fn cmp(&self, other: &Self) -> Ordering {
        other.frequency().cmp(&self.frequency())
    }
}
```

## ğŸ§® çº¿æ€§ä»£æ•°åŸºç¡€

### çŸ©é˜µè¿ç®—

#### çŸ©é˜µä¹˜æ³•

```rust
// çŸ©é˜µè¿ç®—
pub struct Matrix {
    data: Vec<Vec<f64>>,
    rows: usize,
    cols: usize,
}

impl Matrix {
    pub fn new(rows: usize, cols: usize) -> Self {
        Self {
            data: vec![vec![0.0; cols]; rows],
            rows,
            cols,
        }
    }
    
    pub fn multiply(&self, other: &Matrix) -> Result<Matrix, String> {
        if self.cols != other.rows {
            return Err("Matrix dimensions incompatible".to_string());
        }
        
        let mut result = Matrix::new(self.rows, other.cols);
        
        for i in 0..self.rows {
            for j in 0..other.cols {
                for k in 0..self.cols {
                    result.data[i][j] += self.data[i][k] * other.data[k][j];
                }
            }
        }
        
        Ok(result)
    }
    
    // çŸ©é˜µè½¬ç½®
    pub fn transpose(&self) -> Matrix {
        let mut result = Matrix::new(self.cols, self.rows);
        
        for i in 0..self.rows {
            for j in 0..self.cols {
                result.data[j][i] = self.data[i][j];
            }
        }
        
        result
    }
    
    // è®¡ç®—è¡Œåˆ—å¼
    pub fn determinant(&self) -> Result<f64, String> {
        if self.rows != self.cols {
            return Err("Matrix must be square".to_string());
        }
        
        if self.rows == 1 {
            return Ok(self.data[0][0]);
        }
        
        if self.rows == 2 {
            return Ok(self.data[0][0] * self.data[1][1] - self.data[0][1] * self.data[1][0]);
        }
        
        let mut det = 0.0;
        for j in 0..self.cols {
            let minor = self.minor(0, j);
            det += self.data[0][j] * minor.determinant().unwrap() * if j % 2 == 0 { 1.0 } else { -1.0 };
        }
        
        Ok(det)
    }
    
    // è®¡ç®—å­çŸ©é˜µ
    fn minor(&self, row: usize, col: usize) -> Matrix {
        let mut result = Matrix::new(self.rows - 1, self.cols - 1);
        let mut r = 0;
        
        for i in 0..self.rows {
            if i != row {
                let mut c = 0;
                for j in 0..self.cols {
                    if j != col {
                        result.data[r][c] = self.data[i][j];
                        c += 1;
                    }
                }
                r += 1;
            }
        }
        
        result
    }
}
```

### ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡

#### å¹‚è¿­ä»£æ³•

```rust
// ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡è®¡ç®—
pub struct EigenvalueSolver {
    matrix: Matrix,
    tolerance: f64,
    max_iterations: usize,
}

impl EigenvalueSolver {
    pub fn new(matrix: Matrix) -> Self {
        Self {
            matrix,
            tolerance: 1e-6,
            max_iterations: 1000,
        }
    }
    
    // å¹‚è¿­ä»£æ³•è®¡ç®—ä¸»ç‰¹å¾å€¼
    pub fn power_iteration(&self) -> Result<(f64, Vec<f64>), String> {
        let n = self.matrix.rows;
        let mut eigenvector = vec![1.0; n];
        let mut prev_eigenvalue = 0.0;
        
        for _ in 0..self.max_iterations {
            // å½’ä¸€åŒ–å‘é‡
            let norm = eigenvector.iter().map(|x| x * x).sum::<f64>().sqrt();
            for i in 0..n {
                eigenvector[i] /= norm;
            }
            
            // è®¡ç®—æ–°çš„å‘é‡
            let mut new_vector = vec![0.0; n];
            for i in 0..n {
                for j in 0..n {
                    new_vector[i] += self.matrix.data[i][j] * eigenvector[j];
                }
            }
            
            // è®¡ç®—ç‰¹å¾å€¼
            let eigenvalue = new_vector.iter().zip(&eigenvector)
                .map(|(a, b)| a * b)
                .sum::<f64>();
            
            // æ£€æŸ¥æ”¶æ•›
            if (eigenvalue - prev_eigenvalue).abs() < self.tolerance {
                return Ok((eigenvalue, eigenvector));
            }
            
            prev_eigenvalue = eigenvalue;
            eigenvector = new_vector;
        }
        
        Err("Power iteration did not converge".to_string())
    }
}
```

### å¥‡å¼‚å€¼åˆ†è§£

#### SVDç®—æ³•

```rust
// å¥‡å¼‚å€¼åˆ†è§£
pub struct SVD {
    u: Matrix,
    s: Vec<f64>,
    v: Matrix,
}

impl SVD {
    pub fn decompose(matrix: &Matrix) -> Result<SVD, String> {
        let m = matrix.rows;
        let n = matrix.cols;
        
        // è®¡ç®— A^T * A
        let at = matrix.transpose();
        let ata = at.multiply(matrix)?;
        
        // è®¡ç®— A * A^T
        let aat = matrix.multiply(&at)?;
        
        // è®¡ç®— A^T * A çš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
        let solver = EigenvalueSolver::new(ata);
        let (eigenvalue, eigenvector) = solver.power_iteration()?;
        
        // è®¡ç®—å¥‡å¼‚å€¼
        let sigma = eigenvalue.sqrt();
        
        // è®¡ç®— V çŸ©é˜µ
        let v = Matrix::from_vector(eigenvector, n, 1);
        
        // è®¡ç®— U çŸ©é˜µ
        let u_vector = matrix.multiply(&v)?;
        let u = Matrix::from_vector(u_vector.data[0].clone(), m, 1);
        
        // å½’ä¸€åŒ– U
        let u_norm = u.data[0].iter().map(|x| x * x).sum::<f64>().sqrt();
        for i in 0..m {
            u.data[i][0] /= u_norm;
        }
        
        Ok(SVD {
            u,
            s: vec![sigma],
            v,
        })
    }
}

impl Matrix {
    fn from_vector(vector: Vec<f64>, rows: usize, cols: usize) -> Matrix {
        let mut matrix = Matrix::new(rows, cols);
        for i in 0..rows {
            for j in 0..cols {
                matrix.data[i][j] = vector[i * cols + j];
            }
        }
        matrix
    }
}
```

## ğŸ“Š ç»Ÿè®¡å­¦åŸºç¡€

### æè¿°æ€§ç»Ÿè®¡

#### ç»Ÿè®¡é‡è®¡ç®—

```rust
// æè¿°æ€§ç»Ÿè®¡
pub struct DescriptiveStatistics {
    data: Vec<f64>,
}

impl DescriptiveStatistics {
    pub fn new(data: Vec<f64>) -> Self {
        Self { data }
    }
    
    // è®¡ç®—å‡å€¼
    pub fn mean(&self) -> f64 {
        self.data.iter().sum::<f64>() / self.data.len() as f64
    }
    
    // è®¡ç®—ä¸­ä½æ•°
    pub fn median(&self) -> f64 {
        let mut sorted_data = self.data.clone();
        sorted_data.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let n = sorted_data.len();
        if n % 2 == 0 {
            (sorted_data[n / 2 - 1] + sorted_data[n / 2]) / 2.0
        } else {
            sorted_data[n / 2]
        }
    }
    
    // è®¡ç®—æ ‡å‡†å·®
    pub fn standard_deviation(&self) -> f64 {
        let mean = self.mean();
        let variance = self.data.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f64>() / self.data.len() as f64;
        variance.sqrt()
    }
    
    // è®¡ç®—ååº¦
    pub fn skewness(&self) -> f64 {
        let mean = self.mean();
        let std_dev = self.standard_deviation();
        
        let n = self.data.len() as f64;
        let skewness = self.data.iter()
            .map(|x| ((x - mean) / std_dev).powi(3))
            .sum::<f64>() / n;
        
        skewness
    }
    
    // è®¡ç®—å³°åº¦
    pub fn kurtosis(&self) -> f64 {
        let mean = self.mean();
        let std_dev = self.standard_deviation();
        
        let n = self.data.len() as f64;
        let kurtosis = self.data.iter()
            .map(|x| ((x - mean) / std_dev).powi(4))
            .sum::<f64>() / n;
        
        kurtosis - 3.0 // è¶…é¢å³°åº¦
    }
}
```

### å‡è®¾æ£€éªŒ

#### tæ£€éªŒ

```rust
// å‡è®¾æ£€éªŒ
pub struct HypothesisTesting {
    data: Vec<f64>,
}

impl HypothesisTesting {
    pub fn new(data: Vec<f64>) -> Self {
        Self { data }
    }
    
    // å•æ ·æœ¬tæ£€éªŒ
    pub fn one_sample_t_test(&self, hypothesized_mean: f64) -> TTestResult {
        let n = self.data.len() as f64;
        let sample_mean = self.data.iter().sum::<f64>() / n;
        let sample_std = self.standard_deviation();
        
        let t_statistic = (sample_mean - hypothesized_mean) / (sample_std / n.sqrt());
        let degrees_of_freedom = n - 1.0;
        
        let p_value = self.t_distribution_p_value(t_statistic, degrees_of_freedom);
        
        TTestResult {
            t_statistic,
            degrees_of_freedom,
            p_value,
            significant: p_value < 0.05,
        }
    }
    
    // åŒæ ·æœ¬tæ£€éªŒ
    pub fn two_sample_t_test(&self, other: &HypothesisTesting) -> TTestResult {
        let n1 = self.data.len() as f64;
        let n2 = other.data.len() as f64;
        
        let mean1 = self.data.iter().sum::<f64>() / n1;
        let mean2 = other.data.iter().sum::<f64>() / n2;
        
        let var1 = self.variance();
        let var2 = other.variance();
        
        let pooled_variance = ((n1 - 1.0) * var1 + (n2 - 1.0) * var2) / (n1 + n2 - 2.0);
        let standard_error = (pooled_variance * (1.0 / n1 + 1.0 / n2)).sqrt();
        
        let t_statistic = (mean1 - mean2) / standard_error;
        let degrees_of_freedom = n1 + n2 - 2.0;
        
        let p_value = self.t_distribution_p_value(t_statistic, degrees_of_freedom);
        
        TTestResult {
            t_statistic,
            degrees_of_freedom,
            p_value,
            significant: p_value < 0.05,
        }
    }
    
    fn variance(&self) -> f64 {
        let mean = self.data.iter().sum::<f64>() / self.data.len() as f64;
        self.data.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f64>() / (self.data.len() - 1) as f64
    }
    
    fn t_distribution_p_value(&self, t: f64, df: f64) -> f64 {
        // ç®€åŒ–çš„tåˆ†å¸ƒpå€¼è®¡ç®—
        // å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ›´ç²¾ç¡®çš„ç®—æ³•
        if t.abs() > 2.0 {
            0.05
        } else {
            0.1
        }
    }
}

#[derive(Debug)]
pub struct TTestResult {
    pub t_statistic: f64,
    pub degrees_of_freedom: f64,
    pub p_value: f64,
    pub significant: bool,
}
```

### å›å½’åˆ†æ

#### çº¿æ€§å›å½’

```rust
// çº¿æ€§å›å½’
pub struct LinearRegression {
    x: Vec<f64>,
    y: Vec<f64>,
}

impl LinearRegression {
    pub fn new(x: Vec<f64>, y: Vec<f64>) -> Result<Self, String> {
        if x.len() != y.len() {
            return Err("X and Y vectors must have the same length".to_string());
        }
        Ok(Self { x, y })
    }
    
    // è®¡ç®—å›å½’ç³»æ•°
    pub fn fit(&self) -> RegressionResult {
        let n = self.x.len() as f64;
        
        let sum_x = self.x.iter().sum::<f64>();
        let sum_y = self.y.iter().sum::<f64>();
        let sum_xy = self.x.iter().zip(&self.y).map(|(x, y)| x * y).sum::<f64>();
        let sum_x2 = self.x.iter().map(|x| x * x).sum::<f64>();
        let sum_y2 = self.y.iter().map(|y| y * y).sum::<f64>();
        
        // è®¡ç®—æ–œç‡å’Œæˆªè·
        let slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x);
        let intercept = (sum_y - slope * sum_x) / n;
        
        // è®¡ç®—å†³å®šç³»æ•°
        let y_mean = sum_y / n;
        let ss_tot = self.y.iter().map(|y| (y - y_mean).powi(2)).sum::<f64>();
        let ss_res = self.x.iter().zip(&self.y)
            .map(|(x, y)| (y - (slope * x + intercept)).powi(2))
            .sum::<f64>();
        let r_squared = 1.0 - ss_res / ss_tot;
        
        // è®¡ç®—æ ‡å‡†è¯¯å·®
        let mse = ss_res / (n - 2.0);
        let se_slope = (mse / (n * sum_x2 - sum_x * sum_x)).sqrt();
        let se_intercept = (mse * sum_x2 / (n * sum_x2 - sum_x * sum_x)).sqrt();
        
        RegressionResult {
            slope,
            intercept,
            r_squared,
            standard_error_slope: se_slope,
            standard_error_intercept: se_intercept,
            mean_squared_error: mse,
        }
    }
    
    // é¢„æµ‹
    pub fn predict(&self, x: f64, result: &RegressionResult) -> f64 {
        result.slope * x + result.intercept
    }
}

#[derive(Debug)]
pub struct RegressionResult {
    pub slope: f64,
    pub intercept: f64,
    pub r_squared: f64,
    pub standard_error_slope: f64,
    pub standard_error_intercept: f64,
    pub mean_squared_error: f64,
}
```

## ğŸ” å¯†ç å­¦æ•°å­¦åŸºç¡€

### ç¾¤è®º

#### ç¾¤çš„å®šä¹‰å’Œæ€§è´¨

```rust
// ç¾¤è®ºåŸºç¡€
pub trait Group {
    type Element;
    
    // ç¾¤è¿ç®—
    fn operation(&self, a: &Self::Element, b: &Self::Element) -> Self::Element;
    
    // å•ä½å…ƒ
    fn identity(&self) -> Self::Element;
    
    // é€†å…ƒ
    fn inverse(&self, a: &Self::Element) -> Self::Element;
    
    // éªŒè¯ç¾¤å…¬ç†
    fn verify_group_axioms(&self) -> bool {
        // ç»“åˆå¾‹: (a * b) * c = a * (b * c)
        // å•ä½å…ƒ: a * e = e * a = a
        // é€†å…ƒ: a * a^(-1) = a^(-1) * a = e
        true // ç®€åŒ–å®ç°
    }
}

// æ¨¡nä¹˜æ³•ç¾¤
pub struct ModularMultiplicativeGroup {
    modulus: u64,
}

impl ModularMultiplicativeGroup {
    pub fn new(modulus: u64) -> Self {
        Self { modulus }
    }
    
    // æ£€æŸ¥å…ƒç´ æ˜¯å¦åœ¨ç¾¤ä¸­
    pub fn is_element(&self, a: u64) -> bool {
        gcd(a, self.modulus) == 1
    }
    
    // è®¡ç®—ç¾¤çš„é˜¶
    pub fn order(&self) -> u64 {
        self.euler_phi(self.modulus)
    }
    
    // æ¬§æ‹‰å‡½æ•°
    fn euler_phi(&self, n: u64) -> u64 {
        let mut result = n;
        let mut p = 2;
        
        while p * p <= n {
            if n % p == 0 {
                while n % p == 0 {
                    n /= p;
                }
                result -= result / p;
            }
            p += 1;
        }
        
        if n > 1 {
            result -= result / n;
        }
        
        result
    }
}

impl Group for ModularMultiplicativeGroup {
    type Element = u64;
    
    fn operation(&self, a: &Self::Element, b: &Self::Element) -> Self::Element {
        (a * b) % self.modulus
    }
    
    fn identity(&self) -> Self::Element {
        1
    }
    
    fn inverse(&self, a: &Self::Element) -> Self::Element {
        // ä½¿ç”¨æ‰©å±•æ¬§å‡ é‡Œå¾—ç®—æ³•è®¡ç®—é€†å…ƒ
        let (gcd, x, _) = extended_gcd(*a, self.modulus);
        if gcd == 1 {
            (x % self.modulus as i64 + self.modulus as i64) as u64 % self.modulus
        } else {
            panic!("Element has no inverse");
        }
    }
}
```

### æ¤­åœ†æ›²çº¿

#### æ¤­åœ†æ›²çº¿å¯†ç å­¦

```rust
// æ¤­åœ†æ›²çº¿ç‚¹
#[derive(Debug, Clone, PartialEq)]
pub struct EllipticCurvePoint {
    x: Option<u64>,
    y: Option<u64>,
    is_infinity: bool,
}

impl EllipticCurvePoint {
    pub fn new(x: u64, y: u64) -> Self {
        Self {
            x: Some(x),
            y: Some(y),
            is_infinity: false,
        }
    }
    
    pub fn infinity() -> Self {
        Self {
            x: None,
            y: None,
            is_infinity: true,
        }
    }
}

// æ¤­åœ†æ›²çº¿
pub struct EllipticCurve {
    a: u64,
    b: u64,
    p: u64, // æ¨¡æ•°
}

impl EllipticCurve {
    pub fn new(a: u64, b: u64, p: u64) -> Self {
        Self { a, b, p }
    }
    
    // æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨æ›²çº¿ä¸Š
    pub fn is_on_curve(&self, point: &EllipticCurvePoint) -> bool {
        if point.is_infinity {
            return true;
        }
        
        let x = point.x.unwrap();
        let y = point.y.unwrap();
        
        let left = (y * y) % self.p;
        let right = (x * x * x + self.a * x + self.b) % self.p;
        
        left == right
    }
    
    // ç‚¹åŠ æ³•
    pub fn point_add(&self, p1: &EllipticCurvePoint, p2: &EllipticCurvePoint) -> EllipticCurvePoint {
        if p1.is_infinity {
            return p2.clone();
        }
        if p2.is_infinity {
            return p1.clone();
        }
        
        let x1 = p1.x.unwrap();
        let y1 = p1.y.unwrap();
        let x2 = p2.x.unwrap();
        let y2 = p2.y.unwrap();
        
        if x1 == x2 {
            if y1 == y2 {
                return self.point_double(p1);
            } else {
                return EllipticCurvePoint::infinity();
            }
        }
        
        let delta_x = (x2 - x1 + self.p) % self.p;
        let delta_y = (y2 - y1 + self.p) % self.p;
        
        let slope = (delta_y * self.modular_inverse(delta_x)) % self.p;
        
        let x3 = (slope * slope - x1 - x2 + self.p) % self.p;
        let y3 = (slope * (x1 - x3 + self.p) - y1 + self.p) % self.p;
        
        EllipticCurvePoint::new(x3, y3)
    }
    
    // ç‚¹å€ä¹˜
    pub fn point_double(&self, point: &EllipticCurvePoint) -> EllipticCurvePoint {
        if point.is_infinity {
            return EllipticCurvePoint::infinity();
        }
        
        let x = point.x.unwrap();
        let y = point.y.unwrap();
        
        let slope = (3 * x * x + self.a) * self.modular_inverse(2 * y) % self.p;
        
        let x3 = (slope * slope - 2 * x + self.p) % self.p;
        let y3 = (slope * (x - x3 + self.p) - y + self.p) % self.p;
        
        EllipticCurvePoint::new(x3, y3)
    }
    
    // æ ‡é‡ä¹˜æ³•
    pub fn scalar_multiply(&self, point: &EllipticCurvePoint, scalar: u64) -> EllipticCurvePoint {
        let mut result = EllipticCurvePoint::infinity();
        let mut addend = point.clone();
        let mut k = scalar;
        
        while k > 0 {
            if k & 1 == 1 {
                result = self.point_add(&result, &addend);
            }
            addend = self.point_double(&addend);
            k >>= 1;
        }
        
        result
    }
    
    // æ¨¡é€†å…ƒ
    fn modular_inverse(&self, a: u64) -> u64 {
        let (gcd, x, _) = extended_gcd(a, self.p);
        if gcd == 1 {
            (x % self.p as i64 + self.p as i64) as u64 % self.p
        } else {
            panic!("No modular inverse exists");
        }
    }
}
```

### ç¦»æ•£å¯¹æ•°

#### ç¦»æ•£å¯¹æ•°é—®é¢˜

```rust
// ç¦»æ•£å¯¹æ•°æ±‚è§£
pub struct DiscreteLogarithm {
    base: u64,
    modulus: u64,
}

impl DiscreteLogarithm {
    pub fn new(base: u64, modulus: u64) -> Self {
        Self { base, modulus }
    }
    
    // æš´åŠ›æœç´¢
    pub fn brute_force(&self, target: u64) -> Option<u64> {
        let mut result = 1;
        for i in 0..self.modulus {
            if result == target {
                return Some(i);
            }
            result = (result * self.base) % self.modulus;
        }
        None
    }
    
    // å¤§æ­¥å°æ­¥ç®—æ³•
    pub fn baby_step_giant_step(&self, target: u64) -> Option<u64> {
        let m = (self.modulus as f64).sqrt().ceil() as u64;
        
        // è®¡ç®—å°æ­¥
        let mut baby_steps = HashMap::new();
        let mut result = 1;
        for j in 0..m {
            baby_steps.insert(result, j);
            result = (result * self.base) % self.modulus;
        }
        
        // è®¡ç®—å¤§æ­¥
        let giant_step = self.modular_power(self.base, m, self.modulus);
        result = 1;
        for i in 0..m {
            let target_inv = self.modular_inverse(result, self.modulus);
            let target_mod = (target * target_inv) % self.modulus;
            
            if let Some(&j) = baby_steps.get(&target_mod) {
                return Some(i * m + j);
            }
            
            result = (result * giant_step) % self.modulus;
        }
        
        None
    }
    
    // æ¨¡å¹‚è¿ç®—
    fn modular_power(&self, base: u64, exponent: u64, modulus: u64) -> u64 {
        let mut result = 1;
        let mut base = base % modulus;
        let mut exp = exponent;
        
        while exp > 0 {
            if exp % 2 == 1 {
                result = (result * base) % modulus;
            }
            exp >>= 1;
            base = (base * base) % modulus;
        }
        
        result
    }
    
    // æ¨¡é€†å…ƒ
    fn modular_inverse(&self, a: u64, modulus: u64) -> u64 {
        let (gcd, x, _) = extended_gcd(a, modulus);
        if gcd == 1 {
            (x % modulus as i64 + modulus as i64) as u64 % modulus
        } else {
            panic!("No modular inverse exists");
        }
    }
}
```

## ğŸ¯ ä¼˜åŒ–ç†è®º

### çº¿æ€§è§„åˆ’

#### å•çº¯å½¢æ³•

```rust
// çº¿æ€§è§„åˆ’
pub struct LinearProgram {
    // ç›®æ ‡å‡½æ•°ç³»æ•°
    objective: Vec<f64>,
    // çº¦æŸçŸ©é˜µ
    constraints: Vec<Vec<f64>>,
    // çº¦æŸå³ç«¯é¡¹
    rhs: Vec<f64>,
    // çº¦æŸç±»å‹ (<=, =, >=)
    constraint_types: Vec<ConstraintType>,
}

#[derive(Debug, Clone)]
pub enum ConstraintType {
    LessThanOrEqual,
    Equal,
    GreaterThanOrEqual,
}

impl LinearProgram {
    pub fn new(objective: Vec<f64>, constraints: Vec<Vec<f64>>, rhs: Vec<f64>, constraint_types: Vec<ConstraintType>) -> Self {
        Self {
            objective,
            constraints,
            rhs,
            constraint_types,
        }
    }
    
    // å•çº¯å½¢æ³•æ±‚è§£
    pub fn solve_simplex(&self) -> Result<LinearProgramResult, String> {
        // è½¬æ¢ä¸ºæ ‡å‡†å½¢å¼
        let standard_form = self.to_standard_form();
        
        // åˆå§‹åŒ–å•çº¯å½¢è¡¨
        let mut tableau = self.create_initial_tableau(&standard_form);
        
        // ä¸»å¾ªç¯
        while !self.is_optimal(&tableau) {
            let pivot_column = self.find_pivot_column(&tableau);
            let pivot_row = self.find_pivot_row(&tableau, pivot_column);
            
            if pivot_row == None {
                return Err("Unbounded solution".to_string());
            }
            
            self.pivot(&mut tableau, pivot_row.unwrap(), pivot_column);
        }
        
        // æå–è§£
        let solution = self.extract_solution(&tableau);
        let objective_value = self.calculate_objective_value(&solution);
        
        Ok(LinearProgramResult {
            solution,
            objective_value,
            optimal: true,
        })
    }
    
    // è½¬æ¢ä¸ºæ ‡å‡†å½¢å¼
    fn to_standard_form(&self) -> LinearProgram {
        // å®ç°æ ‡å‡†å½¢å¼è½¬æ¢
        self.clone()
    }
    
    // åˆ›å»ºåˆå§‹å•çº¯å½¢è¡¨
    fn create_initial_tableau(&self, standard_form: &LinearProgram) -> Vec<Vec<f64>> {
        // å®ç°åˆå§‹å•çº¯å½¢è¡¨åˆ›å»º
        vec![vec![0.0; 10]; 10] // ç®€åŒ–å®ç°
    }
    
    // æ£€æŸ¥æ˜¯å¦æœ€ä¼˜
    fn is_optimal(&self, tableau: &[Vec<f64>]) -> bool {
        // æ£€æŸ¥ç›®æ ‡å‡½æ•°è¡Œæ˜¯å¦æ‰€æœ‰ç³»æ•°éè´Ÿ
        tableau[0].iter().skip(1).all(|&x| x >= 0.0)
    }
    
    // å¯»æ‰¾ä¸»å…ƒåˆ—
    fn find_pivot_column(&self, tableau: &[Vec<f64>]) -> usize {
        tableau[0].iter().skip(1).position(|&x| x < 0.0).unwrap_or(0)
    }
    
    // å¯»æ‰¾ä¸»å…ƒè¡Œ
    fn find_pivot_row(&self, tableau: &[Vec<f64>], pivot_column: usize) -> Option<usize> {
        let mut min_ratio = f64::INFINITY;
        let mut pivot_row = None;
        
        for i in 1..tableau.len() {
            if tableau[i][pivot_column] > 0.0 {
                let ratio = tableau[i][0] / tableau[i][pivot_column];
                if ratio < min_ratio {
                    min_ratio = ratio;
                    pivot_row = Some(i);
                }
            }
        }
        
        pivot_row
    }
    
    // ä¸»å…ƒå˜æ¢
    fn pivot(&self, tableau: &mut [Vec<f64>], pivot_row: usize, pivot_column: usize) {
        let pivot_element = tableau[pivot_row][pivot_column];
        
        // å½’ä¸€åŒ–ä¸»å…ƒè¡Œ
        for j in 0..tableau[pivot_row].len() {
            tableau[pivot_row][j] /= pivot_element;
        }
        
        // æ¶ˆå…ƒ
        for i in 0..tableau.len() {
            if i != pivot_row {
                let factor = tableau[i][pivot_column];
                for j in 0..tableau[i].len() {
                    tableau[i][j] -= factor * tableau[pivot_row][j];
                }
            }
        }
    }
    
    // æå–è§£
    fn extract_solution(&self, tableau: &[Vec<f64>]) -> Vec<f64> {
        // å®ç°è§£æå–
        vec![0.0; self.objective.len()]
    }
    
    // è®¡ç®—ç›®æ ‡å‡½æ•°å€¼
    fn calculate_objective_value(&self, solution: &[f64]) -> f64 {
        solution.iter().zip(&self.objective).map(|(x, c)| x * c).sum()
    }
}

#[derive(Debug)]
pub struct LinearProgramResult {
    pub solution: Vec<f64>,
    pub objective_value: f64,
    pub optimal: bool,
}
```

### åŠ¨æ€è§„åˆ’

#### ç½‘ç»œæµé—®é¢˜

```rust
// åŠ¨æ€è§„åˆ’æ±‚è§£ç½‘ç»œæµ
pub struct NetworkFlowDP {
    graph: NetworkGraph,
    source: usize,
    sink: usize,
}

impl NetworkFlowDP {
    pub fn new(graph: NetworkGraph, source: usize, sink: usize) -> Self {
        Self { graph, source, sink }
    }
    
    // æœ€å¤§æµé—®é¢˜
    pub fn max_flow(&self) -> f64 {
        let mut residual_graph = self.graph.clone();
        let mut max_flow = 0.0;
        
        // ä½¿ç”¨å¢å¹¿è·¯å¾„ç®—æ³•
        while let Some(path) = self.find_augmenting_path(&residual_graph) {
            let flow = self.find_bottleneck(&path, &residual_graph);
            self.update_residual_graph(&mut residual_graph, &path, flow);
            max_flow += flow;
        }
        
        max_flow
    }
    
    // å¯»æ‰¾å¢å¹¿è·¯å¾„
    fn find_augmenting_path(&self, graph: &NetworkGraph) -> Option<Vec<usize>> {
        let mut visited = vec![false; graph.vertices.len()];
        let mut path = Vec::new();
        
        if self.dfs_path(graph, self.source, self.sink, &mut visited, &mut path) {
            Some(path)
        } else {
            None
        }
    }
    
    // æ·±åº¦ä¼˜å…ˆæœç´¢å¯»æ‰¾è·¯å¾„
    fn dfs_path(&self, graph: &NetworkGraph, current: usize, target: usize, visited: &mut Vec<bool>, path: &mut Vec<usize>) -> bool {
        visited[current] = true;
        path.push(current);
        
        if current == target {
            return true;
        }
        
        for (neighbor, &weight) in graph.adjacency_matrix[current].iter().enumerate() {
            if weight > 0.0 && !visited[neighbor] {
                if self.dfs_path(graph, neighbor, target, visited, path) {
                    return true;
                }
            }
        }
        
        path.pop();
        false
    }
    
    // å¯»æ‰¾ç“¶é¢ˆå®¹é‡
    fn find_bottleneck(&self, path: &[usize], graph: &NetworkGraph) -> f64 {
        let mut min_capacity = f64::INFINITY;
        
        for i in 0..path.len() - 1 {
            let capacity = graph.adjacency_matrix[path[i]][path[i + 1]];
            min_capacity = min_capacity.min(capacity);
        }
        
        min_capacity
    }
    
    // æ›´æ–°æ®‹é‡å›¾
    fn update_residual_graph(&self, graph: &mut NetworkGraph, path: &[usize], flow: f64) {
        for i in 0..path.len() - 1 {
            let from = path[i];
            let to = path[i + 1];
            
            // å‡å°‘æ­£å‘è¾¹å®¹é‡
            graph.adjacency_matrix[from][to] -= flow;
            
            // å¢åŠ åå‘è¾¹å®¹é‡
            graph.adjacency_matrix[to][from] += flow;
        }
    }
}
```

### å¯å‘å¼ç®—æ³•

#### é—ä¼ ç®—æ³•

```rust
// é—ä¼ ç®—æ³•
pub struct GeneticAlgorithm {
    population_size: usize,
    mutation_rate: f64,
    crossover_rate: f64,
    max_generations: usize,
}

impl GeneticAlgorithm {
    pub fn new(population_size: usize, mutation_rate: f64, crossover_rate: f64, max_generations: usize) -> Self {
        Self {
            population_size,
            mutation_rate,
            crossover_rate,
            max_generations,
        }
    }
    
    // è¿è¡Œé—ä¼ ç®—æ³•
    pub fn run<F>(&self, fitness_function: F) -> Vec<f64>
    where
        F: Fn(&[f64]) -> f64,
    {
        // åˆå§‹åŒ–ç§ç¾¤
        let mut population = self.initialize_population();
        
        for generation in 0..self.max_generations {
            // è¯„ä¼°é€‚åº”åº¦
            let fitness_scores: Vec<f64> = population.iter()
                .map(|individual| fitness_function(individual))
                .collect();
            
            // é€‰æ‹©
            let selected = self.selection(&population, &fitness_scores);
            
            // äº¤å‰
            let offspring = self.crossover(&selected);
            
            // å˜å¼‚
            let mutated = self.mutation(&offspring);
            
            // æ›´æ–°ç§ç¾¤
            population = mutated;
        }
        
        // è¿”å›æœ€ä¼˜è§£
        population.into_iter()
            .max_by(|a, b| fitness_function(a).partial_cmp(&fitness_function(b)).unwrap())
            .unwrap()
    }
    
    // åˆå§‹åŒ–ç§ç¾¤
    fn initialize_population(&self) -> Vec<Vec<f64>> {
        (0..self.population_size)
            .map(|_| {
                (0..10) // å‡è®¾10ä¸ªå˜é‡
                    .map(|_| rand::random::<f64>() * 10.0 - 5.0) // èŒƒå›´[-5, 5]
                    .collect()
            })
            .collect()
    }
    
    // é€‰æ‹©æ“ä½œ
    fn selection(&self, population: &[Vec<f64>], fitness_scores: &[f64]) -> Vec<Vec<f64>> {
        let total_fitness: f64 = fitness_scores.iter().sum();
        let mut selected = Vec::new();
        
        for _ in 0..self.population_size {
            let random = rand::random::<f64>() * total_fitness;
            let mut cumulative = 0.0;
            
            for (i, &fitness) in fitness_scores.iter().enumerate() {
                cumulative += fitness;
                if cumulative >= random {
                    selected.push(population[i].clone());
                    break;
                }
            }
        }
        
        selected
    }
    
    // äº¤å‰æ“ä½œ
    fn crossover(&self, population: &[Vec<f64>]) -> Vec<Vec<f64>> {
        let mut offspring = Vec::new();
        
        for i in (0..population.len()).step_by(2) {
            if i + 1 < population.len() {
                let parent1 = &population[i];
                let parent2 = &population[i + 1];
                
                if rand::random::<f64>() < self.crossover_rate {
                    let (child1, child2) = self.single_point_crossover(parent1, parent2);
                    offspring.push(child1);
                    offspring.push(child2);
                } else {
                    offspring.push(parent1.clone());
                    offspring.push(parent2.clone());
                }
            }
        }
        
        offspring
    }
    
    // å•ç‚¹äº¤å‰
    fn single_point_crossover(&self, parent1: &[f64], parent2: &[f64]) -> (Vec<f64>, Vec<f64>) {
        let crossover_point = rand::random::<usize>() % parent1.len();
        
        let mut child1 = parent1[..crossover_point].to_vec();
        child1.extend_from_slice(&parent2[crossover_point..]);
        
        let mut child2 = parent2[..crossover_point].to_vec();
        child2.extend_from_slice(&parent1[crossover_point..]);
        
        (child1, child2)
    }
    
    // å˜å¼‚æ“ä½œ
    fn mutation(&self, population: &[Vec<f64>]) -> Vec<Vec<f64>> {
        population.iter()
            .map(|individual| {
                individual.iter()
                    .map(|&gene| {
                        if rand::random::<f64>() < self.mutation_rate {
                            gene + rand::random::<f64>() * 0.1 - 0.05 // å°å¹…å˜å¼‚
                        } else {
                            gene
                        }
                    })
                    .collect()
            })
            .collect()
    }
}
```

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Ross, S. M. (2014). *Introduction to Probability Models*. Academic Press.
2. Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). *Introduction to Algorithms*. MIT Press.
3. Cover, T. M., & Thomas, J. A. (2006). *Elements of Information Theory*. Wiley.
4. Strang, G. (2016). *Introduction to Linear Algebra*. Wellesley-Cambridge Press.
5. Montgomery, D. C., Peck, E. A., & Vining, G. G. (2012). *Introduction to Linear Regression Analysis*. Wiley.
6. Menezes, A. J., Van Oorschot, P. C., & Vanstone, S. A. (1996). *Handbook of Applied Cryptography*. CRC Press.
7. Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.
8. Goldberg, D. E. (1989). *Genetic Algorithms in Search, Optimization, and Machine Learning*. Addison-Wesley.

---

**æ•°å­¦åŸºç¡€ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ  
**ç»´æŠ¤è€…**: C10 Networks æ•°å­¦ç†è®ºå›¢é˜Ÿ
