# C10 Networks ç½‘ç»œæ€§èƒ½æ¨¡å‹

> é€‚ç”¨èŒƒå›´ï¼šRust 1.90+ï¼ŒTokio 1.35+ã€‚æ–‡æ¡£é£æ ¼éµå¾ª [`STYLE.md`](STYLE.md)ã€‚

## ğŸ“‹ ç›®å½•

- [C10 Networks ç½‘ç»œæ€§èƒ½æ¨¡å‹](#c10-networks-ç½‘ç»œæ€§èƒ½æ¨¡å‹)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ¯ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ“Š æ’é˜Ÿè®ºæ¨¡å‹](#-æ’é˜Ÿè®ºæ¨¡å‹)
    - [M/M/1é˜Ÿåˆ—æ¨¡å‹](#mm1é˜Ÿåˆ—æ¨¡å‹)
      - [æ¨¡å‹å®šä¹‰](#æ¨¡å‹å®šä¹‰)
      - [æ•°å­¦å…¬å¼](#æ•°å­¦å…¬å¼)
      - [å®ç°](#å®ç°)
    - [M/M/cé˜Ÿåˆ—æ¨¡å‹](#mmcé˜Ÿåˆ—æ¨¡å‹)
      - [æ¨¡å‹å®šä¹‰1](#æ¨¡å‹å®šä¹‰1)
      - [æ•°å­¦å…¬å¼1](#æ•°å­¦å…¬å¼1)
      - [å®ç°1](#å®ç°1)
    - [M/G/1é˜Ÿåˆ—æ¨¡å‹](#mg1é˜Ÿåˆ—æ¨¡å‹)
      - [æ¨¡å‹å®šä¹‰2](#æ¨¡å‹å®šä¹‰2)
      - [Pollaczek-Khinchineå…¬å¼](#pollaczek-khinchineå…¬å¼)
      - [å®ç°4](#å®ç°4)
    - [G/G/1é˜Ÿåˆ—æ¨¡å‹](#gg1é˜Ÿåˆ—æ¨¡å‹)
      - [æ¨¡å‹å®šä¹‰3](#æ¨¡å‹å®šä¹‰3)
      - [Kingmanå…¬å¼](#kingmanå…¬å¼)
      - [å®ç°2](#å®ç°2)
  - [ğŸ”— ç½‘ç»œæ‹“æ‰‘æ¨¡å‹](#-ç½‘ç»œæ‹“æ‰‘æ¨¡å‹)
    - [éšæœºå›¾æ¨¡å‹](#éšæœºå›¾æ¨¡å‹)
      - [ErdÅ‘s-RÃ©nyiæ¨¡å‹](#erdÅ‘s-rÃ©nyiæ¨¡å‹)
      - [å®ç°3](#å®ç°3)
    - [å°ä¸–ç•Œç½‘ç»œæ¨¡å‹](#å°ä¸–ç•Œç½‘ç»œæ¨¡å‹)
      - [Watts-Strogatzæ¨¡å‹](#watts-strogatzæ¨¡å‹)
      - [å®ç°6](#å®ç°6)
    - [æ— æ ‡åº¦ç½‘ç»œæ¨¡å‹](#æ— æ ‡åº¦ç½‘ç»œæ¨¡å‹)
      - [BarabÃ¡si-Albertæ¨¡å‹](#barabÃ¡si-albertæ¨¡å‹)
      - [å®ç°5](#å®ç°5)
    - [å±‚æ¬¡ç½‘ç»œæ¨¡å‹](#å±‚æ¬¡ç½‘ç»œæ¨¡å‹)
      - [å±‚æ¬¡ç½‘ç»œ](#å±‚æ¬¡ç½‘ç»œ)
      - [å®ç°7](#å®ç°7)
  - [âš¡ å»¶è¿Ÿåˆ†ææ¨¡å‹](#-å»¶è¿Ÿåˆ†ææ¨¡å‹)
    - [ä¼ æ’­å»¶è¿Ÿæ¨¡å‹](#ä¼ æ’­å»¶è¿Ÿæ¨¡å‹)
      - [ä¼ æ’­å»¶è¿Ÿ](#ä¼ æ’­å»¶è¿Ÿ)
      - [å®ç°8](#å®ç°8)
    - [ä¼ è¾“å»¶è¿Ÿæ¨¡å‹](#ä¼ è¾“å»¶è¿Ÿæ¨¡å‹)
      - [ä¼ è¾“å»¶è¿Ÿ](#ä¼ è¾“å»¶è¿Ÿ)
      - [å®ç°9](#å®ç°9)
    - [å¤„ç†å»¶è¿Ÿæ¨¡å‹](#å¤„ç†å»¶è¿Ÿæ¨¡å‹)
      - [å¤„ç†å»¶è¿Ÿ](#å¤„ç†å»¶è¿Ÿ)
      - [å®ç°10](#å®ç°10)
    - [æ’é˜Ÿå»¶è¿Ÿæ¨¡å‹](#æ’é˜Ÿå»¶è¿Ÿæ¨¡å‹)
      - [æ’é˜Ÿå»¶è¿Ÿ](#æ’é˜Ÿå»¶è¿Ÿ)
      - [å®ç°11](#å®ç°11)
  - [ğŸ“ˆ ååé‡æ¨¡å‹](#-ååé‡æ¨¡å‹)
    - [TCPååé‡æ¨¡å‹](#tcpååé‡æ¨¡å‹)
      - [TCPååé‡](#tcpååé‡)
      - [å®ç°12](#å®ç°12)
    - [UDPååé‡æ¨¡å‹](#udpååé‡æ¨¡å‹)
      - [UDPååé‡](#udpååé‡)
      - [å®ç°13](#å®ç°13)
    - [HTTPååé‡æ¨¡å‹](#httpååé‡æ¨¡å‹)
      - [HTTPååé‡](#httpååé‡)
      - [å®ç°14](#å®ç°14)
    - [WebSocketååé‡æ¨¡å‹](#websocketååé‡æ¨¡å‹)
      - [WebSocketååé‡](#websocketååé‡)
      - [å®ç°15](#å®ç°15)
  - [ğŸ”’ å¯é æ€§æ¨¡å‹](#-å¯é æ€§æ¨¡å‹)
    - [æ•…éšœæ¨¡å‹](#æ•…éšœæ¨¡å‹)
      - [æ•…éšœç‡æ¨¡å‹](#æ•…éšœç‡æ¨¡å‹)
      - [å®ç°16](#å®ç°16)
    - [æ¢å¤æ¨¡å‹](#æ¢å¤æ¨¡å‹)
      - [æ¢å¤æ—¶é—´æ¨¡å‹](#æ¢å¤æ—¶é—´æ¨¡å‹)
      - [å®ç°17](#å®ç°17)
    - [å†—ä½™æ¨¡å‹](#å†—ä½™æ¨¡å‹)
      - [N+1å†—ä½™æ¨¡å‹](#n1å†—ä½™æ¨¡å‹)
      - [å®ç°18](#å®ç°18)
    - [ä¸€è‡´æ€§æ¨¡å‹](#ä¸€è‡´æ€§æ¨¡å‹)
      - [å¼ºä¸€è‡´æ€§æ¨¡å‹](#å¼ºä¸€è‡´æ€§æ¨¡å‹)
      - [å®ç°19](#å®ç°19)
  - [ğŸ¯ ä¼˜åŒ–æ¨¡å‹](#-ä¼˜åŒ–æ¨¡å‹)
    - [è´Ÿè½½å‡è¡¡æ¨¡å‹](#è´Ÿè½½å‡è¡¡æ¨¡å‹)
      - [è´Ÿè½½å‡è¡¡ç®—æ³•](#è´Ÿè½½å‡è¡¡ç®—æ³•)
      - [å®ç°20](#å®ç°20)
    - [ç¼“å­˜æ¨¡å‹](#ç¼“å­˜æ¨¡å‹)
      - [LRUç¼“å­˜æ¨¡å‹](#lruç¼“å­˜æ¨¡å‹)
      - [å®ç°21](#å®ç°21)
    - [å‹ç¼©æ¨¡å‹](#å‹ç¼©æ¨¡å‹)
      - [å‹ç¼©ç®—æ³•æ¨¡å‹](#å‹ç¼©ç®—æ³•æ¨¡å‹)
      - [å®ç°22](#å®ç°22)
    - [è·¯ç”±ä¼˜åŒ–æ¨¡å‹](#è·¯ç”±ä¼˜åŒ–æ¨¡å‹)
      - [æœ€çŸ­è·¯å¾„ç®—æ³•](#æœ€çŸ­è·¯å¾„ç®—æ³•)
      - [å®ç°23](#å®ç°23)
  - [ğŸ“š å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº†C10 Networksé¡¹ç›®ä¸­ç½‘ç»œæ€§èƒ½åˆ†æçš„æ•°å­¦æ¨¡å‹ï¼ŒåŒ…æ‹¬æ’é˜Ÿè®ºã€ç½‘ç»œæ‹“æ‰‘ã€å»¶è¿Ÿåˆ†æã€ååé‡å»ºæ¨¡ã€å¯é æ€§åˆ†æå’Œä¼˜åŒ–æ¨¡å‹ç­‰ã€‚è¿™äº›æ¨¡å‹ä¸ºç½‘ç»œç³»ç»Ÿè®¾è®¡ã€æ€§èƒ½é¢„æµ‹å’Œä¼˜åŒ–æä¾›äº†ç†è®ºåŸºç¡€ã€‚

## ğŸ“Š æ’é˜Ÿè®ºæ¨¡å‹

### M/M/1é˜Ÿåˆ—æ¨¡å‹

#### æ¨¡å‹å®šä¹‰

M/M/1é˜Ÿåˆ—æ¨¡å‹å‡è®¾ï¼š

- åˆ°è¾¾è¿‡ç¨‹ä¸ºæ³Šæ¾è¿‡ç¨‹ï¼ˆMï¼‰
- æœåŠ¡æ—¶é—´ä¸ºæŒ‡æ•°åˆ†å¸ƒï¼ˆMï¼‰
- å•æœåŠ¡å™¨ï¼ˆ1ï¼‰

#### æ•°å­¦å…¬å¼

**åˆ°è¾¾ç‡**: $\lambda$ (packets/second)
**æœåŠ¡ç‡**: $\mu$ (packets/second)
**åˆ©ç”¨ç‡**: $\rho = \frac{\lambda}{\mu}$

**ç¨³æ€æ¦‚ç‡**:
$$P_n = \rho^n(1-\rho), \quad n = 0, 1, 2, \ldots$$

**å¹³å‡é˜Ÿåˆ—é•¿åº¦**:
$$L = \frac{\rho}{1-\rho}$$

**å¹³å‡ç­‰å¾…æ—¶é—´**:
$$W = \frac{1}{\mu - \lambda}$$

**å¹³å‡å“åº”æ—¶é—´**:
$$T = W + \frac{1}{\mu} = \frac{1}{\mu - \lambda}$$

#### å®ç°

```rust
// M/M/1é˜Ÿåˆ—æ¨¡å‹
pub struct MM1Queue {
    arrival_rate: f64,    // Î»
    service_rate: f64,    // Î¼
    utilization: f64,     // Ï
}

impl MM1Queue {
    pub fn new(arrival_rate: f64, service_rate: f64) -> Result<Self, String> {
        if arrival_rate >= service_rate {
            return Err("System must be stable (Î» < Î¼)".to_string());
        }
        
        let utilization = arrival_rate / service_rate;
        
        Ok(Self {
            arrival_rate,
            service_rate,
            utilization,
        })
    }
    
    // è®¡ç®—ç¨³æ€æ¦‚ç‡
    pub fn steady_state_probability(&self, n: usize) -> f64 {
        self.utilization.powi(n as i32) * (1.0 - self.utilization)
    }
    
    // è®¡ç®—å¹³å‡é˜Ÿåˆ—é•¿åº¦
    pub fn average_queue_length(&self) -> f64 {
        self.utilization / (1.0 - self.utilization)
    }
    
    // è®¡ç®—å¹³å‡ç­‰å¾…æ—¶é—´
    pub fn average_waiting_time(&self) -> f64 {
        1.0 / (self.service_rate - self.arrival_rate)
    }
    
    // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    pub fn average_response_time(&self) -> f64 {
        self.average_waiting_time() + 1.0 / self.service_rate
    }
    
    // è®¡ç®—é˜Ÿåˆ—é•¿åº¦æ–¹å·®
    pub fn queue_length_variance(&self) -> f64 {
        self.utilization / (1.0 - self.utilization).powi(2)
    }
    
    // è®¡ç®—ç­‰å¾…æ—¶é—´æ–¹å·®
    pub fn waiting_time_variance(&self) -> f64 {
        1.0 / (self.service_rate - self.arrival_rate).powi(2)
    }
    
    // è®¡ç®—ç³»ç»Ÿç©ºé—²æ¦‚ç‡
    pub fn idle_probability(&self) -> f64 {
        1.0 - self.utilization
    }
    
    // è®¡ç®—ç³»ç»Ÿç¹å¿™æ¦‚ç‡
    pub fn busy_probability(&self) -> f64 {
        self.utilization
    }
}
```

### M/M/cé˜Ÿåˆ—æ¨¡å‹

#### æ¨¡å‹å®šä¹‰1

M/M/cé˜Ÿåˆ—æ¨¡å‹å‡è®¾ï¼š

- åˆ°è¾¾è¿‡ç¨‹ä¸ºæ³Šæ¾è¿‡ç¨‹ï¼ˆMï¼‰
- æœåŠ¡æ—¶é—´ä¸ºæŒ‡æ•°åˆ†å¸ƒï¼ˆMï¼‰
- cä¸ªæœåŠ¡å™¨ï¼ˆcï¼‰

#### æ•°å­¦å…¬å¼1

**åˆ°è¾¾ç‡**: $\lambda$ (packets/second)
**æœåŠ¡ç‡**: $\mu$ (packets/second)
**æœåŠ¡å™¨æ•°é‡**: $c$
**åˆ©ç”¨ç‡**: $\rho = \frac{\lambda}{c\mu}$

**ç¨³æ€æ¦‚ç‡**:
$$
P_0 = \left[\sum_{n=0}^{c-1} \frac{(\lambda/\mu)^n}{n!} + \frac{(\lambda/\mu)^c}{c!(1-\rho)}\right]^{-1}
$$

$$
P_n = \begin{cases}
\frac{(\lambda/\mu)^n}{n!}P_0, & n \leq c \\
\frac{(\lambda/\mu)^n}{c!c^{n-c}}P_0, & n > c
\end{cases}
$$

**å¹³å‡é˜Ÿåˆ—é•¿åº¦**:
$$L_q = \frac{(\lambda/\mu)^c\rho}{c!(1-\rho)^2}P_0$$

**å¹³å‡ç­‰å¾…æ—¶é—´**:
$$W_q = \frac{L_q}{\lambda}$$

#### å®ç°1

```rust
// M/M/cé˜Ÿåˆ—æ¨¡å‹
pub struct MMcQueue {
    arrival_rate: f64,    // Î»
    service_rate: f64,    // Î¼
    servers: usize,       // c
    utilization: f64,     // Ï
}

impl MMcQueue {
    pub fn new(arrival_rate: f64, service_rate: f64, servers: usize) -> Result<Self, String> {
        if arrival_rate >= servers as f64 * service_rate {
            return Err("System must be stable (Î» < cÎ¼)".to_string());
        }

        let utilization = arrival_rate / (servers as f64 * service_rate);

        Ok(Self {
            arrival_rate,
            service_rate,
            servers,
            utilization,
        })
    }

    // è®¡ç®—P0
    fn calculate_p0(&self) -> f64 {
        let mut sum = 0.0;
        let lambda_mu = self.arrival_rate / self.service_rate;

        // è®¡ç®—å‰c-1é¡¹
        for n in 0..self.servers {
            sum += lambda_mu.powi(n as i32) / factorial(n);
        }

        // è®¡ç®—ç¬¬cé¡¹
        sum += lambda_mu.powi(self.servers as i32) /
               (factorial(self.servers) * (1.0 - self.utilization));

        1.0 / sum
    }

    // è®¡ç®—ç¨³æ€æ¦‚ç‡
    pub fn steady_state_probability(&self, n: usize) -> f64 {
        let p0 = self.calculate_p0();
        let lambda_mu = self.arrival_rate / self.service_rate;

        if n <= self.servers {
            lambda_mu.powi(n as i32) / factorial(n) * p0
        } else {
            lambda_mu.powi(n as i32) /
            (factorial(self.servers) * (self.servers as f64).powi((n - self.servers) as i32)) * p0
        }
    }

    // è®¡ç®—å¹³å‡é˜Ÿåˆ—é•¿åº¦
    pub fn average_queue_length(&self) -> f64 {
        let p0 = self.calculate_p0();
        let lambda_mu = self.arrival_rate / self.service_rate;

        lambda_mu.powi(self.servers as i32) * self.utilization /
        (factorial(self.servers) * (1.0 - self.utilization).powi(2)) * p0
    }

    // è®¡ç®—å¹³å‡ç­‰å¾…æ—¶é—´
    pub fn average_waiting_time(&self) -> f64 {
        self.average_queue_length() / self.arrival_rate
    }

    // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    pub fn average_response_time(&self) -> f64 {
        self.average_waiting_time() + 1.0 / self.service_rate
    }

    // è®¡ç®—Erlang-Cå…¬å¼
    pub fn erlang_c(&self) -> f64 {
        let p0 = self.calculate_p0();
        let lambda_mu = self.arrival_rate / self.service_rate;

        lambda_mu.powi(self.servers as i32) /
        (factorial(self.servers) * (1.0 - self.utilization)) * p0
    }
}

fn factorial(n: usize) -> f64 {
    (1..=n).fold(1.0, |acc, x| acc * x as f64)
}
```

### M/G/1é˜Ÿåˆ—æ¨¡å‹

#### æ¨¡å‹å®šä¹‰2

M/G/1é˜Ÿåˆ—æ¨¡å‹å‡è®¾ï¼š

- åˆ°è¾¾è¿‡ç¨‹ä¸ºæ³Šæ¾è¿‡ç¨‹ï¼ˆMï¼‰
- æœåŠ¡æ—¶é—´ä¸ºä¸€èˆ¬åˆ†å¸ƒï¼ˆGï¼‰
- å•æœåŠ¡å™¨ï¼ˆ1ï¼‰

#### Pollaczek-Khinchineå…¬å¼

**å¹³å‡é˜Ÿåˆ—é•¿åº¦**:
$$L_q = \frac{\lambda^2\sigma^2 + \rho^2}{2(1-\rho)}$$

å…¶ä¸­ï¼š

- $\lambda$: åˆ°è¾¾ç‡
- $\sigma^2$: æœåŠ¡æ—¶é—´æ–¹å·®
- $\rho$: åˆ©ç”¨ç‡

**å¹³å‡ç­‰å¾…æ—¶é—´**:
$$W_q = \frac{L_q}{\lambda}$$

#### å®ç°4

```rust
// M/G/1é˜Ÿåˆ—æ¨¡å‹
pub struct MG1Queue {
    arrival_rate: f64,    // Î»
    service_rate: f64,    // Î¼
    service_variance: f64, // ÏƒÂ²
    utilization: f64,     // Ï
}

impl MG1Queue {
    pub fn new(arrival_rate: f64, service_rate: f64, service_variance: f64) -> Result<Self, String> {
        if arrival_rate >= service_rate {
            return Err("System must be stable (Î» < Î¼)".to_string());
        }

        let utilization = arrival_rate / service_rate;

        Ok(Self {
            arrival_rate,
            service_rate,
            service_variance,
            utilization,
        })
    }

    // è®¡ç®—å¹³å‡é˜Ÿåˆ—é•¿åº¦ï¼ˆPollaczek-Khinchineå…¬å¼ï¼‰
    pub fn average_queue_length(&self) -> f64 {
        let lambda_squared = self.arrival_rate.powi(2);
        let rho_squared = self.utilization.powi(2);

        (lambda_squared * self.service_variance + rho_squared) /
        (2.0 * (1.0 - self.utilization))
    }

    // è®¡ç®—å¹³å‡ç­‰å¾…æ—¶é—´
    pub fn average_waiting_time(&self) -> f64 {
        self.average_queue_length() / self.arrival_rate
    }

    // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    pub fn average_response_time(&self) -> f64 {
        self.average_waiting_time() + 1.0 / self.service_rate
    }

    // è®¡ç®—æœåŠ¡æ—¶é—´å˜å¼‚ç³»æ•°
    pub fn coefficient_of_variation(&self) -> f64 {
        self.service_variance.sqrt() / (1.0 / self.service_rate)
    }

    // è®¡ç®—Pollaczek-Khinchineå…¬å¼çš„ç®€åŒ–å½¢å¼
    pub fn pollaczek_khinchine_simplified(&self) -> f64 {
        let cv_squared = self.coefficient_of_variation().powi(2);
        self.utilization.powi(2) * (1.0 + cv_squared) /
        (2.0 * (1.0 - self.utilization))
    }
}
```

### G/G/1é˜Ÿåˆ—æ¨¡å‹

#### æ¨¡å‹å®šä¹‰3

G/G/1é˜Ÿåˆ—æ¨¡å‹å‡è®¾ï¼š

- åˆ°è¾¾è¿‡ç¨‹ä¸ºä¸€èˆ¬åˆ†å¸ƒï¼ˆGï¼‰
- æœåŠ¡æ—¶é—´ä¸ºä¸€èˆ¬åˆ†å¸ƒï¼ˆGï¼‰
- å•æœåŠ¡å™¨ï¼ˆ1ï¼‰

#### Kingmanå…¬å¼

**å¹³å‡ç­‰å¾…æ—¶é—´**:
$$W_q \approx \frac{\rho}{1-\rho} \cdot \frac{C_a^2 + C_s^2}{2} \cdot \frac{1}{\mu}$$

å…¶ä¸­ï¼š

- $C_a^2$: åˆ°è¾¾è¿‡ç¨‹å˜å¼‚ç³»æ•°å¹³æ–¹
- $C_s^2$: æœåŠ¡è¿‡ç¨‹å˜å¼‚ç³»æ•°å¹³æ–¹

#### å®ç°2

```rust
// G/G/1é˜Ÿåˆ—æ¨¡å‹
pub struct GG1Queue {
    arrival_rate: f64,    // Î»
    service_rate: f64,    // Î¼
    arrival_variance: f64, // åˆ°è¾¾è¿‡ç¨‹æ–¹å·®
    service_variance: f64, // æœåŠ¡è¿‡ç¨‹æ–¹å·®
    utilization: f64,     // Ï
}

impl GG1Queue {
    pub fn new(
        arrival_rate: f64,
        service_rate: f64,
        arrival_variance: f64,
        service_variance: f64
    ) -> Result<Self, String> {
        if arrival_rate >= service_rate {
            return Err("System must be stable (Î» < Î¼)".to_string());
        }

        let utilization = arrival_rate / service_rate;

        Ok(Self {
            arrival_rate,
            service_rate,
            arrival_variance,
            service_variance,
            utilization,
        })
    }

    // è®¡ç®—åˆ°è¾¾è¿‡ç¨‹å˜å¼‚ç³»æ•°å¹³æ–¹
    pub fn arrival_coefficient_of_variation_squared(&self) -> f64 {
        let arrival_mean = 1.0 / self.arrival_rate;
        self.arrival_variance / arrival_mean.powi(2)
    }

    // è®¡ç®—æœåŠ¡è¿‡ç¨‹å˜å¼‚ç³»æ•°å¹³æ–¹
    pub fn service_coefficient_of_variation_squared(&self) -> f64 {
        let service_mean = 1.0 / self.service_rate;
        self.service_variance / service_mean.powi(2)
    }

    // è®¡ç®—å¹³å‡ç­‰å¾…æ—¶é—´ï¼ˆKingmanå…¬å¼ï¼‰
    pub fn average_waiting_time(&self) -> f64 {
        let ca_squared = self.arrival_coefficient_of_variation_squared();
        let cs_squared = self.service_coefficient_of_variation_squared();

        self.utilization / (1.0 - self.utilization) *
        (ca_squared + cs_squared) / 2.0 *
        (1.0 / self.service_rate)
    }

    // è®¡ç®—å¹³å‡é˜Ÿåˆ—é•¿åº¦
    pub fn average_queue_length(&self) -> f64 {
        self.average_waiting_time() * self.arrival_rate
    }

    // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    pub fn average_response_time(&self) -> f64 {
        self.average_waiting_time() + 1.0 / self.service_rate
    }

    // è®¡ç®—ç³»ç»Ÿç¨³å®šæ€§æŒ‡æ ‡
    pub fn stability_index(&self) -> f64 {
        let ca_squared = self.arrival_coefficient_of_variation_squared();
        let cs_squared = self.service_coefficient_of_variation_squared();

        self.utilization * (ca_squared + cs_squared) / 2.0
    }
}
```

## ğŸ”— ç½‘ç»œæ‹“æ‰‘æ¨¡å‹

### éšæœºå›¾æ¨¡å‹

#### ErdÅ‘s-RÃ©nyiæ¨¡å‹

**æ¨¡å‹å®šä¹‰**:

- $n$ä¸ªèŠ‚ç‚¹
- æ¯æ¡è¾¹ä»¥æ¦‚ç‡$p$ç‹¬ç«‹å­˜åœ¨
- æ€»è¾¹æ•°æœŸæœ›: $E[E] = \binom{n}{2}p$

**åº¦åˆ†å¸ƒ**:
$$P(k) = \binom{n-1}{k}p^k(1-p)^{n-1-k}$$

#### å®ç°3

```rust
// éšæœºå›¾æ¨¡å‹
pub struct RandomGraph {
    nodes: usize,
    edge_probability: f64,
    edges: Vec<(usize, usize)>,
}

impl RandomGraph {
    pub fn new(nodes: usize, edge_probability: f64) -> Self {
        Self {
            nodes,
            edge_probability,
            edges: Vec::new(),
        }
    }

    // ç”Ÿæˆéšæœºå›¾
    pub fn generate(&mut self) {
        self.edges.clear();

        for i in 0..self.nodes {
            for j in i+1..self.nodes {
                if rand::random::<f64>() < self.edge_probability {
                    self.edges.push((i, j));
                }
            }
        }
    }

    // è®¡ç®—å¹³å‡åº¦æ•°
    pub fn average_degree(&self) -> f64 {
        (2.0 * self.edges.len() as f64) / self.nodes as f64
    }

    // è®¡ç®—èšç±»ç³»æ•°
    pub fn clustering_coefficient(&self) -> f64 {
        let mut total_clustering = 0.0;
        let mut nodes_with_neighbors = 0;

        for node in 0..self.nodes {
            let neighbors = self.get_neighbors(node);
            if neighbors.len() >= 2 {
                let possible_edges = neighbors.len() * (neighbors.len() - 1) / 2;
                let actual_edges = self.count_edges_between_neighbors(&neighbors);

                if possible_edges > 0 {
                    total_clustering += actual_edges as f64 / possible_edges as f64;
                    nodes_with_neighbors += 1;
                }
            }
        }

        if nodes_with_neighbors > 0 {
            total_clustering / nodes_with_neighbors as f64
        } else {
            0.0
        }
    }

    // è®¡ç®—è·¯å¾„é•¿åº¦
    pub fn average_path_length(&self) -> f64 {
        let mut total_length = 0.0;
        let mut path_count = 0;

        for i in 0..self.nodes {
            for j in i+1..self.nodes {
                if let Some(length) = self.shortest_path_length(i, j) {
                    total_length += length as f64;
                    path_count += 1;
                }
            }
        }

        if path_count > 0 {
            total_length / path_count as f64
        } else {
            0.0
        }
    }

    // è·å–é‚»å±…èŠ‚ç‚¹
    fn get_neighbors(&self, node: usize) -> Vec<usize> {
        let mut neighbors = Vec::new();

        for &(u, v) in &self.edges {
            if u == node {
                neighbors.push(v);
            } else if v == node {
                neighbors.push(u);
            }
        }

        neighbors
    }

    // è®¡ç®—é‚»å±…é—´çš„è¾¹æ•°
    fn count_edges_between_neighbors(&self, neighbors: &[usize]) -> usize {
        let mut count = 0;

        for i in 0..neighbors.len() {
            for j in i+1..neighbors.len() {
                if self.has_edge(neighbors[i], neighbors[j]) {
                    count += 1;
                }
            }
        }

        count
    }

    // æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¾¹
    fn has_edge(&self, u: usize, v: usize) -> bool {
        self.edges.contains(&(u, v)) || self.edges.contains(&(v, u))
    }

    // è®¡ç®—æœ€çŸ­è·¯å¾„é•¿åº¦
    fn shortest_path_length(&self, start: usize, end: usize) -> Option<usize> {
        if start == end {
            return Some(0);
        }

        let mut visited = vec![false; self.nodes];
        let mut queue = std::collections::VecDeque::new();
        let mut distances = vec![0; self.nodes];

        queue.push_back(start);
        visited[start] = true;

        while let Some(current) = queue.pop_front() {
            let neighbors = self.get_neighbors(current);

            for neighbor in neighbors {
                if !visited[neighbor] {
                    visited[neighbor] = true;
                    distances[neighbor] = distances[current] + 1;

                    if neighbor == end {
                        return Some(distances[neighbor]);
                    }

                    queue.push_back(neighbor);
                }
            }
        }

        None
    }
}
```

### å°ä¸–ç•Œç½‘ç»œæ¨¡å‹

#### Watts-Strogatzæ¨¡å‹

**æ¨¡å‹å®šä¹‰**:

1. ä»è§„åˆ™ç¯å¼€å§‹ï¼Œæ¯ä¸ªèŠ‚ç‚¹è¿æ¥åˆ°$k$ä¸ªæœ€è¿‘é‚»å±…
2. ä»¥æ¦‚ç‡$p$é‡è¿æ¯æ¡è¾¹

**èšç±»ç³»æ•°**:
$$C(p) = C(0)(1-p)^3$$

**è·¯å¾„é•¿åº¦**:
$$L(p) \approx \frac{n}{2k}f(pn)$$

å…¶ä¸­$f(x)$æ˜¯é‡è¿å‚æ•°$x$çš„å‡½æ•°ã€‚

#### å®ç°6

```rust
// å°ä¸–ç•Œç½‘ç»œæ¨¡å‹
pub struct SmallWorldNetwork {
    nodes: usize,
    k: usize,
    rewire_probability: f64,
    edges: Vec<(usize, usize)>,
}

impl SmallWorldNetwork {
    pub fn new(nodes: usize, k: usize, rewire_probability: f64) -> Self {
        Self {
            nodes,
            k,
            rewire_probability,
            edges: Vec::new(),
        }
    }

    // ç”Ÿæˆå°ä¸–ç•Œç½‘ç»œ
    pub fn generate(&mut self) {
        self.edges.clear();

        // ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºè§„åˆ™ç¯
        for i in 0..self.nodes {
            for j in 1..=self.k/2 {
                let neighbor = (i + j) % self.nodes;
                self.edges.push((i, neighbor));
            }
        }

        // ç¬¬äºŒæ­¥ï¼šé‡è¿è¾¹
        let mut edges_to_rewire = Vec::new();

        for (i, &(u, v)) in self.edges.iter().enumerate() {
            if rand::random::<f64>() < self.rewire_probability {
                edges_to_rewire.push(i);
            }
        }

        for edge_index in edges_to_rewire {
            let (u, _) = self.edges[edge_index];

            // é€‰æ‹©æ–°çš„ç›®æ ‡èŠ‚ç‚¹
            let mut new_v = rand::random::<usize>() % self.nodes;
            while new_v == u || self.has_edge(u, new_v) {
                new_v = rand::random::<usize>() % self.nodes;
            }

            self.edges[edge_index] = (u, new_v);
        }
    }

    // è®¡ç®—èšç±»ç³»æ•°
    pub fn clustering_coefficient(&self) -> f64 {
        let mut total_clustering = 0.0;
        let mut nodes_with_neighbors = 0;

        for node in 0..self.nodes {
            let neighbors = self.get_neighbors(node);
            if neighbors.len() >= 2 {
                let possible_edges = neighbors.len() * (neighbors.len() - 1) / 2;
                let actual_edges = self.count_edges_between_neighbors(&neighbors);

                if possible_edges > 0 {
                    total_clustering += actual_edges as f64 / possible_edges as f64;
                    nodes_with_neighbors += 1;
                }
            }
        }

        if nodes_with_neighbors > 0 {
            total_clustering / nodes_with_neighbors as f64
        } else {
            0.0
        }
    }

    // è®¡ç®—ç†è®ºèšç±»ç³»æ•°
    pub fn theoretical_clustering_coefficient(&self) -> f64 {
        let c0 = 3.0 * (self.k - 1) as f64 / (2.0 * (2.0 * self.k - 1) as f64);
        c0 * (1.0 - self.rewire_probability).powi(3)
    }

    // è®¡ç®—å¹³å‡è·¯å¾„é•¿åº¦
    pub fn average_path_length(&self) -> f64 {
        let mut total_length = 0.0;
        let mut path_count = 0;

        for i in 0..self.nodes {
            for j in i+1..self.nodes {
                if let Some(length) = self.shortest_path_length(i, j) {
                    total_length += length as f64;
                    path_count += 1;
                }
            }
        }

        if path_count > 0 {
            total_length / path_count as f64
        } else {
            0.0
        }
    }

    // è®¡ç®—ç†è®ºè·¯å¾„é•¿åº¦
    pub fn theoretical_path_length(&self) -> f64 {
        if self.rewire_probability == 0.0 {
            self.nodes as f64 / (4.0 * self.k as f64)
        } else {
            let x = self.rewire_probability * self.nodes as f64;
            self.nodes as f64 / (2.0 * self.k as f64) * self.function_f(x)
        }
    }

    // è¾…åŠ©å‡½æ•°f(x)
    fn function_f(&self, x: f64) -> f64 {
        if x < 1.0 {
            1.0
        } else if x < 10.0 {
            1.0 / (4.0 * x) * (1.0 - x.exp())
        } else {
            1.0 / (4.0 * x)
        }
    }

    // è·å–é‚»å±…èŠ‚ç‚¹
    fn get_neighbors(&self, node: usize) -> Vec<usize> {
        let mut neighbors = Vec::new();

        for &(u, v) in &self.edges {
            if u == node {
                neighbors.push(v);
            } else if v == node {
                neighbors.push(u);
            }
        }

        neighbors
    }

    // è®¡ç®—é‚»å±…é—´çš„è¾¹æ•°
    fn count_edges_between_neighbors(&self, neighbors: &[usize]) -> usize {
        let mut count = 0;

        for i in 0..neighbors.len() {
            for j in i+1..neighbors.len() {
                if self.has_edge(neighbors[i], neighbors[j]) {
                    count += 1;
                }
            }
        }

        count
    }

    // æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¾¹
    fn has_edge(&self, u: usize, v: usize) -> bool {
        self.edges.contains(&(u, v)) || self.edges.contains(&(v, u))
    }

    // è®¡ç®—æœ€çŸ­è·¯å¾„é•¿åº¦
    fn shortest_path_length(&self, start: usize, end: usize) -> Option<usize> {
        if start == end {
            return Some(0);
        }

        let mut visited = vec![false; self.nodes];
        let mut queue = std::collections::VecDeque::new();
        let mut distances = vec![0; self.nodes];

        queue.push_back(start);
        visited[start] = true;

        while let Some(current) = queue.pop_front() {
            let neighbors = self.get_neighbors(current);

            for neighbor in neighbors {
                if !visited[neighbor] {
                    visited[neighbor] = true;
                    distances[neighbor] = distances[current] + 1;

                    if neighbor == end {
                        return Some(distances[neighbor]);
                    }

                    queue.push_back(neighbor);
                }
            }
        }

        None
    }
}
```

### æ— æ ‡åº¦ç½‘ç»œæ¨¡å‹

#### BarabÃ¡si-Albertæ¨¡å‹

**æ¨¡å‹å®šä¹‰**:

1. ä»$m_0$ä¸ªèŠ‚ç‚¹å¼€å§‹
2. æ¯æ¬¡æ·»åŠ ä¸€ä¸ªæ–°èŠ‚ç‚¹ï¼Œè¿æ¥åˆ°$m$ä¸ªç°æœ‰èŠ‚ç‚¹
3. è¿æ¥æ¦‚ç‡ä¸èŠ‚ç‚¹åº¦æ•°æˆæ­£æ¯”

**åº¦åˆ†å¸ƒ**:
$$P(k) \sim k^{-3}$$

#### å®ç°5

```rust
// æ— æ ‡åº¦ç½‘ç»œæ¨¡å‹
pub struct ScaleFreeNetwork {
    nodes: usize,
    m0: usize,
    m: usize,
    edges: Vec<(usize, usize)>,
    degrees: Vec<usize>,
}

impl ScaleFreeNetwork {
    pub fn new(nodes: usize, m0: usize, m: usize) -> Result<Self, String> {
        if m0 >= nodes || m > m0 {
            return Err("Invalid parameters".to_string());
        }

        Ok(Self {
            nodes,
            m0,
            m,
            edges: Vec::new(),
            degrees: vec![0; nodes],
        })
    }

    // ç”Ÿæˆæ— æ ‡åº¦ç½‘ç»œ
    pub fn generate(&mut self) {
        self.edges.clear();
        self.degrees.fill(0);

        // ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºåˆå§‹å®Œå…¨å›¾
        for i in 0..self.m0 {
            for j in i+1..self.m0 {
                self.edges.push((i, j));
                self.degrees[i] += 1;
                self.degrees[j] += 1;
            }
        }

        // ç¬¬äºŒæ­¥ï¼šæ·»åŠ æ–°èŠ‚ç‚¹
        for new_node in self.m0..self.nodes {
            let mut connections = 0;
            let mut attempts = 0;
            let max_attempts = 1000;

            while connections < self.m && attempts < max_attempts {
                let target = self.select_target_node(new_node);
                if target.is_some() {
                    let target = target.unwrap();
                    self.edges.push((new_node, target));
                    self.degrees[new_node] += 1;
                    self.degrees[target] += 1;
                    connections += 1;
                }
                attempts += 1;
            }
        }
    }

    // é€‰æ‹©ç›®æ ‡èŠ‚ç‚¹ï¼ˆä¼˜å…ˆè¿æ¥ï¼‰
    fn select_target_node(&self, new_node: usize) -> Option<usize> {
        let total_degree: usize = self.degrees.iter().sum();
        if total_degree == 0 {
            return None;
        }

        let random = rand::random::<f64>() * total_degree as f64;
        let mut cumulative = 0.0;

        for (node, &degree) in self.degrees.iter().enumerate() {
            cumulative += degree as f64;
            if cumulative >= random {
                return Some(node);
            }
        }

        None
    }

    // è®¡ç®—åº¦åˆ†å¸ƒ
    pub fn degree_distribution(&self) -> HashMap<usize, usize> {
        let mut distribution = HashMap::new();

        for &degree in &self.degrees {
            *distribution.entry(degree).or_insert(0) += 1;
        }

        distribution
    }

    // è®¡ç®—åº¦åˆ†å¸ƒçš„å¹‚å¾‹æŒ‡æ•°
    pub fn power_law_exponent(&self) -> f64 {
        let distribution = self.degree_distribution();
        let mut log_degrees = Vec::new();
        let mut log_counts = Vec::new();

        for (&degree, &count) in &distribution {
            if degree > 0 && count > 0 {
                log_degrees.push(degree as f64);
                log_counts.push(count as f64);
            }
        }

        if log_degrees.len() < 2 {
            return 0.0;
        }

        // ä½¿ç”¨æœ€å°äºŒä¹˜æ³•æ‹Ÿåˆå¹‚å¾‹
        let n = log_degrees.len() as f64;
        let sum_log_degree: f64 = log_degrees.iter().sum();
        let sum_log_count: f64 = log_counts.iter().sum();
        let sum_log_degree_squared: f64 = log_degrees.iter().map(|x| x.powi(2)).sum();
        let sum_log_degree_log_count: f64 = log_degrees.iter()
            .zip(log_counts.iter())
            .map(|(x, y)| x * y)
            .sum();

        let slope = (n * sum_log_degree_log_count - sum_log_degree * sum_log_count) /
                   (n * sum_log_degree_squared - sum_log_degree.powi(2));

        -slope
    }

    // è®¡ç®—å¹³å‡åº¦æ•°
    pub fn average_degree(&self) -> f64 {
        self.degrees.iter().sum::<usize>() as f64 / self.nodes as f64
    }

    // è®¡ç®—æœ€å¤§åº¦æ•°
    pub fn max_degree(&self) -> usize {
        self.degrees.iter().max().copied().unwrap_or(0)
    }

    // è®¡ç®—åº¦ç›¸å…³æ€§
    pub fn degree_correlation(&self) -> f64 {
        let mut numerator = 0.0;
        let mut denominator = 0.0;

        for &(u, v) in &self.edges {
            let degree_u = self.degrees[u] as f64;
            let degree_v = self.degrees[v] as f64;

            numerator += degree_u * degree_v;
            denominator += degree_u.powi(2) + degree_v.powi(2);
        }

        if denominator > 0.0 {
            2.0 * numerator / denominator
        } else {
            0.0
        }
    }
}
```

### å±‚æ¬¡ç½‘ç»œæ¨¡å‹

#### å±‚æ¬¡ç½‘ç»œ

**æ¨¡å‹å®šä¹‰**:

- ç½‘ç»œå…·æœ‰å±‚æ¬¡ç»“æ„
- ä¸åŒå±‚æ¬¡æœ‰ä¸åŒçš„è¿æ¥æ¨¡å¼
- ä¸Šå±‚èŠ‚ç‚¹è¿æ¥ä¸‹å±‚èŠ‚ç‚¹

#### å®ç°7

```rust
// å±‚æ¬¡ç½‘ç»œæ¨¡å‹
pub struct HierarchicalNetwork {
    levels: usize,
    nodes_per_level: Vec<usize>,
    edges: Vec<(usize, usize)>,
    level_assignments: Vec<usize>,
}

impl HierarchicalNetwork {
    pub fn new(levels: usize, nodes_per_level: Vec<usize>) -> Result<Self, String> {
        if levels != nodes_per_level.len() {
            return Err("Levels and nodes_per_level must have same length".to_string());
        }

        Ok(Self {
            levels,
            nodes_per_level,
            edges: Vec::new(),
            level_assignments: Vec::new(),
        })
    }

    // ç”Ÿæˆå±‚æ¬¡ç½‘ç»œ
    pub fn generate(&mut self) {
        self.edges.clear();
        self.level_assignments.clear();

        let total_nodes: usize = self.nodes_per_level.iter().sum();
        self.level_assignments.resize(total_nodes, 0);

        // åˆ†é…èŠ‚ç‚¹åˆ°å±‚æ¬¡
        let mut node_id = 0;
        for (level, &count) in self.nodes_per_level.iter().enumerate() {
            for _ in 0..count {
                self.level_assignments[node_id] = level;
                node_id += 1;
            }
        }

        // ç”Ÿæˆå±‚æ¬¡å†…è¿æ¥
        self.generate_intra_level_connections();

        // ç”Ÿæˆå±‚æ¬¡é—´è¿æ¥
        self.generate_inter_level_connections();
    }

    // ç”Ÿæˆå±‚æ¬¡å†…è¿æ¥
    fn generate_intra_level_connections(&mut self) {
        let mut node_id = 0;

        for (level, &count) in self.nodes_per_level.iter().enumerate() {
            if count > 1 {
                // åœ¨å±‚æ¬¡å†…åˆ›å»ºè¿æ¥
                for i in 0..count {
                    for j in i+1..count {
                        if rand::random::<f64>() < 0.3 { // 30%æ¦‚ç‡è¿æ¥
                            self.edges.push((node_id + i, node_id + j));
                        }
                    }
                }
            }
            node_id += count;
        }
    }

    // ç”Ÿæˆå±‚æ¬¡é—´è¿æ¥
    fn generate_inter_level_connections(&mut self) {
        let mut node_id = 0;

        for (level, &count) in self.nodes_per_level.iter().enumerate() {
            if level > 0 {
                // è¿æ¥åˆ°ä¸Šå±‚
                let upper_level_start = node_id - self.nodes_per_level[level - 1];
                let upper_level_count = self.nodes_per_level[level - 1];

                for i in 0..count {
                    let current_node = node_id + i;

                    // æ¯ä¸ªèŠ‚ç‚¹è¿æ¥åˆ°ä¸Šå±‚çš„ä¸€äº›èŠ‚ç‚¹
                    let connections = (upper_level_count / 2).max(1);
                    for _ in 0..connections {
                        let target = upper_level_start + rand::random::<usize>() % upper_level_count;
                        self.edges.push((current_node, target));
                    }
                }
            }

            node_id += count;
        }
    }

    // è®¡ç®—å±‚æ¬¡å†…èšç±»ç³»æ•°
    pub fn intra_level_clustering_coefficient(&self) -> Vec<f64> {
        let mut coefficients = Vec::new();
        let mut node_id = 0;

        for (level, &count) in self.nodes_per_level.iter().enumerate() {
            let mut total_clustering = 0.0;
            let mut nodes_with_neighbors = 0;

            for i in 0..count {
                let current_node = node_id + i;
                let neighbors = self.get_neighbors_in_level(current_node, level);

                if neighbors.len() >= 2 {
                    let possible_edges = neighbors.len() * (neighbors.len() - 1) / 2;
                    let actual_edges = self.count_edges_between_neighbors(&neighbors);

                    if possible_edges > 0 {
                        total_clustering += actual_edges as f64 / possible_edges as f64;
                        nodes_with_neighbors += 1;
                    }
                }
            }

            if nodes_with_neighbors > 0 {
                coefficients.push(total_clustering / nodes_with_neighbors as f64);
            } else {
                coefficients.push(0.0);
            }

            node_id += count;
        }

        coefficients
    }

    // è®¡ç®—å±‚æ¬¡é—´è¿æ¥å¯†åº¦
    pub fn inter_level_connection_density(&self) -> Vec<Vec<f64>> {
        let mut densities = vec![vec![0.0; self.levels]; self.levels];

        for &(u, v) in &self.edges {
            let level_u = self.level_assignments[u];
            let level_v = self.level_assignments[v];

            if level_u != level_v {
                densities[level_u][level_v] += 1.0;
                densities[level_v][level_u] += 1.0;
            }
        }

        // å½’ä¸€åŒ–
        for i in 0..self.levels {
            for j in 0..self.levels {
                if i != j {
                    let total_possible = self.nodes_per_level[i] * self.nodes_per_level[j];
                    densities[i][j] /= total_possible as f64;
                }
            }
        }

        densities
    }

    // è·å–å±‚æ¬¡å†…çš„é‚»å±…
    fn get_neighbors_in_level(&self, node: usize, level: usize) -> Vec<usize> {
        let mut neighbors = Vec::new();

        for &(u, v) in &self.edges {
            if u == node && self.level_assignments[v] == level {
                neighbors.push(v);
            } else if v == node && self.level_assignments[u] == level {
                neighbors.push(u);
            }
        }

        neighbors
    }

    // è®¡ç®—é‚»å±…é—´çš„è¾¹æ•°
    fn count_edges_between_neighbors(&self, neighbors: &[usize]) -> usize {
        let mut count = 0;

        for i in 0..neighbors.len() {
            for j in i+1..neighbors.len() {
                if self.has_edge(neighbors[i], neighbors[j]) {
                    count += 1;
                }
            }
        }

        count
    }

    // æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¾¹
    fn has_edge(&self, u: usize, v: usize) -> bool {
        self.edges.contains(&(u, v)) || self.edges.contains(&(v, u))
    }
}
```

## âš¡ å»¶è¿Ÿåˆ†ææ¨¡å‹

### ä¼ æ’­å»¶è¿Ÿæ¨¡å‹

#### ä¼ æ’­å»¶è¿Ÿ

**å…¬å¼**:
$$D_{prop} = \frac{d}{c}$$

å…¶ä¸­ï¼š

- $d$: è·ç¦»
- $c$: ä¼ æ’­é€Ÿåº¦ï¼ˆå…‰é€Ÿï¼‰

#### å®ç°8

```rust
// ä¼ æ’­å»¶è¿Ÿæ¨¡å‹
pub struct PropagationDelayModel {
    distance: f64,        // è·ç¦» (km)
    propagation_speed: f64, // ä¼ æ’­é€Ÿåº¦ (km/s)
}

impl PropagationDelayModel {
    pub fn new(distance: f64) -> Self {
        Self {
            distance,
            propagation_speed: 299792.458, // å…‰é€Ÿ (km/s)
        }
    }

    // è®¡ç®—ä¼ æ’­å»¶è¿Ÿ
    pub fn calculate_delay(&self) -> f64 {
        self.distance / self.propagation_speed
    }

    // è®¡ç®—å¾€è¿”ä¼ æ’­å»¶è¿Ÿ
    pub fn calculate_round_trip_delay(&self) -> f64 {
        2.0 * self.calculate_delay()
    }

    // è®¡ç®—ä¸åŒä»‹è´¨çš„ä¼ æ’­å»¶è¿Ÿ
    pub fn calculate_delay_in_medium(&self, medium: PropagationMedium) -> f64 {
        let speed = match medium {
            PropagationMedium::Vacuum => 299792.458,
            PropagationMedium::Air => 299702.547,
            PropagationMedium::Water => 225000.0,
            PropagationMedium::Glass => 200000.0,
            PropagationMedium::Copper => 200000.0,
        };

        self.distance / speed
    }

    // è®¡ç®—å»¶è¿Ÿå˜åŒ–ï¼ˆç”±äºæ¸©åº¦ã€æ¹¿åº¦ç­‰ï¼‰
    pub fn calculate_delay_variation(&self, temperature: f64, humidity: f64) -> f64 {
        let base_delay = self.calculate_delay();
        let temperature_factor = 1.0 + (temperature - 20.0) * 0.0001;
        let humidity_factor = 1.0 + humidity * 0.00001;

        base_delay * temperature_factor * humidity_factor
    }
}

# [derive(Debug, Clone)]
pub enum PropagationMedium {
    Vacuum,
    Air,
    Water,
    Glass,
    Copper,
}
```

### ä¼ è¾“å»¶è¿Ÿæ¨¡å‹

#### ä¼ è¾“å»¶è¿Ÿ

**å…¬å¼**:
$$D_{trans} = \frac{L}{R}$$

å…¶ä¸­ï¼š

- $L$: æ•°æ®åŒ…é•¿åº¦ (bits)
- $R$: ä¼ è¾“é€Ÿç‡ (bps)

#### å®ç°9

```rust
// ä¼ è¾“å»¶è¿Ÿæ¨¡å‹
pub struct TransmissionDelayModel {
    packet_length: usize,  // æ•°æ®åŒ…é•¿åº¦ (bits)
    transmission_rate: f64, // ä¼ è¾“é€Ÿç‡ (bps)
}

impl TransmissionDelayModel {
    pub fn new(packet_length: usize, transmission_rate: f64) -> Self {
        Self {
            packet_length,
            transmission_rate,
        }
    }

    // è®¡ç®—ä¼ è¾“å»¶è¿Ÿ
    pub fn calculate_delay(&self) -> f64 {
        self.packet_length as f64 / self.transmission_rate
    }

    // è®¡ç®—ä¸åŒæ•°æ®åŒ…å¤§å°çš„ä¼ è¾“å»¶è¿Ÿ
    pub fn calculate_delay_for_packet(&self, packet_length: usize) -> f64 {
        packet_length as f64 / self.transmission_rate
    }

    // è®¡ç®—æ‰¹é‡ä¼ è¾“å»¶è¿Ÿ
    pub fn calculate_batch_delay(&self, packet_count: usize) -> f64 {
        (self.packet_length * packet_count) as f64 / self.transmission_rate
    }

    // è®¡ç®—æœ‰æ•ˆä¼ è¾“é€Ÿç‡ï¼ˆè€ƒè™‘å¼€é”€ï¼‰
    pub fn calculate_effective_rate(&self, overhead_percentage: f64) -> f64 {
        self.transmission_rate * (1.0 - overhead_percentage / 100.0)
    }

    // è®¡ç®—ä¼ è¾“æ•ˆç‡
    pub fn calculate_efficiency(&self, useful_data: usize) -> f64 {
        useful_data as f64 / self.packet_length as f64
    }
}
```

### å¤„ç†å»¶è¿Ÿæ¨¡å‹

#### å¤„ç†å»¶è¿Ÿ

**å…¬å¼**:
$$D_{proc} = \frac{C}{f}$$

å…¶ä¸­ï¼š

- $C$: å¤„ç†å‘¨æœŸæ•°
- $f$: å¤„ç†å™¨é¢‘ç‡

#### å®ç°10

```rust
// å¤„ç†å»¶è¿Ÿæ¨¡å‹
pub struct ProcessingDelayModel {
    processing_cycles: u64, // å¤„ç†å‘¨æœŸæ•°
    processor_frequency: f64, // å¤„ç†å™¨é¢‘ç‡ (Hz)
}

impl ProcessingDelayModel {
    pub fn new(processing_cycles: u64, processor_frequency: f64) -> Self {
        Self {
            processing_cycles,
            processor_frequency,
        }
    }

    // è®¡ç®—å¤„ç†å»¶è¿Ÿ
    pub fn calculate_delay(&self) -> f64 {
        self.processing_cycles as f64 / self.processor_frequency
    }

    // è®¡ç®—ä¸åŒå¤„ç†å™¨çš„å»¶è¿Ÿ
    pub fn calculate_delay_for_processor(&self, frequency: f64) -> f64 {
        self.processing_cycles as f64 / frequency
    }

    // è®¡ç®—å¹¶è¡Œå¤„ç†å»¶è¿Ÿ
    pub fn calculate_parallel_delay(&self, cores: usize) -> f64 {
        self.calculate_delay() / cores as f64
    }

    // è®¡ç®—ç¼“å­˜å‘½ä¸­å»¶è¿Ÿ
    pub fn calculate_cache_hit_delay(&self, cache_hit_rate: f64) -> f64 {
        let cache_hit_delay = self.calculate_delay() * 0.1; // ç¼“å­˜å‘½ä¸­å»¶è¿Ÿ
        let cache_miss_delay = self.calculate_delay(); // ç¼“å­˜æœªå‘½ä¸­å»¶è¿Ÿ

        cache_hit_rate * cache_hit_delay + (1.0 - cache_hit_rate) * cache_miss_delay
    }

    // è®¡ç®—æµæ°´çº¿å¤„ç†å»¶è¿Ÿ
    pub fn calculate_pipeline_delay(&self, pipeline_stages: usize) -> f64 {
        self.processing_cycles as f64 / (self.processor_frequency * pipeline_stages as f64)
    }
}
```

### æ’é˜Ÿå»¶è¿Ÿæ¨¡å‹

#### æ’é˜Ÿå»¶è¿Ÿ

**å…¬å¼**:
$$D_{queue} = \frac{L_q}{\lambda}$$

å…¶ä¸­ï¼š

- $L_q$: å¹³å‡é˜Ÿåˆ—é•¿åº¦
- $\lambda$: åˆ°è¾¾ç‡

#### å®ç°11

```rust
// æ’é˜Ÿå»¶è¿Ÿæ¨¡å‹
pub struct QueuingDelayModel {
    queue_length: f64,    // å¹³å‡é˜Ÿåˆ—é•¿åº¦
    arrival_rate: f64,    // åˆ°è¾¾ç‡
}

impl QueuingDelayModel {
    pub fn new(queue_length: f64, arrival_rate: f64) -> Self {
        Self {
            queue_length,
            arrival_rate,
        }
    }

    // è®¡ç®—æ’é˜Ÿå»¶è¿Ÿ
    pub fn calculate_delay(&self) -> f64 {
        self.queue_length / self.arrival_rate
    }

    // è®¡ç®—ä¸åŒé˜Ÿåˆ—é•¿åº¦çš„å»¶è¿Ÿ
    pub fn calculate_delay_for_queue_length(&self, queue_length: f64) -> f64 {
        queue_length / self.arrival_rate
    }

    // è®¡ç®—ä¼˜å…ˆçº§é˜Ÿåˆ—å»¶è¿Ÿ
    pub fn calculate_priority_queue_delay(&self, priority_levels: &[f64]) -> Vec<f64> {
        priority_levels.iter()
            .map(|&priority| self.calculate_delay() * priority)
            .collect()
    }

    // è®¡ç®—åŠ æƒå…¬å¹³é˜Ÿåˆ—å»¶è¿Ÿ
    pub fn calculate_wfq_delay(&self, weights: &[f64]) -> Vec<f64> {
        let total_weight: f64 = weights.iter().sum();

        weights.iter()
            .map(|&weight| self.calculate_delay() * total_weight / weight)
            .collect()
    }

    // è®¡ç®—éšæœºæ—©æœŸæ£€æµ‹å»¶è¿Ÿ
    pub fn calculate_red_delay(&self, drop_probability: f64) -> f64 {
        self.calculate_delay() * (1.0 - drop_probability)
    }
}
```

## ğŸ“ˆ ååé‡æ¨¡å‹

### TCPååé‡æ¨¡å‹

#### TCPååé‡

**å…¬å¼**:
$$Throughput = \frac{MSS \times 1.22}{RTT \times \sqrt{p}}$$

å…¶ä¸­ï¼š

- $MSS$: æœ€å¤§æ®µå¤§å°
- $RTT$: å¾€è¿”æ—¶é—´
- $p$: ä¸¢åŒ…ç‡

#### å®ç°12

```rust
// TCPååé‡æ¨¡å‹
pub struct TcpThroughputModel {
    mss: usize,           // æœ€å¤§æ®µå¤§å° (bytes)
    rtt: f64,             // å¾€è¿”æ—¶é—´ (seconds)
    packet_loss_rate: f64, // ä¸¢åŒ…ç‡
    window_size: usize,   // çª—å£å¤§å° (bytes)
    bandwidth: f64,       // å¸¦å®½ (bps)
}

impl TcpThroughputModel {
    pub fn new(mss: usize, rtt: f64, packet_loss_rate: f64) -> Self {
        Self {
            mss,
            rtt,
            packet_loss_rate,
            window_size: 65536, // é»˜è®¤çª—å£å¤§å°
            bandwidth: 1e9,     // é»˜è®¤å¸¦å®½ 1Gbps
        }
    }

    // è®¡ç®—TCPååé‡ï¼ˆç®€åŒ–æ¨¡å‹ï¼‰
    pub fn calculate_throughput(&self) -> f64 {
        if self.packet_loss_rate <= 0.0 {
            return 0.0;
        }

        let mss_bits = (self.mss * 8) as f64;
        mss_bits * 1.22 / (self.rtt * self.packet_loss_rate.sqrt())
    }

    // è®¡ç®—çª—å£é™åˆ¶çš„ååé‡
    pub fn calculate_window_limited_throughput(&self) -> f64 {
        (self.window_size * 8) as f64 / self.rtt
    }

    // è®¡ç®—å¸¦å®½é™åˆ¶çš„ååé‡
    pub fn calculate_bandwidth_limited_throughput(&self) -> f64 {
        self.bandwidth
    }

    // è®¡ç®—å®é™…ååé‡ï¼ˆè€ƒè™‘æ‰€æœ‰é™åˆ¶ï¼‰
    pub fn calculate_actual_throughput(&self) -> f64 {
        let tcp_throughput = self.calculate_throughput();
        let window_limited = self.calculate_window_limited_throughput();
        let bandwidth_limited = self.calculate_bandwidth_limited_throughput();

        tcp_throughput.min(window_limited).min(bandwidth_limited)
    }

    // è®¡ç®—ä¸åŒRTTçš„ååé‡
    pub fn calculate_throughput_for_rtt(&self, rtt: f64) -> f64 {
        let mss_bits = (self.mss * 8) as f64;
        mss_bits * 1.22 / (rtt * self.packet_loss_rate.sqrt())
    }

    // è®¡ç®—ä¸åŒä¸¢åŒ…ç‡çš„ååé‡
    pub fn calculate_throughput_for_loss_rate(&self, loss_rate: f64) -> f64 {
        if loss_rate <= 0.0 {
            return 0.0;
        }

        let mss_bits = (self.mss * 8) as f64;
        mss_bits * 1.22 / (self.rtt * loss_rate.sqrt())
    }

    // è®¡ç®—TCP Renoååé‡
    pub fn calculate_reno_throughput(&self) -> f64 {
        let mss_bits = (self.mss * 8) as f64;
        mss_bits * 1.22 / (self.rtt * self.packet_loss_rate.sqrt())
    }

    // è®¡ç®—TCP Vegasååé‡
    pub fn calculate_vegas_throughput(&self) -> f64 {
        let mss_bits = (self.mss * 8) as f64;
        mss_bits * 1.0 / (self.rtt * self.packet_loss_rate.sqrt())
    }

    // è®¡ç®—TCP CUBICååé‡
    pub fn calculate_cubic_throughput(&self) -> f64 {
        let mss_bits = (self.mss * 8) as f64;
        mss_bits * 1.0 / (self.rtt * self.packet_loss_rate.sqrt())
    }
}
```

### UDPååé‡æ¨¡å‹

#### UDPååé‡

**å…¬å¼**:
$$Throughput = \frac{Data\_Rate}{1 + Overhead\_Ratio}$$

#### å®ç°13

```rust
// UDPååé‡æ¨¡å‹
pub struct UdpThroughputModel {
    data_rate: f64,        // æ•°æ®é€Ÿç‡ (bps)
    overhead_ratio: f64,   // å¼€é”€æ¯”ä¾‹
    packet_size: usize,    // æ•°æ®åŒ…å¤§å° (bytes)
    header_size: usize,    // å¤´éƒ¨å¤§å° (bytes)
}

impl UdpThroughputModel {
    pub fn new(data_rate: f64, packet_size: usize, header_size: usize) -> Self {
        let overhead_ratio = header_size as f64 / packet_size as f64;

        Self {
            data_rate,
            overhead_ratio,
            packet_size,
            header_size,
        }
    }

    // è®¡ç®—UDPååé‡
    pub fn calculate_throughput(&self) -> f64 {
        self.data_rate / (1.0 + self.overhead_ratio)
    }

    // è®¡ç®—æœ‰æ•ˆæ•°æ®ååé‡
    pub fn calculate_effective_throughput(&self) -> f64 {
        let total_size = self.packet_size + self.header_size;
        let data_ratio = self.packet_size as f64 / total_size as f64;

        self.calculate_throughput() * data_ratio
    }

    // è®¡ç®—ä¸åŒæ•°æ®åŒ…å¤§å°çš„ååé‡
    pub fn calculate_throughput_for_packet_size(&self, packet_size: usize) -> f64 {
        let overhead_ratio = self.header_size as f64 / packet_size as f64;
        self.data_rate / (1.0 + overhead_ratio)
    }

    // è®¡ç®—æœ€ä¼˜æ•°æ®åŒ…å¤§å°
    pub fn calculate_optimal_packet_size(&self) -> usize {
        // ç®€åŒ–è®¡ç®—ï¼šå‡è®¾å¼€é”€å›ºå®š
        self.packet_size
    }

    // è®¡ç®—UDP over TCPååé‡
    pub fn calculate_udp_over_tcp_throughput(&self, tcp_overhead: f64) -> f64 {
        self.calculate_throughput() * (1.0 - tcp_overhead)
    }
}
```

### HTTPååé‡æ¨¡å‹

#### HTTPååé‡

**å…¬å¼**:
$$Throughput = \frac{Response\_Size}{Response\_Time}$$

#### å®ç°14

```rust
// HTTPååé‡æ¨¡å‹
pub struct HttpThroughputModel {
    response_size: usize,  // å“åº”å¤§å° (bytes)
    response_time: f64,    // å“åº”æ—¶é—´ (seconds)
    connection_count: usize, // è¿æ¥æ•°
    concurrent_requests: usize, // å¹¶å‘è¯·æ±‚æ•°
}

impl HttpThroughputModel {
    pub fn new(response_size: usize, response_time: f64) -> Self {
        Self {
            response_size,
            response_time,
            connection_count: 1,
            concurrent_requests: 1,
        }
    }

    // è®¡ç®—HTTPååé‡
    pub fn calculate_throughput(&self) -> f64 {
        (self.response_size * 8) as f64 / self.response_time
    }

    // è®¡ç®—å¹¶å‘ååé‡
    pub fn calculate_concurrent_throughput(&self) -> f64 {
        self.calculate_throughput() * self.concurrent_requests as f64
    }

    // è®¡ç®—è¿æ¥æ± ååé‡
    pub fn calculate_connection_pool_throughput(&self) -> f64 {
        self.calculate_throughput() * self.connection_count as f64
    }

    // è®¡ç®—HTTP/2å¤šè·¯å¤ç”¨ååé‡
    pub fn calculate_http2_throughput(&self, multiplexing_factor: f64) -> f64 {
        self.calculate_throughput() * multiplexing_factor
    }

    // è®¡ç®—å‹ç¼©åçš„ååé‡
    pub fn calculate_compressed_throughput(&self, compression_ratio: f64) -> f64 {
        self.calculate_throughput() / compression_ratio
    }

    // è®¡ç®—ç¼“å­˜å‘½ä¸­ååé‡
    pub fn calculate_cached_throughput(&self, cache_hit_rate: f64) -> f64 {
        let cached_response_time = self.response_time * 0.1; // ç¼“å­˜å“åº”æ—¶é—´
        let cached_throughput = (self.response_size * 8) as f64 / cached_response_time;

        cache_hit_rate * cached_throughput + (1.0 - cache_hit_rate) * self.calculate_throughput()
    }
}
```

### WebSocketååé‡æ¨¡å‹

#### WebSocketååé‡

**å…¬å¼**:
$$Throughput = \frac{Message\_Size}{Transmission\_Time}$$

#### å®ç°15

```rust
// WebSocketååé‡æ¨¡å‹
pub struct WebSocketThroughputModel {
    message_size: usize,   // æ¶ˆæ¯å¤§å° (bytes)
    transmission_time: f64, // ä¼ è¾“æ—¶é—´ (seconds)
    frame_overhead: usize,  // å¸§å¼€é”€ (bytes)
    connection_count: usize, // è¿æ¥æ•°
}

impl WebSocketThroughputModel {
    pub fn new(message_size: usize, transmission_time: f64) -> Self {
        Self {
            message_size,
            transmission_time,
            frame_overhead: 2, // æœ€å°å¸§å¼€é”€
            connection_count: 1,
        }
    }

    // è®¡ç®—WebSocketååé‡
    pub fn calculate_throughput(&self) -> f64 {
        (self.message_size * 8) as f64 / self.transmission_time
    }

    // è®¡ç®—æœ‰æ•ˆååé‡ï¼ˆè€ƒè™‘å¸§å¼€é”€ï¼‰
    pub fn calculate_effective_throughput(&self) -> f64 {
        let total_size = self.message_size + self.frame_overhead;
        let data_ratio = self.message_size as f64 / total_size as f64;

        self.calculate_throughput() * data_ratio
    }

    // è®¡ç®—å¤šè¿æ¥ååé‡
    pub fn calculate_multi_connection_throughput(&self) -> f64 {
        self.calculate_throughput() * self.connection_count as f64
    }

    // è®¡ç®—ä¸åŒæ¶ˆæ¯å¤§å°çš„ååé‡
    pub fn calculate_throughput_for_message_size(&self, message_size: usize) -> f64 {
        (message_size * 8) as f64 / self.transmission_time
    }

    // è®¡ç®—äºŒè¿›åˆ¶æ¶ˆæ¯ååé‡
    pub fn calculate_binary_throughput(&self) -> f64 {
        self.calculate_effective_throughput()
    }

    // è®¡ç®—æ–‡æœ¬æ¶ˆæ¯ååé‡
    pub fn calculate_text_throughput(&self) -> f64 {
        // æ–‡æœ¬æ¶ˆæ¯å¯èƒ½æœ‰ç¼–ç å¼€é”€
        self.calculate_effective_throughput() * 0.9
    }
}
```

## ğŸ”’ å¯é æ€§æ¨¡å‹

### æ•…éšœæ¨¡å‹

#### æ•…éšœç‡æ¨¡å‹

**å…¬å¼**:
$$\lambda(t) = \lambda_0 e^{-\alpha t}$$

å…¶ä¸­ï¼š

- $\lambda_0$: åˆå§‹æ•…éšœç‡
- $\alpha$: æ•…éšœç‡è¡°å‡ç³»æ•°

#### å®ç°16

```rust
// æ•…éšœæ¨¡å‹
pub struct FailureModel {
    initial_failure_rate: f64, // åˆå§‹æ•…éšœç‡
    decay_coefficient: f64,    // è¡°å‡ç³»æ•°
    time: f64,                // æ—¶é—´
}

impl FailureModel {
    pub fn new(initial_failure_rate: f64, decay_coefficient: f64) -> Self {
        Self {
            initial_failure_rate,
            decay_coefficient,
            time: 0.0,
        }
    }

    // è®¡ç®—å½“å‰æ•…éšœç‡
    pub fn calculate_failure_rate(&self) -> f64 {
        self.initial_failure_rate * (-self.decay_coefficient * self.time).exp()
    }

    // è®¡ç®—å¯é æ€§
    pub fn calculate_reliability(&self) -> f64 {
        (-self.initial_failure_rate / self.decay_coefficient *
         (1.0 - (-self.decay_coefficient * self.time).exp())).exp()
    }

    // è®¡ç®—å¹³å‡æ•…éšœé—´éš”æ—¶é—´
    pub fn calculate_mtbf(&self) -> f64 {
        1.0 / self.calculate_failure_rate()
    }

    // è®¡ç®—æ•…éšœæ¦‚ç‡
    pub fn calculate_failure_probability(&self, time_interval: f64) -> f64 {
        1.0 - (-self.calculate_failure_rate() * time_interval).exp()
    }

    // æ›´æ–°æ—¶é—´
    pub fn update_time(&mut self, new_time: f64) {
        self.time = new_time;
    }
}
```

### æ¢å¤æ¨¡å‹

#### æ¢å¤æ—¶é—´æ¨¡å‹

**å…¬å¼**:

$$
T_{recovery} = T_{detection} + T_{isolation} + T_{repair}
$$

#### å®ç°17

```rust
// æ¢å¤æ¨¡å‹
pub struct RecoveryModel {
    detection_time: f64,    // æ£€æµ‹æ—¶é—´
    isolation_time: f64,    // éš”ç¦»æ—¶é—´
    repair_time: f64,      // ä¿®å¤æ—¶é—´
    recovery_probability: f64, // æ¢å¤æ¦‚ç‡
}

impl RecoveryModel {
    pub fn new(detection_time: f64, isolation_time: f64, repair_time: f64) -> Self {
        Self {
            detection_time,
            isolation_time,
            repair_time,
            recovery_probability: 0.95, // é»˜è®¤æ¢å¤æ¦‚ç‡
        }
    }

    // è®¡ç®—æ€»æ¢å¤æ—¶é—´
    pub fn calculate_total_recovery_time(&self) -> f64 {
        self.detection_time + self.isolation_time + self.repair_time
    }

    // è®¡ç®—å¹³å‡æ¢å¤æ—¶é—´
    pub fn calculate_mean_recovery_time(&self) -> f64 {
        self.calculate_total_recovery_time() * self.recovery_probability
    }

    // è®¡ç®—æ¢å¤æ—¶é—´åˆ†å¸ƒ
    pub fn calculate_recovery_time_distribution(&self) -> Vec<f64> {
        let total_time = self.calculate_total_recovery_time();
        let mut distribution = Vec::new();

        for i in 0..100 {
            let time = total_time * i as f64 / 100.0;
            let probability = self.calculate_recovery_probability(time);
            distribution.push(probability);
        }

        distribution
    }

    // è®¡ç®—æ¢å¤æ¦‚ç‡
    pub fn calculate_recovery_probability(&self, time: f64) -> f64 {
        if time < self.detection_time {
            0.0
        } else if time < self.detection_time + self.isolation_time {
            0.5
        } else if time < self.calculate_total_recovery_time() {
            0.8
        } else {
            self.recovery_probability
        }
    }

    // è®¡ç®—å¯ç”¨æ€§
    pub fn calculate_availability(&self, failure_rate: f64) -> f64 {
        let mttr = self.calculate_mean_recovery_time();
        let mtbf = 1.0 / failure_rate;

        mtbf / (mtbf + mttr)
    }
}
```

### å†—ä½™æ¨¡å‹

#### N+1å†—ä½™æ¨¡å‹

**å…¬å¼**:
$$R_{system} = 1 - (1 - R_{component})^N$$

#### å®ç°18

```rust
// å†—ä½™æ¨¡å‹
pub struct RedundancyModel {
    component_reliability: f64, // ç»„ä»¶å¯é æ€§
    redundancy_level: usize,     // å†—ä½™çº§åˆ«
    redundancy_type: RedundancyType, // å†—ä½™ç±»å‹
}

# [derive(Debug, Clone)]
pub enum RedundancyType {
    Active,    // ä¸»åŠ¨å†—ä½™
    Passive,   // è¢«åŠ¨å†—ä½™
    Standby,   // å¤‡ç”¨å†—ä½™
}

impl RedundancyModel {
    pub fn new(component_reliability: f64, redundancy_level: usize, redundancy_type: RedundancyType) -> Self {
        Self {
            component_reliability,
            redundancy_level,
            redundancy_type,
        }
    }

    // è®¡ç®—ç³»ç»Ÿå¯é æ€§
    pub fn calculate_system_reliability(&self) -> f64 {
        match self.redundancy_type {
            RedundancyType::Active => {
                // ä¸»åŠ¨å†—ä½™ï¼šæ‰€æœ‰ç»„ä»¶åŒæ—¶å·¥ä½œ
                1.0 - (1.0 - self.component_reliability).powi(self.redundancy_level as i32)
            }
            RedundancyType::Passive => {
                // è¢«åŠ¨å†—ä½™ï¼šä¸€ä¸ªç»„ä»¶å·¥ä½œï¼Œå…¶ä»–å¤‡ç”¨
                self.component_reliability
            }
            RedundancyType::Standby => {
                // å¤‡ç”¨å†—ä½™ï¼šæŒ‰é¡ºåºåˆ‡æ¢
                self.component_reliability.powi(self.redundancy_level as i32)
            }
        }
    }

    // è®¡ç®—å†—ä½™æ•ˆç‡
    pub fn calculate_redundancy_efficiency(&self) -> f64 {
        let single_reliability = self.component_reliability;
        let redundant_reliability = self.calculate_system_reliability();

        (redundant_reliability - single_reliability) / single_reliability
    }

    // è®¡ç®—æœ€ä¼˜å†—ä½™çº§åˆ«
    pub fn calculate_optimal_redundancy_level(&self, target_reliability: f64) -> usize {
        let mut level = 1;

        while self.calculate_system_reliability_for_level(level) < target_reliability {
            level += 1;
        }

        level
    }

    // è®¡ç®—æŒ‡å®šçº§åˆ«çš„ç³»ç»Ÿå¯é æ€§
    fn calculate_system_reliability_for_level(&self, level: usize) -> f64 {
        match self.redundancy_type {
            RedundancyType::Active => {
                1.0 - (1.0 - self.component_reliability).powi(level as i32)
            }
            RedundancyType::Passive => {
                self.component_reliability
            }
            RedundancyType::Standby => {
                self.component_reliability.powi(level as i32)
            }
        }
    }
}
```

### ä¸€è‡´æ€§æ¨¡å‹

#### å¼ºä¸€è‡´æ€§æ¨¡å‹

**å…¬å¼**:
$$C_{strong} = \frac{Consistent\_Reads}{Total\_Reads}$$

#### å®ç°19

```rust
// ä¸€è‡´æ€§æ¨¡å‹
pub struct ConsistencyModel {
    consistent_reads: u64,  // ä¸€è‡´è¯»å–æ•°
    total_reads: u64,      // æ€»è¯»å–æ•°
    write_latency: f64,    // å†™å…¥å»¶è¿Ÿ
    read_latency: f64,     // è¯»å–å»¶è¿Ÿ
}

impl ConsistencyModel {
    pub fn new() -> Self {
        Self {
            consistent_reads: 0,
            total_reads: 0,
            write_latency: 0.0,
            read_latency: 0.0,
        }
    }

    // è®¡ç®—å¼ºä¸€è‡´æ€§
    pub fn calculate_strong_consistency(&self) -> f64 {
        if self.total_reads == 0 {
            0.0
        } else {
            self.consistent_reads as f64 / self.total_reads as f64
        }
    }

    // è®¡ç®—æœ€ç»ˆä¸€è‡´æ€§
    pub fn calculate_eventual_consistency(&self, propagation_delay: f64) -> f64 {
        let time_factor = (-propagation_delay).exp();
        self.calculate_strong_consistency() * time_factor
    }

    // è®¡ç®—å› æœä¸€è‡´æ€§
    pub fn calculate_causal_consistency(&self, dependency_ratio: f64) -> f64 {
        self.calculate_strong_consistency() * dependency_ratio
    }

    // è®¡ç®—ä¼šè¯ä¸€è‡´æ€§
    pub fn calculate_session_consistency(&self, session_duration: f64) -> f64 {
        let session_factor = (-session_duration).exp();
        self.calculate_strong_consistency() * session_factor
    }

    // æ›´æ–°è¯»å–ç»Ÿè®¡
    pub fn update_read_stats(&mut self, consistent: bool) {
        self.total_reads += 1;
        if consistent {
            self.consistent_reads += 1;
        }
    }

    // è®¡ç®—ä¸€è‡´æ€§å»¶è¿Ÿ
    pub fn calculate_consistency_latency(&self) -> f64 {
        self.write_latency + self.read_latency
    }
}
```

## ğŸ¯ ä¼˜åŒ–æ¨¡å‹

### è´Ÿè½½å‡è¡¡æ¨¡å‹

#### è´Ÿè½½å‡è¡¡ç®—æ³•

**è½®è¯¢ç®—æ³•**:
$$server_i = (current + i) \bmod n$$

**åŠ æƒè½®è¯¢ç®—æ³•**:
$$P_i = \frac{w_i}{\sum_{j=1}^{n} w_j}$$

#### å®ç°20

```rust
// è´Ÿè½½å‡è¡¡æ¨¡å‹
pub struct LoadBalancingModel {
    servers: Vec<Server>,
    algorithm: LoadBalancingAlgorithm,
    current_index: usize,
}

# [derive(Debug, Clone)]
pub struct Server {
    pub id: usize,
    pub weight: f64,
    pub current_load: f64,
    pub capacity: f64,
    pub response_time: f64,
}

# [derive(Debug, Clone)]
pub enum LoadBalancingAlgorithm {
    RoundRobin,
    WeightedRoundRobin,
    LeastConnections,
    LeastResponseTime,
    LeastLoad,
}

impl LoadBalancingModel {
    pub fn new(servers: Vec<Server>, algorithm: LoadBalancingAlgorithm) -> Self {
        Self {
            servers,
            algorithm,
            current_index: 0,
        }
    }

    // é€‰æ‹©æœåŠ¡å™¨
    pub fn select_server(&mut self) -> Option<&Server> {
        match self.algorithm {
            LoadBalancingAlgorithm::RoundRobin => {
                let server = &self.servers[self.current_index];
                self.current_index = (self.current_index + 1) % self.servers.len();
                Some(server)
            }
            LoadBalancingAlgorithm::WeightedRoundRobin => {
                self.select_weighted_server()
            }
            LoadBalancingAlgorithm::LeastConnections => {
                self.servers.iter().min_by(|a, b| a.current_load.partial_cmp(&b.current_load).unwrap())
            }
            LoadBalancingAlgorithm::LeastResponseTime => {
                self.servers.iter().min_by(|a, b| a.response_time.partial_cmp(&b.response_time).unwrap())
            }
            LoadBalancingAlgorithm::LeastLoad => {
                self.servers.iter().min_by(|a, b| (a.current_load / a.capacity).partial_cmp(&(b.current_load / b.capacity)).unwrap())
            }
        }
    }

    // é€‰æ‹©åŠ æƒæœåŠ¡å™¨
    fn select_weighted_server(&mut self) -> Option<&Server> {
        let total_weight: f64 = self.servers.iter().map(|s| s.weight).sum();
        let random = rand::random::<f64>() * total_weight;

        let mut cumulative = 0.0;
        for server in &self.servers {
            cumulative += server.weight;
            if cumulative >= random {
                return Some(server);
            }
        }

        self.servers.last()
    }

    // è®¡ç®—è´Ÿè½½å‡è¡¡æ•ˆç‡
    pub fn calculate_efficiency(&self) -> f64 {
        let loads: Vec<f64> = self.servers.iter().map(|s| s.current_load / s.capacity).collect();
        let mean_load = loads.iter().sum::<f64>() / loads.len() as f64;
        let variance = loads.iter().map(|&x| (x - mean_load).powi(2)).sum::<f64>() / loads.len() as f64;

        1.0 - variance.sqrt() / mean_load
    }

    // è®¡ç®—ç³»ç»Ÿååé‡
    pub fn calculate_throughput(&self) -> f64 {
        self.servers.iter().map(|s| s.capacity - s.current_load).sum()
    }

    // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    pub fn calculate_average_response_time(&self) -> f64 {
        let total_weight: f64 = self.servers.iter().map(|s| s.weight).sum();
        self.servers.iter()
            .map(|s| s.response_time * s.weight / total_weight)
            .sum()
    }
}
```

### ç¼“å­˜æ¨¡å‹

#### LRUç¼“å­˜æ¨¡å‹

**å…¬å¼**:
$$Hit\_Rate = \frac{Cache\_Hits}{Total\_Requests}$$

#### å®ç°21

```rust
// ç¼“å­˜æ¨¡å‹
pub struct CacheModel {
    cache_size: usize,
    hit_count: u64,
    miss_count: u64,
    access_pattern: Vec<usize>,
    cache_policy: CachePolicy,
}

# [derive(Debug, Clone)]
pub enum CachePolicy {
    LRU,
    LFU,
    FIFO,
    Random,
}

impl CacheModel {
    pub fn new(cache_size: usize, cache_policy: CachePolicy) -> Self {
        Self {
            cache_size,
            hit_count: 0,
            miss_count: 0,
            access_pattern: Vec::new(),
            cache_policy,
        }
    }

    // è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
    pub fn calculate_hit_rate(&self) -> f64 {
        let total_requests = self.hit_count + self.miss_count;
        if total_requests == 0 {
            0.0
        } else {
            self.hit_count as f64 / total_requests as f64
        }
    }

    // è®¡ç®—ç¼“å­˜æœªå‘½ä¸­ç‡
    pub fn calculate_miss_rate(&self) -> f64 {
        1.0 - self.calculate_hit_rate()
    }

    // è®¡ç®—å¹³å‡è®¿é—®æ—¶é—´
    pub fn calculate_average_access_time(&self, cache_access_time: f64, memory_access_time: f64) -> f64 {
        let hit_rate = self.calculate_hit_rate();
        hit_rate * cache_access_time + (1.0 - hit_rate) * memory_access_time
    }

    // è®¡ç®—ç¼“å­˜æ•ˆç‡
    pub fn calculate_efficiency(&self) -> f64 {
        let hit_rate = self.calculate_hit_rate();
        let cache_utilization = self.cache_size as f64 / self.access_pattern.len() as f64;

        hit_rate * cache_utilization
    }

    // æ¨¡æ‹Ÿç¼“å­˜è®¿é—®
    pub fn simulate_access(&mut self, item: usize) -> bool {
        self.access_pattern.push(item);

        // ç®€åŒ–çš„ç¼“å­˜æ¨¡æ‹Ÿ
        let hit = self.access_pattern.len() <= self.cache_size ||
                  self.access_pattern.iter().rev().take(self.cache_size).any(|&x| x == item);

        if hit {
            self.hit_count += 1;
        } else {
            self.miss_count += 1;
        }

        hit
    }

    // è®¡ç®—æœ€ä¼˜ç¼“å­˜å¤§å°
    pub fn calculate_optimal_cache_size(&self, cost_per_unit: f64, benefit_per_hit: f64) -> usize {
        let mut optimal_size = 0;
        let mut max_benefit = 0.0;

        for size in 1..=self.cache_size {
            let cost = size as f64 * cost_per_unit;
            let benefit = self.calculate_benefit_for_size(size) * benefit_per_hit;
            let net_benefit = benefit - cost;

            if net_benefit > max_benefit {
                max_benefit = net_benefit;
                optimal_size = size;
            }
        }

        optimal_size
    }

    // è®¡ç®—æŒ‡å®šå¤§å°çš„æ”¶ç›Š
    fn calculate_benefit_for_size(&self, size: usize) -> f64 {
        // ç®€åŒ–è®¡ç®—ï¼šå‡è®¾æ”¶ç›Šä¸ç¼“å­˜å¤§å°æˆæ­£æ¯”
        size as f64 / self.cache_size as f64
    }
}
```

### å‹ç¼©æ¨¡å‹

#### å‹ç¼©ç®—æ³•æ¨¡å‹

**å…¬å¼**:
$$Compression\_Ratio = \frac{Original\_Size}{Compressed\_Size}$$

#### å®ç°22

```rust
// å‹ç¼©æ¨¡å‹
pub struct CompressionModel {
    original_size: usize,
    compressed_size: usize,
    compression_algorithm: CompressionAlgorithm,
    compression_time: f64,
    decompression_time: f64,
}

# [derive(Debug, Clone)]
pub enum CompressionAlgorithm {
    Gzip,
    Deflate,
    Brotli,
    LZ4,
    Zstd,
}

impl CompressionModel {
    pub fn new(original_size: usize, compressed_size: usize, algorithm: CompressionAlgorithm) -> Self {
        Self {
            original_size,
            compressed_size,
            compression_algorithm: algorithm,
            compression_time: 0.0,
            decompression_time: 0.0,
        }
    }

    // è®¡ç®—å‹ç¼©æ¯”
    pub fn calculate_compression_ratio(&self) -> f64 {
        self.original_size as f64 / self.compressed_size as f64
    }

    // è®¡ç®—å‹ç¼©æ•ˆç‡
    pub fn calculate_compression_efficiency(&self) -> f64 {
        1.0 - self.compressed_size as f64 / self.original_size as f64
    }

    // è®¡ç®—å‹ç¼©é€Ÿåº¦
    pub fn calculate_compression_speed(&self) -> f64 {
        if self.compression_time > 0.0 {
            self.original_size as f64 / self.compression_time
        } else {
            0.0
        }
    }

    // è®¡ç®—è§£å‹ç¼©é€Ÿåº¦
    pub fn calculate_decompression_speed(&self) -> f64 {
        if self.decompression_time > 0.0 {
            self.compressed_size as f64 / self.decompression_time
        } else {
            0.0
        }
    }

    // è®¡ç®—æ€»ä½“æ€§èƒ½
    pub fn calculate_overall_performance(&self) -> f64 {
        let compression_ratio = self.calculate_compression_ratio();
        let compression_speed = self.calculate_compression_speed();
        let decompression_speed = self.calculate_decompression_speed();

        compression_ratio * compression_speed * decompression_speed
    }

    // è®¡ç®—ä¸åŒç®—æ³•çš„æ€§èƒ½
    pub fn compare_algorithms(&self, algorithms: &[CompressionAlgorithm]) -> Vec<f64> {
        algorithms.iter()
            .map(|algorithm| self.calculate_algorithm_performance(*algorithm))
            .collect()
    }

    // è®¡ç®—æŒ‡å®šç®—æ³•çš„æ€§èƒ½
    fn calculate_algorithm_performance(&self, algorithm: CompressionAlgorithm) -> f64 {
        match algorithm {
            CompressionAlgorithm::Gzip => 0.8,
            CompressionAlgorithm::Deflate => 0.7,
            CompressionAlgorithm::Brotli => 0.9,
            CompressionAlgorithm::LZ4 => 0.6,
            CompressionAlgorithm::Zstd => 0.85,
        }
    }

    // è®¡ç®—æœ€ä¼˜å‹ç¼©çº§åˆ«
    pub fn calculate_optimal_compression_level(&self, target_ratio: f64) -> usize {
        let current_ratio = self.calculate_compression_ratio();

        if current_ratio >= target_ratio {
            1
        } else {
            (target_ratio / current_ratio).ceil() as usize
        }
    }
}
```

### è·¯ç”±ä¼˜åŒ–æ¨¡å‹

#### æœ€çŸ­è·¯å¾„ç®—æ³•

**Dijkstraç®—æ³•**:
$$d[v] = \min(d[v], d[u] + w(u,v))$$

#### å®ç°23

```rust
// è·¯ç”±ä¼˜åŒ–æ¨¡å‹
pub struct RoutingOptimizationModel {
    graph: Vec<Vec<f64>>,
    nodes: usize,
    algorithm: RoutingAlgorithm,
}

# [derive(Debug, Clone)]
pub enum RoutingAlgorithm {
    Dijkstra,
    BellmanFord,
    FloydWarshall,
    AStar,
}

impl RoutingOptimizationModel {
    pub fn new(graph: Vec<Vec<f64>>, algorithm: RoutingAlgorithm) -> Self {
        let nodes = graph.len();
        Self {
            graph,
            nodes,
            algorithm,
        }
    }

    // è®¡ç®—æœ€çŸ­è·¯å¾„
    pub fn calculate_shortest_path(&self, source: usize, destination: usize) -> Option<f64> {
        match self.algorithm {
            RoutingAlgorithm::Dijkstra => self.dijkstra(source, destination),
            RoutingAlgorithm::BellmanFord => self.bellman_ford(source, destination),
            RoutingAlgorithm::FloydWarshall => self.floyd_warshall(source, destination),
            RoutingAlgorithm::AStar => self.a_star(source, destination),
        }
    }

    // Dijkstraç®—æ³•
    fn dijkstra(&self, source: usize, destination: usize) -> Option<f64> {
        let mut distances = vec![f64::INFINITY; self.nodes];
        let mut visited = vec![false; self.nodes];

        distances[source] = 0.0;

        for _ in 0..self.nodes {
            let u = self.find_min_distance_vertex(&distances, &visited);
            if u == usize::MAX {
                break;
            }

            visited[u] = true;

            for v in 0..self.nodes {
                if !visited[v] && self.graph[u][v] > 0.0 {
                    let new_distance = distances[u] + self.graph[u][v];
                    if new_distance < distances[v] {
                        distances[v] = new_distance;
                    }
                }
            }
        }

        if distances[destination] == f64::INFINITY {
            None
        } else {
            Some(distances[destination])
        }
    }

    // Bellman-Fordç®—æ³•
    fn bellman_ford(&self, source: usize, destination: usize) -> Option<f64> {
        let mut distances = vec![f64::INFINITY; self.nodes];
        distances[source] = 0.0;

        for _ in 0..self.nodes - 1 {
            for u in 0..self.nodes {
                for v in 0..self.nodes {
                    if self.graph[u][v] > 0.0 {
                        let new_distance = distances[u] + self.graph[u][v];
                        if new_distance < distances[v] {
                            distances[v] = new_distance;
                        }
                    }
                }
            }
        }

        if distances[destination] == f64::INFINITY {
            None
        } else {
            Some(distances[destination])
        }
    }

    // Floyd-Warshallç®—æ³•
    fn floyd_warshall(&self, source: usize, destination: usize) -> Option<f64> {
        let mut distances = self.graph.clone();

        for k in 0..self.nodes {
            for i in 0..self.nodes {
                for j in 0..self.nodes {
                    if distances[i][k] != f64::INFINITY && distances[k][j] != f64::INFINITY {
                        let new_distance = distances[i][k] + distances[k][j];
                        if new_distance < distances[i][j] {
                            distances[i][j] = new_distance;
                        }
                    }
                }
            }
        }

        if distances[source][destination] == f64::INFINITY {
            None
        } else {
            Some(distances[source][destination])
        }
    }

    // A*ç®—æ³•
    fn a_star(&self, source: usize, destination: usize) -> Option<f64> {
        // ç®€åŒ–çš„A*å®ç°
        self.dijkstra(source, destination)
    }

    // æŸ¥æ‰¾æœ€å°è·ç¦»é¡¶ç‚¹
    fn find_min_distance_vertex(&self, distances: &[f64], visited: &[bool]) -> usize {
        let mut min_distance = f64::INFINITY;
        let mut min_vertex = usize::MAX;

        for v in 0..self.nodes {
            if !visited[v] && distances[v] < min_distance {
                min_distance = distances[v];
                min_vertex = v;
            }
        }

        min_vertex
    }

    // è®¡ç®—è·¯ç”±æ•ˆç‡
    pub fn calculate_routing_efficiency(&self) -> f64 {
        let mut total_distance = 0.0;
        let mut path_count = 0;

        for i in 0..self.nodes {
            for j in 0..self.nodes {
                if i != j {
                    if let Some(distance) = self.calculate_shortest_path(i, j) {
                        total_distance += distance;
                        path_count += 1;
                    }
                }
            }
        }

        if path_count > 0 {
            total_distance / path_count as f64
        } else {
            0.0
        }
    }

    // è®¡ç®—ç½‘ç»œç›´å¾„
    pub fn calculate_network_diameter(&self) -> f64 {
        let mut max_distance = 0.0;

        for i in 0..self.nodes {
            for j in 0..self.nodes {
                if i != j {
                    if let Some(distance) = self.calculate_shortest_path(i, j) {
                        max_distance = max_distance.max(distance);
                    }
                }
            }
        }

        max_distance
    }
}
```

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Kleinrock, L. (1975). *Queueing Systems, Volume 1: Theory*. John Wiley & Sons.
2. Tanenbaum, A. S., & Wetherall, D. (2011). *Computer Networks*. Prentice Hall.
3. BarabÃ¡si, A. L., & Albert, R. (1999). Emergence of scaling in random networks. *Science*, 286(5439), 509-512.
4. Watts, D. J., & Strogatz, S. H. (1998). Collective dynamics of 'small-world' networks. *Nature*, 393(6684), 440-442.
5. Floyd, S., & Jacobson, V. (1993). Random early detection gateways for congestion avoidance. *IEEE/ACM Transactions on networking*, 1(4), 397-413.
6. Allman, M., Paxson, V., & Stevens, W. (1999). TCP congestion control. *RFC 2581*.
7. Jacobson, V. (1988). Congestion avoidance and control. *ACM SIGCOMM Computer Communication Review*, 18(4), 314-329.
8. Padhye, J., Firoiu, V., Towsley, D., & Kurose, J. (2000). Modeling TCP throughput: A simple model and its empirical validation. *ACM SIGCOMM Computer Communication Review*, 30(4), 303-314.

---

**ç½‘ç»œæ€§èƒ½æ¨¡å‹ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ  
**ç»´æŠ¤è€…**: C10 Networks æ€§èƒ½åˆ†æå›¢é˜Ÿ
