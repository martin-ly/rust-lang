# IoTéƒ¨ç½²å’Œè¿ç»´æŒ‡å— - Rust 1.90

## ğŸ¯ éƒ¨ç½²å’Œè¿ç»´æ¦‚è§ˆ

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†åŸºäºRust 1.90çš„IoTåº”ç”¨éƒ¨ç½²å’Œè¿ç»´ç­–ç•¥ï¼Œæ¶µç›–å®¹å™¨åŒ–ã€äº‘å¹³å°éƒ¨ç½²ã€ç›‘æ§å‘Šè­¦å’Œæ•…éšœæ’é™¤ç­‰æ–¹é¢ã€‚

## ğŸ³ å®¹å™¨åŒ–éƒ¨ç½²

### 1. Dockeré…ç½®ä¼˜åŒ–

```dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
FROM rust:1.90-slim as builder

# å®‰è£…æ„å»ºä¾èµ–
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY Cargo.toml Cargo.lock ./

# æ„å»ºä¾èµ–ï¼ˆåˆ©ç”¨Dockerç¼“å­˜ï¼‰
RUN cargo build --release --dependencies-only

# å¤åˆ¶æºä»£ç 
COPY src ./src

# æ„å»ºåº”ç”¨
RUN cargo build --release

# è¿è¡Œæ—¶é•œåƒ
FROM debian:bookworm-slim

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r iot && useradd -r -g iot iot

# å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /app/target/release/iot-app /usr/local/bin/iot-app

# è®¾ç½®æƒé™
RUN chown iot:iot /usr/local/bin/iot-app
USER iot

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

EXPOSE 8080

CMD ["iot-app"]
```

### 2. Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  iot-app:
    build: .
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=info
      - DATABASE_URL=postgresql://user:pass@postgres:5432/iot_db
      - MQTT_BROKER=mqtt://mosquitto:1883
    depends_on:
      - postgres
      - mosquitto
      - redis
    volumes:
      - ./config:/app/config:ro
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=iot_db
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: unless-stopped

  mosquitto:
    image: eclipse-mosquitto:2
    ports:
      - "1883:1883"
      - "9001:9001"
    volumes:
      - ./mosquitto.conf:/mosquitto/config/mosquitto.conf
      - mosquitto_data:/mosquitto/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    restart: unless-stopped

volumes:
  postgres_data:
  mosquitto_data:
  redis_data:
  prometheus_data:
  grafana_data:
```

## â˜ï¸ äº‘å¹³å°éƒ¨ç½²

### 1. Kuberneteséƒ¨ç½²

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: iot-app
  labels:
    app: iot-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: iot-app
  template:
    metadata:
      labels:
        app: iot-app
    spec:
      containers:
      - name: iot-app
        image: iot-app:latest
        ports:
        - containerPort: 8080
        env:
        - name: RUST_LOG
          value: "info"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: iot-secrets
              key: database-url
        - name: MQTT_BROKER
          valueFrom:
            configMapKeyRef:
              name: iot-config
              key: mqtt-broker
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        - name: logs-volume
          mountPath: /app/logs
      volumes:
      - name: config-volume
        configMap:
          name: iot-config
      - name: logs-volume
        emptyDir: {}
      restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: iot-app-service
spec:
  selector:
    app: iot-app
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: iot-config
data:
  mqtt-broker: "mqtt://mqtt-broker:1883"
  redis-url: "redis://redis:6379"
  config.toml: |
    [device]
    id = "gateway_001"
    location = "cloud"
    
    [communication]
    keep_alive = 60
    qos = 1
    
    [storage]
    batch_size = 1000
    flush_interval = 30

---
apiVersion: v1
kind: Secret
metadata:
  name: iot-secrets
type: Opaque
data:
  database-url: cG9zdGdyZXNxbDovL3VzZXI6cGFzc0BkYjo1NDMyL2lvdF9kYg==
  api-key: YWJjZGVmZ2hpams=
```

### 2. Helm Charté…ç½®

```yaml
# Chart.yaml
apiVersion: v2
name: iot-app
description: IoT Application Helm Chart
type: application
version: 0.1.0
appVersion: "1.0.0"

# values.yaml
replicaCount: 3

image:
  repository: iot-app
  tag: latest
  pullPolicy: IfNotPresent

service:
  type: LoadBalancer
  port: 80
  targetPort: 8080

ingress:
  enabled: true
  className: nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  hosts:
    - host: iot.example.com
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

# templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "iot-app.fullname" . }}
  labels:
    {{- include "iot-app.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "iot-app.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "iot-app.selectorLabels" . | nindent 8 }}
    spec:
      containers:
        - name: {{ .Chart.Name }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: {{ .Values.service.targetPort }}
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: http
          readinessProbe:
            httpGet:
              path: /ready
              port: http
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
```

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

### 1. Prometheusé…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "iot-alerts.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'iot-app'
    static_configs:
      - targets: ['iot-app:8080']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
```

### 2. å‘Šè­¦è§„åˆ™

```yaml
# iot-alerts.yml
groups:
- name: iot-alerts
  rules:
  - alert: HighTemperature
    expr: iot_temperature_celsius > 35
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "è®¾å¤‡æ¸©åº¦è¿‡é«˜"
      description: "è®¾å¤‡ {{ $labels.device_id }} æ¸©åº¦è¾¾åˆ° {{ $value }}Â°C"

  - alert: DeviceOffline
    expr: up{job="iot-app"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "è®¾å¤‡ç¦»çº¿"
      description: "è®¾å¤‡ {{ $labels.device_id }} å·²ç¦»çº¿è¶…è¿‡1åˆ†é’Ÿ"

  - alert: HighErrorRate
    expr: rate(iot_errors_total[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "é”™è¯¯ç‡è¿‡é«˜"
      description: "è®¾å¤‡ {{ $labels.device_id }} é”™è¯¯ç‡è¾¾åˆ° {{ $value }}"

  - alert: HighMemoryUsage
    expr: (process_resident_memory_bytes / 1024 / 1024) > 400
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "å†…å­˜ä½¿ç”¨è¿‡é«˜"
      description: "åº”ç”¨å†…å­˜ä½¿ç”¨è¾¾åˆ° {{ $value }}MB"

  - alert: HighCPUUsage
    expr: rate(process_cpu_seconds_total[5m]) > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "CPUä½¿ç”¨è¿‡é«˜"
      description: "åº”ç”¨CPUä½¿ç”¨ç‡è¾¾åˆ° {{ $value }}"
```

### 3. Grafanaä»ªè¡¨ç›˜

```json
{
  "dashboard": {
    "title": "IoTåº”ç”¨ç›‘æ§",
    "panels": [
      {
        "title": "è¯·æ±‚é€Ÿç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(iot_requests_total[5m])",
            "legendFormat": "{{device_id}}"
          }
        ]
      },
      {
        "title": "å“åº”æ—¶é—´",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(iot_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "è®¾å¤‡çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "count(up{job=\"iot-app\"})",
            "legendFormat": "åœ¨çº¿è®¾å¤‡"
          }
        ]
      }
    ]
  }
}
```

## ğŸ”§ è¿ç»´è‡ªåŠ¨åŒ–

### 1. å¥åº·æ£€æŸ¥å®ç°

```rust
use axum::{response::Json, routing::get, Router};
use serde_json::{json, Value};
use std::sync::Arc;
use tokio::sync::RwLock;

pub struct HealthChecker {
    database: Arc<DatabaseClient>,
    mqtt: Arc<MqttClient>,
    redis: Arc<RedisClient>,
    start_time: std::time::Instant,
}

impl HealthChecker {
    pub fn new(
        database: Arc<DatabaseClient>,
        mqtt: Arc<MqttClient>,
        redis: Arc<RedisClient>,
    ) -> Self {
        Self {
            database,
            mqtt,
            redis,
            start_time: std::time::Instant::now(),
        }
    }
    
    pub async fn health_check(&self) -> Json<Value> {
        let uptime = self.start_time.elapsed();
        
        Json(json!({
            "status": "healthy",
            "timestamp": chrono::Utc::now(),
            "uptime_seconds": uptime.as_secs(),
            "version": env!("CARGO_PKG_VERSION"),
            "components": {
                "database": self.check_database().await,
                "mqtt": self.check_mqtt().await,
                "redis": self.check_redis().await
            }
        }))
    }
    
    pub async fn readiness_check(&self) -> Json<Value> {
        let database_healthy = self.check_database().await;
        let mqtt_healthy = self.check_mqtt().await;
        let redis_healthy = self.check_redis().await;
        
        let all_healthy = database_healthy && mqtt_healthy && redis_healthy;
        
        Json(json!({
            "status": if all_healthy { "ready" } else { "not_ready" },
            "components": {
                "database": database_healthy,
                "mqtt": mqtt_healthy,
                "redis": redis_healthy
            }
        }))
    }
    
    async fn check_database(&self) -> bool {
        match self.database.ping().await {
            Ok(_) => true,
            Err(_) => false,
        }
    }
    
    async fn check_mqtt(&self) -> bool {
        match self.mqtt.is_connected().await {
            Ok(connected) => connected,
            Err(_) => false,
        }
    }
    
    async fn check_redis(&self) -> bool {
        match self.redis.ping().await {
            Ok(_) => true,
            Err(_) => false,
        }
    }
}

pub fn create_health_router(health_checker: Arc<HealthChecker>) -> Router {
    Router::new()
        .route("/health", get({
            let checker = Arc::clone(&health_checker);
            move || async move { checker.health_check().await }
        }))
        .route("/ready", get({
            let checker = Arc::clone(&health_checker);
            move || async move { checker.readiness_check().await }
        }))
}
```

### 2. è‡ªåŠ¨æ‰©ç¼©å®¹

```rust
use std::sync::Arc;
use tokio::sync::RwLock;
use std::time::Duration;

pub struct AutoScaler {
    metrics: Arc<PerformanceMetrics>,
    current_replicas: Arc<RwLock<u32>>,
    min_replicas: u32,
    max_replicas: u32,
    scale_up_threshold: f64,
    scale_down_threshold: f64,
}

impl AutoScaler {
    pub fn new(
        min_replicas: u32,
        max_replicas: u32,
        scale_up_threshold: f64,
        scale_down_threshold: f64,
    ) -> Self {
        Self {
            metrics: Arc::new(PerformanceMetrics::new()),
            current_replicas: Arc::new(RwLock::new(min_replicas)),
            min_replicas,
            max_replicas,
            scale_up_threshold,
            scale_down_threshold,
        }
    }
    
    pub async fn start_scaling(&self) {
        let mut interval = tokio::time::interval(Duration::from_secs(30));
        
        loop {
            interval.tick().await;
            
            let metrics = self.metrics.get_current_metrics().await;
            let current_replicas = *self.current_replicas.read().await;
            
            let should_scale_up = metrics.cpu_usage > self.scale_up_threshold
                || metrics.memory_usage > 0.8
                || metrics.request_queue_length > 100;
            
            let should_scale_down = metrics.cpu_usage < self.scale_down_threshold
                && metrics.memory_usage < 0.5
                && metrics.request_queue_length < 10;
            
            if should_scale_up && current_replicas < self.max_replicas {
                self.scale_up().await;
            } else if should_scale_down && current_replicas > self.min_replicas {
                self.scale_down().await;
            }
        }
    }
    
    async fn scale_up(&self) {
        let mut replicas = self.current_replicas.write().await;
        *replicas += 1;
        
        println!("æ‰©ç¼©å®¹: å¢åŠ åˆ° {} ä¸ªå‰¯æœ¬", *replicas);
        
        // é€šçŸ¥Kubernetesæˆ–å…¶ä»–ç¼–æ’ç³»ç»Ÿ
        self.notify_scaling_change(*replicas).await;
    }
    
    async fn scale_down(&self) {
        let mut replicas = self.current_replicas.write().await;
        *replicas -= 1;
        
        println!("æ‰©ç¼©å®¹: å‡å°‘åˆ° {} ä¸ªå‰¯æœ¬", *replicas);
        
        // é€šçŸ¥Kubernetesæˆ–å…¶ä»–ç¼–æ’ç³»ç»Ÿ
        self.notify_scaling_change(*replicas).await;
    }
    
    async fn notify_scaling_change(&self, replicas: u32) {
        // å®ç°é€šçŸ¥é€»è¾‘ï¼Œä¾‹å¦‚è°ƒç”¨Kubernetes API
        println!("é€šçŸ¥ç¼–æ’ç³»ç»Ÿ: å‰¯æœ¬æ•°é‡å˜æ›´ä¸º {}", replicas);
    }
}
```

## ğŸš¨ æ•…éšœæ’é™¤

### 1. æ—¥å¿—åˆ†æ

```rust
use tracing::{info, warn, error, instrument};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

pub struct LogAnalyzer {
    log_patterns: Vec<LogPattern>,
}

#[derive(Debug, Clone)]
pub struct LogPattern {
    pub name: String,
    pub pattern: regex::Regex,
    pub severity: LogSeverity,
    pub action: LogAction,
}

#[derive(Debug, Clone)]
pub enum LogSeverity {
    Info,
    Warning,
    Error,
    Critical,
}

#[derive(Debug, Clone)]
pub enum LogAction {
    Alert,
    Restart,
    Scale,
    Ignore,
}

impl LogAnalyzer {
    pub fn new() -> Self {
        Self {
            log_patterns: vec![
                LogPattern {
                    name: "Connection Error".to_string(),
                    pattern: regex::Regex::new(r"connection.*failed").unwrap(),
                    severity: LogSeverity::Error,
                    action: LogAction::Alert,
                },
                LogPattern {
                    name: "Memory Leak".to_string(),
                    pattern: regex::Regex::new(r"memory.*leak").unwrap(),
                    severity: LogSeverity::Critical,
                    action: LogAction::Restart,
                },
                LogPattern {
                    name: "High Load".to_string(),
                    pattern: regex::Regex::new(r"high.*load").unwrap(),
                    severity: LogSeverity::Warning,
                    action: LogAction::Scale,
                },
            ],
        }
    }
    
    pub async fn analyze_log_line(&self, line: &str) -> Option<LogAnalysisResult> {
        for pattern in &self.log_patterns {
            if pattern.pattern.is_match(line) {
                return Some(LogAnalysisResult {
                    pattern: pattern.clone(),
                    line: line.to_string(),
                    timestamp: chrono::Utc::now(),
                });
            }
        }
        None
    }
    
    pub async fn handle_log_result(&self, result: LogAnalysisResult) {
        match result.pattern.action {
            LogAction::Alert => {
                error!("æ£€æµ‹åˆ°é—®é¢˜: {} - {}", result.pattern.name, result.line);
                self.send_alert(&result).await;
            }
            LogAction::Restart => {
                error!("éœ€è¦é‡å¯: {} - {}", result.pattern.name, result.line);
                self.restart_service().await;
            }
            LogAction::Scale => {
                warn!("éœ€è¦æ‰©ç¼©å®¹: {} - {}", result.pattern.name, result.line);
                self.trigger_scaling().await;
            }
            LogAction::Ignore => {
                info!("å¿½ç•¥æ—¥å¿—: {} - {}", result.pattern.name, result.line);
            }
        }
    }
    
    async fn send_alert(&self, result: &LogAnalysisResult) {
        // å‘é€å‘Šè­¦é€šçŸ¥
        println!("å‘é€å‘Šè­¦: {}", result.pattern.name);
    }
    
    async fn restart_service(&self) {
        // é‡å¯æœåŠ¡
        println!("é‡å¯æœåŠ¡");
    }
    
    async fn trigger_scaling(&self) {
        // è§¦å‘æ‰©ç¼©å®¹
        println!("è§¦å‘æ‰©ç¼©å®¹");
    }
}

#[derive(Debug, Clone)]
pub struct LogAnalysisResult {
    pub pattern: LogPattern,
    pub line: String,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}
```

### 2. æ•…éšœæ¢å¤

```rust
use std::sync::Arc;
use tokio::sync::RwLock;
use std::time::Duration;

pub struct FailureRecovery {
    failure_count: Arc<RwLock<u32>>,
    last_failure: Arc<RwLock<Option<std::time::Instant>>>,
    recovery_strategies: Vec<RecoveryStrategy>,
}

#[derive(Debug, Clone)]
pub enum RecoveryStrategy {
    Retry { max_attempts: u32, delay: Duration },
    CircuitBreaker { failure_threshold: u32, timeout: Duration },
    Fallback { fallback_service: String },
    Restart { delay: Duration },
}

impl FailureRecovery {
    pub fn new() -> Self {
        Self {
            failure_count: Arc::new(RwLock::new(0)),
            last_failure: Arc::new(RwLock::new(None)),
            recovery_strategies: vec![
                RecoveryStrategy::Retry {
                    max_attempts: 3,
                    delay: Duration::from_secs(1),
                },
                RecoveryStrategy::CircuitBreaker {
                    failure_threshold: 5,
                    timeout: Duration::from_secs(60),
                },
                RecoveryStrategy::Fallback {
                    fallback_service: "backup-service".to_string(),
                },
                RecoveryStrategy::Restart {
                    delay: Duration::from_secs(30),
                },
            ],
        }
    }
    
    pub async fn handle_failure(&self, error: &str) -> Result<(), Box<dyn std::error::Error>> {
        let mut count = self.failure_count.write().await;
        *count += 1;
        
        let mut last_failure = self.last_failure.write().await;
        *last_failure = Some(std::time::Instant::now());
        
        println!("å¤„ç†æ•…éšœ: {} (ç¬¬{}æ¬¡)", error, *count);
        
        // åº”ç”¨æ¢å¤ç­–ç•¥
        for strategy in &self.recovery_strategies {
            match strategy {
                RecoveryStrategy::Retry { max_attempts, delay } => {
                    if *count <= *max_attempts {
                        tokio::time::sleep(*delay).await;
                        return Ok(());
                    }
                }
                RecoveryStrategy::CircuitBreaker { failure_threshold, timeout } => {
                    if *count >= *failure_threshold {
                        println!("ç†”æ–­å™¨å¼€å¯ï¼Œç­‰å¾… {} ç§’", timeout.as_secs());
                        tokio::time::sleep(*timeout).await;
                        *count = 0; // é‡ç½®è®¡æ•°
                        return Ok(());
                    }
                }
                RecoveryStrategy::Fallback { fallback_service } => {
                    println!("ä½¿ç”¨å¤‡ç”¨æœåŠ¡: {}", fallback_service);
                    return self.call_fallback_service(fallback_service).await;
                }
                RecoveryStrategy::Restart { delay } => {
                    println!("å‡†å¤‡é‡å¯æœåŠ¡ï¼Œç­‰å¾… {} ç§’", delay.as_secs());
                    tokio::time::sleep(*delay).await;
                    return self.restart_service().await;
                }
            }
        }
        
        Ok(())
    }
    
    async fn call_fallback_service(&self, service: &str) -> Result<(), Box<dyn std::error::Error>> {
        // è°ƒç”¨å¤‡ç”¨æœåŠ¡
        println!("è°ƒç”¨å¤‡ç”¨æœåŠ¡: {}", service);
        Ok(())
    }
    
    async fn restart_service(&self) -> Result<(), Box<dyn std::error::Error>> {
        // é‡å¯æœåŠ¡
        println!("é‡å¯æœåŠ¡");
        Ok(())
    }
    
    pub async fn reset_failure_count(&self) {
        let mut count = self.failure_count.write().await;
        *count = 0;
    }
}
```

## ğŸ“‹ è¿ç»´æ£€æŸ¥æ¸…å•

### 1. éƒ¨ç½²å‰æ£€æŸ¥

- [ ] ä»£ç è´¨é‡æ£€æŸ¥é€šè¿‡
- [ ] å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•é€šè¿‡
- [ ] æ€§èƒ½æµ‹è¯•æ»¡è¶³è¦æ±‚
- [ ] å®‰å…¨æ‰«ææ— é«˜å±æ¼æ´
- [ ] é…ç½®æ–‡ä»¶æ­£ç¡®
- [ ] ä¾èµ–ç‰ˆæœ¬å…¼å®¹
- [ ] èµ„æºéœ€æ±‚è¯„ä¼°
- [ ] å¤‡ä»½ç­–ç•¥ç¡®è®¤

### 2. éƒ¨ç½²åæ£€æŸ¥

- [ ] æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] ç›‘æ§æŒ‡æ ‡æ­£å¸¸
- [ ] æ—¥å¿—è¾“å‡ºæ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] å¤–éƒ¨æœåŠ¡è¿æ¥æ­£å¸¸
- [ ] æ€§èƒ½æŒ‡æ ‡ç¬¦åˆé¢„æœŸ
- [ ] å‘Šè­¦è§„åˆ™ç”Ÿæ•ˆ
- [ ] å¤‡ä»½ä»»åŠ¡æ­£å¸¸

### 3. æ—¥å¸¸è¿ç»´æ£€æŸ¥

- [ ] ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
- [ ] åº”ç”¨æ€§èƒ½æŒ‡æ ‡
- [ ] é”™è¯¯æ—¥å¿—åˆ†æ
- [ ] å®‰å…¨äº‹ä»¶æ£€æŸ¥
- [ ] å¤‡ä»½ä»»åŠ¡çŠ¶æ€
- [ ] è¯ä¹¦æœ‰æ•ˆæœŸæ£€æŸ¥
- [ ] ä¾èµ–æ›´æ–°æ£€æŸ¥
- [ ] å®¹é‡è§„åˆ’è¯„ä¼°

## ğŸ”„ æŒç»­æ”¹è¿›

### 1. æ€§èƒ½ç›‘æ§

- å®šæœŸåˆ†ææ€§èƒ½æŒ‡æ ‡
- è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
- ä¼˜åŒ–çƒ­ç‚¹ä»£ç 
- è°ƒæ•´èµ„æºé…ç½®

### 2. å®‰å…¨æ›´æ–°

- å®šæœŸæ›´æ–°ä¾èµ–åº“
- ç›‘æ§å®‰å…¨æ¼æ´
- å®æ–½å®‰å…¨è¡¥ä¸
- åŠ å¼ºè®¿é—®æ§åˆ¶

### 3. å®¹é‡è§„åˆ’

- ç›‘æ§èµ„æºä½¿ç”¨è¶‹åŠ¿
- é¢„æµ‹å®¹é‡éœ€æ±‚
- è§„åˆ’æ‰©å®¹æ–¹æ¡ˆ
- ä¼˜åŒ–èµ„æºåˆ©ç”¨ç‡

---

**IoTéƒ¨ç½²å’Œè¿ç»´æŒ‡å—** - åŸºäºRust 1.90çš„å®Œæ•´éƒ¨ç½²å’Œè¿ç»´è§£å†³æ–¹æ¡ˆ ğŸ¦€ğŸš€
