//! AIé›†æˆæ¼”ç¤ºç¤ºä¾‹
//! 
//! å±•ç¤ºå¦‚ä½•ä½¿ç”¨c17_iotçš„AIé›†æˆåŠŸèƒ½è¿›è¡Œæ™ºèƒ½æ•°æ®åˆ†æå’Œé¢„æµ‹

use c17_iot::ai_integration::{
    AIIntegrationManager,
    AIModelConfig,
    AIModelType,
    AIConfig,
    AnalysisType,
    //PredictionType,
};
use std::time::Duration;
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ å¯åŠ¨AIé›†æˆæ¼”ç¤º...");

    println!("ğŸ“Š å¼€å§‹æ¼”ç¤ºIoTç³»ç»ŸAIé›†æˆåŠŸèƒ½...");

    // 1. AIé›†æˆç®¡ç†å™¨åˆ›å»ºå’Œé…ç½®
    println!("\n1ï¸âƒ£ AIé›†æˆç®¡ç†å™¨åˆ›å»ºå’Œé…ç½®");
    demo_ai_manager_creation().await?;

    // 2. AIæ¨¡å‹æ³¨å†Œå’Œç®¡ç†
    println!("\n2ï¸âƒ£ AIæ¨¡å‹æ³¨å†Œå’Œç®¡ç†");
    demo_model_registration().await?;

    // 3. æ™ºèƒ½é¢„æµ‹
    println!("\n3ï¸âƒ£ æ™ºèƒ½é¢„æµ‹");
    demo_intelligent_prediction().await?;

    // 4. æ•°æ®åˆ†æ
    println!("\n4ï¸âƒ£ æ•°æ®åˆ†æ");
    demo_data_analysis().await?;

    // 5. å¼‚å¸¸æ£€æµ‹
    println!("\n5ï¸âƒ£ å¼‚å¸¸æ£€æµ‹");
    demo_anomaly_detection().await?;

    // 6. è¶‹åŠ¿åˆ†æ
    println!("\n6ï¸âƒ£ è¶‹åŠ¿åˆ†æ");
    demo_trend_analysis().await?;

    // 7. æ¨¡å¼è¯†åˆ«
    println!("\n7ï¸âƒ£ æ¨¡å¼è¯†åˆ«");
    demo_pattern_recognition().await?;

    // 8. æ‰¹é‡å¤„ç†
    println!("\n8ï¸âƒ£ æ‰¹é‡å¤„ç†");
    demo_batch_processing().await?;

    // 9. å®æ—¶åˆ†æ
    println!("\n9ï¸âƒ£ å®æ—¶åˆ†æ");
    demo_realtime_analysis().await?;

    // 10. AIç»Ÿè®¡å’ŒæŠ¥å‘Š
    println!("\nğŸ”Ÿ AIç»Ÿè®¡å’ŒæŠ¥å‘Š");
    demo_ai_statistics().await?;

    println!("\nâœ… AIé›†æˆæ¼”ç¤ºå®Œæˆ!");
    println!("ğŸ¯ æ¼”ç¤ºå±•ç¤ºäº†ä»¥ä¸‹åŠŸèƒ½:");
    println!("  - AIæ¨¡å‹ç®¡ç†å’Œæ³¨å†Œ");
    println!("  - æ™ºèƒ½é¢„æµ‹å’Œåˆ†æ");
    println!("  - å¼‚å¸¸æ£€æµ‹å’Œè¶‹åŠ¿åˆ†æ");
    println!("  - æ¨¡å¼è¯†åˆ«å’Œèšç±»åˆ†æ");
    println!("  - å®æ—¶åˆ†æå’Œæ‰¹é‡å¤„ç†");

    Ok(())
}

/// AIé›†æˆç®¡ç†å™¨åˆ›å»ºå’Œé…ç½®æ¼”ç¤º
async fn demo_ai_manager_creation() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ›å»ºAIé…ç½®
    let config = AIConfig {
        enable_ai: true,
        max_prediction_history: 1000,
        max_analysis_history: 500,
        batch_size: 32,
        processing_timeout: Duration::from_secs(30),
        enable_realtime_analysis: true,
        realtime_analysis_interval: Duration::from_secs(60),
    };

    println!("  åˆ›å»ºAIé›†æˆç®¡ç†å™¨...");
    let ai_manager = AIIntegrationManager::new(config);
    
    // è·å–åˆå§‹ç»Ÿè®¡ä¿¡æ¯
    let stats = ai_manager.get_stats().await;
    println!("  åˆå§‹AIç»Ÿè®¡:");
    println!("    æ€»é¢„æµ‹æ•°: {}", stats.total_predictions);
    println!("    æ€»åˆ†ææ•°: {}", stats.total_analyses);
    println!("    å¹³å‡é¢„æµ‹æ—¶é—´: {:?}", stats.avg_prediction_time);
    println!("    å¹³å‡åˆ†ææ—¶é—´: {:?}", stats.avg_analysis_time);

    Ok(())
}

/// AIæ¨¡å‹æ³¨å†Œå’Œç®¡ç†æ¼”ç¤º
async fn demo_model_registration() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    // æ³¨å†Œå¤šä¸ªAIæ¨¡å‹
    let models = vec![
        ("anomaly_detector", AIModelType::AnomalyDetection, 10, 1),
        ("temperature_predictor", AIModelType::Prediction, 5, 1),
        ("device_classifier", AIModelType::Classification, 8, 3),
        ("sensor_clusterer", AIModelType::Clustering, 6, 4),
        ("time_series_forecaster", AIModelType::TimeSeries, 12, 1),
    ];

    println!("  æ³¨å†ŒAIæ¨¡å‹...");
    for (name, model_type, input_features, output_dimensions) in models {
        let model_config = AIModelConfig {
            model_type: model_type.clone(),
            name: name.to_string(),
            version: "1.0".to_string(),
            model_path: format!("/models/{}", name),
            input_features,
            output_dimensions,
            enable_gpu: true,
            batch_size: 32,
            confidence_threshold: 0.8,
            custom_params: HashMap::new(),
        };
        
        ai_manager.register_model(model_config).await?;
        println!("    æ³¨å†Œæ¨¡å‹: {} ({:?})", name, model_type);
    }

    // è·å–å·²æ³¨å†Œçš„æ¨¡å‹åˆ—è¡¨
    let registered_models = ai_manager.get_models().await;
    println!("  å·²æ³¨å†Œæ¨¡å‹æ•°é‡: {}", registered_models.len());
    for model in registered_models {
        println!("    - {}: {:?} (è¾“å…¥: {}, è¾“å‡º: {})", 
                model.name, model.model_type, model.input_features, model.output_dimensions);
    }

    Ok(())
}

/// æ™ºèƒ½é¢„æµ‹æ¼”ç¤º
async fn demo_intelligent_prediction() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    // æ³¨å†Œé¢„æµ‹æ¨¡å‹
    let model_config = AIModelConfig {
        model_type: AIModelType::Prediction,
        name: "temperature_predictor".to_string(),
        version: "1.0".to_string(),
        model_path: "/models/temperature_predictor".to_string(),
        input_features: 5,
        output_dimensions: 1,
        enable_gpu: true,
        batch_size: 32,
        confidence_threshold: 0.8,
        custom_params: HashMap::new(),
    };
    
    ai_manager.register_model(model_config).await?;
    
    println!("  æ‰§è¡Œæ™ºèƒ½é¢„æµ‹...");
    
    // æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®
    let sensor_data = vec![
        vec![20.5, 21.0, 21.5, 22.0, 22.5], // æ¸©åº¦ä¸Šå‡è¶‹åŠ¿
        vec![25.0, 24.5, 24.0, 23.5, 23.0], // æ¸©åº¦ä¸‹é™è¶‹åŠ¿
        vec![18.0, 18.2, 18.1, 18.3, 18.2], // æ¸©åº¦ç¨³å®š
    ];
    
    for (i, features) in sensor_data.iter().enumerate() {
        println!("    é¢„æµ‹ {}: è¾“å…¥ç‰¹å¾ {:?}", i + 1, features);
        
        let prediction = ai_manager.predict("temperature_predictor", features.clone()).await?;
        
        println!("      é¢„æµ‹ç»“æœ: {:?}", prediction.prediction);
        println!("      ç½®ä¿¡åº¦: {:.2}%", prediction.confidence * 100.0);
        println!("      é¢„æµ‹ç±»å‹: {:?}", prediction.prediction_type);
        println!("      é¢„æµ‹æ—¶é—´: {}", prediction.timestamp.format("%H:%M:%S"));
    }

    Ok(())
}

/// æ•°æ®åˆ†ææ¼”ç¤º
async fn demo_data_analysis() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    println!("  æ‰§è¡Œæ•°æ®åˆ†æ...");
    
    // æ¨¡æ‹ŸIoTè®¾å¤‡æ•°æ®
    let device_data = vec![
        1.0, 1.2, 1.5, 1.8, 2.0, 2.3, 2.5, 2.8, 3.0, 3.2, // ä¸Šå‡è¶‹åŠ¿
        3.0, 2.8, 2.5, 2.2, 2.0, 1.8, 1.5, 1.2, 1.0, 0.8, // ä¸‹é™è¶‹åŠ¿
        1.0, 1.1, 0.9, 1.2, 0.8, 1.3, 0.7, 1.4, 0.6, 1.5, // æ³¢åŠ¨æ¨¡å¼
    ];
    
    // æ‰§è¡Œå¤šç§åˆ†æ
    let analyses = vec![
        (AnalysisType::TrendAnalysis, "è¶‹åŠ¿åˆ†æ"),
        (AnalysisType::CorrelationAnalysis, "ç›¸å…³æ€§åˆ†æ"),
        (AnalysisType::ClusteringAnalysis, "èšç±»åˆ†æ"),
    ];
    
    for (analysis_type, description) in analyses {
        println!("    æ‰§è¡Œ{}...", description);
        
        let analysis = ai_manager.analyze(analysis_type, device_data.clone(), "sensor_data".to_string()).await?;
        
        println!("      åˆ†æID: {}", analysis.id);
        println!("      åˆ†æç±»å‹: {:?}", analysis.analysis_type);
        println!("      å¤„ç†æ—¶é—´: {:?}", analysis.processing_time);
        println!("      ç½®ä¿¡åº¦: {:.2}%", analysis.confidence * 100.0);
        println!("      å»ºè®®æ•°é‡: {}", analysis.recommendations.len());
        
        for (i, recommendation) in analysis.recommendations.iter().enumerate() {
            println!("        å»ºè®® {}: {}", i + 1, recommendation);
        }
    }

    Ok(())
}

/// å¼‚å¸¸æ£€æµ‹æ¼”ç¤º
async fn demo_anomaly_detection() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    println!("  æ‰§è¡Œå¼‚å¸¸æ£€æµ‹...");
    
    // æ¨¡æ‹ŸåŒ…å«å¼‚å¸¸çš„æ•°æ®
    let normal_data = vec![1.0, 1.1, 1.0, 1.2, 1.1, 1.0, 1.1, 1.2, 1.0, 1.1];
    let anomaly_data = vec![1.0, 1.1, 1.0, 5.0, 1.1, 1.0, 1.1, 1.2, 1.0, 1.1]; // åŒ…å«å¼‚å¸¸å€¼5.0
    
    let datasets = vec![
        (normal_data, "æ­£å¸¸æ•°æ®"),
        (anomaly_data, "å¼‚å¸¸æ•°æ®"),
    ];
    
    for (data, description) in datasets {
        println!("    æ£€æµ‹{}...", description);
        
        let analysis = ai_manager.analyze(AnalysisType::AnomalyDetection, data, "anomaly_detection".to_string()).await?;
        
        if let c17_iot::ai_integration::AnalysisResults::Anomaly(anomaly_result) = analysis.results {
            println!("      æ˜¯å¦å¼‚å¸¸: {}", if anomaly_result.is_anomaly { "æ˜¯" } else { "å¦" });
            println!("      å¼‚å¸¸åˆ†æ•°: {:.2}", anomaly_result.anomaly_score);
            println!("      å¼‚å¸¸ç±»å‹: {:?}", anomaly_result.anomaly_type);
            println!("      å¼‚å¸¸ä½ç½®: {:?}", anomaly_result.anomaly_positions);
            println!("      æ­£å¸¸èŒƒå›´: ({:.1}, {:.1})", anomaly_result.normal_range.0, anomaly_result.normal_range.1);
        }
    }

    Ok(())
}

/// è¶‹åŠ¿åˆ†ææ¼”ç¤º
async fn demo_trend_analysis() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    println!("  æ‰§è¡Œè¶‹åŠ¿åˆ†æ...");
    
    // æ¨¡æ‹Ÿä¸åŒè¶‹åŠ¿çš„æ•°æ®
    let trend_data = vec![
        (vec![1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0], "ä¸Šå‡è¶‹åŠ¿"),
        (vec![5.0, 4.5, 4.0, 3.5, 3.0, 2.5, 2.0], "ä¸‹é™è¶‹åŠ¿"),
        (vec![2.0, 2.1, 1.9, 2.0, 2.1, 1.9, 2.0], "ç¨³å®šè¶‹åŠ¿"),
        (vec![1.0, 3.0, 1.5, 4.0, 2.0, 5.0, 2.5], "æ³¢åŠ¨è¶‹åŠ¿"),
    ];
    
    for (data, description) in trend_data {
        println!("    åˆ†æ{}...", description);
        
        let analysis = ai_manager.analyze(AnalysisType::TrendAnalysis, data, "trend_analysis".to_string()).await?;
        
        if let c17_iot::ai_integration::AnalysisResults::Trend(trend_result) = analysis.results {
            println!("      è¶‹åŠ¿æ–¹å‘: {:?}", trend_result.direction);
            println!("      è¶‹åŠ¿å¼ºåº¦: {:.2}", trend_result.strength);
            println!("      å˜åŒ–ç‡: {:.2}", trend_result.change_rate);
            println!("      é¢„æµ‹å€¼: {:?}", trend_result.forecast_values);
            println!("      ç½®ä¿¡åŒºé—´: ({:.1}, {:.1})", trend_result.confidence_interval.0, trend_result.confidence_interval.1);
        }
    }

    Ok(())
}

/// æ¨¡å¼è¯†åˆ«æ¼”ç¤º
async fn demo_pattern_recognition() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    println!("  æ‰§è¡Œæ¨¡å¼è¯†åˆ«...");
    
    // æ¨¡æ‹ŸåŒ…å«æ¨¡å¼çš„æ•°æ®
    let pattern_data = vec![
        1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, // é‡å¤æ¨¡å¼
        0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, // çº¿æ€§å¢é•¿
        2.0, 1.5, 1.0, 0.5, 1.0, 1.5, 2.0, 1.5, 1.0, // å‘¨æœŸæ€§æ¨¡å¼
    ];
    
    let analysis = ai_manager.analyze(AnalysisType::PatternRecognition, pattern_data, "pattern_recognition".to_string()).await?;
    
    if let c17_iot::ai_integration::AnalysisResults::Pattern(pattern_result) = analysis.results {
        println!("    è¯†åˆ«åˆ°çš„æ¨¡å¼æ•°é‡: {}", pattern_result.pattern_count);
        println!("    æ¨¡å¼è´¨é‡: {:.2}", pattern_result.pattern_quality);
        
        for (i, pattern) in pattern_result.patterns.iter().enumerate() {
            println!("      æ¨¡å¼ {}: {}", i + 1, pattern.description);
            println!("        ç±»å‹: {}", pattern.pattern_type);
            println!("        å¼ºåº¦: {:.2}", pattern.strength);
            println!("        ä½ç½®: {:?}", pattern.positions);
        }
    }

    Ok(())
}

/// æ‰¹é‡å¤„ç†æ¼”ç¤º
async fn demo_batch_processing() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    // æ³¨å†Œæ‰¹é‡é¢„æµ‹æ¨¡å‹
    let model_config = AIModelConfig {
        model_type: AIModelType::Prediction,
        name: "batch_predictor".to_string(),
        version: "1.0".to_string(),
        model_path: "/models/batch_predictor".to_string(),
        input_features: 3,
        output_dimensions: 1,
        enable_gpu: true,
        batch_size: 10,
        confidence_threshold: 0.8,
        custom_params: HashMap::new(),
    };
    
    ai_manager.register_model(model_config).await?;
    
    println!("  æ‰§è¡Œæ‰¹é‡é¢„æµ‹...");
    
    // å‡†å¤‡æ‰¹é‡æ•°æ®
    let batch_data = vec![
        vec![1.0, 2.0, 3.0],
        vec![2.0, 3.0, 4.0],
        vec![3.0, 4.0, 5.0],
        vec![4.0, 5.0, 6.0],
        vec![5.0, 6.0, 7.0],
    ];
    
    println!("    æ‰¹é‡æ•°æ®å¤§å°: {}", batch_data.len());
    
    let start_time = std::time::Instant::now();
    let predictions = ai_manager.batch_predict("batch_predictor", batch_data).await?;
    let batch_time = start_time.elapsed();
    
    println!("    æ‰¹é‡é¢„æµ‹å®Œæˆï¼Œè€—æ—¶: {:?}", batch_time);
    println!("    é¢„æµ‹ç»“æœæ•°é‡: {}", predictions.len());
    
    for (i, prediction) in predictions.iter().enumerate() {
        println!("      é¢„æµ‹ {}: å€¼={:.2}, ç½®ä¿¡åº¦={:.2}%", 
                i + 1, 
                prediction.prediction[0], 
                prediction.confidence * 100.0);
    }

    Ok(())
}

/// å®æ—¶åˆ†ææ¼”ç¤º
async fn demo_realtime_analysis() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    println!("  æ‰§è¡Œå®æ—¶åˆ†æ...");
    
    // æ¨¡æ‹Ÿå®æ—¶æ•°æ®æµ
    let realtime_data = vec![
        0.8, 0.75, 0.82, 0.78, 0.85, 0.88, 0.92, 0.95, 0.98, 1.0, // ç³»ç»Ÿè´Ÿè½½ä¸Šå‡
    ];
    
    let analysis = ai_manager.analyze(AnalysisType::RealTimeAnalysis, realtime_data, "realtime_monitor".to_string()).await?;
    
    if let c17_iot::ai_integration::AnalysisResults::RealTime(realtime_result) = analysis.results {
        println!("    å®æ—¶æŒ‡æ ‡:");
        for (metric, value) in &realtime_result.metrics {
            println!("      {}: {:.2}", metric, value);
        }
        
        println!("    å®æ—¶çŠ¶æ€: {:?}", realtime_result.status);
        println!("    å‘Šè­¦æ•°é‡: {}", realtime_result.alerts.len());
        println!("    å»ºè®®æ•°é‡: {}", realtime_result.suggestions.len());
        
        for (i, suggestion) in realtime_result.suggestions.iter().enumerate() {
            println!("      å»ºè®® {}: {}", i + 1, suggestion);
        }
    }

    Ok(())
}

/// AIç»Ÿè®¡å’ŒæŠ¥å‘Šæ¼”ç¤º
async fn demo_ai_statistics() -> Result<(), Box<dyn std::error::Error>> {
    let ai_manager = AIIntegrationManager::new(AIConfig::default());
    
    println!("  ç”ŸæˆAIç»Ÿè®¡æŠ¥å‘Š...");
    
    // æ‰§è¡Œä¸€äº›æ“ä½œä»¥ç”Ÿæˆç»Ÿè®¡æ•°æ®
    let model_config = AIModelConfig {
        model_type: AIModelType::Prediction,
        name: "stats_model".to_string(),
        version: "1.0".to_string(),
        model_path: "/models/stats_model".to_string(),
        input_features: 2,
        output_dimensions: 1,
        enable_gpu: false,
        batch_size: 1,
        confidence_threshold: 0.8,
        custom_params: HashMap::new(),
    };
    
    ai_manager.register_model(model_config).await?;
    
    // æ‰§è¡Œä¸€äº›é¢„æµ‹
    for i in 0..5 {
        let features = vec![i as f64, (i + 1) as f64];
        let _ = ai_manager.predict("stats_model", features).await?;
    }
    
    // æ‰§è¡Œä¸€äº›åˆ†æ
    for i in 0..3 {
        let data = vec![i as f64, (i + 1) as f64, (i + 2) as f64];
        let _ = ai_manager.analyze(AnalysisType::TrendAnalysis, data, "stats_analysis".to_string()).await?;
    }
    
    // è·å–ç»Ÿè®¡ä¿¡æ¯
    let stats = ai_manager.get_stats().await;
    println!("  AIç»Ÿè®¡æŠ¥å‘Š:");
    println!("    æ€»é¢„æµ‹æ•°: {}", stats.total_predictions);
    println!("    æ€»åˆ†ææ•°: {}", stats.total_analyses);
    println!("    å¹³å‡é¢„æµ‹æ—¶é—´: {:?}", stats.avg_prediction_time);
    println!("    å¹³å‡åˆ†ææ—¶é—´: {:?}", stats.avg_analysis_time);
    println!("    é¢„æµ‹å‡†ç¡®ç‡: {:.2}%", stats.prediction_accuracy * 100.0);
    println!("    åˆ†ææˆåŠŸç‡: {:.2}%", stats.analysis_success_rate * 100.0);
    println!("    æœ€åæ›´æ–°æ—¶é—´: {}", stats.last_updated.format("%Y-%m-%d %H:%M:%S"));
    
    println!("    æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡:");
    for (model_name, usage_count) in &stats.model_usage {
        println!("      {}: {} æ¬¡", model_name, usage_count);
    }
    
    // è·å–é¢„æµ‹å†å²
    let prediction_history = ai_manager.get_prediction_history(Some(3)).await;
    println!("    æœ€è¿‘é¢„æµ‹å†å² ({} æ¡):", prediction_history.len());
    for (i, prediction) in prediction_history.iter().enumerate() {
        println!("      {}: {} - ç½®ä¿¡åº¦ {:.2}%", 
                i + 1, 
                prediction.model_name, 
                prediction.confidence * 100.0);
    }
    
    // è·å–åˆ†æå†å²
    let analysis_history = ai_manager.get_analysis_history(Some(2)).await;
    println!("    æœ€è¿‘åˆ†æå†å² ({} æ¡):", analysis_history.len());
    for (i, analysis) in analysis_history.iter().enumerate() {
        println!("      {}: {:?} - å¤„ç†æ—¶é—´ {:?}", 
                i + 1, 
                analysis.analysis_type, 
                analysis.processing_time);
    }

    Ok(())
}
