# 3.5 Rust 类型系统 - 性能优化参考

> **文档类型**: Tier 3 - 参考层  
> **文档定位**: 类型系统性能优化完整参考  
> **适用对象**: 中级 → 高级开发者  
> **前置知识**: [2.3 泛型编程指南](../tier_02_guides/03_泛型编程指南.md), [3.3 分派机制参考](./03_分派机制参考.md)  
> **最后更新**: 2025-10-22

---

## 📋 目录

- [3.5 Rust 类型系统 - 性能优化参考](#35-rust-类型系统---性能优化参考)
  - [📋 目录](#-目录)
  - [🎯 概述](#-概述)
  - [1. 零成本抽象](#1-零成本抽象)
    - [1.1 核心原则](#11-核心原则)
    - [1.2 单态化](#12-单态化)
    - [1.3 内联优化](#13-内联优化)
  - [2. 内存布局优化](#2-内存布局优化)
    - [2.1 结构体布局](#21-结构体布局)
    - [2.2 枚举优化](#22-枚举优化)
    - [2.3 零大小类型](#23-零大小类型)
  - [3. 避免分配](#3-避免分配)
    - [3.1 栈 vs 堆](#31-栈-vs-堆)
    - [3.2 SmallVec 和 Cow](#32-smallvec-和-cow)
    - [3.3 Arena 分配](#33-arena-分配)
  - [4. 编译时计算](#4-编译时计算)
    - [4.1 Const 泛型](#41-const-泛型)
    - [4.2 Const 函数](#42-const-函数)
    - [4.3 类型级计算](#43-类型级计算)
    - [4.4 编译时字符串处理](#44-编译时字符串处理)
    - [4.5 Build-Time Code Generation](#45-build-time-code-generation)
  - [5. 缓存友好](#5-缓存友好)
    - [5.1 数据局部性](#51-数据局部性)
    - [5.2 内存对齐](#52-内存对齐)
    - [5.3 预取](#53-预取)
    - [5.4 向量化计算](#54-向量化计算)
    - [5.5 数据结构的缓存优化](#55-数据结构的缓存优化)
    - [5.6 批处理优化](#56-批处理优化)
  - [6. 性能测量](#6-性能测量)
    - [6.1 Criterion](#61-criterion)
    - [6.2 Profiling](#62-profiling)
    - [6.3 优化策略](#63-优化策略)
  - [7. 实战案例](#7-实战案例)
    - [案例 1: 高性能集合](#案例-1-高性能集合)
    - [案例 2: 零拷贝解析](#案例-2-零拷贝解析)
    - [案例 3: SIMD 优化](#案例-3-simd-优化)
    - [案例 4: 自定义分配器](#案例-4-自定义分配器)
    - [案例 5: 内存池优化](#案例-5-内存池优化)
  - [8. 常见陷阱](#8-常见陷阱)
  - [9. 总结](#9-总结)
  - [10. 参考资源](#10-参考资源)

---

## 🎯 概述

Rust 的类型系统提供了**零成本抽象**：

| 优化维度 | 技术 | 收益 |
|---------|------|------|
| **编译时** | 单态化 + 内联 | 消除抽象开销 |
| **内存** | 布局优化 + ZST | 减少内存占用 |
| **分配** | 栈分配 + Arena | 减少堆分配 |
| **缓存** | 数据局部性 + 对齐 | 提升缓存命中 |

---

## 1. 零成本抽象

### 1.1 核心原则

**"你不用的不付费，你使用的无法写得更快"**-

```rust
// 抽象代码
fn sum_generic<T: std::iter::Iterator<Item = i32>>(iter: T) -> i32 {
    iter.sum()
}

// 编译后等价于手写循环
fn sum_manual(slice: &[i32]) -> i32 {
    let mut total = 0;
    for &item in slice {
        total += item;
    }
    total
}

fn main() {
    let data = vec![1, 2, 3, 4, 5];
    
    // 两者性能相同
    let result1 = sum_generic(data.iter().copied());
    let result2 = sum_manual(&data);
    
    println!("{} {}", result1, result2);
}
```

### 1.2 单态化

**为每个具体类型生成专门代码**:

```rust
fn process<T: std::fmt::Display>(value: T) {
    println!("Value: {}", value);
}

fn main() {
    process(42);      // 生成 process_i32
    process(3.14);    // 生成 process_f64
    process("hi");    // 生成 process_str
}
```

**性能对比**:

```rust
use std::time::Instant;

trait Compute {
    fn compute(&self) -> i64;
}

struct Simple(i64);

impl Compute for Simple {
    fn compute(&self) -> i64 {
        self.0 * 2
    }
}

// 静态分发
fn static_sum<T: Compute>(items: &[T]) -> i64 {
    items.iter().map(|x| x.compute()).sum()
}

// 动态分发
fn dynamic_sum(items: &[&dyn Compute]) -> i64 {
    items.iter().map(|x| x.compute()).sum()
}

fn main() {
    let items: Vec<Simple> = (0..1_000_000).map(Simple).collect();
    
    let start = Instant::now();
    let _result = static_sum(&items);
    println!("Static: {:?}", start.elapsed());
    
    let dyn_items: Vec<&dyn Compute> = items.iter()
        .map(|x| x as &dyn Compute)
        .collect();
    
    let start = Instant::now();
    let _result = dynamic_sum(&dyn_items);
    println!("Dynamic: {:?}", start.elapsed());
}
```

### 1.3 内联优化

**#[inline] 属性**:

```rust
// 总是内联
#[inline(always)]
fn hot_function(x: i32) -> i32 {
    x * 2 + 1
}

// 提示编译器内联
#[inline]
fn warm_function(x: i32) -> i32 {
    x + 1
}

// 禁止内联
#[inline(never)]
fn cold_function(x: i32) -> i32 {
    println!("Called with {}", x);
    x
}

fn main() {
    let result = hot_function(21);
    println!("Result: {}", result);
}
```

---

## 2. 内存布局优化

### 2.1 结构体布局

**字段顺序影响大小**:

```rust
use std::mem;

// ❌ 未优化：16 字节 (填充)
struct Unoptimized {
    a: u8,   // 1 byte
    // 3 bytes padding
    b: u32,  // 4 bytes
    c: u8,   // 1 byte
    // 3 bytes padding
}

// ✅ 优化：8 字节
struct Optimized {
    b: u32,  // 4 bytes
    a: u8,   // 1 byte
    c: u8,   // 1 byte
    // 2 bytes padding
}

fn main() {
    println!("Unoptimized: {}", mem::size_of::<Unoptimized>());  // 12
    println!("Optimized: {}", mem::size_of::<Optimized>());      // 8
}
```

### 2.2 枚举优化

**空指针优化**:

```rust
use std::mem;

// Option<Box<T>> 大小等于 Box<T>
fn main() {
    println!("Box<i32>: {}", mem::size_of::<Box<i32>>());           // 8
    println!("Option<Box<i32>>: {}", mem::size_of::<Option<Box<i32>>>());  // 8
    
    // 利用 Box 不为 null，None 用 null 表示
}
```

**Discriminant 优化**:

```rust
use std::mem;

// 小枚举
enum Small {
    A,
    B,
    C,
}

// 带数据的枚举
enum WithData {
    A(u32),
    B(u64),
    C,
}

fn main() {
    println!("Small: {}", mem::size_of::<Small>());         // 1
    println!("WithData: {}", mem::size_of::<WithData>());   // 16 (8 + 8)
}
```

### 2.3 零大小类型

**ZST 不占空间**:

```rust
use std::mem;

struct Empty;

struct PhantomMarker<T> {
    _marker: std::marker::PhantomData<T>,
}

fn main() {
    println!("Empty: {}", mem::size_of::<Empty>());                // 0
    println!("PhantomMarker<i32>: {}", mem::size_of::<PhantomMarker<i32>>());  // 0
    
    // Vec 的分配不受 ZST 影响
    let vec: Vec<Empty> = vec![Empty; 1000];
    println!("Vec<Empty> capacity: {}", vec.capacity());  // 不分配
}
```

---

## 3. 避免分配

### 3.1 栈 vs 堆

**优先使用栈**:

```rust
// ❌ 堆分配
fn heap_allocation() -> Box<[i32; 1000]> {
    Box::new([0; 1000])
}

// ✅ 栈分配
fn stack_allocation() -> [i32; 1000] {
    [0; 1000]
}

// ✅ 引用，避免移动
fn reference_stack(data: &[i32; 1000]) {
    println!("Sum: {}", data.iter().sum::<i32>());
}

fn main() {
    let data = stack_allocation();
    reference_stack(&data);
}
```

### 3.2 SmallVec 和 Cow

**SmallVec**:

```rust
use smallvec::{SmallVec, smallvec};

fn main() {
    // 小数据在栈上
    let mut vec: SmallVec<[i32; 4]> = smallvec![1, 2, 3];
    println!("On stack: {:?}", vec);
    
    // 超出容量后才堆分配
    vec.push(4);
    vec.push(5);
    println!("Now on heap: {:?}", vec);
}
```

**Cow (Clone on Write)**:

```rust
use std::borrow::Cow;

fn process(input: &str) -> Cow<str> {
    if input.contains("bad") {
        // 需要修改，分配
        Cow::Owned(input.replace("bad", "good"))
    } else {
        // 不需要修改，借用
        Cow::Borrowed(input)
    }
}

fn main() {
    let text1 = "This is bad";
    let text2 = "This is fine";
    
    let result1 = process(text1);  // 分配
    let result2 = process(text2);  // 不分配
    
    println!("{} {}", result1, result2);
}
```

### 3.3 Arena 分配

**批量分配，批量释放**:

```rust
use typed_arena::Arena;

struct Node<'a> {
    value: i32,
    next: Option<&'a Node<'a>>,
}

fn main() {
    let arena = Arena::new();
    
    // 在 arena 中分配，无需单独释放
    let node1 = arena.alloc(Node {
        value: 1,
        next: None,
    });
    
    let node2 = arena.alloc(Node {
        value: 2,
        next: Some(node1),
    });
    
    println!("Node2: {}", node2.value);
    
    // arena 析构时一次性释放所有节点
}
```

---

## 4. 编译时计算

### 4.1 Const 泛型

**编译时确定数组大小**:

```rust
// 泛型数组，零运行时开销
fn sum<const N: usize>(arr: &[i32; N]) -> i32 {
    arr.iter().sum()
}

fn main() {
    let arr3 = [1, 2, 3];
    let arr5 = [1, 2, 3, 4, 5];
    
    println!("Sum3: {}", sum(&arr3));
    println!("Sum5: {}", sum(&arr5));
}
```

### 4.2 Const 函数

**编译时求值**:

```rust
const fn factorial(n: u32) -> u32 {
    match n {
        0 | 1 => 1,
        _ => n * factorial(n - 1),
    }
}

// 编译时计算
const FACT_5: u32 = factorial(5);

fn main() {
    println!("5! = {}", FACT_5);  // 120，编译时已知
}
```

### 4.3 类型级计算

**使用类型系统进行计算**:

```rust
use std::marker::PhantomData;

struct Zero;
struct Succ<N>(PhantomData<N>);

type One = Succ<Zero>;
type Two = Succ<One>;
type Three = Succ<Two>;

// 类型级加法
trait Add<N> {
    type Output;
}

impl<N> Add<Zero> for N {
    type Output = N;
}

impl<N, M> Add<Succ<M>> for N
where
    N: Add<M>,
    Succ<N::Output>: Sized,
{
    type Output = Succ<N::Output>;
}

fn main() {
    // 类型系统证明 1 + 2 = 3
    let _: <One as Add<Two>>::Output = Succ(PhantomData::<Two>);
}
```

### 4.4 编译时字符串处理

**const fn进阶**:

```rust
const fn parse_hex(s: &str) -> Option<u32> {
    let bytes = s.as_bytes();
    if bytes.len() == 0 {
        return None;
    }
    
    let mut result = 0u32;
    let mut i = 0;
    
    while i < bytes.len() {
        let digit = match bytes[i] {
            b'0'..=b'9' => bytes[i] - b'0',
            b'a'..=b'f' => bytes[i] - b'a' + 10,
            b'A'..=b'F' => bytes[i] - b'A' + 10,
            _ => return None,
        };
        
        result = result * 16 + digit as u32;
        i += 1;
    }
    
    Some(result)
}

const HEX_VALUE: u32 = match parse_hex("FF") {
    Some(v) => v,
    None => 0,
};

fn main() {
    println!("0xFF = {}", HEX_VALUE);  // 255，编译时已知
}
```

### 4.5 Build-Time Code Generation

**使用build.rs生成代码**:

```rust
// build.rs
use std::env;
use std::fs::File;
use std::io::Write;
use std::path::Path;

fn main() {
    let out_dir = env::var("OUT_DIR").unwrap();
    let dest_path = Path::new(&out_dir).join("lookup_table.rs");
    let mut f = File::create(&dest_path).unwrap();
    
    // 生成查找表
    writeln!(f, "const LOOKUP_TABLE: [u32; 256] = [").unwrap();
    for i in 0..256 {
        writeln!(f, "    {},", compute_expensive(i)).unwrap();
    }
    writeln!(f, "];").unwrap();
}

fn compute_expensive(x: u32) -> u32 {
    // 昂贵的计算，在编译时执行
    x * x + 2 * x + 1
}
```

```rust
// main.rs
include!(concat!(env!("OUT_DIR"), "/lookup_table.rs"));

fn fast_compute(x: u8) -> u32 {
    LOOKUP_TABLE[x as usize]  // O(1)查找，无运行时计算
}

fn main() {
    println!("Value: {}", fast_compute(10));
}
```

---

## 5. 缓存友好

### 5.1 数据局部性

**SoA vs AoS**:

```rust
// ❌ AoS (Array of Structs) - 缓存不友好
struct PointAoS {
    x: f32,
    y: f32,
    z: f32,
}

fn sum_x_aos(points: &[PointAoS]) -> f32 {
    points.iter().map(|p| p.x).sum()
}

// ✅ SoA (Struct of Arrays) - 缓存友好
struct PointsSoA {
    x: Vec<f32>,
    y: Vec<f32>,
    z: Vec<f32>,
}

fn sum_x_soa(points: &PointsSoA) -> f32 {
    points.x.iter().sum()
}

fn main() {
    let aos: Vec<PointAoS> = vec![
        PointAoS { x: 1.0, y: 2.0, z: 3.0 },
        PointAoS { x: 4.0, y: 5.0, z: 6.0 },
    ];
    
    let soa = PointsSoA {
        x: vec![1.0, 4.0],
        y: vec![2.0, 5.0],
        z: vec![3.0, 6.0],
    };
    
    println!("AoS sum: {}", sum_x_aos(&aos));
    println!("SoA sum: {}", sum_x_soa(&soa));
}
```

### 5.2 内存对齐

**对齐到缓存行**:

```rust
use std::mem;

#[repr(align(64))]  // 对齐到典型缓存行大小
struct CacheLineAligned {
    data: [u8; 64],
}

fn main() {
    println!("Alignment: {}", mem::align_of::<CacheLineAligned>());
}
```

### 5.3 预取

**预取数据到缓存**:

```rust
use std::arch::x86_64::{_mm_prefetch, _MM_HINT_T0};

fn process_with_prefetch(data: &[i32]) -> i64 {
    let mut sum = 0i64;
    
    for i in 0..data.len() {
        // 预取下一个元素
        if i + 1 < data.len() {
            unsafe {
                _mm_prefetch(
                    &data[i + 1] as *const i32 as *const i8,
                    _MM_HINT_T0,
                );
            }
        }
        sum += data[i] as i64;
    }
    
    sum
}

fn main() {
    let data: Vec<i32> = (0..1000).collect();
    let result = process_with_prefetch(&data);
    println!("Sum: {}", result);
}
```

### 5.4 向量化计算

**SIMD优化**:

```rust
use std::arch::x86_64::*;

// 标量版本
fn add_scalar(a: &[f32], b: &[f32], result: &mut [f32]) {
    for i in 0..a.len() {
        result[i] = a[i] + b[i];
    }
}

// SIMD版本（使用AVX）
#[target_feature(enable = "avx")]
unsafe fn add_simd(a: &[f32], b: &[f32], result: &mut [f32]) {
    let chunks = a.len() / 8;
    
    for i in 0..chunks {
        let offset = i * 8;
        
        // 加载8个浮点数
        let va = _mm256_loadu_ps(a.as_ptr().add(offset));
        let vb = _mm256_loadu_ps(b.as_ptr().add(offset));
        
        // 向量加法
        let vr = _mm256_add_ps(va, vb);
        
        // 存储结果
        _mm256_storeu_ps(result.as_mut_ptr().add(offset), vr);
    }
    
    // 处理剩余元素
    for i in (chunks * 8)..a.len() {
        result[i] = a[i] + b[i];
    }
}

fn main() {
    let a = vec![1.0f32; 1000];
    let b = vec![2.0f32; 1000];
    let mut result = vec![0.0f32; 1000];
    
    unsafe {
        add_simd(&a, &b, &mut result);
    }
}
```

### 5.5 数据结构的缓存优化

**热/冷数据分离**:

```rust
// ❌ 混合存储（缓存不友好）
struct EntityBad {
    id: u32,
    position: (f32, f32, f32),
    velocity: (f32, f32, f32),
    health: f32,
    name: String,          // 不常访问
    description: String,   // 不常访问
}

// ✅ 分离存储（缓存友好）
struct EntityHot {
    id: u32,
    position: (f32, f32, f32),
    velocity: (f32, f32, f32),
    health: f32,
    cold_index: usize,  // 指向冷数据
}

struct EntityCold {
    name: String,
    description: String,
}

struct EntitySystem {
    hot: Vec<EntityHot>,
    cold: Vec<EntityCold>,
}

impl EntitySystem {
    fn update_positions(&mut self, dt: f32) {
        // 只访问热数据，缓存友好
        for entity in &mut self.hot {
            entity.position.0 += entity.velocity.0 * dt;
            entity.position.1 += entity.velocity.1 * dt;
            entity.position.2 += entity.velocity.2 * dt;
        }
    }
}
```

### 5.6 批处理优化

**批量处理提升缓存命中**:

```rust
// ❌ 逐个处理
fn process_individually(items: &[Item]) {
    for item in items {
        expensive_operation(item);
    }
}

// ✅ 批量处理
fn process_batched(items: &[Item]) {
    const BATCH_SIZE: usize = 64;
    
    for batch in items.chunks(BATCH_SIZE) {
        // 预处理整个批次
        let mut preprocessed = Vec::with_capacity(BATCH_SIZE);
        for item in batch {
            preprocessed.push(preprocess(item));
        }
        
        // 批量处理
        for data in preprocessed {
            cheap_operation(&data);
        }
    }
}

struct Item {
    data: [u8; 16],
}

fn preprocess(item: &Item) -> [u8; 16] {
    item.data
}

fn cheap_operation(_data: &[u8; 16]) {
    // 快速操作
}

fn expensive_operation(_item: &Item) {
    // 昂贵操作
}
```

---

## 6. 性能测量

### 6.1 Criterion

**基准测试**:

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn fibonacci(n: u64) -> u64 {
    match n {
        0 | 1 => n,
        _ => fibonacci(n - 1) + fibonacci(n - 2),
    }
}

fn criterion_benchmark(c: &mut Criterion) {
    c.bench_function("fib 20", |b| b.iter(|| fibonacci(black_box(20))));
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
```

### 6.2 Profiling

**使用 perf/flamegraph**:

```bash
# Linux perf
cargo build --release
perf record --call-graph dwarf ./target/release/myapp
perf report

# Flamegraph
cargo flamegraph
```

### 6.3 优化策略

**逐步优化**:

1. **测量**: 先测量，找到瓶颈
2. **优化**: 针对热点优化
3. **验证**: 再次测量，确认效果

```rust
use std::time::Instant;

fn benchmark<F: Fn()>(name: &str, f: F) {
    let start = Instant::now();
    f();
    println!("{}: {:?}", name, start.elapsed());
}

fn main() {
    benchmark("Version 1", || {
        // 实现 1
    });
    
    benchmark("Version 2", || {
        // 实现 2
    });
}
```

---

## 7. 实战案例

### 案例 1: 高性能集合

```rust
use std::collections::HashMap;

// 预分配容量
fn optimized_hashmap() -> HashMap<i32, String> {
    let mut map = HashMap::with_capacity(1000);
    
    for i in 0..1000 {
        map.insert(i, format!("value{}", i));
    }
    
    map
}

// 使用 FxHash (更快的哈希)
use rustc_hash::FxHashMap;

fn fast_hashmap() -> FxHashMap<i32, String> {
    let mut map = FxHashMap::default();
    
    for i in 0..1000 {
        map.insert(i, format!("value{}", i));
    }
    
    map
}

fn main() {
    let _map1 = optimized_hashmap();
    let _map2 = fast_hashmap();
}
```

### 案例 2: 零拷贝解析

```rust
use std::str;

// ❌ 分配新字符串
fn parse_owned(data: &[u8]) -> Vec<String> {
    str::from_utf8(data)
        .unwrap()
        .split(',')
        .map(|s| s.to_string())
        .collect()
}

// ✅ 零拷贝，返回切片
fn parse_borrowed(data: &[u8]) -> Vec<&str> {
    str::from_utf8(data)
        .unwrap()
        .split(',')
        .collect()
}

fn main() {
    let data = b"a,b,c,d,e";
    
    let owned = parse_owned(data);
    let borrowed = parse_borrowed(data);
    
    println!("Owned: {:?}", owned);
    println!("Borrowed: {:?}", borrowed);
}
```

### 案例 3: SIMD 优化

```rust
use std::arch::x86_64::*;

// 标量版本
fn sum_scalar(data: &[f32]) -> f32 {
    data.iter().sum()
}

// SIMD 版本
unsafe fn sum_simd(data: &[f32]) -> f32 {
    let mut sum = _mm_setzero_ps();
    let chunks = data.chunks_exact(4);
    let remainder = chunks.remainder();
    
    for chunk in chunks {
        let values = _mm_loadu_ps(chunk.as_ptr());
        sum = _mm_add_ps(sum, values);
    }
    
    // 水平求和
    let mut result = [0f32; 4];
    _mm_storeu_ps(result.as_mut_ptr(), sum);
    let total = result.iter().sum::<f32>();
    
    // 加上余数
    total + remainder.iter().sum::<f32>()
}

fn main() {
    let data: Vec<f32> = (0..1000).map(|x| x as f32).collect();
    
    let result1 = sum_scalar(&data);
    let result2 = unsafe { sum_simd(&data) };
    
    println!("Scalar: {}", result1);
    println!("SIMD: {}", result2);
}
```

### 案例 4: 自定义分配器

**使用自定义分配器**:

```rust
use std::alloc::{GlobalAlloc, Layout, System};
use std::ptr;

struct CountingAllocator;

static mut ALLOCATION_COUNT: usize = 0;

unsafe impl GlobalAlloc for CountingAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        ALLOCATION_COUNT += 1;
        System.alloc(layout)
    }
    
    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        System.dealloc(ptr, layout)
    }
}

#[global_allocator]
static GLOBAL: CountingAllocator = CountingAllocator;

fn main() {
    let data: Vec<i32> = vec![1, 2, 3, 4, 5];
    println!("Allocated {} times", unsafe { ALLOCATION_COUNT });
}
```

### 案例 5: 内存池优化

**对象池模式**:

```rust
use std::sync::Mutex;

struct ObjectPool<T> {
    objects: Mutex<Vec<T>>,
    factory: fn() -> T,
}

impl<T> ObjectPool<T> {
    fn new(factory: fn() -> T, initial_size: usize) -> Self {
        let objects = (0..initial_size).map(|_| factory()).collect();
        ObjectPool {
            objects: Mutex::new(objects),
            factory,
        }
    }
    
    fn acquire(&self) -> PooledObject<T> {
        let obj = self.objects.lock().unwrap().pop()
            .unwrap_or_else(|| (self.factory)());
        PooledObject {
            pool: self,
            obj: Some(obj),
        }
    }
    
    fn release(&self, obj: T) {
        self.objects.lock().unwrap().push(obj);
    }
}

struct PooledObject<'a, T> {
    pool: &'a ObjectPool<T>,
    obj: Option<T>,
}

impl<'a, T> Drop for PooledObject<'a, T> {
    fn drop(&mut self) {
        if let Some(obj) = self.obj.take() {
            self.pool.release(obj);
        }
    }
}

impl<'a, T> std::ops::Deref for PooledObject<'a, T> {
    type Target = T;
    
    fn deref(&self) -> &T {
        self.obj.as_ref().unwrap()
    }
}

impl<'a, T> std::ops::DerefMut for PooledObject<'a, T> {
    fn deref_mut(&mut self) -> &mut T {
        self.obj.as_mut().unwrap()
    }
}

// 使用示例
fn main() {
    let pool = ObjectPool::new(Vec::<i32>::new, 10);
    
    {
        let mut obj = pool.acquire();
        obj.push(1);
        obj.push(2);
        // 自动归还到池中
    }
    
    let obj2 = pool.acquire();  // 重用之前的 Vec
    println!("Len: {}", obj2.len());
}
```

---

## 8. 常见陷阱

**陷阱 1: 过早优化**:

```rust
// ❌ 不必要的优化
// fn complex_optimization() { ... }

// ✅ 先写清晰代码，再优化瓶颈
fn clear_code() {
    // 清晰易懂的实现
}
```

**陷阱 2: 不测量就优化**:

```rust
// ❌ 凭感觉优化
// "这个应该更快"

// ✅ 基于数据优化
use criterion::{black_box, Criterion};

fn benchmark(c: &mut Criterion) {
    c.bench_function("version_a", |b| {
        b.iter(|| black_box(version_a()))
    });
    
    c.bench_function("version_b", |b| {
        b.iter(|| black_box(version_b()))
    });
}

fn version_a() {}
fn version_b() {}
```

**陷阱 3: 忽略编译器优化**:

```rust
// 编译器已经很智能
// 不要过度手动优化

// ✅ 信任编译器
fn simple_sum(data: &[i32]) -> i32 {
    data.iter().sum()  // 已经很快
}
```

---

## 9. 总结

**优化清单**:

| 技术 | 何时使用 | 收益 |
|------|---------|------|
| **静态分发** | 性能关键路径 | 高 |
| **内联** | 小函数 | 中 |
| **布局优化** | 大量小对象 | 中 |
| **避免分配** | 热路径 | 高 |
| **SoA** | 大量数据处理 | 高 |
| **SIMD** | 数值计算 | 非常高 |

**核心原则**:

1. ✅ 先测量，再优化
2. ✅ 优化热点，不是全部
3. ✅ 保持代码清晰
4. ✅ 信任编译器
5. ✅ 零成本抽象

---

## 10. 参考资源

**工具**:

- [Criterion](https://github.com/bheisler/criterion.rs)
- [Flamegraph](https://github.com/flamegraph-rs/flamegraph)
- [perf](https://perf.wiki.kernel.org/)

**相关文档**:

- [2.3 泛型编程指南](../tier_02_guides/03_泛型编程指南.md)
- [3.3 分派机制参考](./03_分派机制参考.md)
- [The Rust Performance Book](https://nnethercote.github.io/perf-book/)

---

**最后更新**: 2025-10-22  
**适用版本**: Rust 1.90+  
**文档类型**: Tier 3 - 参考层

---

**🎉 完成性能优化参考学习！** 🦀
