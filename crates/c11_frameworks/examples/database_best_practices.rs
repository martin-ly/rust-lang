//! æ•°æ®åº“æœ€ä½³å®è·µç¤ºä¾‹
//! 
//! å±•ç¤ºRustä¸­ä¸åŒæ•°æ®åº“çš„æ“ä½œæ¨¡å¼å’Œæœ€ä½³å®è·µ

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::Duration;
use tokio::time::sleep;
use uuid::Uuid;

/// ç”¨æˆ·æ¨¡å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct User {
    pub id: Uuid,
    pub name: String,
    pub email: String,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}

/// è®¢å•æ¨¡å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Order {
    pub id: Uuid,
    pub user_id: Uuid,
    pub product_name: String,
    pub amount: f64,
    pub status: OrderStatus,
    pub created_at: chrono::DateTime<chrono::Utc>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum OrderStatus {
    Pending,
    Processing,
    Shipped,
    Delivered,
    Cancelled,
}

/// æ•°æ®åº“è¿æ¥æ± é…ç½®
#[derive(Debug, Clone)]
pub struct DatabaseConfig {
    pub max_connections: u32,
    pub min_connections: u32,
    pub connection_timeout: Duration,
    pub idle_timeout: Duration,
    pub max_lifetime: Duration,
}

impl Default for DatabaseConfig {
    fn default() -> Self {
        Self {
            max_connections: 10,
            min_connections: 1,
            connection_timeout: Duration::from_secs(30),
            idle_timeout: Duration::from_secs(600),
            max_lifetime: Duration::from_secs(1800),
        }
    }
}

/// æ•°æ®åº“æ“ä½œç»“æœ
#[derive(Debug)]
pub enum DatabaseResult<T> {
    Success(T),
    NotFound,
    Conflict(String),
    Timeout,
    ConnectionError(String),
    QueryError(String),
}

impl<T> DatabaseResult<T> {
    pub fn is_success(&self) -> bool {
        matches!(self, DatabaseResult::Success(_))
    }
    
    pub fn unwrap_or_default(self) -> T 
    where 
        T: Default 
    {
        match self {
            DatabaseResult::Success(value) => value,
            _ => T::default(),
        }
    }
}

/// æ•°æ®åº“æ“ä½œtrait
pub trait DatabaseOperations {
    type Connection;
    type Error;
    
    /// å»ºç«‹è¿æ¥
    async fn connect(&self) -> Result<Self::Connection, Self::Error>;
    
    /// æ‰§è¡Œäº‹åŠ¡
    async fn execute_transaction<F, R>(&self, f: F) -> Result<R, Self::Error>
    where
        F: FnOnce(&mut Self::Connection) -> Result<R, Self::Error> + Send + Sync;
    
    /// å¥åº·æ£€æŸ¥
    async fn health_check(&self) -> Result<bool, Self::Error>;
}

/// PostgreSQL æ•°æ®åº“æ“ä½œå®ç°
pub struct PostgresDatabase {
    config: DatabaseConfig,
    connection_string: String,
}

impl PostgresDatabase {
    pub fn new(connection_string: String, config: DatabaseConfig) -> Self {
        Self {
            config,
            connection_string,
        }
    }
    
    /// åˆ›å»ºç”¨æˆ·è¡¨
    pub async fn create_user_table(&self) -> DatabaseResult<()> {
        // æ¨¡æ‹Ÿåˆ›å»ºè¡¨
        sleep(Duration::from_millis(100)).await;
        println!("âœ… PostgreSQL: ç”¨æˆ·è¡¨åˆ›å»ºæˆåŠŸ");
        DatabaseResult::Success(())
    }
    
    /// æ’å…¥ç”¨æˆ·
    pub async fn insert_user(&self, user: &User) -> DatabaseResult<User> {
        // æ¨¡æ‹Ÿæ’å…¥æ“ä½œ
        sleep(Duration::from_millis(50)).await;
        println!("âœ… PostgreSQL: ç”¨æˆ· {} æ’å…¥æˆåŠŸ", user.name);
        DatabaseResult::Success(user.clone())
    }
    
    /// æŸ¥è¯¢ç”¨æˆ·
    pub async fn get_user(&self, id: Uuid) -> DatabaseResult<User> {
        // æ¨¡æ‹ŸæŸ¥è¯¢æ“ä½œ
        sleep(Duration::from_millis(30)).await;
        
        if id == Uuid::nil() {
            return DatabaseResult::NotFound;
        }
        
        let user = User {
            id,
            name: "ç¤ºä¾‹ç”¨æˆ·".to_string(),
            email: "user@example.com".to_string(),
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
        };
        
        println!("âœ… PostgreSQL: ç”¨æˆ· {} æŸ¥è¯¢æˆåŠŸ", user.name);
        DatabaseResult::Success(user)
    }
    
    /// æ‰¹é‡æ’å…¥
    pub async fn batch_insert_users(&self, users: &[User]) -> DatabaseResult<Vec<User>> {
        // æ¨¡æ‹Ÿæ‰¹é‡æ’å…¥
        sleep(Duration::from_millis(users.len() as u64 * 10)).await;
        println!("âœ… PostgreSQL: æ‰¹é‡æ’å…¥ {} ä¸ªç”¨æˆ·æˆåŠŸ", users.len());
        DatabaseResult::Success(users.to_vec())
    }
    
    /// å¤æ‚æŸ¥è¯¢
    pub async fn search_users(&self, query: &str, limit: usize) -> DatabaseResult<Vec<User>> {
        // æ¨¡æ‹Ÿå¤æ‚æŸ¥è¯¢
        sleep(Duration::from_millis(200)).await;
        
        let users: Vec<User> = (0..limit.min(5))
            .map(|i| User {
                id: Uuid::new_v4(),
                name: format!("ç”¨æˆ·{}", i + 1),
                email: format!("user{}@example.com", i + 1),
                created_at: chrono::Utc::now(),
                updated_at: chrono::Utc::now(),
            })
            .collect();
        
        println!("âœ… PostgreSQL: æœç´¢ '{}' è¿”å› {} ä¸ªç»“æœ", query, users.len());
        DatabaseResult::Success(users)
    }
}

/// Redis ç¼“å­˜æ“ä½œ
pub struct RedisCache {
    config: DatabaseConfig,
    connection_string: String,
}

impl RedisCache {
    pub fn new(connection_string: String, config: DatabaseConfig) -> Self {
        Self {
            config,
            connection_string,
        }
    }
    
    /// è®¾ç½®ç¼“å­˜
    pub async fn set(&self, key: &str, value: &str, ttl: Duration) -> DatabaseResult<()> {
        // æ¨¡æ‹ŸRedis SETæ“ä½œ
        sleep(Duration::from_millis(5)).await;
        println!("âœ… Redis: è®¾ç½®ç¼“å­˜ {} = {}", key, value);
        DatabaseResult::Success(())
    }
    
    /// è·å–ç¼“å­˜
    pub async fn get(&self, key: &str) -> DatabaseResult<Option<String>> {
        // æ¨¡æ‹ŸRedis GETæ“ä½œ
        sleep(Duration::from_millis(3)).await;
        
        if key == "not_found" {
            return DatabaseResult::Success(None);
        }
        
        let value = format!("cached_value_for_{}", key);
        println!("âœ… Redis: è·å–ç¼“å­˜ {} = {}", key, value);
        DatabaseResult::Success(Some(value))
    }
    
    /// åˆ é™¤ç¼“å­˜
    pub async fn delete(&self, key: &str) -> DatabaseResult<bool> {
        // æ¨¡æ‹ŸRedis DELæ“ä½œ
        sleep(Duration::from_millis(2)).await;
        println!("âœ… Redis: åˆ é™¤ç¼“å­˜ {}", key);
        DatabaseResult::Success(true)
    }
    
    /// æ‰¹é‡è®¾ç½®
    pub async fn mset(&self, pairs: &HashMap<String, String>) -> DatabaseResult<()> {
        // æ¨¡æ‹ŸRedis MSETæ“ä½œ
        sleep(Duration::from_millis(pairs.len() as u64 * 2)).await;
        println!("âœ… Redis: æ‰¹é‡è®¾ç½® {} ä¸ªé”®å€¼å¯¹", pairs.len());
        DatabaseResult::Success(())
    }
    
    /// è®¾ç½®è¿‡æœŸæ—¶é—´
    pub async fn expire(&self, key: &str, ttl: Duration) -> DatabaseResult<bool> {
        // æ¨¡æ‹ŸRedis EXPIREæ“ä½œ
        sleep(Duration::from_millis(1)).await;
        println!("âœ… Redis: è®¾ç½® {} è¿‡æœŸæ—¶é—´ {} ç§’", key, ttl.as_secs());
        DatabaseResult::Success(true)
    }
}

/// MongoDB æ–‡æ¡£æ•°æ®åº“æ“ä½œ
pub struct MongoDatabase {
    config: DatabaseConfig,
    connection_string: String,
}

impl MongoDatabase {
    pub fn new(connection_string: String, config: DatabaseConfig) -> Self {
        Self {
            config,
            connection_string,
        }
    }
    
    /// æ’å…¥æ–‡æ¡£
    pub async fn insert_document(&self, collection: &str, _document: &serde_json::Value) -> DatabaseResult<String> {
        // æ¨¡æ‹ŸMongoDBæ’å…¥æ“ä½œ
        sleep(Duration::from_millis(80)).await;
        let id = Uuid::new_v4().to_string();
        println!("âœ… MongoDB: åœ¨é›†åˆ {} ä¸­æ’å…¥æ–‡æ¡£ {}", collection, id);
        DatabaseResult::Success(id)
    }
    
    /// æŸ¥è¯¢æ–‡æ¡£
    pub async fn find_document(&self, collection: &str, _filter: &serde_json::Value) -> DatabaseResult<Option<serde_json::Value>> {
        // æ¨¡æ‹ŸMongoDBæŸ¥è¯¢æ“ä½œ
        sleep(Duration::from_millis(60)).await;
        
        let document = serde_json::json!({
            "_id": Uuid::new_v4().to_string(),
            "name": "ç¤ºä¾‹æ–‡æ¡£",
            "data": "è¿™æ˜¯ç¤ºä¾‹æ•°æ®",
            "created_at": chrono::Utc::now()
        });
        
        println!("âœ… MongoDB: åœ¨é›†åˆ {} ä¸­æŸ¥è¯¢åˆ°æ–‡æ¡£", collection);
        DatabaseResult::Success(Some(document))
    }
    
    /// æ›´æ–°æ–‡æ¡£
    pub async fn update_document(&self, collection: &str, _filter: &serde_json::Value, _update: &serde_json::Value) -> DatabaseResult<u64> {
        // æ¨¡æ‹ŸMongoDBæ›´æ–°æ“ä½œ
        sleep(Duration::from_millis(70)).await;
        println!("âœ… MongoDB: åœ¨é›†åˆ {} ä¸­æ›´æ–°æ–‡æ¡£", collection);
        DatabaseResult::Success(1)
    }
    
    /// èšåˆæŸ¥è¯¢
    pub async fn aggregate(&self, collection: &str, pipeline: &[serde_json::Value]) -> DatabaseResult<Vec<serde_json::Value>> {
        // æ¨¡æ‹ŸMongoDBèšåˆæ“ä½œ
        sleep(Duration::from_millis(150)).await;
        
        let results = vec![
            serde_json::json!({
                "_id": "category1",
                "count": 10,
                "total_amount": 1000.0
            }),
            serde_json::json!({
                "_id": "category2", 
                "count": 5,
                "total_amount": 500.0
            })
        ];
        
        println!("âœ… MongoDB: èšåˆæŸ¥è¯¢è¿”å› {} ä¸ªç»“æœ", results.len());
        DatabaseResult::Success(results)
    }
}

/// æ•°æ®åº“è¿æ¥æ± ç®¡ç†
pub struct ConnectionPool<T> {
    connections: Vec<T>,
    config: DatabaseConfig,
    current_size: usize,
}

impl<T> ConnectionPool<T> {
    pub fn new(config: DatabaseConfig) -> Self {
        Self {
            connections: Vec::new(),
            config,
            current_size: 0,
        }
    }
    
    /// è·å–è¿æ¥
    pub async fn get_connection(&mut self) -> Option<T> {
        if self.connections.is_empty() {
            if self.current_size < self.config.max_connections as usize {
                // åˆ›å»ºæ–°è¿æ¥
                self.current_size += 1;
                println!("ğŸ”— åˆ›å»ºæ–°è¿æ¥ï¼Œå½“å‰è¿æ¥æ•°: {}", self.current_size);
                return None; // å®é™…å®ç°ä¸­ä¼šåˆ›å»ºæ–°è¿æ¥
            } else {
                println!("âŒ è¿æ¥æ± å·²æ»¡ï¼Œæ— æ³•è·å–è¿æ¥");
                return None;
            }
        }
        
        let connection = self.connections.pop().unwrap();
        println!("ğŸ”— ä»è¿æ¥æ± è·å–è¿æ¥ï¼Œå‰©ä½™è¿æ¥æ•°: {}", self.connections.len());
        Some(connection)
    }
    
    /// å½’è¿˜è¿æ¥
    pub fn return_connection(&mut self, connection: T) {
        if self.connections.len() < self.config.max_connections as usize {
            self.connections.push(connection);
            println!("ğŸ”— è¿æ¥å·²å½’è¿˜ï¼Œå½“å‰è¿æ¥æ•°: {}", self.connections.len());
        } else {
            println!("ğŸ”— è¿æ¥æ± å·²æ»¡ï¼Œä¸¢å¼ƒè¿æ¥");
        }
    }
    
    /// å¥åº·æ£€æŸ¥
    pub async fn health_check(&self) -> bool {
        println!("ğŸ¥ æ‰§è¡Œè¿æ¥æ± å¥åº·æ£€æŸ¥");
        self.current_size > 0
    }
}

/// æ•°æ®åº“äº‹åŠ¡ç®¡ç†
pub struct TransactionManager {
    transactions: HashMap<String, TransactionState>,
}

#[derive(Debug, Clone)]
pub enum TransactionState {
    Started,
    Committed,
    RolledBack,
    Failed(String),
}

impl TransactionManager {
    pub fn new() -> Self {
        Self {
            transactions: HashMap::new(),
        }
    }
    
    /// å¼€å§‹äº‹åŠ¡
    pub async fn begin_transaction(&mut self, id: &str) -> DatabaseResult<()> {
        println!("ğŸ”„ å¼€å§‹äº‹åŠ¡: {}", id);
        self.transactions.insert(id.to_string(), TransactionState::Started);
        DatabaseResult::Success(())
    }
    
    /// æäº¤äº‹åŠ¡
    pub async fn commit_transaction(&mut self, id: &str) -> DatabaseResult<()> {
        if let Some(state) = self.transactions.get_mut(id) {
            *state = TransactionState::Committed;
            println!("âœ… æäº¤äº‹åŠ¡: {}", id);
            DatabaseResult::Success(())
        } else {
            DatabaseResult::NotFound
        }
    }
    
    /// å›æ»šäº‹åŠ¡
    pub async fn rollback_transaction(&mut self, id: &str) -> DatabaseResult<()> {
        if let Some(state) = self.transactions.get_mut(id) {
            *state = TransactionState::RolledBack;
            println!("ğŸ”„ å›æ»šäº‹åŠ¡: {}", id);
            DatabaseResult::Success(())
        } else {
            DatabaseResult::NotFound
        }
    }
    
    /// è·å–äº‹åŠ¡çŠ¶æ€
    pub fn get_transaction_state(&self, id: &str) -> Option<&TransactionState> {
        self.transactions.get(id)
    }
}

/// æ•°æ®åº“è¿ç§»ç®¡ç†
pub struct MigrationManager {
    migrations: Vec<Migration>,
    applied_migrations: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct Migration {
    pub version: String,
    pub name: String,
    pub up_sql: String,
    pub down_sql: String,
}

impl MigrationManager {
    pub fn new() -> Self {
        Self {
            migrations: Vec::new(),
            applied_migrations: Vec::new(),
        }
    }
    
    /// æ·»åŠ è¿ç§»
    pub fn add_migration(&mut self, migration: Migration) {
        self.migrations.push(migration);
    }
    
    /// æ‰§è¡Œè¿ç§»
    pub async fn migrate(&mut self) -> DatabaseResult<()> {
        println!("ğŸ”„ å¼€å§‹æ‰§è¡Œæ•°æ®åº“è¿ç§»");
        
        for migration in &self.migrations {
            if !self.applied_migrations.contains(&migration.version) {
                println!("ğŸ“ æ‰§è¡Œè¿ç§»: {} - {}", migration.version, migration.name);
                sleep(Duration::from_millis(100)).await;
                self.applied_migrations.push(migration.version.clone());
                println!("âœ… è¿ç§» {} æ‰§è¡ŒæˆåŠŸ", migration.version);
            }
        }
        
        println!("âœ… æ‰€æœ‰è¿ç§»æ‰§è¡Œå®Œæˆ");
        DatabaseResult::Success(())
    }
    
    /// å›æ»šè¿ç§»
    pub async fn rollback(&mut self, version: &str) -> DatabaseResult<()> {
        println!("ğŸ”„ å›æ»šè¿ç§»åˆ°ç‰ˆæœ¬: {}", version);
        
        for migration in self.migrations.iter().rev() {
            if migration.version.as_str() > version && self.applied_migrations.contains(&migration.version) {
                println!("ğŸ“ å›æ»šè¿ç§»: {} - {}", migration.version, migration.name);
                sleep(Duration::from_millis(100)).await;
                self.applied_migrations.retain(|v| v != &migration.version);
                println!("âœ… è¿ç§» {} å›æ»šæˆåŠŸ", migration.version);
            }
        }
        
        DatabaseResult::Success(())
    }
}

#[tokio::main]
async fn main() {
    println!("ğŸš€ æ•°æ®åº“æœ€ä½³å®è·µç¤ºä¾‹");
    println!("========================");
    
    // 1. PostgreSQL æ“ä½œç¤ºä¾‹
    println!("\nğŸ“Š PostgreSQL æ•°æ®åº“æ“ä½œ:");
    let postgres = PostgresDatabase::new(
        "postgresql://localhost/mydb".to_string(),
        DatabaseConfig::default(),
    );
    
    // åˆ›å»ºè¡¨
    postgres.create_user_table().await;
    
    // æ’å…¥ç”¨æˆ·
    let user = User {
        id: Uuid::new_v4(),
        name: "å¼ ä¸‰".to_string(),
        email: "zhangsan@example.com".to_string(),
        created_at: chrono::Utc::now(),
        updated_at: chrono::Utc::now(),
    };
    postgres.insert_user(&user).await;
    
    // æŸ¥è¯¢ç”¨æˆ·
    postgres.get_user(user.id).await;
    
    // æ‰¹é‡æ’å…¥
    let users = vec![
        User {
            id: Uuid::new_v4(),
            name: "æå››".to_string(),
            email: "lisi@example.com".to_string(),
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
        },
        User {
            id: Uuid::new_v4(),
            name: "ç‹äº”".to_string(),
            email: "wangwu@example.com".to_string(),
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
        },
    ];
    postgres.batch_insert_users(&users).await;
    
    // å¤æ‚æŸ¥è¯¢
    postgres.search_users("å¼ ", 10).await;
    
    // 2. Redis ç¼“å­˜æ“ä½œç¤ºä¾‹
    println!("\nğŸ’¾ Redis ç¼“å­˜æ“ä½œ:");
    let redis = RedisCache::new(
        "redis://localhost:6379".to_string(),
        DatabaseConfig::default(),
    );
    
    // è®¾ç½®ç¼“å­˜
    redis.set("user:1", "å¼ ä¸‰", Duration::from_secs(3600)).await;
    redis.set("user:2", "æå››", Duration::from_secs(3600)).await;
    
    // è·å–ç¼“å­˜
    redis.get("user:1").await;
    redis.get("not_found").await;
    
    // æ‰¹é‡è®¾ç½®
    let mut cache_data = HashMap::new();
    cache_data.insert("key1".to_string(), "value1".to_string());
    cache_data.insert("key2".to_string(), "value2".to_string());
    redis.mset(&cache_data).await;
    
    // è®¾ç½®è¿‡æœŸæ—¶é—´
    redis.expire("user:1", Duration::from_secs(1800)).await;
    
    // åˆ é™¤ç¼“å­˜
    redis.delete("user:2").await;
    
    // 3. MongoDB æ–‡æ¡£æ•°æ®åº“æ“ä½œç¤ºä¾‹
    println!("\nğŸ“„ MongoDB æ–‡æ¡£æ•°æ®åº“æ“ä½œ:");
    let mongo = MongoDatabase::new(
        "mongodb://localhost:27017/mydb".to_string(),
        DatabaseConfig::default(),
    );
    
    // æ’å…¥æ–‡æ¡£
    let document = serde_json::json!({
        "name": "äº§å“A",
        "price": 99.99,
        "category": "ç”µå­äº§å“",
        "in_stock": true
    });
    mongo.insert_document("products", &document).await;
    
    // æŸ¥è¯¢æ–‡æ¡£
    let filter = serde_json::json!({"category": "ç”µå­äº§å“"});
    mongo.find_document("products", &filter).await;
    
    // æ›´æ–°æ–‡æ¡£
    let update = serde_json::json!({"$set": {"price": 89.99}});
    mongo.update_document("products", &filter, &update).await;
    
    // èšåˆæŸ¥è¯¢
    let pipeline = vec![
        serde_json::json!({"$match": {"category": "ç”µå­äº§å“"}}),
        serde_json::json!({"$group": {"_id": "$category", "count": {"$sum": 1}, "avg_price": {"$avg": "$price"}}})
    ];
    mongo.aggregate("products", &pipeline).await;
    
    // 4. è¿æ¥æ± ç®¡ç†ç¤ºä¾‹
    println!("\nğŸ”— è¿æ¥æ± ç®¡ç†:");
    let mut pool: ConnectionPool<String> = ConnectionPool::new(DatabaseConfig::default());
    
    // è·å–è¿æ¥
    pool.get_connection().await;
    pool.get_connection().await;
    
    // å½’è¿˜è¿æ¥
    pool.return_connection("connection1".to_string());
    pool.return_connection("connection2".to_string());
    
    // å¥åº·æ£€æŸ¥
    pool.health_check().await;
    
    // 5. äº‹åŠ¡ç®¡ç†ç¤ºä¾‹
    println!("\nğŸ”„ äº‹åŠ¡ç®¡ç†:");
    let mut tx_manager = TransactionManager::new();
    
    // å¼€å§‹äº‹åŠ¡
    tx_manager.begin_transaction("tx1").await;
    tx_manager.begin_transaction("tx2").await;
    
    // æäº¤äº‹åŠ¡
    tx_manager.commit_transaction("tx1").await;
    
    // å›æ»šäº‹åŠ¡
    tx_manager.rollback_transaction("tx2").await;
    
    // 6. æ•°æ®åº“è¿ç§»ç¤ºä¾‹
    println!("\nğŸ“ æ•°æ®åº“è¿ç§»:");
    let mut migration_manager = MigrationManager::new();
    
    // æ·»åŠ è¿ç§»
    migration_manager.add_migration(Migration {
        version: "001".to_string(),
        name: "åˆ›å»ºç”¨æˆ·è¡¨".to_string(),
        up_sql: "CREATE TABLE users (id UUID PRIMARY KEY, name VARCHAR(100), email VARCHAR(100))".to_string(),
        down_sql: "DROP TABLE users".to_string(),
    });
    
    migration_manager.add_migration(Migration {
        version: "002".to_string(),
        name: "åˆ›å»ºè®¢å•è¡¨".to_string(),
        up_sql: "CREATE TABLE orders (id UUID PRIMARY KEY, user_id UUID, amount DECIMAL(10,2))".to_string(),
        down_sql: "DROP TABLE orders".to_string(),
    });
    
    // æ‰§è¡Œè¿ç§»
    migration_manager.migrate().await;
    
    // å›æ»šè¿ç§»
    migration_manager.rollback("001").await;
    
    println!("\nâœ… æ•°æ®åº“æœ€ä½³å®è·µç¤ºä¾‹å®Œæˆï¼");
}
