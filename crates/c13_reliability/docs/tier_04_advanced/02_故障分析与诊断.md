# C13 Reliability - Tier 4: æ•…éšœåˆ†æä¸è¯Šæ–­

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **æœ€åæ›´æ–°**: 2025-10-23  
> **Rust ç‰ˆæœ¬**: 1.90+  
> **é¢„è®¡é˜…è¯»**: 65 åˆ†é’Ÿ  
> **éš¾åº¦**: â­â­â­â­â­ (ä¸“å®¶çº§)

---

## ğŸ“‹ ç›®å½•

- [C13 Reliability - Tier 4: æ•…éšœåˆ†æä¸è¯Šæ–­](#c13-reliability---tier-4-æ•…éšœåˆ†æä¸è¯Šæ–­)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ•…éšœåˆ†ææ¦‚è¿°](#1-æ•…éšœåˆ†ææ¦‚è¿°)
    - [1.1 æ•…éšœåˆ†ç±»ä½“ç³»](#11-æ•…éšœåˆ†ç±»ä½“ç³»)
    - [1.2 è¯Šæ–­æµç¨‹](#12-è¯Šæ–­æµç¨‹)
  - [2. æ—¥å¿—åˆ†ææŠ€æœ¯](#2-æ—¥å¿—åˆ†ææŠ€æœ¯)
    - [2.1 ç»“æ„åŒ–æ—¥å¿—](#21-ç»“æ„åŒ–æ—¥å¿—)
    - [2.2 æ—¥å¿—èšåˆä¸æœç´¢](#22-æ—¥å¿—èšåˆä¸æœç´¢)
    - [2.3 æ—¥å¿—æ¨¡å¼è¯†åˆ«](#23-æ—¥å¿—æ¨¡å¼è¯†åˆ«)
  - [3. æ ¸å¿ƒè½¬å‚¨åˆ†æ](#3-æ ¸å¿ƒè½¬å‚¨åˆ†æ)
    - [3.1 é…ç½®æ ¸å¿ƒè½¬å‚¨](#31-é…ç½®æ ¸å¿ƒè½¬å‚¨)
    - [3.2 ä½¿ç”¨ gdb åˆ†æ](#32-ä½¿ç”¨-gdb-åˆ†æ)
    - [3.3 å¸¸è§å´©æºƒæ¨¡å¼](#33-å¸¸è§å´©æºƒæ¨¡å¼)
  - [4. åˆ†å¸ƒå¼è¿½è¸ª](#4-åˆ†å¸ƒå¼è¿½è¸ª)
    - [4.1 OpenTelemetry é›†æˆ](#41-opentelemetry-é›†æˆ)
    - [4.2 è¿½è¸ªä¸Šä¸‹æ–‡ä¼ æ’­](#42-è¿½è¸ªä¸Šä¸‹æ–‡ä¼ æ’­)
    - [4.3 è¿½è¸ªæ•°æ®åˆ†æ](#43-è¿½è¸ªæ•°æ®åˆ†æ)
  - [5. æ ¹å› åˆ†ææ–¹æ³•](#5-æ ¹å› åˆ†ææ–¹æ³•)
    - [5.1 5-Why åˆ†ææ³•](#51-5-why-åˆ†ææ³•)
    - [5.2 é±¼éª¨å›¾åˆ†æ](#52-é±¼éª¨å›¾åˆ†æ)
    - [5.3 æ•…éšœæ ‘åˆ†æ (FTA)](#53-æ•…éšœæ ‘åˆ†æ-fta)
  - [6. å®æˆ˜æ¡ˆä¾‹](#6-å®æˆ˜æ¡ˆä¾‹)
    - [6.1 å†…å­˜æ³„æ¼è¯Šæ–­](#61-å†…å­˜æ³„æ¼è¯Šæ–­)
    - [6.2 æ­»é”è¯Šæ–­](#62-æ­»é”è¯Šæ–­)
    - [6.3 æ€§èƒ½é€€åŒ–è¯Šæ–­](#63-æ€§èƒ½é€€åŒ–è¯Šæ–­)
  - [7. è‡ªåŠ¨åŒ–è¯Šæ–­](#7-è‡ªåŠ¨åŒ–è¯Šæ–­)
    - [7.1 å¥åº·æ£€æŸ¥ç³»ç»Ÿ](#71-å¥åº·æ£€æŸ¥ç³»ç»Ÿ)
    - [7.2 å¼‚å¸¸æ£€æµ‹](#72-å¼‚å¸¸æ£€æµ‹)
    - [7.3 è‡ªåŠ¨ä¿®å¤](#73-è‡ªåŠ¨ä¿®å¤)
  - [8. æ€»ç»“](#8-æ€»ç»“)
    - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
    - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
  - [ğŸ“š å‚è€ƒèµ„æº](#-å‚è€ƒèµ„æº)

---

## 1. æ•…éšœåˆ†ææ¦‚è¿°

### 1.1 æ•…éšœåˆ†ç±»ä½“ç³»

**æ•…éšœç±»å‹é‡‘å­—å¡”**:

```text
       ç¾éš¾æ€§æ•…éšœ
      /          \
   ä¸¥é‡æ•…éšœ
    /          \
  ä¸€èˆ¬æ•…éšœ
   /          \
 è­¦å‘Š
  /          \
ä¿¡æ¯
```

**åˆ†ç±»æ ‡å‡†**:

| çº§åˆ« | å½±å“èŒƒå›´ | å“åº”æ—¶é—´ | ç¤ºä¾‹ |
|------|---------|---------|------|
| **P0 - ç¾éš¾** | å…¨ç«™å®•æœº | < 5 åˆ†é’Ÿ | æ•°æ®åº“å´©æºƒã€æ ¸å¿ƒæœåŠ¡ä¸å¯ç”¨ |
| **P1 - ä¸¥é‡** | æ ¸å¿ƒåŠŸèƒ½å¤±æ•ˆ | < 30 åˆ†é’Ÿ | æ”¯ä»˜å¤±è´¥ã€ç™»å½•å¼‚å¸¸ |
| **P2 - ä¸€èˆ¬** | æ¬¡è¦åŠŸèƒ½æ•…éšœ | < 2 å°æ—¶ | æœç´¢æ…¢ã€å›¾ç‰‡åŠ è½½å¤±è´¥ |
| **P3 - è½»å¾®** | ä¸ªåˆ«ç”¨æˆ·å½±å“ | < 1 å¤© | UI é”™ä¹±ã€éå…³é”®åŠŸèƒ½å¼‚å¸¸ |
| **P4 - ä¿¡æ¯** | æ— ç”¨æˆ·å½±å“ | æŒ‰è®¡åˆ’ | æ—¥å¿—è­¦å‘Šã€æ€§èƒ½è½»å¾®ä¸‹é™ |

**æ•…éšœæ¨¡å¼åº“**:

```rust
#[derive(Debug, Clone)]
pub enum FailurePattern {
    // èµ„æºè€—å°½
    MemoryLeak,
    FileDescriptorLeak,
    ThreadPoolExhaustion,
    
    // å¹¶å‘é—®é¢˜
    Deadlock,
    RaceCondition,
    LiveLock,
    
    // æ€§èƒ½é—®é¢˜
    SlowQuery,
    HighCPU,
    HighMemory,
    NetworkLatency,
    
    // é€»è¾‘é”™è¯¯
    NullPointerDereference,
    IndexOutOfBounds,
    DivisionByZero,
    
    // å¤–éƒ¨ä¾èµ–
    DatabaseDown,
    CacheUnavailable,
    ThirdPartyAPIFailure,
}

impl FailurePattern {
    pub fn severity(&self) -> u8 {
        match self {
            Self::Deadlock | Self::MemoryLeak => 0, // P0
            Self::DatabaseDown | Self::NullPointerDereference => 1, // P1
            Self::SlowQuery | Self::HighCPU => 2, // P2
            _ => 3, // P3+
        }
    }
    
    pub fn diagnostic_steps(&self) -> Vec<&'static str> {
        match self {
            Self::MemoryLeak => vec![
                "æ£€æŸ¥ heaptrack/valgrind æŠ¥å‘Š",
                "åˆ†æå¯¹è±¡åˆ†é…çƒ­ç‚¹",
                "æ£€æŸ¥æ˜¯å¦æœ‰å¿˜è®° drop çš„èµ„æº",
                "æŸ¥çœ‹é•¿æœŸè¿è¡Œçš„ç¼“å­˜",
            ],
            Self::Deadlock => vec![
                "è·å–çº¿ç¨‹å †æ ˆ",
                "åˆ†æé”çš„è·å–é¡ºåº",
                "æ£€æŸ¥æ˜¯å¦æœ‰å¾ªç¯ä¾èµ–",
                "ä½¿ç”¨ TSAN é‡ç°é—®é¢˜",
            ],
            _ => vec!["æŸ¥çœ‹æ—¥å¿—", "æ£€æŸ¥ç›‘æ§æŒ‡æ ‡"],
        }
    }
}
```

### 1.2 è¯Šæ–­æµç¨‹

**ç³»ç»ŸåŒ–è¯Šæ–­æµç¨‹**:

```rust
pub struct DiagnosticSession {
    failure_id: String,
    pattern: FailurePattern,
    evidence: Vec<Evidence>,
    hypotheses: Vec<Hypothesis>,
    root_cause: Option<RootCause>,
}

#[derive(Debug)]
pub struct Evidence {
    source: String,      // logs, metrics, traces
    timestamp: u64,
    data: String,
    confidence: f32,     // 0.0-1.0
}

#[derive(Debug)]
pub struct Hypothesis {
    description: String,
    likelihood: f32,     // 0.0-1.0
    tests: Vec<String>,  // éªŒè¯æ–¹æ³•
}

#[derive(Debug)]
pub struct RootCause {
    description: String,
    evidence_ids: Vec<usize>,
    remediation: Vec<String>,
}

impl DiagnosticSession {
    pub fn new(failure_id: String, pattern: FailurePattern) -> Self {
        Self {
            failure_id,
            pattern,
            evidence: Vec::new(),
            hypotheses: Vec::new(),
            root_cause: None,
        }
    }

    pub fn collect_evidence(&mut self, evidence: Evidence) {
        self.evidence.push(evidence);
    }

    pub fn propose_hypothesis(&mut self, hypothesis: Hypothesis) {
        self.hypotheses.push(hypothesis);
    }

    pub fn rank_hypotheses(&mut self) {
        self.hypotheses.sort_by(|a, b| {
            b.likelihood.partial_cmp(&a.likelihood).unwrap()
        });
    }

    pub fn identify_root_cause(&mut self, cause: RootCause) {
        self.root_cause = Some(cause);
    }

    pub fn generate_report(&self) -> String {
        format!(
            "Failure ID: {}\nPattern: {:?}\nEvidence: {} items\nHypotheses: {}\nRoot Cause: {}",
            self.failure_id,
            self.pattern,
            self.evidence.len(),
            self.hypotheses.len(),
            self.root_cause.is_some()
        )
    }
}
```

---

## 2. æ—¥å¿—åˆ†ææŠ€æœ¯

### 2.1 ç»“æ„åŒ–æ—¥å¿—

**ä½¿ç”¨ tracing è¿›è¡Œç»“æ„åŒ–æ—¥å¿—**:

```rust
use tracing::{info, warn, error, span, Level};
use tracing_subscriber::{fmt, EnvFilter};

pub fn setup_logging() {
    tracing_subscriber::fmt()
        .with_env_filter(EnvFilter::from_default_env())
        .json()  // JSON æ ¼å¼ï¼Œä¾¿äºåˆ†æ
        .init();
}

pub async fn process_request(request_id: &str, user_id: u64) {
    let span = span!(Level::INFO, "request", request_id, user_id);
    let _enter = span.enter();

    info!(
        event = "request_start",
        method = "POST",
        path = "/api/users"
    );

    // ä¸šåŠ¡é€»è¾‘
    match process_user_data(user_id).await {
        Ok(result) => {
            info!(
                event = "request_success",
                duration_ms = 120,
                result_size = result.len()
            );
        }
        Err(e) => {
            error!(
                event = "request_error",
                error = ?e,
                error_type = std::any::type_name_of_val(&e)
            );
        }
    }
}

async fn process_user_data(user_id: u64) -> Result<String, Box<dyn std::error::Error>> {
    // æ¨¡æ‹Ÿå¤„ç†
    Ok(format!("Data for user {}", user_id))
}
```

### 2.2 æ—¥å¿—èšåˆä¸æœç´¢

**ä½¿ç”¨ Elasticsearch è¿›è¡Œæ—¥å¿—æœç´¢**:

```rust
use elasticsearch::{Elasticsearch, SearchParts};
use serde_json::json;

pub struct LogSearcher {
    client: Elasticsearch,
}

impl LogSearcher {
    pub fn new(url: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let transport = elasticsearch::http::transport::Transport::single_node(url)?;
        Ok(Self {
            client: Elasticsearch::new(transport),
        })
    }

    pub async fn search_errors(
        &self,
        start_time: &str,
        end_time: &str,
    ) -> Result<Vec<serde_json::Value>, Box<dyn std::error::Error>> {
        let response = self
            .client
            .search(SearchParts::Index(&["logs-*"]))
            .body(json!({
                "query": {
                    "bool": {
                        "must": [
                            {
                                "range": {
                                    "@timestamp": {
                                        "gte": start_time,
                                        "lte": end_time
                                    }
                                }
                            },
                            {
                                "term": {
                                    "level": "ERROR"
                                }
                            }
                        ]
                    }
                },
                "sort": [
                    { "@timestamp": "desc" }
                ],
                "size": 100
            }))
            .send()
            .await?;

        let response_body = response.json::<serde_json::Value>().await?;
        let hits = response_body["hits"]["hits"]
            .as_array()
            .unwrap()
            .iter()
            .map(|hit| hit["_source"].clone())
            .collect();

        Ok(hits)
    }

    pub async fn aggregate_error_types(
        &self,
        start_time: &str,
        end_time: &str,
    ) -> Result<Vec<(String, u64)>, Box<dyn std::error::Error>> {
        let response = self
            .client
            .search(SearchParts::Index(&["logs-*"]))
            .body(json!({
                "query": {
                    "bool": {
                        "must": [
                            {
                                "range": {
                                    "@timestamp": {
                                        "gte": start_time,
                                        "lte": end_time
                                    }
                                }
                            },
                            {
                                "term": {
                                    "level": "ERROR"
                                }
                            }
                        ]
                    }
                },
                "aggs": {
                    "error_types": {
                        "terms": {
                            "field": "error_type.keyword",
                            "size": 20
                        }
                    }
                },
                "size": 0
            }))
            .send()
            .await?;

        let response_body = response.json::<serde_json::Value>().await?;
        let buckets = response_body["aggregations"]["error_types"]["buckets"]
            .as_array()
            .unwrap();

        let mut results = Vec::new();
        for bucket in buckets {
            let key = bucket["key"].as_str().unwrap().to_string();
            let count = bucket["doc_count"].as_u64().unwrap();
            results.push((key, count));
        }

        Ok(results)
    }
}
```

### 2.3 æ—¥å¿—æ¨¡å¼è¯†åˆ«

**åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„æ¨¡å¼è¯†åˆ«**:

```rust
use regex::Regex;
use std::collections::HashMap;

pub struct LogPatternAnalyzer {
    patterns: HashMap<String, Regex>,
    matches: HashMap<String, usize>,
}

impl LogPatternAnalyzer {
    pub fn new() -> Self {
        let mut patterns = HashMap::new();
        
        // å®šä¹‰å¸¸è§æ•…éšœæ¨¡å¼
        patterns.insert(
            "out_of_memory".to_string(),
            Regex::new(r"(?i)(out of memory|oom|memory allocation failed)").unwrap(),
        );
        patterns.insert(
            "connection_timeout".to_string(),
            Regex::new(r"(?i)(connection timeout|timed out|timeout exceeded)").unwrap(),
        );
        patterns.insert(
            "null_pointer".to_string(),
            Regex::new(r"(?i)(null pointer|segmentation fault|sigsegv)").unwrap(),
        );
        patterns.insert(
            "deadlock".to_string(),
            Regex::new(r"(?i)(deadlock detected|circular dependency)").unwrap(),
        );

        Self {
            patterns,
            matches: HashMap::new(),
        }
    }

    pub fn analyze_log(&mut self, log_line: &str) {
        for (pattern_name, regex) in &self.patterns {
            if regex.is_match(log_line) {
                *self.matches.entry(pattern_name.clone()).or_insert(0) += 1;
            }
        }
    }

    pub fn get_top_patterns(&self, n: usize) -> Vec<(String, usize)> {
        let mut sorted: Vec<_> = self.matches.iter().collect();
        sorted.sort_by(|a, b| b.1.cmp(a.1));
        sorted
            .into_iter()
            .take(n)
            .map(|(k, v)| (k.clone(), *v))
            .collect()
    }

    pub fn report(&self) -> String {
        let mut report = String::from("=== Log Pattern Analysis ===\n");
        for (pattern, count) in self.get_top_patterns(10) {
            report.push_str(&format!("{}: {} matches\n", pattern, count));
        }
        report
    }
}
```

---

## 3. æ ¸å¿ƒè½¬å‚¨åˆ†æ

### 3.1 é…ç½®æ ¸å¿ƒè½¬å‚¨

**å¯ç”¨æ ¸å¿ƒè½¬å‚¨**:

```bash
# è®¾ç½®æ ¸å¿ƒè½¬å‚¨å¤§å°é™åˆ¶ï¼ˆæ— é™åˆ¶ï¼‰
ulimit -c unlimited

# é…ç½®æ ¸å¿ƒè½¬å‚¨æ–‡ä»¶åæ ¼å¼
echo "core.%e.%p.%t" > /proc/sys/kernel/core_pattern

# åœ¨ Cargo.toml ä¸­å¯ç”¨è°ƒè¯•ç¬¦å·
[profile.release]
debug = true
```

**Rust ä»£ç ä¸­æ•è·å´©æºƒä¿¡æ¯**:

```rust
use std::panic;
use std::fs::OpenOptions;
use std::io::Write;
use backtrace::Backtrace;

pub fn setup_panic_handler() {
    panic::set_hook(Box::new(|panic_info| {
        let backtrace = Backtrace::new();
        
        let mut crash_log = OpenOptions::new()
            .create(true)
            .append(true)
            .open("/var/log/myapp/crash.log")
            .expect("Failed to open crash log");

        let crash_report = format!(
            "===== PANIC =====\nTime: {}\nThread: {:?}\nMessage: {}\nBacktrace:\n{:?}\n\n",
            chrono::Utc::now(),
            std::thread::current().id(),
            panic_info,
            backtrace
        );

        crash_log.write_all(crash_report.as_bytes()).ok();
        eprintln!("{}", crash_report);
    }));
}
```

### 3.2 ä½¿ç”¨ gdb åˆ†æ

**åŸºæœ¬ gdb å‘½ä»¤**:

```bash
# åŠ è½½æ ¸å¿ƒè½¬å‚¨
gdb ./target/release/myapp core.myapp.12345.1698123456

# å¸¸ç”¨å‘½ä»¤
(gdb) bt         # æŸ¥çœ‹è°ƒç”¨æ ˆ
(gdb) bt full    # æŸ¥çœ‹è¯¦ç»†è°ƒç”¨æ ˆ
(gdb) info threads  # æŸ¥çœ‹æ‰€æœ‰çº¿ç¨‹
(gdb) thread 3   # åˆ‡æ¢åˆ°çº¿ç¨‹ 3
(gdb) frame 2    # åˆ‡æ¢åˆ°æ ˆå¸§ 2
(gdb) print var  # æ‰“å°å˜é‡å€¼
(gdb) info locals  # æŸ¥çœ‹å±€éƒ¨å˜é‡
```

### 3.3 å¸¸è§å´©æºƒæ¨¡å¼

**Panic åˆ†æ**:

```rust
// ä½¿ç”¨ anyhow æä¾›æ›´å¥½çš„é”™è¯¯ä¸Šä¸‹æ–‡
use anyhow::{Context, Result};

pub fn load_config(path: &str) -> Result<Config> {
    let contents = std::fs::read_to_string(path)
        .with_context(|| format!("Failed to read config file: {}", path))?;
    
    let config: Config = toml::from_str(&contents)
        .with_context(|| format!("Failed to parse config file: {}", path))?;
    
    Ok(config)
}

// é…ç½®ç»“æ„
#[derive(serde::Deserialize)]
pub struct Config {
    pub server: ServerConfig,
}

#[derive(serde::Deserialize)]
pub struct ServerConfig {
    pub host: String,
    pub port: u16,
}
```

---

## 4. åˆ†å¸ƒå¼è¿½è¸ª

### 4.1 OpenTelemetry é›†æˆ

```rust
use opentelemetry::{global, sdk::propagation::TraceContextPropagator};
use opentelemetry::sdk::trace as sdktrace;
use opentelemetry::trace::{TraceContextExt, Tracer};
use tracing_subscriber::layer::SubscriberExt;

pub fn init_tracing() {
    global::set_text_map_propagator(TraceContextPropagator::new());
    
    let tracer = opentelemetry_jaeger::new_agent_pipeline()
        .with_service_name("my-service")
        .install_simple()
        .expect("Failed to install tracer");
    
    let telemetry = tracing_opentelemetry::layer().with_tracer(tracer);
    let subscriber = tracing_subscriber::registry().with(telemetry);
    
    tracing::subscriber::set_global_default(subscriber)
        .expect("Failed to set subscriber");
}

// ä½¿ç”¨ç¤ºä¾‹
#[tracing::instrument]
async fn handle_request(request_id: &str) -> Result<String, Box<dyn std::error::Error>> {
    tracing::info!("Processing request");
    
    let data = fetch_data().await?;
    let result = process_data(&data).await?;
    
    Ok(result)
}

#[tracing::instrument]
async fn fetch_data() -> Result<String, Box<dyn std::error::Error>> {
    // æ¨¡æ‹Ÿæ•°æ®è·å–
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    Ok("data".to_string())
}

#[tracing::instrument]
async fn process_data(data: &str) -> Result<String, Box<dyn std::error::Error>> {
    // æ¨¡æ‹Ÿæ•°æ®å¤„ç†
    tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
    Ok(format!("processed: {}", data))
}
```

### 4.2 è¿½è¸ªä¸Šä¸‹æ–‡ä¼ æ’­

```rust
use opentelemetry::{global, Context};
use opentelemetry::propagation::{Injector, Extractor};
use std::collections::HashMap;

// HTTP è¯·æ±‚ä¸­æ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡
pub struct HttpHeadersInjector<'a> {
    headers: &'a mut HashMap<String, String>,
}

impl<'a> Injector for HttpHeadersInjector<'a> {
    fn set(&mut self, key: &str, value: String) {
        self.headers.insert(key.to_string(), value);
    }
}

// HTTP è¯·æ±‚ä¸­æå–è¿½è¸ªä¸Šä¸‹æ–‡
pub struct HttpHeadersExtractor<'a> {
    headers: &'a HashMap<String, String>,
}

impl<'a> Extractor for HttpHeadersExtractor<'a> {
    fn get(&self, key: &str) -> Option<&str> {
        self.headers.get(key).map(|v| v.as_str())
    }

    fn keys(&self) -> Vec<&str> {
        self.headers.keys().map(|k| k.as_str()).collect()
    }
}

// å®¢æˆ·ç«¯ï¼šæ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡
pub fn make_http_request(url: &str) -> reqwest::RequestBuilder {
    let mut headers = HashMap::new();
    let propagator = global::get_text_map_propagator(|propagator| {
        propagator.inject_context(
            &Context::current(),
            &mut HttpHeadersInjector { headers: &mut headers },
        );
    });
    
    let mut request = reqwest::Client::new().get(url);
    for (key, value) in headers {
        request = request.header(key, value);
    }
    request
}

// æœåŠ¡ç«¯ï¼šæå–è¿½è¸ªä¸Šä¸‹æ–‡
pub fn extract_context(headers: &HashMap<String, String>) -> Context {
    global::get_text_map_propagator(|propagator| {
        propagator.extract(&HttpHeadersExtractor { headers })
    })
}
```

### 4.3 è¿½è¸ªæ•°æ®åˆ†æ

**æ…¢è¯·æ±‚æ£€æµ‹**:

```rust
use std::time::{Duration, Instant};

pub struct SpanAnalyzer {
    slow_threshold: Duration,
}

impl SpanAnalyzer {
    pub fn new(slow_threshold: Duration) -> Self {
        Self { slow_threshold }
    }

    pub fn analyze_span(&self, name: &str, duration: Duration) -> Option<SlowSpanAlert> {
        if duration > self.slow_threshold {
            Some(SlowSpanAlert {
                name: name.to_string(),
                duration,
                threshold: self.slow_threshold,
                severity: self.calculate_severity(duration),
            })
        } else {
            None
        }
    }

    fn calculate_severity(&self, duration: Duration) -> Severity {
        let ratio = duration.as_secs_f64() / self.slow_threshold.as_secs_f64();
        if ratio > 10.0 {
            Severity::Critical
        } else if ratio > 5.0 {
            Severity::High
        } else if ratio > 2.0 {
            Severity::Medium
        } else {
            Severity::Low
        }
    }
}

#[derive(Debug)]
pub struct SlowSpanAlert {
    pub name: String,
    pub duration: Duration,
    pub threshold: Duration,
    pub severity: Severity,
}

#[derive(Debug)]
pub enum Severity {
    Low,
    Medium,
    High,
    Critical,
}
```

---

## 5. æ ¹å› åˆ†ææ–¹æ³•

### 5.1 5-Why åˆ†ææ³•

```rust
pub struct FiveWhyAnalysis {
    problem: String,
    whys: Vec<String>,
    root_cause: Option<String>,
}

impl FiveWhyAnalysis {
    pub fn new(problem: String) -> Self {
        Self {
            problem,
            whys: Vec::new(),
            root_cause: None,
        }
    }

    pub fn ask_why(&mut self, answer: String) {
        self.whys.push(answer);
    }

    pub fn identify_root_cause(&mut self, cause: String) {
        self.root_cause = Some(cause);
    }

    pub fn report(&self) -> String {
        let mut report = format!("Problem: {}\n\n", self.problem);
        for (i, why) in self.whys.iter().enumerate() {
            report.push_str(&format!("Why {}: {}\n", i + 1, why));
        }
        if let Some(cause) = &self.root_cause {
            report.push_str(&format!("\nRoot Cause: {}\n", cause));
        }
        report
    }
}

// ä½¿ç”¨ç¤ºä¾‹
fn analyze_database_slowdown() {
    let mut analysis = FiveWhyAnalysis::new(
        "Database queries are slow".to_string()
    );
    
    analysis.ask_why("CPU usage is at 100%".to_string());
    analysis.ask_why("Too many concurrent queries".to_string());
    analysis.ask_why("No connection pooling".to_string());
    analysis.ask_why("Default configuration was used".to_string());
    analysis.ask_why("Documentation was not consulted".to_string());
    
    analysis.identify_root_cause(
        "Lack of proper database configuration review during setup".to_string()
    );
    
    println!("{}", analysis.report());
}
```

### 5.2 é±¼éª¨å›¾åˆ†æ

```rust
pub struct FishboneAnalysis {
    effect: String,
    categories: Vec<Category>,
}

pub struct Category {
    name: String,
    causes: Vec<String>,
}

impl FishboneAnalysis {
    pub fn new(effect: String) -> Self {
        Self {
            effect,
            categories: vec![
                Category { name: "People".to_string(), causes: Vec::new() },
                Category { name: "Process".to_string(), causes: Vec::new() },
                Category { name: "Technology".to_string(), causes: Vec::new() },
                Category { name: "Environment".to_string(), causes: Vec::new() },
            ],
        }
    }

    pub fn add_cause(&mut self, category: &str, cause: String) {
        if let Some(cat) = self.categories.iter_mut().find(|c| c.name == category) {
            cat.causes.push(cause);
        }
    }

    pub fn report(&self) -> String {
        let mut report = format!("Effect: {}\n\n", self.effect);
        for category in &self.categories {
            if !category.causes.is_empty() {
                report.push_str(&format!("{}:\n", category.name));
                for cause in &category.causes {
                    report.push_str(&format!("  - {}\n", cause));
                }
                report.push('\n');
            }
        }
        report
    }
}
```

### 5.3 æ•…éšœæ ‘åˆ†æ (FTA)

```rust
pub enum FaultTreeNode {
    Event {
        description: String,
        probability: f64,
    },
    AndGate {
        inputs: Vec<Box<FaultTreeNode>>,
    },
    OrGate {
        inputs: Vec<Box<FaultTreeNode>>,
    },
}

impl FaultTreeNode {
    pub fn probability(&self) -> f64 {
        match self {
            Self::Event { probability, .. } => *probability,
            Self::AndGate { inputs } => {
                inputs.iter().map(|node| node.probability()).product()
            }
            Self::OrGate { inputs } => {
                1.0 - inputs.iter().map(|node| 1.0 - node.probability()).product::<f64>()
            }
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
fn build_system_failure_tree() -> FaultTreeNode {
    FaultTreeNode::OrGate {
        inputs: vec![
            Box::new(FaultTreeNode::Event {
                description: "Database failure".to_string(),
                probability: 0.001,
            }),
            Box::new(FaultTreeNode::Event {
                description: "Network outage".to_string(),
                probability: 0.002,
            }),
            Box::new(FaultTreeNode::AndGate {
                inputs: vec![
                    Box::new(FaultTreeNode::Event {
                        description: "Primary server down".to_string(),
                        probability: 0.01,
                    }),
                    Box::new(FaultTreeNode::Event {
                        description: "Failover failed".to_string(),
                        probability: 0.1,
                    }),
                ],
            }),
        ],
    }
}
```

---

## 6. å®æˆ˜æ¡ˆä¾‹

### 6.1 å†…å­˜æ³„æ¼è¯Šæ–­

```rust
// ä½¿ç”¨ heaptrack æˆ– valgrind è¿›è¡Œè¯Šæ–­

// å¸¸è§å†…å­˜æ³„æ¼æ¨¡å¼
pub struct LeakyCache {
    data: std::collections::HashMap<String, Vec<u8>>,
}

impl LeakyCache {
    // âŒ å†…å­˜æ³„æ¼ï¼šä»ä¸æ¸…ç†æ—§æ•°æ®
    pub fn insert(&mut self, key: String, value: Vec<u8>) {
        self.data.insert(key, value);
    }

    // âœ… ä¿®å¤ï¼šä½¿ç”¨ LRU ç¼“å­˜
    pub fn insert_fixed(&mut self, key: String, value: Vec<u8>, max_size: usize) {
        if self.data.len() >= max_size {
            // ç§»é™¤æœ€æ—§çš„é¡¹
            if let Some(oldest_key) = self.data.keys().next().cloned() {
                self.data.remove(&oldest_key);
            }
        }
        self.data.insert(key, value);
    }
}

// è¯Šæ–­å·¥å…·ï¼šå†…å­˜ä½¿ç”¨è¿½è¸ª
pub struct MemoryTracker {
    baseline: usize,
    samples: Vec<(std::time::Instant, usize)>,
}

impl MemoryTracker {
    pub fn new() -> Self {
        let baseline = Self::get_memory_usage();
        Self {
            baseline,
            samples: Vec::new(),
        }
    }

    pub fn sample(&mut self) {
        let usage = Self::get_memory_usage();
        self.samples.push((std::time::Instant::now(), usage));
    }

    pub fn detect_leak(&self, threshold_mb: usize) -> bool {
        if let Some((_, latest)) = self.samples.last() {
            (*latest - self.baseline) / 1024 / 1024 > threshold_mb
        } else {
            false
        }
    }

    fn get_memory_usage() -> usize {
        // ç®€åŒ–å®ç°ï¼šè¯»å– /proc/self/status
        #[cfg(target_os = "linux")]
        {
            if let Ok(status) = std::fs::read_to_string("/proc/self/status") {
                for line in status.lines() {
                    if line.starts_with("VmRSS:") {
                        if let Some(kb) = line.split_whitespace().nth(1) {
                            return kb.parse::<usize>().unwrap_or(0) * 1024;
                        }
                    }
                }
            }
        }
        0
    }
}
```

### 6.2 æ­»é”è¯Šæ–­

```rust
use std::sync::{Arc, Mutex};
use std::thread;
use std::time::Duration;

// âŒ æ­»é”ç¤ºä¾‹
fn deadlock_example() {
    let resource1 = Arc::new(Mutex::new(0));
    let resource2 = Arc::new(Mutex::new(0));

    let r1 = Arc::clone(&resource1);
    let r2 = Arc::clone(&resource2);
    let thread1 = thread::spawn(move || {
        let _lock1 = r1.lock().unwrap();
        thread::sleep(Duration::from_millis(10));
        let _lock2 = r2.lock().unwrap();  // æ­»é”ï¼
    });

    let r1 = Arc::clone(&resource1);
    let r2 = Arc::clone(&resource2);
    let thread2 = thread::spawn(move || {
        let _lock2 = r2.lock().unwrap();
        thread::sleep(Duration::from_millis(10));
        let _lock1 = r1.lock().unwrap();  // æ­»é”ï¼
    });

    thread1.join().unwrap();
    thread2.join().unwrap();
}

// âœ… ä¿®å¤ï¼šå§‹ç»ˆæŒ‰ç›¸åŒé¡ºåºè·å–é”
fn no_deadlock_example() {
    let resource1 = Arc::new(Mutex::new(0));
    let resource2 = Arc::new(Mutex::new(0));

    let r1 = Arc::clone(&resource1);
    let r2 = Arc::clone(&resource2);
    let thread1 = thread::spawn(move || {
        let _lock1 = r1.lock().unwrap();
        let _lock2 = r2.lock().unwrap();
    });

    let r1 = Arc::clone(&resource1);
    let r2 = Arc::clone(&resource2);
    let thread2 = thread::spawn(move || {
        let _lock1 = r1.lock().unwrap();  // ç›¸åŒé¡ºåº
        let _lock2 = r2.lock().unwrap();
    });

    thread1.join().unwrap();
    thread2.join().unwrap();
}

// æ­»é”æ£€æµ‹å·¥å…·
pub struct DeadlockDetector {
    lock_graph: std::collections::HashMap<usize, Vec<usize>>,
}

impl DeadlockDetector {
    pub fn new() -> Self {
        Self {
            lock_graph: std::collections::HashMap::new(),
        }
    }

    pub fn add_lock_acquisition(&mut self, thread_id: usize, lock_id: usize) {
        self.lock_graph
            .entry(thread_id)
            .or_insert_with(Vec::new)
            .push(lock_id);
    }

    pub fn detect_cycle(&self) -> bool {
        // ç®€åŒ–çš„ç¯æ£€æµ‹ï¼ˆå®é™…åº”ä½¿ç”¨æ‹“æ‰‘æ’åºï¼‰
        for locks in self.lock_graph.values() {
            if locks.len() > 1 {
                // æ£€æŸ¥æ˜¯å¦æœ‰åå‘ä¾èµ–
                for other_locks in self.lock_graph.values() {
                    if other_locks.len() > 1 && locks[0] == other_locks[1] && locks[1] == other_locks[0] {
                        return true;  // æ£€æµ‹åˆ°å¾ªç¯
                    }
                }
            }
        }
        false
    }
}
```

### 6.3 æ€§èƒ½é€€åŒ–è¯Šæ–­

```rust
use std::collections::VecDeque;
use std::time::{Duration, Instant};

pub struct PerformanceBaseline {
    metric_name: String,
    baseline: f64,
    threshold_percent: f64,
    recent_values: VecDeque<(Instant, f64)>,
    max_history: usize,
}

impl PerformanceBaseline {
    pub fn new(metric_name: String, baseline: f64, threshold_percent: f64) -> Self {
        Self {
            metric_name,
            baseline,
            threshold_percent,
            recent_values: VecDeque::new(),
            max_history: 100,
        }
    }

    pub fn record(&mut self, value: f64) {
        self.recent_values.push_back((Instant::now(), value));
        if self.recent_values.len() > self.max_history {
            self.recent_values.pop_front();
        }
    }

    pub fn detect_degradation(&self) -> Option<DegradationAlert> {
        if self.recent_values.is_empty() {
            return None;
        }

        let recent_avg = self.recent_values.iter().map(|(_, v)| v).sum::<f64>()
            / self.recent_values.len() as f64;

        let degradation_percent = ((recent_avg - self.baseline) / self.baseline) * 100.0;

        if degradation_percent > self.threshold_percent {
            Some(DegradationAlert {
                metric_name: self.metric_name.clone(),
                baseline: self.baseline,
                current: recent_avg,
                degradation_percent,
            })
        } else {
            None
        }
    }
}

#[derive(Debug)]
pub struct DegradationAlert {
    pub metric_name: String,
    pub baseline: f64,
    pub current: f64,
    pub degradation_percent: f64,
}
```

---

## 7. è‡ªåŠ¨åŒ–è¯Šæ–­

### 7.1 å¥åº·æ£€æŸ¥ç³»ç»Ÿ

```rust
use std::sync::Arc;
use tokio::sync::RwLock;

#[derive(Debug, Clone)]
pub enum HealthStatus {
    Healthy,
    Degraded(String),
    Unhealthy(String),
}

pub trait HealthCheck: Send + Sync {
    async fn check(&self) -> HealthStatus;
    fn name(&self) -> &str;
}

pub struct HealthChecker {
    checks: Vec<Arc<dyn HealthCheck>>,
}

impl HealthChecker {
    pub fn new() -> Self {
        Self { checks: Vec::new() }
    }

    pub fn add_check(&mut self, check: Arc<dyn HealthCheck>) {
        self.checks.push(check);
    }

    pub async fn run_all_checks(&self) -> Vec<(String, HealthStatus)> {
        let mut results = Vec::new();
        for check in &self.checks {
            let status = check.check().await;
            results.push((check.name().to_string(), status));
        }
        results
    }

    pub async fn is_healthy(&self) -> bool {
        self.run_all_checks()
            .await
            .iter()
            .all(|(_, status)| matches!(status, HealthStatus::Healthy))
    }
}

// ç¤ºä¾‹ï¼šæ•°æ®åº“å¥åº·æ£€æŸ¥
pub struct DatabaseHealthCheck {
    // æ•°æ®åº“è¿æ¥
}

impl HealthCheck for DatabaseHealthCheck {
    async fn check(&self) -> HealthStatus {
        // ç®€åŒ–å®ç°
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        HealthStatus::Healthy
    }

    fn name(&self) -> &str {
        "database"
    }
}
```

### 7.2 å¼‚å¸¸æ£€æµ‹

```rust
pub struct AnomalyDetector {
    window_size: usize,
    threshold_stddev: f64,
    values: VecDeque<f64>,
}

impl AnomalyDetector {
    pub fn new(window_size: usize, threshold_stddev: f64) -> Self {
        Self {
            window_size,
            threshold_stddev,
            values: VecDeque::new(),
        }
    }

    pub fn add_value(&mut self, value: f64) -> bool {
        self.values.push_back(value);
        if self.values.len() > self.window_size {
            self.values.pop_front();
        }

        if self.values.len() < 10 {
            return false;  // æ•°æ®ä¸è¶³
        }

        let mean = self.values.iter().sum::<f64>() / self.values.len() as f64;
        let variance = self.values.iter()
            .map(|v| (v - mean).powi(2))
            .sum::<f64>() / self.values.len() as f64;
        let stddev = variance.sqrt();

        (value - mean).abs() > self.threshold_stddev * stddev
    }
}
```

### 7.3 è‡ªåŠ¨ä¿®å¤

```rust
pub trait AutoRemediation: Send + Sync {
    async fn diagnose(&self) -> Option<String>;
    async fn remediate(&self, issue: &str) -> Result<(), String>;
    fn name(&self) -> &str;
}

pub struct AutoRemediationSystem {
    remediations: Vec<Arc<dyn AutoRemediation>>,
}

impl AutoRemediationSystem {
    pub fn new() -> Self {
        Self {
            remediations: Vec::new(),
        }
    }

    pub fn register(&mut self, remediation: Arc<dyn AutoRemediation>) {
        self.remediations.push(remediation);
    }

    pub async fn run(&self) {
        for remediation in &self.remediations {
            if let Some(issue) = remediation.diagnose().await {
                println!("[{}] Detected issue: {}", remediation.name(), issue);
                match remediation.remediate(&issue).await {
                    Ok(_) => println!("[{}] Successfully remediated", remediation.name()),
                    Err(e) => eprintln!("[{}] Remediation failed: {}", remediation.name(), e),
                }
            }
        }
    }
}

// ç¤ºä¾‹ï¼šè‡ªåŠ¨é‡å¯æœåŠ¡
pub struct ServiceRestarter;

impl AutoRemediation for ServiceRestarter {
    async fn diagnose(&self) -> Option<String> {
        // æ£€æŸ¥æœåŠ¡æ˜¯å¦å“åº”
        None  // ç®€åŒ–å®ç°
    }

    async fn remediate(&self, issue: &str) -> Result<(), String> {
        // é‡å¯æœåŠ¡
        Ok(())
    }

    fn name(&self) -> &str {
        "service_restarter"
    }
}
```

---

## 8. æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **æ•…éšœåˆ†ç±»**: P0-P4 çº§åˆ«ï¼Œæ˜ç¡®å“åº”æ—¶é—´
2. **ç³»ç»ŸåŒ–è¯Šæ–­**: æ”¶é›†è¯æ® â†’ æå‡ºå‡è®¾ â†’ éªŒè¯ â†’ æ ¹å› åˆ†æ
3. **æ—¥å¿—åˆ†æ**: ç»“æ„åŒ–æ—¥å¿—ã€èšåˆæœç´¢ã€æ¨¡å¼è¯†åˆ«
4. **æ ¸å¿ƒè½¬å‚¨**: é…ç½®ã€åˆ†æã€å¸¸è§å´©æºƒæ¨¡å¼
5. **åˆ†å¸ƒå¼è¿½è¸ª**: OpenTelemetryã€ä¸Šä¸‹æ–‡ä¼ æ’­ã€æ…¢è¯·æ±‚æ£€æµ‹
6. **æ ¹å› åˆ†æ**: 5-Whyã€é±¼éª¨å›¾ã€æ•…éšœæ ‘åˆ†æ
7. **è‡ªåŠ¨åŒ–**: å¥åº·æ£€æŸ¥ã€å¼‚å¸¸æ£€æµ‹ã€è‡ªåŠ¨ä¿®å¤

### æœ€ä½³å®è·µ

| åœºæ™¯ | æ¨èåšæ³• | å·¥å…· |
|------|---------|------|
| **æ—¥å¿—åˆ†æ** | ç»“æ„åŒ–æ—¥å¿— + JSON æ ¼å¼ | tracing, Elasticsearch |
| **å´©æºƒè¯Šæ–­** | æ ¸å¿ƒè½¬å‚¨ + è°ƒè¯•ç¬¦å· | gdb, rust-gdb |
| **æ€§èƒ½é—®é¢˜** | åˆ†å¸ƒå¼è¿½è¸ª | OpenTelemetry, Jaeger |
| **æ ¹å› åˆ†æ** | 5-Why + é±¼éª¨å›¾ | è‡ªå®šä¹‰å·¥å…· |
| **è‡ªåŠ¨åŒ–** | å¥åº·æ£€æŸ¥ + è‡ªåŠ¨ä¿®å¤ | è‡ªå®šä¹‰ç³»ç»Ÿ |

**å¸¸è§é™·é˜±**:

- âŒ ç¼ºä¹ç»“æ„åŒ–æ—¥å¿—
- âŒ æœªå¯ç”¨æ ¸å¿ƒè½¬å‚¨
- âŒ å¿½ç•¥åˆ†å¸ƒå¼è¿½è¸ª
- âŒ ç¼ºä¹è‡ªåŠ¨åŒ–è¯Šæ–­
- âŒ ä¸è¿›è¡Œæ ¹å› åˆ†æ
- âœ… ä½¿ç”¨ç»Ÿä¸€çš„å¯è§‚æµ‹æ€§å¹³å°
- âœ… ä¿ç•™è°ƒè¯•ç¬¦å·
- âœ… å®æ–½ç«¯åˆ°ç«¯è¿½è¸ª
- âœ… å»ºç«‹è‡ªåŠ¨åŒ–æ•…éšœå“åº”
- âœ… æ–‡æ¡£åŒ–å¸¸è§æ•…éšœæ¨¡å¼

---

## ğŸ“š å‚è€ƒèµ„æº

**å®˜æ–¹æ–‡æ¡£**:

- [Rust Error Handling](https://doc.rust-lang.org/book/ch09-00-error-handling.html)
- [tracing Documentation](https://docs.rs/tracing/)
- [OpenTelemetry Rust](https://opentelemetry.io/docs/instrumentation/rust/)

**å·¥å…·**:

- `gdb` / `rust-gdb` - è°ƒè¯•å™¨
- `valgrind` - å†…å­˜åˆ†æ
- `heaptrack` - å†…å­˜è¿½è¸ª
- `Jaeger` - åˆ†å¸ƒå¼è¿½è¸ª
- `Elasticsearch` - æ—¥å¿—èšåˆ

**ç›¸å…³æ–‡æ¡£**:

- [Tier 2: ç›‘æ§å¯è§‚æµ‹æ€§æŒ‡å—](../tier_02_guides/04_ç›‘æ§å¯è§‚æµ‹æ€§æŒ‡å—.md)
- [Tier 4: æ€§èƒ½è°ƒä¼˜](./01_æ€§èƒ½è°ƒä¼˜.md)
- [Tier 4: æµ‹è¯•ç­–ç•¥è¿›é˜¶](./03_æµ‹è¯•ç­–ç•¥è¿›é˜¶.md)

---

**æ–‡æ¡£ç»´æŠ¤**: C13 Reliability Team  
**æœ€åå®¡æ ¸**: 2025-10-23  
**ä¸‹æ¬¡æ›´æ–°**: 2026-01-23
