# C13 Reliability - Tier 4: 性能调优

> **文档版本**: v1.0.0  
> **最后更新**: 2025-10-23  
> **Rust 版本**: 1.90+  
> **预计阅读**: 60 分钟  
> **难度**: ⭐⭐⭐⭐⭐ (专家级)

---

## 📋 目录

- [C13 Reliability - Tier 4: 性能调优](#c13-reliability---tier-4-性能调优)
  - [📋 目录](#-目录)
  - [1. 性能调优概述](#1-性能调优概述)
    - [1.1 性能优化金字塔](#11-性能优化金字塔)
    - [1.2 测量驱动优化](#12-测量驱动优化)
  - [2. 内存优化](#2-内存优化)
    - [2.1 堆与栈优化](#21-堆与栈优化)
    - [2.2 内存池技术](#22-内存池技术)
    - [2.3 零拷贝技术](#23-零拷贝技术)
    - [2.4 内存对齐与缓存行](#24-内存对齐与缓存行)
  - [3. 并发性能优化](#3-并发性能优化)
    - [3.1 线程池优化](#31-线程池优化)
    - [3.2 异步性能优化](#32-异步性能优化)
    - [3.3 锁优化策略](#33-锁优化策略)
    - [3.4 无锁数据结构](#34-无锁数据结构)
  - [4. I/O 性能优化](#4-io-性能优化)
    - [4.1 缓冲策略](#41-缓冲策略)
    - [4.2 批处理技术](#42-批处理技术)
    - [4.3 异步 I/O](#43-异步-io)
    - [4.4 零拷贝 I/O](#44-零拷贝-io)
  - [5. CPU 优化](#5-cpu-优化)
    - [5.1 SIMD 优化](#51-simd-优化)
    - [5.2 分支预测优化](#52-分支预测优化)
    - [5.3 缓存友好设计](#53-缓存友好设计)
    - [5.4 CPU 亲和性](#54-cpu-亲和性)
  - [6. 性能分析工具](#6-性能分析工具)
    - [6.1 perf + FlameGraph](#61-perf--flamegraph)
    - [6.2 valgrind (Cachegrind/Callgrind)](#62-valgrind-cachegrindcallgrind)
    - [6.3 Criterion 基准测试](#63-criterion-基准测试)
    - [6.4 自定义性能分析](#64-自定义性能分析)
  - [7. 实战案例](#7-实战案例)
    - [7.1 高性能 JSON 解析器](#71-高性能-json-解析器)
    - [7.2 内存高效的缓存系统](#72-内存高效的缓存系统)
    - [7.3 高吞吐量消息队列](#73-高吞吐量消息队列)
  - [8. 总结](#8-总结)
    - [核心要点](#核心要点)
    - [最佳实践](#最佳实践)
  - [📚 参考资源](#-参考资源)

---

## 1. 性能调优概述

### 1.1 性能优化金字塔

```text
          算法优化
         /          \
     数据结构设计
       /          \
   编译器优化
     /          \
  架构设计
    /          \
 微优化
```

**优化优先级**:

1. **算法复杂度** (10x-1000x 提升)
2. **数据结构** (5x-50x 提升)
3. **系统架构** (2x-10x 提升)
4. **编译器优化** (1.2x-3x 提升)
5. **微优化** (1.05x-1.5x 提升)

### 1.2 测量驱动优化

**性能优化的黄金法则**: **先测量，再优化**

```rust
use std::time::Instant;

pub struct PerformanceMonitor {
    start: Instant,
    name: &'static str,
}

impl PerformanceMonitor {
    pub fn new(name: &'static str) -> Self {
        Self {
            start: Instant::now(),
            name,
        }
    }
}

impl Drop for PerformanceMonitor {
    fn drop(&mut self) {
        let elapsed = self.start.elapsed();
        eprintln!("[PERF] {} took {:?}", self.name, elapsed);
    }
}

// 使用
fn expensive_operation() {
    let _monitor = PerformanceMonitor::new("expensive_operation");
    // 你的代码
}
```

---

## 2. 内存优化

### 2.1 堆与栈优化

**栈分配 vs 堆分配**:

```rust
// ❌ 慢：堆分配
fn process_slow(data: Vec<u8>) -> Vec<u8> {
    let mut result = Vec::new();
    for &byte in &data {
        result.push(byte * 2);
    }
    result
}

// ✅ 快：栈分配 (小数据)
fn process_fast<const N: usize>(data: &[u8; N]) -> [u8; N] {
    let mut result = [0u8; N];
    for i in 0..N {
        result[i] = data[i] * 2;
    }
    result
}

// ✅ 更好：预分配容量
fn process_preallocated(data: &[u8]) -> Vec<u8> {
    let mut result = Vec::with_capacity(data.len());
    for &byte in data {
        result.push(byte * 2);
    }
    result
}
```

**SmallVec 优化**:

```rust
use smallvec::{SmallVec, smallvec};

// 小于等于 8 个元素时使用栈，否则使用堆
type FastVec<T> = SmallVec<[T; 8]>;

fn process_with_smallvec(items: &[i32]) -> FastVec<i32> {
    let mut result: FastVec<i32> = smallvec![];
    for &item in items {
        result.push(item * 2);
    }
    result
}
```

### 2.2 内存池技术

**对象池模式**:

```rust
use std::sync::Mutex;

pub struct ObjectPool<T> {
    objects: Mutex<Vec<T>>,
    factory: fn() -> T,
}

impl<T> ObjectPool<T> {
    pub fn new(factory: fn() -> T, initial_size: usize) -> Self {
        let mut objects = Vec::with_capacity(initial_size);
        for _ in 0..initial_size {
            objects.push(factory());
        }
        Self {
            objects: Mutex::new(objects),
            factory,
        }
    }

    pub fn acquire(&self) -> PooledObject<T> {
        let obj = self.objects.lock().unwrap().pop()
            .unwrap_or_else(|| (self.factory)());
        PooledObject {
            obj: Some(obj),
            pool: self,
        }
    }

    fn release(&self, obj: T) {
        self.objects.lock().unwrap().push(obj);
    }
}

pub struct PooledObject<'a, T> {
    obj: Option<T>,
    pool: &'a ObjectPool<T>,
}

impl<T> std::ops::Deref for PooledObject<'_, T> {
    type Target = T;
    fn deref(&self) -> &Self::Target {
        self.obj.as_ref().unwrap()
    }
}

impl<T> std::ops::DerefMut for PooledObject<'_, T> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        self.obj.as_mut().unwrap()
    }
}

impl<T> Drop for PooledObject<'_, T> {
    fn drop(&mut self) {
        if let Some(obj) = self.obj.take() {
            self.pool.release(obj);
        }
    }
}

// 使用示例
fn buffer_factory() -> Vec<u8> {
    Vec::with_capacity(4096)
}

fn use_pool() {
    let pool = ObjectPool::new(buffer_factory, 10);
    
    let mut buffer = pool.acquire();
    buffer.extend_from_slice(b"Hello, world!");
    // buffer 自动归还到池中
}
```

### 2.3 零拷贝技术

**使用 `Cow` 避免不必要的克隆**:

```rust
use std::borrow::Cow;

// ❌ 总是克隆
fn process_always_clone(input: &str) -> String {
    if input.contains("special") {
        input.replace("special", "modified")
    } else {
        input.to_string()  // 不必要的克隆
    }
}

// ✅ 按需克隆
fn process_cow(input: &str) -> Cow<str> {
    if input.contains("special") {
        Cow::Owned(input.replace("special", "modified"))
    } else {
        Cow::Borrowed(input)
    }
}
```

**使用 `bytes` crate 零拷贝**:

```rust
use bytes::{Bytes, BytesMut};

fn zero_copy_slice(data: Bytes) -> Bytes {
    // 零拷贝切片
    data.slice(0..100)
}

fn efficient_buffer() -> Bytes {
    let mut buf = BytesMut::with_capacity(1024);
    buf.extend_from_slice(b"Hello, world!");
    buf.freeze()  // 转换为不可变 Bytes，无拷贝
}
```

### 2.4 内存对齐与缓存行

**避免伪共享 (False Sharing)**:

```rust
use std::sync::atomic::{AtomicU64, Ordering};

// ❌ 伪共享：两个原子变量在同一缓存行
struct BadCounter {
    counter1: AtomicU64,
    counter2: AtomicU64,
}

// ✅ 缓存行对齐：避免伪共享
#[repr(align(64))]
struct AlignedCounter {
    counter: AtomicU64,
}

struct GoodCounter {
    counter1: AlignedCounter,
    counter2: AlignedCounter,
}

// 使用
fn use_aligned_counter() {
    let counter = GoodCounter {
        counter1: AlignedCounter { counter: AtomicU64::new(0) },
        counter2: AlignedCounter { counter: AtomicU64::new(0) },
    };
    
    // 两个线程可以并发修改 counter1 和 counter2 而无伪共享
    std::thread::scope(|s| {
        s.spawn(|| {
            for _ in 0..1_000_000 {
                counter.counter1.counter.fetch_add(1, Ordering::Relaxed);
            }
        });
        s.spawn(|| {
            for _ in 0..1_000_000 {
                counter.counter2.counter.fetch_add(1, Ordering::Relaxed);
            }
        });
    });
}
```

---

## 3. 并发性能优化

### 3.1 线程池优化

**动态线程池**:

```rust
use std::sync::{Arc, Mutex};
use std::sync::mpsc::{channel, Sender, Receiver};
use std::thread;

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: Sender<Job>,
}

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    pub fn new(size: usize) -> Self {
        let (sender, receiver) = channel();
        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);
        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool { workers, sender }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);
        self.sender.send(job).unwrap();
    }
}

struct Worker {
    id: usize,
    thread: Option<thread::JoinHandle<()>>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv();

            match job {
                Ok(job) => {
                    job();
                }
                Err(_) => {
                    break;
                }
            }
        });

        Worker {
            id,
            thread: Some(thread),
        }
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        for worker in &mut self.workers {
            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}
```

### 3.2 异步性能优化

**避免不必要的 `await`**:

```rust
use tokio::time::{sleep, Duration};

// ❌ 慢：顺序执行
async fn slow_sequential() {
    sleep(Duration::from_secs(1)).await;
    sleep(Duration::from_secs(1)).await;
    sleep(Duration::from_secs(1)).await;
    // 总耗时：3 秒
}

// ✅ 快：并发执行
async fn fast_concurrent() {
    let (_, _, _) = tokio::join!(
        sleep(Duration::from_secs(1)),
        sleep(Duration::from_secs(1)),
        sleep(Duration::from_secs(1)),
    );
    // 总耗时：1 秒
}
```

**流式处理**:

```rust
use futures::stream::{self, StreamExt};

async fn process_stream() {
    let items = vec![1, 2, 3, 4, 5];
    
    // ✅ 流式处理：并发处理多个项
    let results: Vec<_> = stream::iter(items)
        .map(|item| async move {
            // 异步处理每个项
            item * 2
        })
        .buffer_unordered(4)  // 最多同时处理 4 个
        .collect()
        .await;
}
```

### 3.3 锁优化策略

**读写锁优化**:

```rust
use std::sync::RwLock;

struct Cache {
    data: RwLock<std::collections::HashMap<String, String>>,
}

impl Cache {
    fn get(&self, key: &str) -> Option<String> {
        // 读锁：允许多个并发读
        self.data.read().unwrap().get(key).cloned()
    }

    fn set(&self, key: String, value: String) {
        // 写锁：独占访问
        self.data.write().unwrap().insert(key, value);
    }
}
```

**锁粒度优化**:

```rust
use std::sync::Mutex;

// ❌ 粗粒度锁：整个结构被锁
struct CoarseGrained {
    data: Mutex<Vec<Vec<i32>>>,
}

// ✅ 细粒度锁：每个子结构独立锁
struct FineGrained {
    data: Vec<Mutex<Vec<i32>>>,
}

impl FineGrained {
    fn update(&self, index: usize, value: i32) {
        // 只锁定一个子向量
        self.data[index].lock().unwrap().push(value);
    }
}
```

### 3.4 无锁数据结构

**使用 crossbeam 的无锁队列**:

```rust
use crossbeam::queue::ArrayQueue;
use std::sync::Arc;

fn lockfree_queue() {
    let queue = Arc::new(ArrayQueue::new(100));
    
    let producer = {
        let queue = Arc::clone(&queue);
        std::thread::spawn(move || {
            for i in 0..1000 {
                while queue.push(i).is_err() {
                    // 队列满，重试
                    std::hint::spin_loop();
                }
            }
        })
    };
    
    let consumer = {
        let queue = Arc::clone(&queue);
        std::thread::spawn(move || {
            let mut sum = 0;
            for _ in 0..1000 {
                while let Err(_) = queue.pop() {
                    // 队列空，重试
                    std::hint::spin_loop();
                }
                sum += queue.pop().unwrap();
            }
            sum
        })
    };
    
    producer.join().unwrap();
    let result = consumer.join().unwrap();
    println!("Sum: {}", result);
}
```

---

## 4. I/O 性能优化

### 4.1 缓冲策略

**使用 BufReader/BufWriter**:

```rust
use std::io::{BufReader, BufWriter, Read, Write};
use std::fs::File;

// ❌ 慢：无缓冲
fn slow_read(path: &str) -> std::io::Result<String> {
    let mut file = File::open(path)?;
    let mut contents = String::new();
    file.read_to_string(&mut contents)?;
    Ok(contents)
}

// ✅ 快：有缓冲
fn fast_read(path: &str) -> std::io::Result<String> {
    let file = File::open(path)?;
    let mut reader = BufReader::new(file);
    let mut contents = String::new();
    reader.read_to_string(&mut contents)?;
    Ok(contents)
}

// ✅ 快：有缓冲写入
fn fast_write(path: &str, data: &[u8]) -> std::io::Result<()> {
    let file = File::create(path)?;
    let mut writer = BufWriter::new(file);
    writer.write_all(data)?;
    writer.flush()?;
    Ok(())
}
```

### 4.2 批处理技术

**批量数据库操作**:

```rust
use tokio_postgres::{Client, Error};

// ❌ 慢：逐条插入
async fn slow_insert(client: &Client, items: &[i32]) -> Result<(), Error> {
    for &item in items {
        client.execute(
            "INSERT INTO items (value) VALUES ($1)",
            &[&item],
        ).await?;
    }
    Ok(())
}

// ✅ 快：批量插入
async fn fast_insert(client: &Client, items: &[i32]) -> Result<(), Error> {
    let mut query = String::from("INSERT INTO items (value) VALUES ");
    for (i, _) in items.iter().enumerate() {
        if i > 0 {
            query.push_str(", ");
        }
        query.push_str(&format!("(${})", i + 1));
    }
    
    client.execute(&query, items).await?;
    Ok(())
}
```

### 4.3 异步 I/O

**tokio 异步文件 I/O**:

```rust
use tokio::fs::File;
use tokio::io::AsyncReadExt;

async fn async_read(path: &str) -> std::io::Result<String> {
    let mut file = File::open(path).await?;
    let mut contents = String::new();
    file.read_to_string(&mut contents).await?;
    Ok(contents)
}
```

### 4.4 零拷贝 I/O

**使用 `sendfile` (Linux)**:

```rust
#[cfg(target_os = "linux")]
use std::os::unix::io::AsRawFd;

#[cfg(target_os = "linux")]
fn zero_copy_transfer(input: &std::fs::File, output: &std::fs::File, size: usize) -> std::io::Result<()> {
    unsafe {
        let ret = libc::sendfile(
            output.as_raw_fd(),
            input.as_raw_fd(),
            std::ptr::null_mut(),
            size,
        );
        if ret < 0 {
            return Err(std::io::Error::last_os_error());
        }
    }
    Ok(())
}
```

---

## 5. CPU 优化

### 5.1 SIMD 优化

**使用 `std::simd` (Rust 1.90+)**:

```rust
#![feature(portable_simd)]
use std::simd::{f32x8, SimdFloat};

// ❌ 标量版本
fn scalar_sum(data: &[f32]) -> f32 {
    data.iter().sum()
}

// ✅ SIMD 版本
fn simd_sum(data: &[f32]) -> f32 {
    let chunks = data.chunks_exact(8);
    let remainder = chunks.remainder();
    
    let sum_vec: f32x8 = chunks
        .map(|chunk| f32x8::from_slice(chunk))
        .fold(f32x8::splat(0.0), |acc, x| acc + x);
    
    let sum_simd: f32 = sum_vec.reduce_sum();
    let sum_remainder: f32 = remainder.iter().sum();
    
    sum_simd + sum_remainder
}
```

### 5.2 分支预测优化

**使用 `likely`/`unlikely` (nightly)**:

```rust
#![feature(core_intrinsics)]
use std::intrinsics::{likely, unlikely};

fn process(data: &[i32]) -> Vec<i32> {
    let mut result = Vec::with_capacity(data.len());
    
    for &value in data {
        // 提示编译器这个分支很可能为真
        if unsafe { likely(value > 0) } {
            result.push(value * 2);
        } else if unsafe { unlikely(value < -1000) } {
            // 这个分支很少执行
            result.push(0);
        } else {
            result.push(value);
        }
    }
    
    result
}
```

### 5.3 缓存友好设计

**Structure of Arrays (SoA) vs Array of Structures (AoS)**:

```rust
// ❌ Array of Structures：缓存不友好
struct ParticleAoS {
    x: f32,
    y: f32,
    z: f32,
    vx: f32,
    vy: f32,
    vz: f32,
}

fn update_aos(particles: &mut [ParticleAoS]) {
    for particle in particles {
        particle.x += particle.vx;
        // 跳过 y, z, vy, vz 字段访问其他粒子的 x
    }
}

// ✅ Structure of Arrays：缓存友好
struct ParticlesSoA {
    x: Vec<f32>,
    y: Vec<f32>,
    z: Vec<f32>,
    vx: Vec<f32>,
    vy: Vec<f32>,
    vz: Vec<f32>,
}

fn update_soa(particles: &mut ParticlesSoA) {
    for i in 0..particles.x.len() {
        particles.x[i] += particles.vx[i];
        // 连续访问 x 和 vx 数组，缓存友好
    }
}
```

### 5.4 CPU 亲和性

**绑定线程到 CPU 核心**:

```rust
#[cfg(target_os = "linux")]
fn set_cpu_affinity(cpu_id: usize) -> std::io::Result<()> {
    use libc::{cpu_set_t, CPU_SET, CPU_ZERO, sched_setaffinity};
    use std::mem;
    
    unsafe {
        let mut cpu_set: cpu_set_t = mem::zeroed();
        CPU_ZERO(&mut cpu_set);
        CPU_SET(cpu_id, &mut cpu_set);
        
        let result = sched_setaffinity(
            0,  // 当前线程
            mem::size_of::<cpu_set_t>(),
            &cpu_set,
        );
        
        if result != 0 {
            return Err(std::io::Error::last_os_error());
        }
    }
    
    Ok(())
}
```

---

## 6. 性能分析工具

### 6.1 perf + FlameGraph

```bash
# 录制性能数据
perf record -F 99 -g ./target/release/my_app

# 生成报告
perf report

# 生成火焰图
perf script | stackcollapse-perf.pl | flamegraph.pl > flame.svg
```

**在 Rust 中集成**:

```rust
use pprof::ProfilerGuard;

fn profile_code() {
    let guard = ProfilerGuard::new(100).unwrap();
    
    // 你的代码
    expensive_function();
    
    if let Ok(report) = guard.report().build() {
        let file = std::fs::File::create("flamegraph.svg").unwrap();
        report.flamegraph(file).unwrap();
    }
}
```

### 6.2 valgrind (Cachegrind/Callgrind)

```bash
# 缓存分析
valgrind --tool=cachegrind ./target/release/my_app

# 调用图分析
valgrind --tool=callgrind ./target/release/my_app

# 可视化
kcachegrind callgrind.out.<pid>
```

### 6.3 Criterion 基准测试

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn fibonacci(n: u64) -> u64 {
    match n {
        0 => 1,
        1 => 1,
        n => fibonacci(n - 1) + fibonacci(n - 2),
    }
}

fn criterion_benchmark(c: &mut Criterion) {
    c.bench_function("fib 20", |b| b.iter(|| fibonacci(black_box(20))));
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);
```

### 6.4 自定义性能分析

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::time::Instant;

pub struct Profiler {
    timings: Arc<Mutex<HashMap<String, Vec<u128>>>>,
}

impl Profiler {
    pub fn new() -> Self {
        Self {
            timings: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    pub fn profile<F, R>(&self, name: &str, f: F) -> R
    where
        F: FnOnce() -> R,
    {
        let start = Instant::now();
        let result = f();
        let elapsed = start.elapsed().as_micros();

        self.timings
            .lock()
            .unwrap()
            .entry(name.to_string())
            .or_insert_with(Vec::new)
            .push(elapsed);

        result
    }

    pub fn report(&self) {
        let timings = self.timings.lock().unwrap();
        for (name, times) in timings.iter() {
            let avg = times.iter().sum::<u128>() / times.len() as u128;
            let min = *times.iter().min().unwrap();
            let max = *times.iter().max().unwrap();
            println!(
                "{}: avg={}μs, min={}μs, max={}μs, count={}",
                name, avg, min, max, times.len()
            );
        }
    }
}
```

---

## 7. 实战案例

### 7.1 高性能 JSON 解析器

```rust
use serde_json::Value;

// 优化策略：
// 1. 使用 simd-json (SIMD 加速)
// 2. 零拷贝解析
// 3. 预分配容量

use simd_json;

fn fast_json_parse(json_bytes: &mut [u8]) -> Result<Value, simd_json::Error> {
    simd_json::to_borrowed_value(json_bytes)
        .map(|v| v.into())
}

// 基准测试对比
#[cfg(test)]
mod benches {
    use super::*;
    use criterion::{black_box, Criterion};

    pub fn benchmark_json(c: &mut Criterion) {
        let mut json = br#"{"name":"Alice","age":30,"city":"NYC"}"#.to_vec();

        c.bench_function("std json", |b| {
            b.iter(|| serde_json::from_slice::<Value>(black_box(&json)))
        });

        c.bench_function("simd json", |b| {
            b.iter(|| fast_json_parse(black_box(&mut json)))
        });
    }
}
```

### 7.2 内存高效的缓存系统

```rust
use std::collections::HashMap;
use std::sync::Arc;
use parking_lot::RwLock;

pub struct LRUCache<K, V> {
    capacity: usize,
    cache: Arc<RwLock<HashMap<K, (V, usize)>>>,
    access_count: Arc<RwLock<usize>>,
}

impl<K: Eq + std::hash::Hash + Clone, V: Clone> LRUCache<K, V> {
    pub fn new(capacity: usize) -> Self {
        Self {
            capacity,
            cache: Arc::new(RwLock::new(HashMap::with_capacity(capacity))),
            access_count: Arc::new(RwLock::new(0)),
        }
    }

    pub fn get(&self, key: &K) -> Option<V> {
        let mut cache = self.cache.write();
        let mut count = self.access_count.write();
        
        if let Some((value, access)) = cache.get_mut(key) {
            *count += 1;
            *access = *count;
            Some(value.clone())
        } else {
            None
        }
    }

    pub fn put(&self, key: K, value: V) {
        let mut cache = self.cache.write();
        let mut count = self.access_count.write();
        
        *count += 1;
        
        if cache.len() >= self.capacity {
            // 移除最少使用的项
            if let Some(lru_key) = cache
                .iter()
                .min_by_key(|(_, (_, access))| access)
                .map(|(k, _)| k.clone())
            {
                cache.remove(&lru_key);
            }
        }
        
        cache.insert(key, (value, *count));
    }
}
```

### 7.3 高吞吐量消息队列

```rust
use crossbeam::channel::{bounded, Sender, Receiver};
use std::sync::Arc;

pub struct MessageQueue<T> {
    sender: Sender<T>,
    receiver: Arc<Receiver<T>>,
}

impl<T: Send + 'static> MessageQueue<T> {
    pub fn new(capacity: usize) -> Self {
        let (sender, receiver) = bounded(capacity);
        Self {
            sender,
            receiver: Arc::new(receiver),
        }
    }

    pub fn send(&self, msg: T) -> Result<(), crossbeam::channel::SendError<T>> {
        self.sender.send(msg)
    }

    pub fn spawn_consumer<F>(&self, f: F) -> std::thread::JoinHandle<()>
    where
        F: Fn(T) + Send + 'static,
    {
        let receiver = Arc::clone(&self.receiver);
        std::thread::spawn(move || {
            while let Ok(msg) = receiver.recv() {
                f(msg);
            }
        })
    }
}

// 使用示例
fn use_message_queue() {
    let queue = MessageQueue::new(1000);
    
    // 启动 4 个消费者
    let mut handles = vec![];
    for i in 0..4 {
        let handle = queue.spawn_consumer(move |msg: String| {
            println!("Consumer {} received: {}", i, msg);
        });
        handles.push(handle);
    }
    
    // 生产者
    for i in 0..10000 {
        queue.send(format!("Message {}", i)).unwrap();
    }
    
    drop(queue);
    for handle in handles {
        handle.join().unwrap();
    }
}
```

---

## 8. 总结

### 核心要点

1. **测量驱动**: 先测量，再优化，避免过早优化
2. **算法优先**: 算法优化带来的提升远超微优化
3. **内存优化**: 栈分配、内存池、零拷贝、缓存行对齐
4. **并发优化**: 线程池、异步、锁粒度、无锁结构
5. **I/O 优化**: 缓冲、批处理、异步 I/O、零拷贝
6. **CPU 优化**: SIMD、分支预测、缓存友好、CPU 亲和性

### 最佳实践

| 场景 | 推荐做法 | 性能提升 |
|------|---------|---------|
| **小数据** | SmallVec / 栈分配 | 2-5x |
| **频繁分配** | 对象池 | 3-10x |
| **字符串处理** | `Cow<str>` | 1.5-3x |
| **并发读** | RwLock | 5-20x |
| **无锁并发** | crossbeam queue | 2-10x |
| **文件 I/O** | BufReader/Writer | 10-100x |
| **批量操作** | 批量插入 | 5-50x |
| **数值计算** | SIMD | 4-8x |
| **缓存友好** | SoA vs AoS | 2-4x |

**常见陷阱**:

- ❌ 过早优化
- ❌ 忽略算法复杂度
- ❌ 不测量就优化
- ❌ 优化非热点路径
- ❌ 牺牲可读性换取微小提升
- ✅ 使用 profiler 找热点
- ✅ 优化算法和数据结构
- ✅ 保持代码可维护性
- ✅ 编写基准测试

---

## 📚 参考资源

**官方文档**:

- [The Rust Performance Book](https://nnethercote.github.io/perf-book/)
- [Rust Compiler Performance](https://rustc-dev-guide.rust-lang.org/backend/codegen.html)

**工具**:

- `perf` + FlameGraph - CPU 性能分析
- `valgrind` - 内存和缓存分析
- `criterion` - 基准测试
- `cargo-flamegraph` - 火焰图生成

**相关文档**:

- [Tier 2: 部署实践指南](../tier_02_guides/05_部署实践指南.md)
- [Tier 4: 故障分析与诊断](./02_故障分析与诊断.md)
- [Tier 3: 并发模型](../features/concurrency-models.md)

---

**文档维护**: C13 Reliability Team  
**最后审核**: 2025-10-23  
**下次更新**: 2026-01-23
