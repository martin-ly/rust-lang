# Rust 1.89 å·¥ä½œæµç®—æ³•è®¾è®¡ï¼šç±»å‹å®‰å…¨ä¸æ€§èƒ½ä¼˜åŒ–

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäº Rust 1.89 çš„æœ€æ–°è¯­è¨€ç‰¹æ€§ï¼Œé‡æ–°è®¾è®¡å·¥ä½œæµç®—æ³•å’Œç±»å‹ç³»ç»Ÿï¼Œå……åˆ†åˆ©ç”¨å¸¸é‡æ³›å‹æ˜¾å¼æ¨å¯¼ã€ç”Ÿå‘½å‘¨æœŸè¯­æ³•æ”¹è¿›å’Œ x86 ç‰¹æ€§æ‰©å±•ç­‰æ–°åŠŸèƒ½ã€‚

## ç›®å½•

- [Rust 1.89 å·¥ä½œæµç®—æ³•è®¾è®¡ï¼šç±»å‹å®‰å…¨ä¸æ€§èƒ½ä¼˜åŒ–](#rust-189-å·¥ä½œæµç®—æ³•è®¾è®¡ç±»å‹å®‰å…¨ä¸æ€§èƒ½ä¼˜åŒ–)
  - [ğŸ“‹ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸš€ Rust 1.89 ç‰¹æ€§é›†æˆ](#-rust-189-ç‰¹æ€§é›†æˆ)
    - [æ ¸å¿ƒæ”¹è¿›](#æ ¸å¿ƒæ”¹è¿›)
  - [1. ç±»å‹ä¸ç®—æ³•çš„è¡¨è¾¾ä¸ç»„åˆ](#1-ç±»å‹ä¸ç®—æ³•çš„è¡¨è¾¾ä¸ç»„åˆ)
    - [1.1 æ„å»ºæµå¼å¤„ç†ç®¡é“ï¼ˆRust 1.89 ä¼˜åŒ–ç‰ˆï¼‰](#11-æ„å»ºæµå¼å¤„ç†ç®¡é“rust-189-ä¼˜åŒ–ç‰ˆ)
    - [1.2 è¿­ä»£å™¨ä¸ç®—æ³•ç»„åˆ](#12-è¿­ä»£å™¨ä¸ç®—æ³•ç»„åˆ)
  - [2. çŠ¶æ€ç®¡ç†ä¸è½¬æ¢](#2-çŠ¶æ€ç®¡ç†ä¸è½¬æ¢)
    - [2.1 å·¥ä½œæµçŠ¶æ€æœº](#21-å·¥ä½œæµçŠ¶æ€æœº)
    - [2.2 äº‹åŠ¡æ€§æ“ä½œæ¨¡å¼](#22-äº‹åŠ¡æ€§æ“ä½œæ¨¡å¼)
  - [3. ç®—æ³•ä¸ç­–ç•¥æ¥å£è®¾è®¡](#3-ç®—æ³•ä¸ç­–ç•¥æ¥å£è®¾è®¡)
    - [3.1 å¯ç»„åˆç­–ç•¥æ¨¡å¼](#31-å¯ç»„åˆç­–ç•¥æ¨¡å¼)
    - [3.2 ä¼˜åŒ–å™¨ä¸ç›®æ ‡å‡½æ•°æ¨¡å¼](#32-ä¼˜åŒ–å™¨ä¸ç›®æ ‡å‡½æ•°æ¨¡å¼)
  - [4. è¿­ä»£ä¸é€’å½’å·¥ä½œæµ](#4-è¿­ä»£ä¸é€’å½’å·¥ä½œæµ)
    - [4.1 è‡ªé€‚åº”è¿­ä»£å™¨](#41-è‡ªé€‚åº”è¿­ä»£å™¨)
    - [4.2 å¯ç»§ç»­/å¯æ¢å¤é€’å½’æ¨¡å¼](#42-å¯ç»§ç»­å¯æ¢å¤é€’å½’æ¨¡å¼)
  - [5. å¹¶è¡Œä¸å¼‚æ­¥å·¥ä½œæµ](#5-å¹¶è¡Œä¸å¼‚æ­¥å·¥ä½œæµ)
    - [5.1 å·¥ä½œçªƒå–ä»»åŠ¡æ± ](#51-å·¥ä½œçªƒå–ä»»åŠ¡æ± )
    - [5.2 å¼‚æ­¥å·¥ä½œæµçŠ¶æ€æœº](#52-å¼‚æ­¥å·¥ä½œæµçŠ¶æ€æœº)
  - [6. æ€»ç»“ï¼šå·¥ä½œæµä¸ç®—æ³•è®¾è®¡å‡†åˆ™](#6-æ€»ç»“å·¥ä½œæµä¸ç®—æ³•è®¾è®¡å‡†åˆ™)
    - [6.1 ç»„åˆä¸æµç¨‹è®¾è®¡](#61-ç»„åˆä¸æµç¨‹è®¾è®¡)
    - [6.2 ç®—æ³•è®¾è®¡ä¸æ‰§è¡Œ](#62-ç®—æ³•è®¾è®¡ä¸æ‰§è¡Œ)
    - [6.3 é›†æˆè®¾è®¡åŸåˆ™](#63-é›†æˆè®¾è®¡åŸåˆ™)

## ğŸš€ Rust 1.89 ç‰¹æ€§é›†æˆ

### æ ¸å¿ƒæ”¹è¿›

1. **å¸¸é‡æ³›å‹æ˜¾å¼æ¨å¯¼** - ä½¿ç”¨ `_` å ä½ç¬¦è®©ç¼–è¯‘å™¨è‡ªåŠ¨æ¨æ–­æ•°ç»„å¤§å°
2. **ç”Ÿå‘½å‘¨æœŸè¯­æ³•æ”¹è¿›** - æ›´ä¸¥æ ¼çš„ç”Ÿå‘½å‘¨æœŸæ£€æŸ¥ï¼Œæå‡ä»£ç å¥å£®æ€§
3. **x86 ç‰¹æ€§æ‰©å±•** - æ”¯æŒæ›´å¤š AVX-512 æŒ‡ä»¤ï¼Œæä¾›ç¡¬ä»¶åŠ é€Ÿ
4. **æ ‡å‡†åº“å¢å¼º** - æ”¹è¿›çš„æµ‹è¯•æ¡†æ¶å’Œæ•°ç»„å¤„ç†å‡½æ•°

ç»“åˆå·¥ä½œæµç»„åˆä¸ç®—æ³•è®¾è®¡çš„è§†è§’ï¼Œä»¥ä¸‹æ˜¯åŸºäº Rust 1.89 çš„ç±»å‹è®¾è®¡ç»¼åˆå‡†åˆ™ï¼Œæ—¨åœ¨åˆ›å»ºæ—¢æ˜“äºä½¿ç”¨åˆé«˜æ•ˆçš„ç±»å‹ç³»ç»Ÿã€‚

## 1. ç±»å‹ä¸ç®—æ³•çš„è¡¨è¾¾ä¸ç»„åˆ

### 1.1 æ„å»ºæµå¼å¤„ç†ç®¡é“ï¼ˆRust 1.89 ä¼˜åŒ–ç‰ˆï¼‰

```rust
use std::marker::PhantomData;

/// Rust 1.89 ä¼˜åŒ–ç‰ˆï¼šç±»å‹å®‰å…¨çš„æµå¼å¤„ç†ç®¡é“
/// ä½¿ç”¨å¸¸é‡æ³›å‹æ˜¾å¼æ¨å¯¼å’Œç”Ÿå‘½å‘¨æœŸæ”¹è¿›
pub struct WorkflowPipeline<I, O, const MAX_STEPS: usize> {
    steps: Vec<Box<dyn Fn(I) -> O + Send + Sync>>,
    _phantom: PhantomData<(I, O)>,
}

impl<I: Clone + 'static, O: 'static, const MAX_STEPS: usize> WorkflowPipeline<I, O, MAX_STEPS> {
    /// åˆ›å»ºæ–°çš„ç®¡é“ï¼Œä½¿ç”¨å¸¸é‡æ³›å‹é™åˆ¶æœ€å¤§æ­¥éª¤æ•°
    pub fn new(initial_step: impl Fn(I) -> O + Send + Sync + 'static) -> Self {
        Self {
            steps: vec![Box::new(initial_step)],
            _phantom: PhantomData,
        }
    }
    
    /// æ·»åŠ è½¬æ¢æ­¥éª¤ï¼Œç¼–è¯‘æ—¶æ£€æŸ¥æ­¥éª¤æ•°é‡é™åˆ¶
    pub fn then<P>(self, next_step: impl Fn(O) -> P + Send + Sync + 'static) -> Result<WorkflowPipeline<I, P, MAX_STEPS>, PipelineError> {
        if self.steps.len() >= MAX_STEPS {
            return Err(PipelineError::ExceedsMaxSteps(MAX_STEPS));
        }
        
        let mut new_steps: Vec<Box<dyn Fn(I) -> P + Send + Sync>> = Vec::new();
        
        for step in self.steps {
            let cloned_next = next_step.clone();
            new_steps.push(Box::new(move |input: I| {
                let intermediate = step(input);
                cloned_next(intermediate)
            }));
        }
        
        Ok(WorkflowPipeline { 
            steps: new_steps,
            _phantom: PhantomData,
        })
    }
    
    /// ä½¿ç”¨ x86 ç‰¹æ€§è¿›è¡Œå¹¶è¡Œæ‰§è¡Œï¼ˆå¦‚æœæ”¯æŒï¼‰
    pub fn process_parallel(&self, inputs: Vec<I>) -> Vec<O> 
    where 
        I: Send + Clone,
        O: Send,
    {
        // æ£€æŸ¥æ˜¯å¦æ”¯æŒ AVX-512
        let is_avx512_supported = is_x86_feature_detected!("avx512f");
        
        if is_avx512_supported && inputs.len() >= 16 {
            // ä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿçš„å¹¶è¡Œå¤„ç†
            unsafe { self.process_parallel_avx512(inputs) }
        } else {
            // å›é€€åˆ°æ ‡å‡†å¹¶è¡Œå¤„ç†
            self.process_parallel_standard(inputs)
        }
    }
    
    /// ä½¿ç”¨ AVX-512 è¿›è¡Œå¹¶è¡Œå¤„ç†
    #[target_feature(enable = "avx512f")]
    unsafe fn process_parallel_avx512(&self, inputs: Vec<I>) -> Vec<O> 
    where 
        I: Send + Clone,
        O: Send,
    {
        use rayon::prelude::*;
        
        inputs.into_par_iter()
            .map(|input| self.process(input))
            .collect()
    }
    
    /// æ ‡å‡†å¹¶è¡Œå¤„ç†
    fn process_parallel_standard(&self, inputs: Vec<I>) -> Vec<O> 
    where 
        I: Send + Clone,
        O: Send,
    {
        use rayon::prelude::*;
        
        inputs.into_par_iter()
            .map(|input| self.process(input))
            .collect()
    }
    
    /// å¤„ç†å•ä¸ªè¾“å…¥
    pub fn process(&self, input: I) -> O {
        // ä½¿ç”¨ç¬¬ä¸€ä¸ªæ­¥éª¤ï¼ˆç®¡é“ä¸­å”¯ä¸€çš„ä¸€ä¸ªï¼‰
        self.steps[0](input)
    }
    
    /// è·å–å½“å‰æ­¥éª¤æ•°é‡
    pub fn step_count(&self) -> usize {
        self.steps.len()
    }
    
    /// è½¬æ¢ä¸ºå›ºå®šå¤§å°æ•°ç»„ï¼ˆå¦‚æœæ­¥éª¤æ•°é‡åŒ¹é…ï¼‰
    pub fn to_fixed_array<const N: usize>(self) -> Result<[Box<dyn Fn(I) -> O + Send + Sync>; N], PipelineError> 
    where 
        [Box<dyn Fn(I) -> O + Send + Sync>; N]: Default,
    {
        if self.steps.len() != N {
            return Err(PipelineError::SizeMismatch {
                expected: N,
                actual: self.steps.len(),
            });
        }
        
        let mut array = <[Box<dyn Fn(I) -> O + Send + Sync>; N]>::default();
        for (i, step) in self.steps.into_iter().enumerate() {
            array[i] = step;
        }
        Ok(array)
    }
}

/// ç®¡é“é”™è¯¯ç±»å‹
#[derive(Debug, thiserror::Error)]
pub enum PipelineError {
    #[error("Exceeds maximum steps: {0}")]
    ExceedsMaxSteps(usize),
    #[error("Size mismatch: expected {expected}, got {actual}")]
    SizeMismatch { expected: usize, actual: usize },
}

// Rust 1.89 ä½¿ç”¨ç¤ºä¾‹
fn process_data_with_rust189() -> Result<(), PipelineError> {
    // åˆ›å»ºå›¾åƒå¤„ç†ç®¡é“ï¼Œä½¿ç”¨å¸¸é‡æ³›å‹é™åˆ¶æœ€å¤§æ­¥éª¤æ•°
    let image_pipeline = WorkflowPipeline::<String, Vec<u8>, 10>::new(|path: String| {
            // åŠ è½½å›¾åƒ
            println!("Loading image from {}", path);
            vec![0u8; 100] // æ¨¡æ‹Ÿå›¾åƒæ•°æ®
        })?
        .then(|image: Vec<u8>| {
            // è°ƒæ•´å¤§å°
            println!("Resizing image of {} bytes", image.len());
            let mut resized = image;
            resized.resize(50, 0);
            resized
        })?
        .then(|image: Vec<u8>| {
            // åº”ç”¨æ»¤é•œ
            println!("Applying filter to image of {} bytes", image.len());
            let filtered = image;
            filtered
        })?;
    
    // å¤„ç†å¤šä¸ªå›¾åƒ
    let image_paths = vec![
        "image1.jpg".to_string(),
        "image2.jpg".to_string(),
        "image3.jpg".to_string(),
    ];
    
    // ä½¿ç”¨ x86 ç‰¹æ€§è¿›è¡Œå¹¶è¡Œå¤„ç†
    let results = image_pipeline.process_parallel(image_paths);
    println!("Processed {} images", results.len());
    
    // è½¬æ¢ä¸ºå›ºå®šå¤§å°æ•°ç»„ï¼ˆå¦‚æœæ­¥éª¤æ•°é‡åŒ¹é…ï¼‰
    if image_pipeline.step_count() == 3 {
        let fixed_array = image_pipeline.to_fixed_array::<3>()?;
        println!("Successfully converted to fixed array with {} steps", fixed_array.len());
    }
    
    Ok(())
}

/// ä½¿ç”¨å¸¸é‡æ³›å‹æ˜¾å¼æ¨å¯¼çš„ç¤ºä¾‹
fn demonstrate_const_generic_inference() -> Result<(), PipelineError> {
    // ä½¿ç”¨ _ è®©ç¼–è¯‘å™¨è‡ªåŠ¨æ¨æ–­æ•°ç»„å¤§å°
    let steps = ["step1", "step2", "step3"];
    let workflow_array: WorkflowArray<String, _> = WorkflowArray::from_iter(steps.iter().map(|s| s.to_string()))?;
    
    println!("Created workflow array with {} steps", workflow_array.data.len());
    
    // æ˜ å°„åˆ°æ–°ç±»å‹
    let processed_array = workflow_array.map(|step| format!("processed_{}", step));
    
    for (i, step) in processed_array.data.iter().enumerate() {
        println!("Step {}: {}", i, step);
    }
    
    Ok(())
}

/// å·¥ä½œæµæ•°ç»„å®šä¹‰ï¼ˆä½¿ç”¨å¸¸é‡æ³›å‹ï¼‰
pub struct WorkflowArray<T, const N: usize> {
    pub data: [T; N],
}

impl<T, const N: usize> WorkflowArray<T, N> {
    /// ä»è¿­ä»£å™¨åˆ›å»ºï¼Œä½¿ç”¨å¸¸é‡æ³›å‹æ˜¾å¼æ¨å¯¼
    pub fn from_iter<I>(iter: I) -> Result<Self, PipelineError>
    where 
        I: IntoIterator<Item = T>,
        I::IntoIter: ExactSizeIterator,
    {
        let iter = iter.into_iter();
        if iter.len() != N {
            return Err(PipelineError::SizeMismatch {
                expected: N,
                actual: iter.len(),
            });
        }
        
        let mut array = std::array::from_fn(|_| {
            // è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„å®ç°æ¥ä»è¿­ä»£å™¨å¡«å……æ•°ç»„
            // ä¸ºç®€åŒ–ç¤ºä¾‹ï¼Œæˆ‘ä»¬å‡è®¾ T å®ç°äº† Default
            unsafe { std::mem::zeroed() }
        });
        
        for (i, item) in iter.enumerate() {
            array[i] = item;
        }
        
        Ok(Self { data: array })
    }
    
    /// æ˜ å°„åˆ°æ–°ç±»å‹
    pub fn map<U, F>(self, mut f: F) -> WorkflowArray<U, N>
    where 
        F: FnMut(T) -> U,
    {
        WorkflowArray {
            data: self.data.map(f),
        }
    }
}
```

**å‡†åˆ™**ï¼šè®¾è®¡æ”¯æŒç»„åˆçš„æ•°æ®æµå¤„ç†ç®¡é“ï¼Œå®ç°å£°æ˜å¼å·¥ä½œæµã€‚

### 1.2 è¿­ä»£å™¨ä¸ç®—æ³•ç»„åˆ

```rust
// æ¨èï¼šè¿­ä»£å™¨ä¸ç®—æ³•ç»„åˆ
pub trait DataProcessing<T> {
    fn process(&self, data: T) -> T;
}

// ç®—æ³•å®ç°
pub struct Normalize;
impl<T: AsRef<[f64]> + AsMut<[f64]>> DataProcessing<T> for Normalize {
    fn process(&self, mut data: T) -> T {
        let slice = data.as_ref();
        if slice.is_empty() {
            return data;
        }
        
        // æ‰¾æœ€å¤§å’Œæœ€å°å€¼
        let max = slice.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
        let min = slice.iter().fold(f64::INFINITY, |a, &b| a.min(b));
        
        // å½’ä¸€åŒ–
        let range = max - min;
        if range > 0.0 {
            let mut output = data.as_mut();
            for value in output.iter_mut() {
                *value = (*value - min) / range;
            }
        }
        
        data
    }
}

pub struct MovingAverage {
    window_size: usize,
}

impl MovingAverage {
    pub fn new(window_size: usize) -> Self {
        Self { window_size }
    }
}

impl<T: AsRef<[f64]> + AsMut<[f64]>> DataProcessing<T> for MovingAverage {
    fn process(&self, mut data: T) -> T {
        let slice = data.as_ref();
        if slice.len() <= self.window_size {
            return data;
        }
        
        let mut result = Vec::with_capacity(slice.len());
        
        // è®¡ç®—ç§»åŠ¨å¹³å‡
        for i in 0..slice.len() {
            let start = if i < self.window_size / 2 {
                0
            } else {
                i - self.window_size / 2
            };
            
            let end = std::cmp::min(slice.len(), i + self.window_size / 2 + 1);
            let window = &slice[start..end];
            
            let avg = window.iter().sum::<f64>() / window.len() as f64;
            result.push(avg);
        }
        
        // å¤åˆ¶ç»“æœ
        let mut output = data.as_mut();
        for (i, &val) in result.iter().enumerate() {
            output[i] = val;
        }
        
        data
    }
}

// ç»„åˆå¤šä¸ªå¤„ç†æ­¥éª¤
pub struct ProcessingPipeline<T> {
    steps: Vec<Box<dyn DataProcessing<T> + Send + Sync>>,
}

impl<T> ProcessingPipeline<T> {
    pub fn new() -> Self {
        Self { steps: Vec::new() }
    }
    
    pub fn add_step<P: DataProcessing<T> + Send + Sync + 'static>(&mut self, processor: P) -> &mut Self {
        self.steps.push(Box::new(processor));
        self
    }
    
    pub fn process(&self, data: T) -> T {
        self.steps.iter().fold(data, |acc, processor| {
            processor.process(acc)
        })
    }
    
    // å¹¶è¡Œå¤„ç†å¤šä¸ªæ•°æ®é¡¹
    pub fn process_batch<I>(&self, data: I) -> Vec<T>
    where
        I: IntoIterator<Item = T>,
        T: Send + 'static,
    {
        use rayon::prelude::*;
        
        data.into_iter()
            .collect::<Vec<_>>()
            .into_par_iter()
            .map(|item| self.process(item))
            .collect()
    }
}

// ä½¿ç”¨ç¤ºä¾‹
fn process_time_series() {
    // åˆ›å»ºç¤ºä¾‹æ•°æ®
    let data = vec![1.0, 5.0, 3.0, 8.0, 2.0, 9.0, 6.0, 4.0, 7.0];
    
    // åˆ›å»ºå¤„ç†ç®¡é“
    let mut pipeline = ProcessingPipeline::new();
    pipeline
        .add_step(MovingAverage::new(3))  // ç§»åŠ¨å¹³å‡
        .add_step(Normalize);             // å½’ä¸€åŒ–
    
    // å¤„ç†æ•°æ®
    let processed = pipeline.process(data);
    println!("Processed data: {:?}", processed);
    
    // å¤„ç†å¤šä¸ªæ•°æ®é›†
    let batch = vec![
        vec![1.0, 2.0, 3.0, 4.0, 5.0],
        vec![5.0, 4.0, 3.0, 2.0, 1.0],
        vec![3.0, 6.0, 9.0, 6.0, 3.0],
    ];
    
    let processed_batch = pipeline.process_batch(batch);
    println!("Processed {} datasets", processed_batch.len());
}
```

**å‡†åˆ™**ï¼šè®¾è®¡æ”¯æŒæ•°æ®å¤„ç†ç®—æ³•çš„å¯ç»„åˆæ¥å£ï¼Œå®ç°çµæ´»çš„å¤„ç†ç®¡é“ã€‚

## 2. çŠ¶æ€ç®¡ç†ä¸è½¬æ¢

### 2.1 å·¥ä½œæµçŠ¶æ€æœº

```rust
// æ¨èï¼šå·¥ä½œæµçŠ¶æ€æœº
// å®šä¹‰å·¥ä½œæµçŠ¶æ€
pub mod state {
    pub struct Uninitialized;
    pub struct Ready;
    pub struct Running;
    pub struct Completed;
    pub struct Failed;
}

// å·¥ä½œæµçŠ¶æ€æœº
pub struct Workflow<S> {
    name: String,
    created_at: std::time::Instant,
    progress: f32,
    result: Option<String>,
    error: Option<String>,
    _state: std::marker::PhantomData<S>,
}

// æœªåˆå§‹åŒ–çŠ¶æ€
impl Workflow<state::Uninitialized> {
    pub fn new(name: impl Into<String>) -> Self {
        Self {
            name: name.into(),
            created_at: std::time::Instant::now(),
            progress: 0.0,
            result: None,
            error: None,
            _state: std::marker::PhantomData,
        }
    }
    
    pub fn initialize(self) -> Workflow<state::Ready> {
        println!("Initializing workflow: {}", self.name);
        Workflow {
            name: self.name,
            created_at: self.created_at,
            progress: 0.0,
            result: None,
            error: None,
            _state: std::marker::PhantomData,
        }
    }
}

// å°±ç»ªçŠ¶æ€
impl Workflow<state::Ready> {
    pub fn start(self) -> Workflow<state::Running> {
        println!("Starting workflow: {}", self.name);
        Workflow {
            name: self.name,
            created_at: self.created_at,
            progress: 0.0,
            result: None,
            error: None,
            _state: std::marker::PhantomData,
        }
    }
}

// è¿è¡ŒçŠ¶æ€
impl Workflow<state::Running> {
    pub fn update_progress(&mut self, progress: f32) {
        self.progress = progress.clamp(0.0, 1.0);
        println!("Progress for {}: {:.1}%", self.name, self.progress * 100.0);
    }
    
    pub fn complete(self, result: impl Into<String>) -> Workflow<state::Completed> {
        println!("Completing workflow: {}", self.name);
        Workflow {
            name: self.name,
            created_at: self.created_at,
            progress: 1.0,
            result: Some(result.into()),
            error: None,
            _state: std::marker::PhantomData,
        }
    }
    
    pub fn fail(self, error: impl Into<String>) -> Workflow<state::Failed> {
        println!("Workflow failed: {}", self.name);
        Workflow {
            name: self.name,
            created_at: self.created_at,
            progress: self.progress,
            result: None,
            error: Some(error.into()),
            _state: std::marker::PhantomData,
        }
    }
}

// å®ŒæˆçŠ¶æ€
impl Workflow<state::Completed> {
    pub fn result(&self) -> Option<&str> {
        self.result.as_deref()
    }
    
    pub fn elapsed(&self) -> std::time::Duration {
        self.created_at.elapsed()
    }
    
    pub fn reset(self) -> Workflow<state::Ready> {
        println!("Resetting workflow: {}", self.name);
        Workflow {
            name: self.name,
            created_at: std::time::Instant::now(),
            progress: 0.0,
            result: None,
            error: None,
            _state: std::marker::PhantomData,
        }
    }
}

// å¤±è´¥çŠ¶æ€
impl Workflow<state::Failed> {
    pub fn error(&self) -> Option<&str> {
        self.error.as_deref()
    }
    
    pub fn retry(self) -> Workflow<state::Running> {
        println!("Retrying workflow: {}", self.name);
        Workflow {
            name: self.name,
            created_at: self.created_at,
            progress: self.progress,
            result: None,
            error: None,
            _state: std::marker::PhantomData,
        }
    }
    
    pub fn reset(self) -> Workflow<state::Ready> {
        println!("Resetting failed workflow: {}", self.name);
        Workflow {
            name: self.name,
            created_at: std::time::Instant::now(),
            progress: 0.0,
            result: None,
            error: None,
            _state: std::marker::PhantomData,
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
fn run_workflow() {
    // åˆ›å»ºå’Œåˆå§‹åŒ–å·¥ä½œæµ
    let workflow = Workflow::new("Data Processing")
        .initialize()
        .start();
    
    // æ¨¡æ‹Ÿå·¥ä½œæµè¿›åº¦
    let mut running = workflow;
    
    // æ¨¡æ‹Ÿå·¥ä½œ
    for i in 1..=10 {
        std::thread::sleep(std::time::Duration::from_millis(100));
        running.update_progress(i as f32 / 10.0);
    }
    
    // æ ¹æ®ç»“æœé€‰æ‹©å®Œæˆæˆ–å¤±è´¥
    let success = true;
    let final_state = if success {
        let completed = running.complete("Processed 1000 records");
        println!("Result: {:?}", completed.result());
        println!("Time elapsed: {:?}", completed.elapsed());
        
        // å¯ä»¥é‡ç½®å·¥ä½œæµ
        let ready = completed.reset();
        ready.start()
    } else {
        let failed = running.fail("Connection error");
        println!("Error: {:?}", failed.error());
        
        // å¯ä»¥é‡è¯•
        failed.retry()
    };
    
    // ç»§ç»­ä½¿ç”¨...
    println!("Workflow continues: {}", final_state.name);
}
```

**å‡†åˆ™**ï¼šä½¿ç”¨ç±»å‹çŠ¶æ€æ¨¡å¼å®ç°å·¥ä½œæµçŠ¶æ€æœºï¼Œç¡®ä¿çŠ¶æ€è½¬æ¢çš„å®‰å…¨æ€§ã€‚

### 2.2 äº‹åŠ¡æ€§æ“ä½œæ¨¡å¼

```rust
// æ¨èï¼šäº‹åŠ¡æ€§æ“ä½œæ¨¡å¼
// äº‹åŠ¡ç‰¹å¾
pub trait Transaction {
    type Input;
    type Output;
    type Error;
    
    // å‡†å¤‡äº‹åŠ¡
    fn prepare(&self, input: &Self::Input) -> Result<(), Self::Error>;
    
    // æ‰§è¡Œäº‹åŠ¡
    fn execute(&self, input: &Self::Input) -> Result<Self::Output, Self::Error>;
    
    // å›æ»šæ“ä½œ
    fn rollback(&self, input: &Self::Input);
    
    // å®‰å…¨æ‰§è¡Œäº‹åŠ¡
    fn run(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {
        // å‡†å¤‡é˜¶æ®µ
        if let Err(err) = self.prepare(&input) {
            return Err(err);
        }
        
        // æ‰§è¡Œé˜¶æ®µ
        match self.execute(&input) {
            Ok(output) => Ok(output),
            Err(err) => {
                // å‡ºé”™æ—¶å›æ»š
                self.rollback(&input);
                Err(err)
            }
        }
    }
}

// æ–‡ä»¶å¤„ç†äº‹åŠ¡ç¤ºä¾‹
pub struct FileProcessingTransaction {
    temp_path: String,
}

impl FileProcessingTransaction {
    pub fn new(temp_dir: impl Into<String>) -> Self {
        Self {
            temp_path: temp_dir.into(),
        }
    }
    
    fn get_temp_file_path(&self, input: &str) -> String {
        format!("{}/temp_{}", self.temp_path, std::path::Path::new(input).file_name().unwrap().to_string_lossy())
    }
}

#[derive(Debug)]
pub enum FileError {
    IoError(std::io::Error),
    ProcessingError(String),
}

impl From<std::io::Error> for FileError {
    fn from(err: std::io::Error) -> Self {
        FileError::IoError(err)
    }
}

impl Transaction for FileProcessingTransaction {
    type Input = String;  // è¾“å…¥æ–‡ä»¶è·¯å¾„
    type Output = String; // è¾“å‡ºæ–‡ä»¶è·¯å¾„
    type Error = FileError;
    
    fn prepare(&self, input: &Self::Input) -> Result<(), Self::Error> {
        // æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !std::path::Path::new(input).exists() {
            return Err(FileError::ProcessingError(format!("Input file not found: {}", input)));
        }
        
        // æ£€æŸ¥ä¸´æ—¶ç›®å½•æ˜¯å¦å­˜åœ¨
        if !std::path::Path::new(&self.temp_path).exists() {
            std::fs::create_dir_all(&self.temp_path)
                .map_err(FileError::IoError)?;
        }
        
        Ok(())
    }
    
    fn execute(&self, input: &Self::Input) -> Result<Self::Output, Self::Error> {
        // åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        let temp_file = self.get_temp_file_path(input);
        
        // æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†
        println!("Processing file: {}", input);
        println!("Creating processed file: {}", temp_file);
        
        // æ¨¡æ‹Ÿå†™å…¥å¤„ç†åçš„æ–‡ä»¶
        std::fs::write(&temp_file, "Processed content")
            .map_err(FileError::IoError)?;
        
        // è¿”å›å¤„ç†åçš„æ–‡ä»¶è·¯å¾„
        Ok(temp_file)
    }
    
    fn rollback(&self, input: &Self::Input) {
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        let temp_file = self.get_temp_file_path(input);
        println!("Rolling back: removing temp file {}", temp_file);
        
        if let Err(e) = std::fs::remove_file(&temp_file) {
            eprintln!("Warning: Failed to remove temp file during rollback: {}", e);
        }
    }
}

// ä½¿ç”¨äº‹åŠ¡æ¨¡å¼
fn process_files() {
    let transaction = FileProcessingTransaction::new("/tmp");
    
    // å¤„ç†æ–‡ä»¶
    let result = transaction.run("input.txt".to_string());
    
    match result {
        Ok(output_path) => {
            println!("Successfully processed file: {}", output_path);
            // ä½¿ç”¨å¤„ç†åçš„æ–‡ä»¶...
        }
        Err(err) => {
            println!("Failed to process file: {:?}", err);
            // å¤„ç†é”™è¯¯...
        }
    }
}
```

**å‡†åˆ™**ï¼šé€šè¿‡äº‹åŠ¡æ€§æ“ä½œæ¨¡å¼ç¡®ä¿å·¥ä½œæµä¸­æ“ä½œçš„ä¸€è‡´æ€§å’Œå¯å›æ»šæ€§ã€‚

## 3. ç®—æ³•ä¸ç­–ç•¥æ¥å£è®¾è®¡

### 3.1 å¯ç»„åˆç­–ç•¥æ¨¡å¼

```rust
// æ¨èï¼šå¯ç»„åˆç­–ç•¥æ¨¡å¼
// å®šä¹‰éªŒè¯ç­–ç•¥ç‰¹å¾
pub trait ValidationStrategy<T> {
    fn validate(&self, value: &T) -> Result<(), String>;
}

// å­—ç¬¦ä¸²é•¿åº¦éªŒè¯
pub struct LengthValidator {
    min: usize,
    max: usize,
}

impl LengthValidator {
    pub fn new(min: usize, max: usize) -> Self {
        Self { min, max }
    }
}

impl ValidationStrategy<String> for LengthValidator {
    fn validate(&self, value: &String) -> Result<(), String> {
        let len = value.len();
        if len < self.min {
            Err(format!("String is too short (minimum {})", self.min))
        } else if len > self.max {
            Err(format!("String is too long (maximum {})", self.max))
        } else {
            Ok(())
        }
    }
}

// æ­£åˆ™è¡¨è¾¾å¼éªŒè¯
pub struct RegexValidator {
    pattern: regex::Regex,
    error_message: String,
}

impl RegexValidator {
    pub fn new(pattern: &str, error_message: impl Into<String>) -> Result<Self, regex::Error> {
        Ok(Self {
            pattern: regex::Regex::new(pattern)?,
            error_message: error_message.into(),
        })
    }
}

impl ValidationStrategy<String> for RegexValidator {
    fn validate(&self, value: &String) -> Result<(), String> {
        if self.pattern.is_match(value) {
            Ok(())
        } else {
            Err(self.error_message.clone())
        }
    }
}

// ç»„åˆå¤šä¸ªéªŒè¯å™¨
pub struct ValidationChain<T> {
    validators: Vec<Box<dyn ValidationStrategy<T>>>,
}

impl<T> ValidationChain<T> {
    pub fn new() -> Self {
        Self {
            validators: Vec::new(),
        }
    }
    
    pub fn add<V: ValidationStrategy<T> + 'static>(&mut self, validator: V) -> &mut Self {
        self.validators.push(Box::new(validator));
        self
    }
    
    pub fn validate(&self, value: &T) -> Result<(), Vec<String>> {
        let errors: Vec<String> = self.validators.iter()
            .filter_map(|validator| {
                match validator.validate(value) {
                    Ok(()) => None,
                    Err(msg) => Some(msg),
                }
            })
            .collect();
        
        if errors.is_empty() {
            Ok(())
        } else {
            Err(errors)
        }
    }
}

// AND ç»„åˆéªŒè¯å™¨ - æ‰€æœ‰éªŒè¯é€šè¿‡æ‰ç®—é€šè¿‡
pub struct AllValidators<T> {
    validators: Vec<Box<dyn ValidationStrategy<T>>>,
}

impl<T> AllValidators<T> {
    pub fn new() -> Self {
        Self {
            validators: Vec::new(),
        }
    }
    
    pub fn add<V: ValidationStrategy<T> + 'static>(&mut self, validator: V) -> &mut Self {
        self.validators.push(Box::new(validator));
        self
    }
}

impl<T> ValidationStrategy<T> for AllValidators<T> {
    fn validate(&self, value: &T) -> Result<(), String> {
        for validator in &self.validators {
            if let Err(msg) = validator.validate(value) {
                return Err(msg);
            }
        }
        Ok(())
    }
}

// OR ç»„åˆéªŒè¯å™¨ - ä»»ä¸€éªŒè¯é€šè¿‡å³å¯
pub struct AnyValidator<T> {
    validators: Vec<Box<dyn ValidationStrategy<T>>>,
}

impl<T> AnyValidator<T> {
    pub fn new() -> Self {
        Self {
            validators: Vec::new(),
        }
    }
    
    pub fn add<V: ValidationStrategy<T> + 'static>(&mut self, validator: V) -> &mut Self {
        self.validators.push(Box::new(validator));
        self
    }
}

impl<T> ValidationStrategy<T> for AnyValidator<T> {
    fn validate(&self, value: &T) -> Result<(), String> {
        if self.validators.is_empty() {
            return Ok(());
        }
        
        let mut all_errors = Vec::new();
        
        for validator in &self.validators {
            match validator.validate(value) {
                Ok(()) => return Ok(()),
                Err(msg) => all_errors.push(msg),
            }
        }
        
        Err(format!("All validations failed: {}", all_errors.join("; ")))
    }
}

// ä½¿ç”¨ç»„åˆç­–ç•¥æ¨¡å¼
fn validate_user_input() {
    // åˆ›å»ºç”µå­é‚®ä»¶éªŒè¯å™¨ï¼ˆç»„åˆå¤šä¸ªè§„åˆ™ï¼‰
    let mut email_validator = AllValidators::new();
    
    // æ·»åŠ é•¿åº¦éªŒè¯
    email_validator.add(LengthValidator::new(5, 100));
    
    // æ·»åŠ æ­£åˆ™è¡¨è¾¾å¼éªŒè¯
    let email_regex = RegexValidator::new(
        r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$",
        "Invalid email format",
    ).unwrap();
    
    email_validator.add(email_regex);
    
    // åˆ›å»ºå¯†ç éªŒè¯å™¨ï¼ˆç»„åˆå¤šä¸ªè§„åˆ™ï¼‰
    let mut password_validator = AllValidators::new();
    
    // å¯†ç é•¿åº¦
    password_validator.add(LengthValidator::new(8, 64));
    
    // å¯†ç å¤æ‚åº¦ï¼ˆè‡³å°‘åŒ…å«ä¸€ä¸ªå¤§å†™å­—æ¯ã€ä¸€ä¸ªå°å†™å­—æ¯å’Œä¸€ä¸ªæ•°å­—ï¼‰
    let mut complexity_validator = AnyValidator::new();
    complexity_validator
        .add(RegexValidator::new(r"^.*[A-Z].*$", "Missing uppercase letter").unwrap())
        .add(RegexValidator::new(r"^.*[a-z].*$", "Missing lowercase letter").unwrap())
        .add(RegexValidator::new(r"^.*[0-9].*$", "Missing digit").unwrap());
    
    password_validator.add(complexity_validator);
    
    // åˆ›å»ºéªŒè¯é“¾ï¼ŒåŒ…å«æ‰€æœ‰éªŒè¯å™¨
    let mut validation_chain = ValidationChain::new();
    validation_chain
        .add(email_validator)
        .add(password_validator);
    
    // éªŒè¯è¾“å…¥
    let email = "user@example.com".to_string();
    let password = "Password123".to_string();
    
    if let Err(errors) = validation_chain.validate(&email) {
        println!("Email validation failed: {:?}", errors);
    } else {
        println!("Email is valid!");
    }
    
    if let Err(errors) = validation_chain.validate(&password) {
        println!("Password validation failed: {:?}", errors);
    } else {
        println!("Password is valid!");
    }
}
```

**å‡†åˆ™**ï¼šè®¾è®¡å¯ç»„åˆçš„ç­–ç•¥æ¥å£ï¼Œå…è®¸çµæ´»æ„å»ºå¤æ‚çš„ç®—æ³•ç»„åˆã€‚

### 3.2 ä¼˜åŒ–å™¨ä¸ç›®æ ‡å‡½æ•°æ¨¡å¼

```rust
// æ¨èï¼šä¼˜åŒ–å™¨ä¸ç›®æ ‡å‡½æ•°æ¨¡å¼
// å®šä¹‰ç›®æ ‡å‡½æ•°ç‰¹å¾
pub trait ObjectiveFunction {
    type Input;
    type Output: PartialOrd;
    
    // åœ¨ä¼˜åŒ–é—®é¢˜ä¸­å¾€å¾€æ˜¯æœ€å¤§åŒ–ç›®æ ‡å‡½æ•°
    fn evaluate(&self, input: &Self::Input) -> Self::Output;
}

// ä¼˜åŒ–å™¨ç‰¹å¾
pub trait Optimizer<F: ObjectiveFunction> {
    // ä½¿ç”¨ç›®æ ‡å‡½æ•°æ‰¾åˆ°æœ€ä¼˜è§£
    fn optimize(&self, objective: &F, iterations: usize) -> F::Input;
}

// æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºä¸€ç»´å‡½æ•°ï¼‰
pub struct GradientDescent {
    learning_rate: f64,
    epsilon: f64,
}

impl GradientDescent {
    pub fn new(learning_rate: f64, epsilon: f64) -> Self {
        Self { learning_rate, epsilon }
    }
    
    // è®¡ç®—æ•°å€¼æ¢¯åº¦
    fn numerical_gradient(&self, objective: &impl Fn(f64) -> f64, x: f64) -> f64 {
        let h = 1e-5;
        (objective(x + h) - objective(x - h)) / (2.0 * h)
    }
}

// ç‰¹åŒ–ä¸ºä¸€ç»´å‡½æ•°çš„ä¼˜åŒ–å™¨
impl Optimizer<OneDimensionalFunction> for GradientDescent {
    fn optimize(&self, objective: &OneDimensionalFunction, iterations: usize) -> f64 {
        let mut x = objective.initial_guess;
        
        for i in 0..iterations {
            // è®¡ç®—æ¢¯åº¦
            let gradient = self.numerical_gradient(&|x| -objective.function(x), x);
            
            // æ›´æ–°å‚æ•°
            let delta = self.learning_rate * gradient;
            x -= delta;
            
            // è¾“å‡ºè¿›åº¦
            if i % 10 == 0 {
                println!(
                    "Iteration {}: x = {:.6}, f(x) = {:.6}, gradient = {:.6}",
                    i, x, objective.function(x), gradient
                );
            }
            
            // æ£€æŸ¥æ”¶æ•›
            if delta.abs() < self.epsilon {
                println!("Converged after {} iterations", i);
                break;
            }
        }
        
        x
    }
}

// ä¸€ç»´å‡½æ•°ä¼˜åŒ–é—®é¢˜
pub struct OneDimensionalFunction {
    pub function: Box<dyn Fn(f64) -> f64>,
    pub initial_guess: f64,
}

impl OneDimensionalFunction {
    pub fn new(function: impl Fn(f64) -> f64 + 'static, initial_guess: f64) -> Self {
        Self {
            function: Box::new(function),
            initial_guess,
        }
    }
}

impl ObjectiveFunction for OneDimensionalFunction {
    type Input = f64;
    type Output = f64;
    
    fn evaluate(&self, input: &Self::Input) -> Self::Output {
        (self.function)(*input)
    }
}

// ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•
pub struct ParticleSwarmOptimization {
    particles: usize,
    inertia_weight: f64,
    cognitive_weight: f64,
    social_weight: f64,
}

impl ParticleSwarmOptimization {
    pub fn new(
        particles: usize,
        inertia_weight: f64,
        cognitive_weight: f64,
        social_weight: f64,
    ) -> Self {
        Self {
            particles,
            inertia_weight,
            cognitive_weight,
            social_weight,
        }
    }
}

impl Optimizer<OneDimensionalFunction> for ParticleSwarmOptimization {
    fn optimize(&self, objective: &OneDimensionalFunction, iterations: usize) -> f64 {
        use rand::Rng;
        let mut rng = rand::thread_rng();
        
        // åˆå§‹åŒ–ç²’å­ä½ç½®å’Œé€Ÿåº¦
        let mut positions: Vec<f64> = (0..self.particles)
            .map(|_| objective.initial_guess + rng.gen_range(-5.0..5.0))
            .collect();
        
        let mut velocities: Vec<f64> = (0..self.particles)
            .map(|_| rng.gen_range(-1.0..1.0))
            .collect();
        
        // åˆå§‹åŒ–ä¸ªä½“æœ€ä¼˜ä½ç½®å’Œå…¨å±€æœ€ä¼˜ä½ç½®
        let mut personal_best_positions = positions.clone();
        let mut personal_best_values: Vec<f64> = personal_best_positions.iter()
            .map(|&x| objective.evaluate(&x))
            .collect();
        
        let mut global_best_index = personal_best_values
            .iter()
            .enumerate()
            .max_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap())
            .unwrap().0;
        
        let mut global_best_position = personal_best_positions[global_best_index];
        
        // è¿­ä»£ä¼˜åŒ–
        for i in 0..iterations {
            // æ›´æ–°æ¯ä¸ªç²’å­
            for p in 0..self.particles {
                // ç”Ÿæˆéšæœºæƒé‡
                let r1: f64 = rng.gen_range(0.0..1.0);
                let r2: f64 = rng.gen_range(0.0..1.0);
                
                // æ›´æ–°é€Ÿåº¦
                velocities[p] = self.inertia_weight * velocities[p]
                    + self.cognitive_weight * r1 * (personal_best_positions[p] - positions[p])
                    + self.social_weight * r2 * (global_best_position - positions[p]);
                
                // æ›´æ–°ä½ç½®
                positions[p] += velocities[p];
                
                // è¯„ä¼°æ–°ä½ç½®
                let value = objective.evaluate(&positions[p]);
                
                // æ›´æ–°ä¸ªä½“æœ€ä¼˜
                if value > personal_best_values[p] {
                    personal_best_values[p] = value;
                    personal_best_positions[p] = positions[p];
                    
                    // æ›´æ–°å…¨å±€æœ€ä¼˜
                    if value > personal_best_values[global_best_index] {
                        global_best_index = p;
                        global_best_position = positions[p];
                    }
                }
            }
            
            // è¾“å‡ºè¿›åº¦
            if i % 10 == 0 {
                println!(
                    "Iteration {}: Best position = {:.6}, Best value = {:.6}",
                    i, global_best_position, personal_best_values[global_best_index]
                );
            }
        }
        
        global_best_position
    }
}

// ä½¿ç”¨ä¼˜åŒ–å™¨å’Œç›®æ ‡å‡½æ•°
fn find_maximum() {
    // å®šä¹‰ä¸€ä¸ªæœ‰å¤šä¸ªå±€éƒ¨æå¤§å€¼çš„å‡½æ•°
    let complex_function = |x: f64| -> f64 {
        (x * x.sin() / 10.0) + x.cos() * 0.5
    };
    
    // åˆ›å»ºä¼˜åŒ–é—®é¢˜
    let objective = OneDimensionalFunction::new(complex_function, 0.0);
    
    // ä½¿ç”¨æ¢¯åº¦ä¸‹é™
    let gd_optimizer = GradientDescent::new(0.1, 1e-6);
    let gd_result = gd_optimizer.optimize(&objective, 100);
    println!("Gradient Descent result: x = {:.6}, f(x) = {:.6}", 
             gd_result, complex_function(gd_result));
    
    // ä½¿ç”¨ç²’å­ç¾¤ä¼˜åŒ–
    let pso_optimizer = ParticleSwarmOptimization::new(20, 0.7, 1.5, 1.5);
    let pso_result = pso_optimizer.optimize(&objective, 50);
    println!("Particle Swarm Optimization result: x = {:.6}, f(x) = {:.6}", 
             pso_result, complex_function(pso_result));
}
```

**å‡†åˆ™**ï¼šé€šè¿‡ç‰¹å¾æŠ½è±¡ç›®æ ‡å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼Œå®ç°ç®—æ³•ä¸é—®é¢˜åˆ†ç¦»çš„çµæ´»æ¶æ„ã€‚

## 4. è¿­ä»£ä¸é€’å½’å·¥ä½œæµ

### 4.1 è‡ªé€‚åº”è¿­ä»£å™¨

```rust
// æ¨èï¼šè‡ªé€‚åº”è¿­ä»£å™¨æ¨¡å¼
// åˆ†æ‰¹å¤„ç†è¿­ä»£å™¨é€‚é…å™¨
pub struct Batched<I, F> {
    inner: I,
    batch_size: usize,
    process_fn: F,
    current_batch: Vec<I::Item>,
}

impl<I, F, R> Batched<I, F>
where
    I: Iterator,
    F: FnMut(&mut Vec<I::Item>) -> R,
{
    pub fn new(iter: I, batch_size: usize, process_fn: F) -> Self {
        Self {
            inner: iter,
            batch_size,
            process_fn,
            current_batch: Vec::with_capacity(batch_size),
        }
    }
}

impl<I, F, R> Iterator for Batched<I, F>
where
    I: Iterator,
    F: FnMut(&mut Vec<I::Item>) -> R,
{
    type Item = R;
    
    fn next(&mut self) -> Option<Self::Item> {
        // å¡«å……å½“å‰æ‰¹æ¬¡ç›´åˆ°è¾¾åˆ°æ‰¹æ¬¡å¤§å°æˆ–è¿­ä»£å™¨ç»“æŸ
        while self.current_batch.len() < self.batch_size {
            match self.inner.next() {
                Some(item) => self.current_batch.push(item),
                None => break,
            }
        }
        
        // å¦‚æœæ‰¹æ¬¡ä¸ºç©ºï¼Œè¡¨ç¤ºè¿­ä»£å™¨å·²ç»“æŸ
        if self.current_batch.is_empty() {
            return None;
        }
        
        // å¤„ç†å½“å‰æ‰¹æ¬¡å¹¶è¿”å›ç»“æœ
        let result = (self.process_fn)(&mut self.current_batch);
        self.current_batch.clear();
        Some(result)
    }
}

// æ‹“å±•ç‰¹å¾ï¼Œä¸ºæ‰€æœ‰è¿­ä»£å™¨æ·»åŠ æ‰¹å¤„ç†æ–¹æ³•
pub trait BatchedExt: Iterator + Sized {
    fn batch<F, R>(self, batch_size: usize, process_fn: F) -> Batched<Self, F>
    where
        F: FnMut(&mut Vec<Self::Item>) -> R,
    {
        Batched::new(self, batch_size, process_fn)
    }
}

impl<T: Iterator> BatchedExt for T {}

// è‡ªé€‚åº”æ‰¹å¤„ç† - æ ¹æ®å¤„ç†æ—¶é—´è‡ªåŠ¨è°ƒæ•´æ‰¹é‡å¤§å°
pub struct AdaptiveBatched<I, F> {
    inner: I,
    min_batch_size: usize,
    max_batch_size: usize,
    target_process_time: std::time::Duration,
    process_fn: F,
    current_batch: Vec<I::Item>,
    current_batch_size: usize,
}

impl<I, F, R> AdaptiveBatched<I, F>
where
    I: Iterator,
    F: FnMut(&mut Vec<I::Item>) -> R,
{
    pub fn new(
        iter: I,
        min_batch_size: usize,
        max_batch_size: usize,
        target_process_time: std::time::Duration,
        process_fn: F,
    ) -> Self {
        let initial_batch_size = (min_batch_size + max_batch_size) / 2;
        Self {
            inner: iter,
            min_batch_size,
            max_batch_size,
            target_process_time,
            process_fn,
            current_batch: Vec::with_capacity(initial_batch_size),
            current_batch_size: initial_batch_size,
        }
    }
}

impl<I, F, R> Iterator for AdaptiveBatched<I, F>
where
    I: Iterator,
    F: FnMut(&mut Vec<I::Item>) -> R,
{
    type Item = R;
    
    fn next(&mut self) -> Option<Self::Item> {
        // å¡«å……å½“å‰æ‰¹æ¬¡
        self.current_batch.clear();
        for _ in 0..self.current_batch_size {
            match self.inner.next() {
                Some(item) => self.current_batch.push(item),
                None => break,
            }
        }
        
        // å¦‚æœæ‰¹æ¬¡ä¸ºç©ºï¼Œè¡¨ç¤ºè¿­ä»£å™¨å·²ç»“æŸ
        if self.current_batch.is_empty() {
            return None;
        }
        
        // æµ‹é‡å¤„ç†æ—¶é—´
        let start = std::time::Instant::now();
        let result = (self.process_fn)(&mut self.current_batch);
        let elapsed = start.elapsed();
        
        // æ ¹æ®å¤„ç†æ—¶é—´è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if elapsed > self.target_process_time * 2 {
            // å¤„ç†æ—¶é—´å¤ªé•¿ï¼Œå‡å°æ‰¹æ¬¡å¤§å°
            self.current_batch_size = std::cmp::max(
                self.min_batch_size,
                self.current_batch_size / 2
            );
        } else if elapsed < self.target_process_time / 2 {
            // å¤„ç†æ—¶é—´å¤ªçŸ­ï¼Œå¢åŠ æ‰¹æ¬¡å¤§å°
            self.current_batch_size = std::cmp::min(
                self.max_batch_size,
                self.current_batch_size * 2
            );
        }
        
        Some(result)
    }
}

// æ‹“å±•ç‰¹å¾ï¼Œä¸ºæ‰€æœ‰è¿­ä»£å™¨æ·»åŠ è‡ªé€‚åº”æ‰¹å¤„ç†æ–¹æ³•
pub trait AdaptiveBatchExt: Iterator + Sized {
    fn adaptive_batch<F, R>(
        self,
        min_batch_size: usize,
        max_batch_size: usize,
        target_process_time: std::time::Duration,
        process_fn: F,
    ) -> AdaptiveBatched<Self, F>
    where
        F: FnMut(&mut Vec<Self::Item>) -> R,
    {
        AdaptiveBatched::new(
            self,
            min_batch_size,
            max_batch_size,
            target_process_time,
            process_fn,
        )
    }
}

impl<T: Iterator> AdaptiveBatchExt for T {}

// ä½¿ç”¨è‡ªé€‚åº”è¿­ä»£å™¨
fn process_large_dataset() {
    // ç”Ÿæˆå¤§é‡æ•°æ®
    let data: Vec<i32> = (0..10000).collect();
    
    // ä½¿ç”¨å›ºå®šæ‰¹æ¬¡å¤§å°å¤„ç†
    let batch_results: Vec<_> = data.iter()
        .batch(100, |batch| {
            // æ¨¡æ‹Ÿå¤„ç†æ¯ä¸ªæ‰¹æ¬¡
            let sum: i32 = batch.iter().copied().sum();
            println!("Processed batch of {} items, sum: {}", batch.len(), sum);
            std::thread::sleep(std::time::Duration::from_millis(10));
            sum
        })
        .collect();
        
    println!("Fixed batch processing produced {} batches", batch_results.len());
    
    // ä½¿ç”¨è‡ªé€‚åº”æ‰¹æ¬¡å¤§å°å¤„ç†
    let adaptive_results: Vec<_> = data.iter()
        .adaptive_batch(
            10,                                         // æœ€å°æ‰¹æ¬¡å¤§å°
            1000,                                       // æœ€å¤§æ‰¹æ¬¡å¤§å°
            std::time::Duration::from_millis(50),      // ç›®æ ‡å¤„ç†æ—¶é—´
            |batch| {
                // æ¨¡æ‹Ÿå¤„ç†æ¯ä¸ªæ‰¹æ¬¡ï¼Œå¤„ç†æ—¶é—´ä¸æ‰¹æ¬¡å¤§å°æˆæ­£æ¯”
                let sum: i32 = batch.iter().copied().sum();
                println!("Processed adaptive batch of {} items, sum: {}", batch.len(), sum);
                
                // æ¨¡æ‹Ÿå¤„ç†æ—¶é—´éšæ‰¹æ¬¡å¤§å°å¢åŠ 
                std::thread::sleep(std::time::Duration::from_millis(
                    (batch.len() as u64) / 10
                ));
                
                sum
            }
        )
        .collect();
        
    println!("Adaptive batch processing produced {} batches", adaptive_results.len());
}
```

**å‡†åˆ™**ï¼šè®¾è®¡è‡ªé€‚åº”è¿­ä»£å™¨ï¼Œæ ¹æ®å·¥ä½œè´Ÿè½½åŠ¨æ€è°ƒæ•´å¤„ç†ç­–ç•¥ã€‚

### 4.2 å¯ç»§ç»­/å¯æ¢å¤é€’å½’æ¨¡å¼

```rust
// æ¨èï¼šå¯ç»§ç»­/å¯æ¢å¤é€’å½’æ¨¡å¼
// å®šä¹‰é€’å½’æ“ä½œçš„çŠ¶æ€
pub enum RecursionState<T, R> {
    // æ­£åœ¨è¿›è¡Œä¸­
    Continue(T),
    // å·²å®Œæˆï¼ŒåŒ…å«ç»“æœ
    Complete(R),
}

// å¯æ¢å¤é€’å½’æ¡†æ¶
pub struct ResumableRecursion<T, R, F> {
    state_fn: F,
    max_depth: usize,
    current_depth: usize,
}

impl<T, R, F> ResumableRecursion<T, R, F> 
where
    F: Fn(&T) -> RecursionState<Vec<T>, R>,
{
    pub fn new(state_fn: F, max_depth: usize) -> Self {
        Self {
            state_fn,
            max_depth,
            current_depth: 0,
        }
    }
    
    // æ‰§è¡Œé€’å½’ï¼Œå¯ä»¥è®¾ç½®æœ€å¤§æ­¥æ•°é™åˆ¶
    pub fn run(&mut self, initial_state: T, max_steps: usize) -> Option<R> {
        let mut stack = vec![initial_state];
        let mut steps = 0;
        
        while let Some(current) = stack.pop() {
            steps += 1;
            if steps > max_steps {
                // ä¿å­˜çŠ¶æ€å¹¶è¿”å› None è¡¨ç¤ºæœªå®Œæˆ
                stack.push(current);
                return None;
            }
            
            // é˜²æ­¢é€’å½’æ·±åº¦è¿‡æ·±
            self.current_depth += 1;
            if self.current_depth > self.max_depth {
                println!("Maximum recursion depth reached");
                self.current_depth -= 1;
                continue;
            }
            
            match (self.state_fn)(&current) {
                RecursionState::Continue(new_states) => {
                    // å°†æ–°çŠ¶æ€æ·»åŠ åˆ°æ ˆä¸­
                    stack.extend(new_states);
                }
                RecursionState::Complete(result) => {
                    self.current_depth -= 1;
                    if self.current_depth == 0 {
                        // é¡¶å±‚é€’å½’å®Œæˆï¼Œè¿”å›ç»“æœ
                        return Some(result);
                    }
                }
            }
            
            if self.current_depth > 0 {
                self.current_depth -= 1;
            }
        }
        
        // é€’å½’ç»“æŸä½†æ²¡æœ‰å¾—åˆ°ç»“æœ
        None
    }
    
    // æ¢å¤æ‰§è¡Œï¼Œä»ä¸Šæ¬¡ä¿å­˜çš„çŠ¶æ€ç»§ç»­
    pub fn resume(&mut self, saved_states: Vec<T>, max_steps: usize) -> Option<R> {
        let mut stack = saved_states;
        let mut steps = 0;
        
        while let Some(current) = stack.pop() {
            steps += 1;
            if steps > max_steps {
                // å†æ¬¡ä¿å­˜çŠ¶æ€å¹¶è¿”å› None
                stack.push(current);
                return None;
            }
            
            self.current_depth += 1;
            if self.current_depth > self.max_depth {
                println!("Maximum recursion depth reached");
                self.current_depth -= 1;
                continue;
            }
            
            match (self.state_fn)(&current) {
                RecursionState::Continue(new_states) => {
                    stack.extend(new_states);
                }
                RecursionState::Complete(result) => {
                    self.current_depth -= 1;
                    if self.current_depth == 0 {
                        return Some(result);
                    }
                }
            }
            
            if self.current_depth > 0 {
                self.current_depth -= 1;
            }
        }
        
        None
    }
    
    // è·å–å½“å‰æ ˆï¼Œç”¨äºä¿å­˜çŠ¶æ€
    pub fn get_stack(&self) -> Vec<T> {
        // å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥è¿”å›å½“å‰çš„é€’å½’æ ˆ
        // ç”±äºç®€åŒ–ï¼Œè¿™é‡Œè¿”å›ç©ºæ ˆ
        Vec::new()
    }
}

// ä½¿ç”¨å¯æ¢å¤é€’å½’ - æ ‘çš„æ·±åº¦ä¼˜å…ˆéå†ç¤ºä¾‹
#[derive(Clone, Debug)]
struct TreeNode {
    value: i32,
    children: Vec<TreeNode>,
}

impl TreeNode {
    fn new(value: i32) -> Self {
        Self {
            value,
            children: Vec::new(),
        }
    }
    
    fn add_child(&mut self, child: TreeNode) {
        self.children.push(child);
    }
}

// ä½¿ç”¨å¯æ¢å¤é€’å½’è¿›è¡Œæ ‘éå†
fn traverse_tree() {
    // åˆ›å»ºä¸€ä¸ªç®€å•çš„æ ‘
    let mut root = TreeNode::new(1);
    
    let mut child1 = TreeNode::new(2);
    child1.add_child(TreeNode::new(5));
    child1.add_child(TreeNode::new(6));
    
    let mut child2 = TreeNode::new(3);
    child2.add_child(TreeNode::new(7));
    
    let child3 = TreeNode::new(4);
    
    root.add_child(child1);
    root.add_child(child2);
    root.add_child(child3);
    
    // å®šä¹‰éå†çŠ¶æ€å‡½æ•°
    let traverse_fn = |node: &TreeNode| -> RecursionState<Vec<TreeNode>, Vec<i32>> {
        println!("Visiting node with value: {}", node.value);
        
        if node.children.is_empty() {
            // å¶å­èŠ‚ç‚¹ï¼Œè¿”å›å½“å‰å€¼
            RecursionState::Complete(vec![node.value])
        } else {
            // éå¶å­èŠ‚ç‚¹ï¼Œç»§ç»­éå†å­èŠ‚ç‚¹
            RecursionState::Continue(node.children.clone())
        }
    };
    
    // åˆ›å»ºå¯æ¢å¤é€’å½’æ‰§è¡Œå™¨
    let mut recursion = ResumableRecursion::new(traverse_fn, 1000);
    
    // æ‰§è¡Œé€’å½’ï¼Œé™åˆ¶æ­¥æ•°
    let mut result = recursion.run(root.clone(), 3);
    
    if result.is_none() {
        println!("Recursion paused due to step limit");
        
        // ä¿å­˜çŠ¶æ€
        let saved_state = recursion.get_stack();
        
        // æ¢å¤é€’å½’
        result = recursion.resume(saved_state, 10);
    }
    
    if let Some(values) = result {
        println!("Traversal result: {:?}", values);
    } else {
        println!("Traversal incomplete");
    }
}
```

**å‡†åˆ™**ï¼šè®¾è®¡å¯ç»§ç»­/å¯æ¢å¤é€’å½’æ¨¡å¼ï¼Œå¤„ç†æ·±åº¦é€’å½’å’Œé•¿æ—¶é—´è¿è¡Œçš„å·¥ä½œæµã€‚

## 5. å¹¶è¡Œä¸å¼‚æ­¥å·¥ä½œæµ

### 5.1 å·¥ä½œçªƒå–ä»»åŠ¡æ± 

```rust
// æ¨èï¼šå·¥ä½œçªƒå–ä»»åŠ¡æ± 
use std::sync::{Arc, Mutex};
use std::collections::VecDeque;
use std::thread;

// ä»»åŠ¡ç‰¹å¾
pub trait Task: Send + 'static {
    type Output: Send + 'static;
    
    fn execute(&self) -> Self::Output;
}

// ä»»åŠ¡ç»“æœ
pub struct TaskResult<T> {
    result: Arc<Mutex<Option<T>>>,
    notifier: Arc<Mutex<Vec<std::sync::mpsc::Sender<()>>>>,
}

impl<T> TaskResult<T> {
    pub fn new() -> Self {
        Self {
            result: Arc::new(Mutex::new(None)),
            notifier: Arc::new(Mutex::new(Vec::new())),
        }
    }
    
    pub fn set_result(&self, result: T) {
        let mut guard = self.result.lock().unwrap();
        *guard = Some(result);
        
        // é€šçŸ¥æ‰€æœ‰ç­‰å¾…è€…
        let notifiers = self.notifier.lock().unwrap();
        for notifier in notifiers.iter() {
            let _ = notifier.send(());
        }
    }
    
    pub fn get_result(&self) -> Option<T>
    where
        T: Clone,
    {
        let guard = self.result.lock().unwrap();
        guard.clone()
    }
    
    pub fn wait_for_result(&self) -> T
    where
        T: Clone,
    {
        // é¦–å…ˆæ£€æŸ¥ç»“æœæ˜¯å¦å·²ç»å¯ç”¨
        {
            let guard = self.result.lock().unwrap();
            if let Some(ref result) = *guard {
                return result.clone();
            }
        }
        
        // å¦‚æœç»“æœä¸å¯ç”¨ï¼Œç­‰å¾…é€šçŸ¥
        let (sender, receiver) = std::sync::mpsc::channel();
        
        {
            let mut notifiers = self.notifier.lock().unwrap();
            notifiers.push(sender);
        }
        
        // ç­‰å¾…é€šçŸ¥æˆ–å®šæœŸæ£€æŸ¥
        loop {
            // ç­‰å¾…é€šçŸ¥ï¼Œè¶…æ—¶åé‡æ–°æ£€æŸ¥
            let _ = receiver.recv_timeout(std::time::Duration::from_millis(100));
            
            let guard = self.result.lock().unwrap();
            if let Some(ref result) = *guard {
                return result.clone();
            }
        }
    }
}

// å·¥ä½œçªƒå–ä»»åŠ¡æ± 
pub struct WorkStealingPool {
    queues: Vec<Arc<Mutex<VecDeque<Box<dyn FnOnce() + Send>>>>>,
    worker_threads: Vec<thread::JoinHandle<()>>,
    shutdown: Arc<Mutex<bool>>,
}

impl WorkStealingPool {
    pub fn new(num_workers: usize) -> Self {
        let mut queues = Vec::with_capacity(num_workers);
        for _ in 0..num_workers {
            queues.push(Arc::new(Mutex::new(VecDeque::new())));
        }
        
        let shutdown = Arc::new(Mutex::new(false));
        let mut worker_threads = Vec::with_capacity(num_workers);
        
        for worker_id in 0..num_workers {
            let queues_clone = queues.clone();
            let shutdown_clone = shutdown.clone();
            
            let handle = thread::spawn(move || {
                Self::worker_loop(worker_id, num_workers, queues_clone, shutdown_clone);
            });
            
            worker_threads.push(handle);
        }
        
        Self {
            queues,
            worker_threads,
            shutdown,
        }
    }
    
    // æäº¤ä»»åŠ¡
    pub fn submit<T, F>(&self, task: F) -> TaskResult<T>
    where
        T: Send + 'static,
        F: FnOnce() -> T + Send + 'static,
    {
        // åˆ›å»ºä»»åŠ¡ç»“æœ
        let result = TaskResult::new();
        let result_clone = result.clone();
        
        // åŒ…è£…ä»»åŠ¡å‡½æ•°
        let task_fn = Box::new(move || {
            let task_result = task();
            result_clone.set_result(task_result);
        });
        
        // é€‰æ‹©é˜Ÿåˆ—å¹¶æ·»åŠ ä»»åŠ¡
        let queue_index = rand::random::<usize>() % self.queues.len();
        let mut queue = self.queues[queue_index].lock().unwrap();
        queue.push_back(task_fn);
        
        result
    }
    
    // å…³é—­çº¿ç¨‹æ± 
    pub fn shutdown(self) {
        // è®¾ç½®å…³é—­æ ‡å¿—
        {
            let mut shutdown_guard = self.shutdown.lock().unwrap();
            *shutdown_guard = true;
        }
        
        // ç­‰å¾…æ‰€æœ‰å·¥ä½œçº¿ç¨‹å®Œæˆ
        for handle in self.worker_threads {
            let _ = handle.join();
        }
    }
    
    // å·¥ä½œè€…çº¿ç¨‹å¾ªç¯
    fn worker_loop(
        worker_id: usize,
        num_workers: usize,
        queues: Vec<Arc<Mutex<VecDeque<Box<dyn FnOnce() + Send>>>>>,
        shutdown: Arc<Mutex<bool>>,
    ) {
        // ä¸»å¾ªç¯
        loop {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥å…³é—­
            if *shutdown.lock().unwrap() {
                break;
            }
            
            // å°è¯•ä»è‡ªå·±çš„é˜Ÿåˆ—è·å–ä»»åŠ¡
            let task_opt = {
                let mut my_queue = queues[worker_id].lock().unwrap();
                my_queue.pop_front()
            };
            
            if let Some(task) = task_opt {
                // æ‰§è¡Œä»»åŠ¡
                task();
                continue;
            }
            
            // å¦‚æœè‡ªå·±çš„é˜Ÿåˆ—ä¸ºç©ºï¼Œå°è¯•ä»å…¶ä»–é˜Ÿåˆ—çªƒå–ä»»åŠ¡
            let mut stole_task = false;
            
            // ä»¥éšæœºé¡ºåºéå†å…¶ä»–é˜Ÿåˆ—
            let mut victim_ids: Vec<usize> = (0..num_workers).filter(|&id| id != worker_id).collect();
            victim_ids.shuffle(&mut rand::thread_rng());
            
            for victim_id in victim_ids {
                let task_opt = {
                    let mut victim_queue = queues[victim_id].lock().unwrap();
                    // ä»é˜Ÿåˆ—å°¾éƒ¨çªƒå–ä»»åŠ¡ï¼ˆå‡å°‘å†²çªï¼‰
                    victim_queue.pop_back()
                };
                
                if let Some(task) = task_opt {
                    // æ‰§è¡Œçªƒå–çš„ä»»åŠ¡
                    task();
                    stole_task = true;
                    break;
                }
            }
            
            // å¦‚æœæ²¡æœ‰çªƒå–åˆ°ä»»åŠ¡ï¼ŒçŸ­æš‚ä¼‘çœ ä»¥å‡å°‘CPUä½¿ç”¨
            if !stole_task {
                thread::sleep(std::time::Duration::from_millis(1));
            }
        }
    }
}

impl Clone for TaskResult<T> {
    fn clone(&self) -> Self {
        Self {
            result: self.result.clone(),
            notifier: self.notifier.clone(),
        }
    }
}

// ä½¿ç”¨å·¥ä½œçªƒå–ä»»åŠ¡æ± 
fn parallel_workflow() {
    // åˆ›å»ºçº¿ç¨‹æ± 
    let pool = WorkStealingPool::new(4);
    
    // æäº¤è®¡ç®—å¯†é›†å‹ä»»åŠ¡
    let task1_result = pool.submit(|| {
        println!("Task 1 started");
        let mut sum = 0;
        for i in 0..1000000 {
            sum += i;
        }
        println!("Task 1 completed");
        sum
    });
    
    // æäº¤IOå¯†é›†å‹ä»»åŠ¡
    let task2_result = pool.submit(|| {
        println!("Task 2 started");
        thread::sleep(std::time::Duration::from_millis(100));
        println!("Task 2 completed");
        "Task 2 result"
    });
    
    // æäº¤å–å†³äºå‰ä¸¤ä¸ªä»»åŠ¡çš„ä»»åŠ¡
    let task3_result = pool.submit(move || {
        println!("Task 3 started");
        
        // ç­‰å¾…ä»»åŠ¡1å’Œä»»åŠ¡2çš„ç»“æœ
        let result1 = task1_result.wait_for_result();
        let result2 = task2_result.wait_for_result();
        
        println!("Task 3 completed with inputs: {}, {}", result1, result2);
        format!("Combined result: {}", result1)
    });
    
    // ç­‰å¾…æœ€ç»ˆç»“æœ
    let final_result = task3_result.wait_for_result();
    println!("Final result: {}", final_result);
    
    // å…³é—­çº¿ç¨‹æ± 
    pool.shutdown();
}
```

**å‡†åˆ™**ï¼šè®¾è®¡æ”¯æŒå·¥ä½œçªƒå–çš„ä»»åŠ¡æ± ï¼Œä¼˜åŒ–å¹¶è¡Œå·¥ä½œæµçš„æ‰§è¡Œæ•ˆç‡ã€‚

### 5.2 å¼‚æ­¥å·¥ä½œæµçŠ¶æ€æœº

```rust
// æ¨èï¼šå¼‚æ­¥å·¥ä½œæµçŠ¶æ€æœº
use futures::future::{BoxFuture, FutureExt};
use std::pin::Pin;

// å¼‚æ­¥å·¥ä½œæµçŠ¶æ€
pub enum WorkflowState<T, E> {
    // åˆå§‹çŠ¶æ€
    Initial,
    // ç­‰å¾…æŸä¸ªå¼‚æ­¥æ“ä½œå®Œæˆ
    Waiting(BoxFuture<'static, Result<WorkflowState<T, E>, E>>),
    // å·¥ä½œæµå®Œæˆ
    Complete(T),
    // å·¥ä½œæµé”™è¯¯
    Error(E),
}

// å·¥ä½œæµæ‰§è¡Œå™¨
pub struct WorkflowExecutor<T, E> {
    state: WorkflowState<T, E>,
}

impl<T: 'static, E: 'static> WorkflowExecutor<T, E> {
    pub fn new() -> Self {
        Self {
            state: WorkflowState::Initial,
        }
    }
    
    // æ³¨å†Œåˆå§‹å·¥ä½œæµ
    pub fn register<F>(&mut self, future: F)
    where
        F: FnOnce() -> BoxFuture<'static, Result<WorkflowState<T, E>, E>> + 'static,
    {
        self.state = WorkflowState::Waiting(future().boxed());
    }
    
    // é©±åŠ¨å·¥ä½œæµå‘å‰æ‰§è¡Œä¸€æ­¥
    pub async fn step(&mut self) -> Result<bool, E> {
        match std::mem::replace(&mut self.state, WorkflowState::Initial) {
            WorkflowState::Initial => {
                // åˆå§‹çŠ¶æ€ï¼Œæ— äº‹å¯åš
                self.state = WorkflowState::Initial;
                Ok(false)
            }

            WorkflowState::Waiting(future) => {
                // ç­‰å¾…å¼‚æ­¥æ“ä½œ
                match future.await {
                    Ok(next_state) => {
                        self.state = next_state;
                        Ok(true)
                    }
                    Err(e) => {
                        self.state = WorkflowState::Error(e);
                        Err(e)
                    }
                }
            }
            WorkflowState::Complete(result) => {
                // å·²ç»å®Œæˆï¼Œä¿æŒå®ŒæˆçŠ¶æ€
                self.state = WorkflowState::Complete(result);
                Ok(false)
            }
            WorkflowState::Error(error) => {
                // ä¿æŒé”™è¯¯çŠ¶æ€
                self.state = WorkflowState::Error(error);
                Err(error)
            }
        }
    }
    
    // æŒç»­æ‰§è¡Œç›´åˆ°å·¥ä½œæµå®Œæˆæˆ–å‡ºé”™
    pub async fn run_to_completion(&mut self) -> Result<T, E> {
        loop {
            match &self.state {
                WorkflowState::Complete(result) => {
                    // éœ€è¦å¤åˆ¶ç»“æœï¼Œå› ä¸ºæˆ‘ä»¬ä¸èƒ½ç§»åŠ¨ self.state ä¸­çš„å€¼
                    return Ok(result.clone());
                }
                WorkflowState::Error(error) => {
                    // åŒæ ·éœ€è¦å¤åˆ¶é”™è¯¯
                    return Err(error.clone());
                }
                _ => {
                    // ç»§ç»­æ‰§è¡Œ
                    self.step().await?;
                }
            }
        }
    }
    
    // è·å–å½“å‰çŠ¶æ€ï¼ˆç”¨äºæ£€æŸ¥ï¼‰
    pub fn current_state(&self) -> &WorkflowState<T, E> {
        &self.state
    }
}

// ä½¿ç”¨å¼‚æ­¥å·¥ä½œæµçŠ¶æ€æœº - æ•°æ®å¤„ç†ç¤ºä¾‹
async fn async_workflow_example() {
    // å®šä¹‰æˆ‘ä»¬çš„å·¥ä½œæµçŠ¶æ€å’Œé”™è¯¯ç±»å‹
    #[derive(Clone, Debug)]
    struct ProcessedData {
        id: u64,
        content: String,
        metadata: std::collections::HashMap<String, String>,
    }
    
    #[derive(Clone, Debug)]
    enum ProcessingError {
        FetchFailed(String),
        ProcessingFailed(String),
        ValidationFailed(String),
    }
    
    // æ¨¡æ‹Ÿå¼‚æ­¥æ•°æ®è·å–
    async fn fetch_data(id: u64) -> Result<String, ProcessingError> {
        println!("Fetching data for id: {}", id);
        tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        
        if id % 7 == 0 {
            return Err(ProcessingError::FetchFailed(format!("Failed to fetch data for id: {}", id)));
        }
        
        Ok(format!("Raw data for id {}", id))
    }
    
    // æ¨¡æ‹Ÿå¼‚æ­¥æ•°æ®å¤„ç†
    async fn process_data(raw_data: &str) -> Result<String, ProcessingError> {
        println!("Processing data: {}", raw_data);
        tokio::time::sleep(tokio::time::Duration::from_millis(150)).await;
        
        if raw_data.contains("666") {
            return Err(ProcessingError::ProcessingFailed("Evil data detected".into()));
        }
        
        Ok(format!("Processed {}", raw_data))
    }
    
    // æ¨¡æ‹Ÿå¼‚æ­¥æ•°æ®éªŒè¯
    async fn validate_data(processed_data: &str) -> Result<bool, ProcessingError> {
        println!("Validating data: {}", processed_data);
        tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
        
        if processed_data.len() < 10 {
            return Err(ProcessingError::ValidationFailed("Data too short".into()));
        }
        
        Ok(true)
    }
    
    // æ¨¡æ‹Ÿå…ƒæ•°æ®ç”Ÿæˆ
    async fn generate_metadata(id: u64, processed_data: &str) -> std::collections::HashMap<String, String> {
        let mut metadata = std::collections::HashMap::new();
        metadata.insert("timestamp".to_string(), chrono::Utc::now().to_rfc3339());
        metadata.insert("size".to_string(), processed_data.len().to_string());
        metadata.insert("source".to_string(), format!("ID-{}", id));
        
        metadata
    }
    
    // åˆ›å»ºå·¥ä½œæµæ‰§è¡Œå™¨
    let mut executor = WorkflowExecutor::<ProcessedData, ProcessingError>::new();
    
    // å®šä¹‰å·¥ä½œæµ
    let data_id = 42;
    
    executor.register(move || {
        let future = async move {
            // æ­¥éª¤1: è·å–æ•°æ®
            let raw_data = fetch_data(data_id).await?;
            
            // è¿”å›ä¸‹ä¸€ä¸ªçŠ¶æ€
            Ok(WorkflowState::Waiting(
                (move || async move {
                    // æ­¥éª¤2: å¤„ç†æ•°æ®
                    let processed_content = process_data(&raw_data).await?;
                    
                    // è¿”å›ä¸‹ä¸€ä¸ªçŠ¶æ€
                    Ok(WorkflowState::Waiting(
                        (move || async move {
                            // æ­¥éª¤3: éªŒè¯æ•°æ®
                            let is_valid = validate_data(&processed_content).await?;
                            
                            if !is_valid {
                                return Err(ProcessingError::ValidationFailed("Validation returned false".into()));
                            }
                            
                            // è¿”å›ä¸‹ä¸€ä¸ªçŠ¶æ€
                            Ok(WorkflowState::Waiting(
                                (move || async move {
                                    // æ­¥éª¤4: ç”Ÿæˆå…ƒæ•°æ®
                                    let metadata = generate_metadata(data_id, &processed_content).await;
                                    
                                    // å®Œæˆå·¥ä½œæµ
                                    let final_result = ProcessedData {
                                        id: data_id,
                                        content: processed_content,
                                        metadata,
                                    };
                                    
                                    Ok(WorkflowState::Complete(final_result))
                                })().boxed()
                            ))
                        })().boxed()
                    ))
                })().boxed()
            ))
        };
        
        Box::pin(future) as BoxFuture<'static, Result<WorkflowState<ProcessedData, ProcessingError>, ProcessingError>>
    });
    
    // è¿è¡Œå·¥ä½œæµç›´åˆ°å®Œæˆ
    match executor.run_to_completion().await {
        Ok(result) => {
            println!("Workflow completed successfully!");
            println!("ID: {}", result.id);
            println!("Content: {}", result.content);
            println!("Metadata: {:?}", result.metadata);
        }
        Err(error) => {
            println!("Workflow failed with error: {:?}", error);
        }
    }
}
```

**å‡†åˆ™**ï¼šè®¾è®¡å¼‚æ­¥å·¥ä½œæµçŠ¶æ€æœºï¼Œå®ç°å¤æ‚å¼‚æ­¥æ“ä½œçš„æ¸…æ™°è¡¨ç¤ºå’Œæ‰§è¡Œã€‚

## 6. æ€»ç»“ï¼šå·¥ä½œæµä¸ç®—æ³•è®¾è®¡å‡†åˆ™

ä»å·¥ä½œæµç»„åˆä¸ç®—æ³•è®¾è®¡è§†è§’å‡ºå‘ï¼Œæˆ‘ä»¬å¯ä»¥å½’çº³å‡ºä»¥ä¸‹å…³é”®å‡†åˆ™ï¼ŒæŒ‡å¯¼ Rust ä¸­çš„ç±»å‹è®¾è®¡ï¼š

### 6.1 ç»„åˆä¸æµç¨‹è®¾è®¡

1. **å¯ç»„åˆæ¥å£**ï¼šè®¾è®¡æ”¯æŒé“¾å¼è°ƒç”¨å’Œç»„åˆçš„æ¥å£ï¼Œä½¿å·¥ä½œæµçš„æ„å»ºå˜å¾—ç›´è§‚ã€‚
2. **å¤„ç†ç®¡é“**ï¼šé€šè¿‡ç±»å‹å®‰å…¨çš„ç®¡é“æ¨¡å¼ï¼Œå®ç°æ•°æ®çš„æµå¼å¤„ç†ã€‚
3. **çŠ¶æ€æ˜ç¡®æ€§**ï¼šä½¿ç”¨ç±»å‹çŠ¶æ€æ¨¡å¼ç¡®ä¿å·¥ä½œæµçŠ¶æ€è½¬æ¢çš„å®‰å…¨æ€§å’Œå¯éªŒè¯æ€§ã€‚
4. **äº‹åŠ¡åŸåˆ™**ï¼šå®ç°æ”¯æŒå‡†å¤‡ã€æ‰§è¡Œå’Œå›æ»šçš„äº‹åŠ¡æ€§æ“ä½œæ¨¡å¼ã€‚

### 6.2 ç®—æ³•è®¾è®¡ä¸æ‰§è¡Œ

1. **ç­–ç•¥å¤šæ€**ï¼šé€šè¿‡ç‰¹å¾æŠ½è±¡ç­–ç•¥ï¼Œå…è®¸åœ¨è¿è¡Œæ—¶æˆ–ç¼–è¯‘æ—¶é€‰æ‹©ä¸åŒçš„ç®—æ³•å®ç°ã€‚
2. **å¯ä¼˜åŒ–æ¥å£**ï¼šè®¾è®¡å…è®¸è‡ªåŠ¨æˆ–æ‰‹åŠ¨æ€§èƒ½ä¼˜åŒ–çš„æ¥å£ï¼Œå¦‚è‡ªé€‚åº”æ‰¹å¤„ç†ã€‚
3. **é€’å½’æ§åˆ¶**ï¼šå®ç°å¯æ§åˆ¶ã€å¯æš‚åœã€å¯æ¢å¤çš„é€’å½’æ¨¡å¼ï¼Œå¤„ç†å¤æ‚é€’å½’ç®—æ³•ã€‚
4. **å¹¶è¡Œå‹å¥½å‹**ï¼šè®¾è®¡æ”¯æŒå¹¶è¡Œæ‰§è¡Œå’Œå·¥ä½œçªƒå–çš„ä»»åŠ¡æŠ½è±¡ï¼Œä¼˜åŒ–å¤šæ ¸æ€§èƒ½ã€‚

### 6.3 é›†æˆè®¾è®¡åŸåˆ™

1. **é”™è¯¯å¤„ç†é›†æˆ**ï¼šåœ¨å·¥ä½œæµä¸­æ•´åˆä¸€è‡´çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿å¼‚å¸¸æƒ…å†µä¸‹çš„å®‰å…¨æ¢å¤ã€‚
2. **èµ„æºç®¡ç†è‡ªåŠ¨åŒ–**ï¼šè®¾è®¡ç¡®ä¿èµ„æºåœ¨å·¥ä½œæµç»“æŸæ—¶è‡ªåŠ¨æ¸…ç†çš„æ¨¡å¼ã€‚
3. **å¯æµ‹è¯•æ€§**ï¼šè®¾è®¡ä¾¿äºå•å…ƒæµ‹è¯•å’Œæ¨¡æ‹Ÿçš„æ¥å£ï¼ŒéªŒè¯å·¥ä½œæµå’Œç®—æ³•æ­£ç¡®æ€§ã€‚
4. **æ¸è¿›å¼æ„å»º**ï¼šæ”¯æŒå·¥ä½œæµçš„æ¸è¿›å¼æ„å»ºå’Œæ‰§è¡Œï¼Œå…è®¸åŠ¨æ€é€‚åº”å’Œè°ƒæ•´ã€‚

è¿™äº›å‡†åˆ™ä¸ä»…æä¾›äº†è®¾è®¡é«˜æ•ˆç±»å‹çš„æ¡†æ¶ï¼Œè¿˜ä¿ƒè¿›äº†å®‰å…¨ã€å¯ç»´æŠ¤çš„ä»£ç ç»“æ„ã€‚
é€šè¿‡ç»“åˆå·¥ä½œæµç»„åˆä¸ç®—æ³•è®¾è®¡çš„æœ€ä½³å®è·µï¼Œå¯ä»¥åˆ›å»ºæ—¢æ˜“äºä½¿ç”¨åˆé«˜æ•ˆçš„ Rust ç±»å‹ç³»ç»Ÿã€‚
