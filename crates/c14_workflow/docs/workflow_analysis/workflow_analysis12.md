# Rust工作流系统架构综合设计与实现

## 目录

## 架构思维导图

```text
工作流系统架构
├── 形式模型层
│   ├── 工作流代数
│   │   ├── 基本操作子（顺序、并行、选择）
│   │   ├── 代数法则（结合律、分配律、幂等律）
│   │   ├── 组合器库
│   │   └── 形式验证支持
│   ├── 资源模型
│   │   ├── 资源类型系统
│   │   ├── 所有权与借用规则
│   │   ├── 生命周期管理
│   │   └── 配额与限制
│   └── 一致性规则
│       ├── 系统不变量
│       ├── 依赖一致性
│       ├── 资源一致性
│       └── 状态一致性验证器
├── 执行引擎层
│   ├── 状态管理
│   │   ├── 事件溯源模型
│   │   ├── 快照与恢复
│   │   ├── 增量状态传输
│   │   └── 本地状态缓存
│   ├── 调度系统
│   │   ├── 依赖图调度器
│   │   ├── 优先级管理
│   │   ├── 资源感知调度
│   │   └── 公平性保证
│   └── 错误处理
│       ├── 错误分类与传播
│       ├── 重试策略与退避
│       ├── 补偿事务
│       └── 降级机制
├── 部署抽象层
│   ├── 资源隔离
│   │   ├── 执行环境抽象
│   │   ├── 容器适配器
│   │   ├── 独立进程适配器
│   │   └── 资源限制实施
│   ├── 通信模型
│   │   ├── 消息传递原语
│   │   ├── 事件总线
│   │   ├── 服务发现
│   │   └── 网络拓扑感知
│   └── 存储抽象
│       ├── 持久化接口
│       ├── 事务支持
│       ├── 多后端适配
│       └── 缓存策略
├── 自管理层
│   ├── 遥测系统
│   │   ├── 指标收集
│   │   ├── 分布式追踪
│   │   ├── 结构化日志
│   │   └── 健康检查
│   ├── 分析引擎
│   │   ├── 异常检测
│   │   ├── 性能分析
│   │   ├── 资源利用预测
│   │   └── 瓶颈识别
│   └── 控制回路
│       ├── 自适应调度
│       ├── 动态资源分配
│       ├── 自动扩缩容
│       └── 自愈机制
└── 高级特性
    ├── 分布式执行
    │   ├── 拓扑感知调度
    │   ├── 数据局部性优化
    │   ├── 去中心化协调
    │   └── 拜占庭容错
    ├── 事件驱动架构
    │   ├── 事件溯源
    │   ├── CQRS模式
    │   ├── 反应式处理
    │   └── 事件编排
    ├── 边缘计算支持
    │   ├── 离线操作模式
    │   ├── 有限资源优化
    │   ├── 状态同步策略
    │   └── 边缘到云协作
    └── 跨组织协作
        ├── 权限与信任模型
        ├── 分布式身份验证
        ├── 工作流联邦
        └── 多方计算支持
```

## 1. 架构概述

工作流系统架构采用分层设计，每层具有明确的职责和边界，允许各层独立演化和替换。核心设计目标包括：

1. **理论基础坚实**：基于工作流代数和形式化方法确保系统正确性
2. **部署灵活性**：支持从独立部署到完全分布式部署的多种模式
3. **自适应能力**：系统能够自我监控、分析和调整，适应变化的工作负载
4. **完备设计**：初始设计考虑系统的完备性，避免后期架构重构

以下是各层次的核心责任和相互关系：

```rust
pub struct WorkflowSystem {
    /// 形式模型层
    model_layer: ModelLayer,
    /// 执行引擎层
    execution_layer: ExecutionLayer,
    /// 部署抽象层
    deployment_layer: DeploymentLayer,
    /// 自管理层
    management_layer: ManagementLayer,
    /// 系统配置
    config: SystemConfig,
}

impl WorkflowSystem {
    /// 创建新的工作流系统
    pub async fn new(config: SystemConfig) -> Result<Self, SystemError> {
        // 初始化各层
        let model_layer = ModelLayer::new(&config.model);
        let deployment_layer = DeploymentLayer::new(&config.deployment).await?;
        let execution_layer = ExecutionLayer::new(&config.execution, deployment_layer.clone()).await?;
        let management_layer = ManagementLayer::new(&config.management, execution_layer.clone()).await?;
        
        Ok(Self {
            model_layer,
            execution_layer,
            deployment_layer,
            management_layer,
            config,
        })
    }
    
    /// 启动系统
    pub async fn start(&self) -> Result<(), SystemError> {
        // 1. 初始化各层
        log::info!("Initializing workflow system...");
        
        // 2. 启动部署层
        log::info!("Starting deployment layer...");
        self.deployment_layer.start().await?;
        
        // 3. 启动执行引擎
        log::info!("Starting execution engine...");
        self.execution_layer.start().await?;
        
        // 4. 启动管理层
        log::info!("Starting management layer...");
        self.management_layer.start().await?;
        
        log::info!("Workflow system started successfully");
        
        Ok(())
    }
    
    // 其他系统方法...
}
```

## 2. 形式模型层

形式模型层为整个系统提供理论基础，确保系统行为的正确性和可预测性。

### 2.1 工作流代数

工作流代数定义了工作流的基本操作和组合规则，使工作流构建具有严格的形式基础。

#### 2.1.1 基本代数结构

```rust
/// 工作流代数核心定义
pub enum WorkflowOp<T> {
    /// 单一活动
    Activity(Activity<T>),
    /// 顺序组合
    Sequence(Box<WorkflowOp<T>>, Box<WorkflowOp<T>>),
    /// 并行组合
    Parallel(Vec<WorkflowOp<T>>),
    /// 选择组合
    Choice(Box<WorkflowOp<T>>, Box<WorkflowOp<T>>, Condition<T>),
    /// 循环构造
    Loop(Box<WorkflowOp<T>>, Condition<T>),
    /// 超时构造
    WithTimeout(Box<WorkflowOp<T>>, Duration),
    /// 错误处理
    WithErrorHandler(Box<WorkflowOp<T>>, Box<WorkflowOp<T>>),
}

impl<T: Clone + Send + Sync + 'static> WorkflowOp<T> {
    /// 顺序组合构建器
    pub fn then(self, next: WorkflowOp<T>) -> Self {
        WorkflowOp::Sequence(Box::new(self), Box::new(next))
    }
    
    /// 并行组合构建器
    pub fn par_with(self, other: WorkflowOp<T>) -> Self {
        match self {
            WorkflowOp::Parallel(mut ops) => {
                ops.push(other);
                WorkflowOp::Parallel(ops)
            }
            _ => WorkflowOp::Parallel(vec![self, other]),
        }
    }
    
    /// 条件选择构建器
    pub fn when(self, condition: Condition<T>, then_op: WorkflowOp<T>) -> Self {
        WorkflowOp::Choice(Box::new(self), Box::new(then_op), condition)
    }
    
    /// 循环构建器
    pub fn repeat_while(self, condition: Condition<T>) -> Self {
        WorkflowOp::Loop(Box::new(self), condition)
    }
    
    /// 超时构建器
    pub fn with_timeout(self, duration: Duration) -> Self {
        WorkflowOp::WithTimeout(Box::new(self), duration)
    }
    
    /// 错误处理构建器
    pub fn on_error(self, handler: WorkflowOp<T>) -> Self {
        WorkflowOp::WithErrorHandler(Box::new(self), Box::new(handler))
    }
}
```

#### 2.1.2 代数法则实现与验证

工作流代数满足关键数学法则，确保工作流变换的正确性：

```rust
/// 工作流代数法则验证器
pub struct AlgebraicLawVerifier;

impl AlgebraicLawVerifier {
    /// 验证结合律: a.then(b.then(c)) == (a.then(b)).then(c)
    pub fn verify_associativity<T: PartialEq + Clone + Send + Sync + 'static>(
        a: &WorkflowOp<T>,
        b: &WorkflowOp<T>,
        c: &WorkflowOp<T>,
    ) -> bool {
        let left = a.clone().then(b.clone().then(c.clone()));
        let right = a.clone().then(b.clone()).then(c.clone());
        
        Self::are_equivalent(&left, &right)
    }
    
    /// 验证分配律: a.then(b.par_with(c)) == a.then(b).par_with(a.then(c))
    pub fn verify_distributivity<T: PartialEq + Clone + Send + Sync + 'static>(
        a: &WorkflowOp<T>,
        b: &WorkflowOp<T>,
        c: &WorkflowOp<T>,
    ) -> bool {
        let left = a.clone().then(b.clone().par_with(c.clone()));
        let right = a.clone().then(b.clone()).par_with(a.clone().then(c.clone()));
        
        Self::are_equivalent(&left, &right)
    }
    
    /// 验证幂等律: 对于特定操作符 a.par_with(a) == a
    pub fn verify_idempotence<T: PartialEq + Clone + Send + Sync + 'static>(
        a: &WorkflowOp<T>,
    ) -> bool {
        match a {
            WorkflowOp::Activity(_) => {
                let repeated = a.clone().par_with(a.clone());
                // 在特定语义下，相同活动的并行执行应等价于单次执行
                Self::are_equivalent(a, &repeated)
            }
            _ => false, // 其他组合操作符可能不具有幂等性
        }
    }
    
    /// 检查两个工作流操作是否等价
    fn are_equivalent<T: PartialEq + Clone + Send + Sync + 'static>(
        a: &WorkflowOp<T>,
        b: &WorkflowOp<T>,
    ) -> bool {
        // 实际实现中，这里需要根据操作语义进行深度比较
        // 简化版本可以使用规范化后的结构比较
        let a_normalized = Self::normalize(a.clone());
        let b_normalized = Self::normalize(b.clone());
        
        a_normalized == b_normalized
    }
    
    /// 规范化工作流操作
    fn normalize<T: Clone + Send + Sync + 'static>(op: WorkflowOp<T>) -> WorkflowOp<T> {
        match op {
            WorkflowOp::Sequence(a, b) => {
                let a_norm = Self::normalize(*a);
                let b_norm = Self::normalize(*b);
                
                match (a_norm, b_norm) {
                    // 处理嵌套序列
                    (WorkflowOp::Sequence(a_inner, b_inner), c) => {
                        Self::normalize(WorkflowOp::Sequence(
                            a_inner,
                            Box::new(WorkflowOp::Sequence(b_inner, Box::new(c))),
                        ))
                    }
                    (norm_a, norm_b) => WorkflowOp::Sequence(Box::new(norm_a), Box::new(norm_b)),
                }
            }
            // 其他操作符规范化...
            _ => op,
        }
    }
}
```

### 2.2 资源模型

资源模型定义了系统中资源的表示、生命周期和使用规则，受到Rust所有权系统的启发。

#### 2.2.1 资源类型系统

```rust
/// 资源类型特征
pub trait Resource: Send + Sync + 'static {
    /// 资源唯一标识符
    fn id(&self) -> ResourceId;
    /// 资源类型
    fn resource_type(&self) -> ResourceType;
    /// 资源容量
    fn capacity(&self) -> ResourceCapacity;
    /// 当前使用量
    fn usage(&self) -> ResourceUsage;
    /// 是否可以分配指定需求
    fn can_allocate(&self, requirements: &ResourceRequirements) -> bool;
    /// 分配资源
    fn allocate(&mut self, requirements: &ResourceRequirements) -> Result<(), ResourceError>;
    /// 释放资源
    fn release(&mut self, allocation: &ResourceAllocation) -> Result<(), ResourceError>;
}

/// 资源分配信息
#[derive(Clone, Debug)]
pub struct ResourceAllocation {
    pub resource_id: ResourceId,
    pub allocation_id: AllocationId,
    pub requirements: ResourceRequirements,
    pub allocated_at: Instant,
    pub valid_until: Option<Instant>,
}

impl ResourceAllocation {
    /// 检查分配是否有效
    pub fn is_valid(&self, now: Instant) -> bool {
        match self.valid_until {
            Some(expiry) => now < expiry,
            None => true,
        }
    }
    
    /// 创建带有生命周期的资源分配
    pub fn with_lifetime(mut self, duration: Duration) -> Self {
        self.valid_until = Some(self.allocated_at + duration);
        self
    }
}
```

#### 2.2.2 所有权与借用模型

```rust
/// 资源借用
pub enum ResourceBorrow {
    /// 共享借用（只读）
    Shared(ResourceId, Duration),
    /// 独占借用（可写）
    Exclusive(ResourceId, Duration),
}

impl ResourceBorrow {
    /// 检查与另一借用的兼容性
    pub fn is_compatible_with(&self, other: &ResourceBorrow) -> bool {
        match (self, other) {
            (ResourceBorrow::Shared(id1, _), ResourceBorrow::Shared(id2, _)) => id1 != id2,
            _ => false // 独占借用与其他任何借用都不兼容
        }
    }
}

/// 资源管理器
pub struct ResourceManager {
    resources: HashMap<ResourceId, Box<dyn Resource>>,
    allocations: HashMap<AllocationId, ResourceAllocation>,
    borrows: Vec<(TaskId, ResourceBorrow)>,
    /// 借用检查器
    borrow_checker: BorrowChecker,
}

impl ResourceManager {
    /// 尝试为任务借用资源
    pub async fn borrow_resource(
        &mut self, 
        task_id: TaskId, 
        borrow: ResourceBorrow
    ) -> Result<BorrowToken, ResourceError> {
        // 使用借用检查器验证借用有效性
        self.borrow_checker.validate_borrow(&task_id, &borrow, &self.borrows)?;
        
        // 创建借用令牌
        let token = BorrowToken::new(task_id, borrow.clone());
        self.borrows.push((task_id, borrow));
        Ok(token)
    }
    
    /// 释放资源借用
    pub fn release_borrow(&mut self, token: BorrowToken) {
        if let Some(pos) = self.borrows.iter().position(|(id, b)| 
            *id == token.task_id && b == &token.borrow) {
            self.borrows.remove(pos);
        }
    }
}

/// 借用检查器 - 灵感来自Rust的借用检查器
pub struct BorrowChecker {
    /// 当前活跃的独占借用
    exclusive_borrows: HashMap<ResourceId, TaskId>,
    /// 当前活跃的共享借用
    shared_borrows: HashMap<ResourceId, HashSet<TaskId>>,
}

impl BorrowChecker {
    /// 验证借用请求是否合法
    pub fn validate_borrow(
        &self,
        task_id: &TaskId,
        borrow: &ResourceBorrow,
        existing_borrows: &[(TaskId, ResourceBorrow)],
    ) -> Result<(), ResourceError> {
        match borrow {
            ResourceBorrow::Exclusive(resource_id, _) => {
                // 检查是否有其他任务正在借用此资源
                for (other_task, other_borrow) in existing_borrows {
                    if other_task != task_id {
                        match other_borrow {
                            ResourceBorrow::Exclusive(other_id, _) if other_id == resource_id => {
                                return Err(ResourceError::ResourceInUse(
                                    format!("Resource {} exclusively borrowed by task {}", 
                                            resource_id, other_task)
                                ));
                            }
                            ResourceBorrow::Shared(other_id, _) if other_id == resource_id => {
                                return Err(ResourceError::ResourceInUse(
                                    format!("Resource {} shared borrowed by task {}", 
                                            resource_id, other_task)
                                ));
                            }
                            _ => {}
                        }
                    }
                }
            }
            ResourceBorrow::Shared(resource_id, _) => {
                // 检查是否有其他任务正在独占借用此资源
                for (other_task, other_borrow) in existing_borrows {
                    if other_task != task_id {
                        if let ResourceBorrow::Exclusive(other_id, _) = other_borrow {
                            if other_id == resource_id {
                                return Err(ResourceError::ResourceInUse(
                                    format!("Resource {} exclusively borrowed by task {}", 
                                            resource_id, other_task)
                                ));
                            }
                        }
                    }
                }
            }
        }
        
        Ok(())
    }
}
```

### 2.3 一致性规则

一致性规则确保系统在所有可能的状态转换中保持关键不变量，防止系统进入无效状态。

#### 2.3.1 系统不变量

```rust
/// 系统不变量检查器
pub struct InvariantChecker {
    checks: Vec<Box<dyn Fn(&SystemState) -> Result<(), InvariantViolation> + Send + Sync>>,
}

impl InvariantChecker {
    /// 创建新的检查器
    pub fn new() -> Self {
        let mut checker = Self { checks: Vec::new() };
        
        // 注册标准不变量检查
        checker.register_check(Box::new(|state| {
            // 资源一致性：检查所有资源分配不超过容量
            for (_, resource) in &state.resources {
                if resource.usage() > resource.capacity() {
                    return Err(InvariantViolation::ResourceOverallocation);
                }
            }
            Ok(())
        }));
        
        // 依赖一致性检查
        checker.register_check(Box::new(|state| {
            for task in &state.running_tasks {
                for dep_id in &task.dependencies {
                    if !state.is_task_completed(dep_id) {
                        return Err(InvariantViolation::DependencyViolation);
                    }
                }
            }
            Ok(())
        }));
        
        // 状态一致性检查
        checker.register_check(Box::new(|state| {
            for (workflow_id, workflow_state) in &state.workflow_states {
                match workflow_state {
                    WorkflowState::Completed { .. } => {
                        // 已完成的工作流不应有运行中的任务
                        if state.running_tasks.iter().any(|t| &t.workflow_id == workflow_id) {
                            return Err(InvariantViolation::StateInconsistency);
                        }
                    }
                    WorkflowState::Running { .. } => {
                        // 运行中的工作流至少应有一个任务正在运行或待处理
                        let has_tasks = state.running_tasks.iter().any(|t| &t.workflow_id == workflow_id) ||
                                        state.pending_tasks.iter().any(|t| &t.workflow_id == workflow_id);
                        if !has_tasks {
                            return Err(InvariantViolation::StateInconsistency);
                        }
                    }
                    // 其他状态检查...
                    _ => {}
                }
            }
            Ok(())
        }));
        
        checker
    }
    
    /// 注册新的不变量检查
    pub fn register_check(
        &mut self,
        check: Box<dyn Fn(&SystemState) -> Result<(), InvariantViolation> + Send + Sync>,
    ) {
        self.checks.push(check);
    }
    
    /// 验证系统状态满足所有不变量
    pub fn verify(&self, state: &SystemState) -> Result<(), Vec<InvariantViolation>> {
        let violations: Vec<_> = self.checks
            .iter()
            .filter_map(|check| check(state).err())
            .collect();
            
        if violations.is_empty() {
            Ok(())
        } else {
            Err(violations)
        }
    }
}

/// 不变量违反类型
#[derive(Debug, Clone, PartialEq)]
pub enum InvariantViolation {
    ResourceOverallocation,
    DependencyViolation,
    StateInconsistency,
    CycleDetected,
    InvalidTransition,
    // 其他违反类型...
    Custom(String),
}
```

#### 2.3.2 形式化证明支持

系统提供形式验证能力，可以验证关键系统属性：

```rust
/// 形式化验证器
pub struct FormalVerifier {
    model_checker: ModelChecker,
    temporal_logic_checker: TemporalLogicChecker,
}

impl FormalVerifier {
    /// 验证工作流无死锁
    pub fn verify_deadlock_freedom(&self, workflow: &WorkflowDefinition) -> Result<ProofResult, VerificationError> {
        // 构建工作流的依赖图
        let graph = self.build_dependency_graph(workflow);
        
        // 检查循环依赖
        if let Some(cycle) = self.detect_cycle(&graph) {
            return Ok(ProofResult::False {
                counterexample: Some(format!("Circular dependency found: {}", 
                    cycle.iter().map(|s| s.as_str()).collect::<Vec<_>>().join(" -> "))),
                property: "DeadlockFreedom".to_string(),
            });
        }
        
        // 验证其他可能导致死锁的条件
        if let Some(issue) = self.check_resource_deadlocks(workflow) {
            return Ok(ProofResult::False {
                counterexample: Some(issue),
                property: "DeadlockFreedom".to_string(),
            });
        }
        
        Ok(ProofResult::True {
            property: "DeadlockFreedom".to_string(),
        })
    }
    
    /// 验证工作流最终会终止
    pub fn verify_termination(&self, workflow: &WorkflowDefinition) -> Result<ProofResult, VerificationError> {
        // 检查是否所有循环都有明确的终止条件
        let mut questionable_loops = Vec::new();
        
        for step in &workflow.steps {
            if let Some(loop_condition) = &step.loop_condition {
                if !self.has_terminating_condition(loop_condition) {
                    questionable_loops.push(step.id.clone());
                }
            }
        }
        
        if !questionable_loops.is_empty() {
            return Ok(ProofResult::Unknown {
                reason: format!("Cannot prove termination for loops in steps: {}", 
                    questionable_loops.join(", ")),
                property: "Termination".to_string(),
            });
        }
        
        // 验证没有无限递归
        if let Some(recursion_issue) = self.check_infinite_recursion(workflow) {
            return Ok(ProofResult::False {
                counterexample: Some(recursion_issue),
                property: "Termination".to_string(),
            });
        }
        
        Ok(ProofResult::True {
            property: "Termination".to_string(),
        })
    }
    
    /// 检测依赖图中的循环
    fn detect_cycle(&self, graph: &HashMap<String, Vec<String>>) -> Option<Vec<String>> {
        let mut visited = HashSet::new();
        let mut path = HashSet::new();
        let mut cycle = Vec::new();
        
        for node in graph.keys() {
            if !visited.contains(node) {
                if self.dfs_cycle_detect(node, graph, &mut visite
让我继续：

```rust
                if self.dfs_cycle_detect(node, graph, &mut visited, &mut path, &mut cycle) {
                    return Some(cycle);
                }
            }
        }
        
        None
    }
    
    /// 深度优先搜索检测循环
    fn dfs_cycle_detect(
        &self,
        node: &str,
        graph: &HashMap<String, Vec<String>>,
        visited: &mut HashSet<String>,
        path: &mut HashSet<String>,
        cycle: &mut Vec<String>
    ) -> bool {
        visited.insert(node.to_string());
        path.insert(node.to_string());
        
        if let Some(neighbors) = graph.get(node) {
            for neighbor in neighbors {
                if !visited.contains(neighbor) {
                    if self.dfs_cycle_detect(neighbor, graph, visited, path, cycle) {
                        cycle.insert(0, node.to_string());
                        return true;
                    }
                } else if path.contains(neighbor) {
                    // 找到循环
                    cycle.push(neighbor.to_string());
                    cycle.push(node.to_string());
                    return true;
                }
            }
        }
        
        path.remove(node);
        false
    }
    
    /// 生成形式证明
    pub fn generate_proof(&self, workflow: &WorkflowDefinition) -> FormalProof {
        let mut proof = FormalProof::new(workflow.id.clone());
        
        // 添加无死锁证明
        match self.verify_deadlock_freedom(workflow) {
            Ok(result) => {
                proof.add_property_result("DeadlockFreedom".to_string(), result);
            }
            Err(e) => {
                proof.add_error("DeadlockFreedom".to_string(), e.to_string());
            }
        }
        
        // 添加终止性证明
        match self.verify_termination(workflow) {
            Ok(result) => {
                proof.add_property_result("Termination".to_string(), result);
            }
            Err(e) => {
                proof.add_error("Termination".to_string(), e.to_string());
            }
        }
        
        // 添加资源安全性证明
        match self.verify_resource_safety(workflow) {
            Ok(result) => {
                proof.add_property_result("ResourceSafety".to_string(), result);
            }
            Err(e) => {
                proof.add_error("ResourceSafety".to_string(), e.to_string());
            }
        }
        
        proof
    }
}

/// 证明结果
#[derive(Debug, Clone)]
pub enum ProofResult {
    /// 属性成立
    True {
        property: String,
    },
    /// 属性不成立，包含反例
    False {
        counterexample: Option<String>,
        property: String,
    },
    /// 无法确定属性是否成立
    Unknown {
        reason: String,
        property: String,
    },
}

/// 形式证明
#[derive(Debug, Clone)]
pub struct FormalProof {
    workflow_id: String,
    property_results: HashMap<String, ProofResult>,
    errors: HashMap<String, String>,
    generated_at: DateTime<Utc>,
}

impl FormalProof {
    pub fn new(workflow_id: String) -> Self {
        Self {
            workflow_id,
            property_results: HashMap::new(),
            errors: HashMap::new(),
            generated_at: Utc::now(),
        }
    }
    
    pub fn add_property_result(&mut self, property: String, result: ProofResult) {
        self.property_results.insert(property, result);
    }
    
    pub fn add_error(&mut self, property: String, error: String) {
        self.errors.insert(property, error);
    }
    
    pub fn is_fully_verified(&self) -> bool {
        !self.property_results.is_empty() && 
        self.property_results.values().all(|r| matches!(r, ProofResult::True { .. }))
    }
}
```

## 3. 执行引擎层

执行引擎层负责工作流的实际执行，包括状态管理、任务调度和错误处理。

### 3.1 状态管理

状态管理基于事件溯源模式设计，提供可靠的状态持久化和恢复能力。

#### 3.1.1 事件溯源模型

```rust
/// 工作流事件
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum WorkflowEvent {
    // 工作流生命周期事件
    WorkflowCreated { workflow_id: WorkflowId, definition: WorkflowDefinition },
    WorkflowStarted { workflow_id: WorkflowId, start_time: DateTime<Utc> },
    WorkflowCompleted { workflow_id: WorkflowId, completion_time: DateTime<Utc> },
    WorkflowFailed { workflow_id: WorkflowId, error: WorkflowError, failure_time: DateTime<Utc> },
    
    // 任务事件
    TaskScheduled { task_id: TaskId, workflow_id: WorkflowId, task_def: TaskDefinition },
    TaskStarted { task_id: TaskId, start_time: DateTime<Utc> },
    TaskCompleted { task_id: TaskId, result: TaskResult, completion_time: DateTime<Utc> },
    TaskFailed { task_id: TaskId, error: TaskError, failure_time: DateTime<Utc> },
    
    // 资源事件
    ResourceAllocated { allocation: ResourceAllocation },
    ResourceReleased { allocation_id: AllocationId },
    
    // 状态事件
    WorkflowStateUpdated { workflow_id: WorkflowId, key: String, value: Value, timestamp: DateTime<Utc> },
    
    // 系统事件
    SnapshotCreated { snapshot_id: String, state_hash: String },
}

/// 事件存储接口
#[async_trait]
pub trait EventStore: Send + Sync + 'static {
    /// 追加事件
    async fn append_events(
        &self,
        workflow_id: &WorkflowId,
        events: Vec<WorkflowEvent>,
        expected_version: Option<u64>,
    ) -> Result<u64, EventStoreError>;
    
    /// 读取事件流
    async fn read_events(
        &self,
        workflow_id: &WorkflowId,
        start_version: u64,
        max_count: usize,
    ) -> Result<Vec<(u64, WorkflowEvent)>, EventStoreError>;
    
    /// 创建快照
    async fn create_snapshot(
        &self,
        workflow_id: &WorkflowId,
        state: &WorkflowState,
        version: u64,
    ) -> Result<(), EventStoreError>;
    
    /// 读取最新快照
    async fn read_latest_snapshot(
        &self,
        workflow_id: &WorkflowId,
    ) -> Result<Option<(WorkflowState, u64)>, EventStoreError>;
}
```

#### 3.1.2 状态管理器

```rust
/// 工作流状态管理器
pub struct WorkflowStateManager<E: EventStore> {
    event_store: E,
    snapshot_frequency: u64,
    state_cache: Mutex<LruCache<WorkflowId, (WorkflowState, u64)>>,
}

impl<E: EventStore> WorkflowStateManager<E> {
    /// 从事件历史重建工作流状态
    pub async fn rebuild_state(&self, workflow_id: &WorkflowId) -> Result<WorkflowState, StateError> {
        // 检查缓存
        {
            let mut cache = self.state_cache.lock().await;
            if let Some((state, _)) = cache.get(workflow_id) {
                return Ok(state.clone());
            }
        }
        
        // 尝试加载最新快照
        let (mut state, mut version) = match self.event_store.read_latest_snapshot(workflow_id).await {
            Ok(Some(snapshot)) => snapshot,
            _ => (WorkflowState::new(), 0),
        };
        
        // 读取后续事件并应用
        let mut current_version = version;
        loop {
            let events = self.event_store.read_events(
                workflow_id, current_version, 100
            ).await?;
            
            if events.is_empty() {
                break;
            }
            
            for (ev_version, event) in events {
                state.apply_event(&event);
                current_version = ev_version;
            }
        }
        
        // 如果读取了足够多的事件，创建新快照
        if current_version - version >= self.snapshot_frequency {
            self.event_store.create_snapshot(workflow_id, &state, current_version).await?;
        }
        
        // 更新缓存
        {
            let mut cache = self.state_cache.lock().await;
            cache.put(workflow_id.clone(), (state.clone(), current_version));
        }
        
        Ok(state)
    }
    
    /// 应用新事件并更新状态
    pub async fn apply_new_events(
        &self,
        workflow_id: &WorkflowId,
        events: Vec<WorkflowEvent>,
        expected_version: Option<u64>,
    ) -> Result<(WorkflowState, u64), StateError> {
        // 追加事件到存储
        let new_version = self.event_store.append_events(
            workflow_id, events.clone(), expected_version
        ).await?;
        
        // 检查缓存
        let mut state = {
            let mut cache = self.state_cache.lock().await;
            if let Some((cached_state, cached_version)) = cache.get(workflow_id) {
                if expected_version.map_or(true, |v| v == *cached_version) {
                    // 缓存有效，只需应用新事件
                    let mut state = cached_state.clone();
                    for event in &events {
                        state.apply_event(event);
                    }
                    
                    // 更新缓存
                    cache.put(workflow_id.clone(), (state.clone(), new_version));
                    
                    state
                } else {
                    // 缓存版本不匹配，需要完全重建
                    drop(cache);
                    self.rebuild_state(workflow_id).await?
                }
            } else {
                // 缓存未命中，需要完全重建
                drop(cache);
                self.rebuild_state(workflow_id).await?
            }
        };
        
        Ok((state, new_version))
    }
}
```

#### 3.1.3 工作流状态实现

```rust
/// 工作流状态
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct WorkflowState {
    /// 工作流ID
    pub workflow_id: WorkflowId,
    /// 工作流定义
    pub definition: Option<WorkflowDefinition>,
    /// 工作流阶段
    pub stage: WorkflowStage,
    /// 开始时间
    pub started_at: Option<DateTime<Utc>>,
    /// 完成时间
    pub completed_at: Option<DateTime<Utc>>,
    /// 错误信息
    pub error: Option<WorkflowError>,
    /// 当前任务
    pub current_tasks: HashMap<TaskId, TaskState>,
    /// 已完成任务
    pub completed_tasks: HashMap<TaskId, TaskResult>,
    /// 工作流数据
    pub data: HashMap<String, Value>,
    /// 上次更新时间
    pub last_updated: DateTime<Utc>,
}

impl WorkflowState {
    /// 创建新的工作流状态
    pub fn new() -> Self {
        Self {
            workflow_id: WorkflowId::new(),
            definition: None,
            stage: WorkflowStage::Created,
            started_at: None,
            completed_at: None,
            error: None,
            current_tasks: HashMap::new(),
            completed_tasks: HashMap::new(),
            data: HashMap::new(),
            last_updated: Utc::now(),
        }
    }
    
    /// 应用事件更新状态
    pub fn apply_event(&mut self, event: &WorkflowEvent) {
        match event {
            WorkflowEvent::WorkflowCreated { workflow_id, definition, .. } => {
                self.workflow_id = workflow_id.clone();
                self.definition = Some(definition.clone());
                self.stage = WorkflowStage::Created;
                self.last_updated = Utc::now();
            }
            WorkflowEvent::WorkflowStarted { workflow_id, start_time } => {
                debug_assert_eq!(self.workflow_id, *workflow_id, "Event workflow ID mismatch");
                self.stage = WorkflowStage::Running;
                self.started_at = Some(*start_time);
                self.last_updated = Utc::now();
            }
            WorkflowEvent::WorkflowCompleted { workflow_id, completion_time } => {
                debug_assert_eq!(self.workflow_id, *workflow_id, "Event workflow ID mismatch");
                self.stage = WorkflowStage::Completed;
                self.completed_at = Some(*completion_time);
                self.last_updated = Utc::now();
            }
            WorkflowEvent::WorkflowFailed { workflow_id, error, failure_time } => {
                debug_assert_eq!(self.workflow_id, *workflow_id, "Event workflow ID mismatch");
                self.stage = WorkflowStage::Failed;
                self.error = Some(error.clone());
                self.completed_at = Some(*failure_time);
                self.last_updated = Utc::now();
            }
            WorkflowEvent::TaskScheduled { task_id, workflow_id, task_def } => {
                debug_assert_eq!(self.workflow_id, *workflow_id, "Event workflow ID mismatch");
                self.current_tasks.insert(task_id.clone(), TaskState {
                    id: task_id.clone(),
                    definition: task_def.clone(),
                    status: TaskStatus::Scheduled,
                    started_at: None,
                    completed_at: None,
                    error: None,
                });
                self.last_updated = Utc::now();
            }
            WorkflowEvent::TaskStarted { task_id, start_time, .. } => {
                if let Some(task) = self.current_tasks.get_mut(task_id) {
                    task.status = TaskStatus::Running;
                    task.started_at = Some(*start_time);
                }
                self.last_updated = Utc::now();
            }
            WorkflowEvent::TaskCompleted { task_id, result, completion_time, .. } => {
                if let Some(task) = self.current_tasks.remove(task_id) {
                    let mut completed_task = task;
                    completed_task.status = TaskStatus::Completed;
                    completed_task.completed_at = Some(*completion_time);
                    
                    self.completed_tasks.insert(task_id.clone(), result.clone());
                }
                self.last_updated = Utc::now();
            }
            WorkflowEvent::TaskFailed { task_id, error, failure_time, .. } => {
                if let Some(task) = self.current_tasks.get_mut(task_id) {
                    task.status = TaskStatus::Failed;
                    task.error = Some(error.clone());
                    task.completed_at = Some(*failure_time);
                }
                self.last_updated = Utc::now();
            }
            WorkflowEvent::WorkflowStateUpdated { workflow_id, key, value, timestamp } => {
                debug_assert_eq!(self.workflow_id, *workflow_id, "Event workflow ID mismatch");
                self.data.insert(key.clone(), value.clone());
                self.last_updated = *timestamp;
            }
            // 处理其他事件类型...
            _ => {}
        }
    }
}
```

### 3.2 调度系统

调度系统负责管理工作流任务的执行顺序和资源分配，确保工作流的高效执行。

#### 3.2.1 依赖图调度器

```rust
/// 工作流依赖图
pub struct WorkflowGraph {
    nodes: HashMap<TaskId, TaskNode>,
    edges: HashMap<TaskId, Vec<TaskId>>,
    entry_points: Vec<TaskId>,
    exit_points: Vec<TaskId>,
}

impl WorkflowGraph {
    /// 从工作流定义构建依赖图
    pub fn from_workflow(workflow: &WorkflowDefinition) -> Self {
        let mut graph = Self {
            nodes: HashMap::new(),
            edges: HashMap::new(),
            entry_points: Vec::new(),
            exit_points: Vec::new(),
        };
        
        // 构建节点
        for step in &workflow.steps {
            let node = TaskNode {
                id: step.id.clone(),
                task: TaskDefinition {
                    name: step.name.clone(),
                    step_type: step.step_type.clone(),
                    resources: step.resource_requirements.clone(),
                    timeout: step.timeout,
                    retry: step.retry_strategy.clone(),
                },
                dependencies: Vec::new(),
                dependents: Vec::new(),
            };
            
            graph.nodes.insert(node.id.clone(), node);
        }
        
        // 构建边
        for step in &workflow.steps {
            for next_step in &step.next_steps {
                graph.add_edge(step.id.clone(), next_step.clone());
            }
        }
        
        // 识别入口和出口点
        graph.analyze_structure();
        
        graph
    }
    
    /// 添加依赖边
    pub fn add_edge(&mut self, from: TaskId, to: TaskId) {
        if let Some(edges) = self.edges.get_mut(&from) {
            edges.push(to.clone());
        } else {
            self.edges.insert(from.clone(), vec![to.clone()]);
        }
        
        if let Some(node) = self.nodes.get_mut(&to) {
            node.dependencies.push(from.clone());
        }
        
        if let Some(node) = self.nodes.get_mut(&from) {
            node.dependents.push(to);
        }
    }
    
    /// 分析图结构识别入口和出口点
    fn analyze_structure(&mut self) {
        self.entry_points.clear();
        self.exit_points.clear();
        
        for (id, node) in &self.nodes {
            if node.dependencies.is_empty() {
                self.entry_points.push(id.clone());
            }
            
            if node.dependents.is_empty() {
                self.exit_points.push(id.clone());
            }
        }
    }
    
    /// 查找可执行任务（所有依赖已完成）
    pub fn find_executable_tasks(&self, completed_tasks: &HashSet<TaskId>) -> Vec<TaskId> {
        let mut executable = Vec::new();
        
        for (id, node) in &self.nodes {
            // 跳过已完成的任务
            if completed_tasks.contains(id) {
                continue;
            }
            
            // 检查所有依赖是否已完成
            let all_deps_completed = node.dependencies.iter()
                .all(|dep| completed_tasks.contains(dep));
                
            if all_deps_completed {
                executable.push(id.clone());
            }
        }
        
        executable
    }
    
    /// 计算关键路径
    pub fn compute_critical_path(&self) -> (Vec<TaskId>, f64) {
        // 拓扑排序任务
        let sorted_tasks = self.topological_sort();
        
        // 计算最早开始时间
        let mut earliest_start: HashMap<TaskId, f64> = HashMap::new();
        let mut earliest_finish: HashMap<TaskId, f64> = HashMap::new();
        
        // 初始化入口任务
        for entry in &self.entry_points {
            earliest_start.insert(entry.clone(), 0.0);
            let duration = self.nodes.get(entry)
                .map(|n| n.task.estimated_duration.as_secs_f64())
                .unwrap_or(0.0);
            earliest_finish.insert(entry.clone(), duration);
        }
        
        // 计算所有任务的最早开始/完成时间
        for task_id in &sorted_tasks {
            let node = match self.nodes.get(task_id) {
                Some(n) => n,
                None => continue,
            };
            
            // 任务的最早开始时间是所有前置任务的最早完成时间的最大值
            let max_predecessor_finish = node.dependencies.iter()
                .filter_map(|dep| earliest_finish.get(dep))
                .fold(0.0, |max, &finish| max.max(finish));
            
            earliest_start.insert(task_id.clone(), max_predecessor_finish);
            
            // 计算最早完成时间
            let duration = node.task.estimated_duration.as_secs_f64();
            earliest_finish.insert(task_id.clone(), max_predecessor_finish + duration);
        }
        
        // 找到项目完成时间 (最后一个任务的最早完成时间)
        let project_finish = self.exit_points.iter()
            .filter_map(|exit| earliest_finish.get(exit))
            .fold(0.0, |max, &finish| max.max(finish));
        
        // 计算最晚开始时间和最晚完成时间
        let mut latest_start: HashMap<TaskId, f64> = HashMap::new();
        let mut latest_finish: HashMap<TaskId, f64> = HashMap::new();
        
        // 初始化出口任务
        for exit in &self.exit_points {
            latest_finish.insert(exit.clone(), project_finish);
            let duration = self.nodes.get(exit)
                .map(|n| n.task.estimated_duration.as_secs_f64())
                .unwrap_or(0.0);
            latest_start.insert(exit.clone(), project_finish - duration);
        }
        
        // 反向计算所有任务的最晚开始/完成时间
        for task_id in sorted_tasks.iter().rev() {
            let node = match self.nodes.get(task_id) {
                Some(n) => n,
                None => continue,
            };
            
            // 任务的最晚完成时间是所有后续任务的最晚开始时间的最小值
            let min_successor_start = node.dependents.iter()
                .filter_map(|succ| latest_start.get(succ))
                .fold(project_finish, |min, &start| min.min(start));
            
            latest_finish.insert(task_id.clone(), min_successor_start);
            
            // 计算最晚开始时间
            let duration = node.task.estimated_duration.as_secs_f64();
            latest_start.insert(task_id.clone(), min_successor_start - duration);
        }
        
        // 计算每个任务的总浮动时间
        let mut float_time: HashMap<TaskId, f64> = HashMap::new();
        for task_id in &sorted_tasks {
            if let (Some(&latest), Some(&earliest)) = (latest_finish.get(task_id), earliest_finish.get(task_id)) {
                float_time.insert(task_id.clone(), latest - earliest);
            }
        }
        
        // 关键路径是浮动时间为0的任务
        let critical_path: Vec<TaskId> = sorted_tasks.into_iter()
            .filter(|task_id| float_time.get(task_id).map_or(false, |&float| float < 1e-6))
            .collect();
        
        (critical_path, project_finish)
    }
    
    /// 执行拓扑排序
    fn topological_sort(&self) -> Vec<TaskId> {
        let mut result = Vec::new();
        let mut visited = HashSet::new();
        let mut temp_visited = HashSet::new();
        
        // 从所有入口节点开始DFS
        for entry in &self.entry_points {
            self.visit_node(entry, &mut visited, &mut temp_visited, &mut result);
        }
        
        result
    }
    
    /// 访问节点进行拓扑排序
    fn visit_node(
        &self,
        node: &TaskId,
        visited: &mut HashSet<TaskId>,
        temp_visited: &mut HashSet<TaskId>,
        result: &mut Vec<TaskId>
    ) {
        // 已经访问过，跳过
        if visited.contains(node) {
            return;
        }
        
        // 检测循环 (理论上不应该有)
        if temp_visited.contains(node) {
            panic!("Cycle detected in task graph");
        }
        
        // 标记为临时访问
        temp_visited.insert(node.clone());
        
        // 访问所有依赖节点
        if let Some(edges) = self.edges.get(node) {
            for neighbor in edges {
                self.visit_node(neighbor, visited, temp_visited, result);
            }
        }
        
        // 移除临时标记，添加到永久访问集合和结果
        temp_visited.remove(node);
        visited.insert(node.clone());
        result.push(node.clone());
    }
}
```

#### 3.2.2 资源感知调度器

```rust
/// 工作流调度器
pub struct WorkflowScheduler<R: ResourceProvider> {
    resource_provider: R,
    task_queue: PriorityQueue<PendingTask>,
    running_tasks: HashMap<TaskId, RunningTask>,
    completed_tasks: HashSet<TaskId>,
    task_priorities: HashMap<TaskId, i32>,
    dependency_tracker: DependencyTracker,
    scheduler_context: SchedulerContext,
}

impl<R: ResourceProvider> WorkflowScheduler<R> {
    /// 提交新的工作流进行调度
    pub async fn schedule_workflow(&mut self, workflow: WorkflowDefinition) -> Result<WorkflowId, SchedulerError> {
        let workflow_id = WorkflowId::new();
        let graph = WorkflowGraph::from_workflow(&workflow);
        
        // 计算关键路径和任务优先级
        let (critical_path, _) = graph.compute_critical_path();
        let priorities = self.calculate_priorities(&graph, &critical_path);
        
        // 更新任务优先级表
        for (task_id, priority) in priorities {
            self.task_priorities.insert(task_id, priority);
        }
        
        // 将依赖关系添加到跟踪器
        self.dependency_tracker.add_workflow_dependencies(&graph);
        
        // 找到入口任务并加入队列
        for task_id in graph.entry_points {
            if let Some(node) = graph.nodes.get(&task_id) {
                let pending_task = PendingTask {
                    id: task_id.clone(),
                    workflow_id: workflow_id.clone(),
                    definition: node.task.clone(),
                    priority: *self.task_priorities.get(&task_id).unwrap_or(&0),
                };
                
                self.task_queue.push(pending_task);
            }
        }
        
        Ok(workflow_id)
    }
    
    /// 运行调度循环
    pub async fn run_scheduling_loop(&mut self) -> Result<(), SchedulerError> {
        loop {
            // 1. 检查资源可用性
            let available_resources = self.resource_provider.available_resources().await?;
            
            // 2. 调度可执行的任务
            let mut scheduled = false;
            
            // 优先考虑高优先级任务
            while let Some(task) = self.task_queue.peek() {
                // 检查资源是否满足
                if self.can_allocate_resources(&task.definition.resources, &available_resources) {
                    // 弹出任务并分配资源
                    let task = self.task_queue.pop().unwrap();
                    
                    // 分配资源
                    let allocation = self.resource_provider.allocate_resources(
                        &task.definition.resources
                    ).await?;
                    
                    // 开始执行任务
                    let running_task = self.start_task(task, allocation).await?;
                    
                    // 记录运行中的任务
                    self.running_tasks.insert(running_task.id.clone(), running_task);
                    
                    scheduled = true;
                } else {
                    // 当前最高优先级任务无法调度，跳出循环
                    break;
                }
            }
            
            // 3. 检查完成的任务
            let completed_tasks = self.check_completed_tasks().await?;
            
            for task_id in completed_tasks {
                // 移除运行中任务记录
                if let Some(task) = self.running_tasks.remove(&task_id) {
                    // 释放资源
                    self.resource_provider.release_resources(&task.allocation).await?;
                    
                    // 记录完成
                    self.completed_tasks.insert(task_id.clone());
                    
                    // 计算下一批可执行任务
                    self.schedule_dependent_tasks(&task_id).await?;
                }
            }
            
            // 4. 调整调度
```rust
            // 4. 调整调度策略（基于资源利用率和执行情况）
            self.adjust_scheduling_strategy().await;
            
            // 5. 执行周期性维护任务
            self.perform_maintenance().await;
            
            // 如果没有调度任务且没有运行中的任务，可以短暂休眠
            if !scheduled && self.running_tasks.is_empty() {
                tokio::time::sleep(Duration::from_millis(100)).await;
            }
        }
    }
    
    /// 计算依赖图中任务的优先级
    fn calculate_priorities(&self, graph: &WorkflowGraph, critical_path: &[TaskId]) -> HashMap<TaskId, i32> {
        let mut priorities = HashMap::new();
        
        // 关键路径上的任务获得最高优先级
        for task_id in critical_path {
            priorities.insert(task_id.clone(), 100);
        }
        
        // 计算非关键路径任务的优先级
        let topo_sorted = graph.topological_sort();
        
        for task_id in topo_sorted {
            // 如果已经设置了优先级（关键路径上的任务），跳过
            if priorities.contains_key(&task_id) {
                continue;
            }
            
            // 查找任务节点
            if let Some(node) = graph.nodes.get(&task_id) {
                // 计算优先级，基于下游任务数量和估计持续时间
                let downstream_count = self.count_downstream_tasks(graph, &task_id);
                let duration_factor = node.task.estimated_duration.as_secs_f64() / 60.0; // 归一化到分钟
                
                // 优先级公式：下游任务数 * 10 + 持续时间因子 * 5
                let priority = (downstream_count as f64 * 10.0 + duration_factor * 5.0) as i32;
                
                priorities.insert(task_id, priority);
            }
        }
        
        priorities
    }
    
    /// 计算从指定任务可达的所有下游任务数量
    fn count_downstream_tasks(&self, graph: &WorkflowGraph, task_id: &TaskId) -> usize {
        let mut visited = HashSet::new();
        self.dfs_count(graph, task_id, &mut visited);
        
        // 减去当前任务本身
        visited.len().saturating_sub(1)
    }
    
    /// 深度优先搜索计算可达节点
    fn dfs_count(&self, graph: &WorkflowGraph, task_id: &TaskId, visited: &mut HashSet<TaskId>) {
        // 已访问，避免循环
        if visited.contains(task_id) {
            return;
        }
        
        // 标记为已访问
        visited.insert(task_id.clone());
        
        // 访问所有后继节点
        if let Some(edges) = graph.edges.get(task_id) {
            for next_id in edges {
                self.dfs_count(graph, next_id, visited);
            }
        }
    }
    
    /// 检查是否可以为任务分配资源
    fn can_allocate_resources(
        &self,
        requirements: &ResourceRequirements,
        available: &ResourceCapacity,
    ) -> bool {
        // 检查所有资源类型是否满足需求
        requirements.cpu <= available.cpu &&
        requirements.memory <= available.memory &&
        requirements.disk <= available.disk &&
        requirements.network <= available.network
    }
    
    /// 启动任务执行
    async fn start_task(
        &self,
        task: PendingTask,
        allocation: ResourceAllocation,
    ) -> Result<RunningTask, SchedulerError> {
        log::info!("Starting task {} of workflow {}", task.id, task.workflow_id);
        
        // 创建任务执行上下文
        let context = TaskExecutionContext {
            task_id: task.id.clone(),
            workflow_id: task.workflow_id.clone(),
            allocation: allocation.clone(),
            scheduler: self.scheduler_context.clone(),
        };
        
        // 在Tokio上执行任务
        let executor = self.get_executor_for_task(&task)?;
        let join_handle = tokio::spawn(async move {
            // 记录开始时间
            let start_time = Instant::now();
            
            // 执行任务
            let result = executor.execute_task(task.definition.clone(), context).await;
            
            // 记录完成时间和结果
            let execution_time = start_time.elapsed();
            
            TaskCompletion {
                task_id: task.id,
                workflow_id: task.workflow_id,
                result,
                execution_time,
            }
        });
        
        // 创建运行中任务记录
        let running_task = RunningTask {
            id: task.id,
            workflow_id: task.workflow_id,
            allocation,
            join_handle,
            started_at: Instant::now(),
        };
        
        Ok(running_task)
    }
    
    /// 检查已完成的任务
    async fn check_completed_tasks(&mut self) -> Result<Vec<TaskId>, SchedulerError> {
        let mut completed = Vec::new();
        let mut tasks_to_check = Vec::new();
        
        // 收集需要检查的任务
        for (task_id, running_task) in &self.running_tasks {
            if running_task.join_handle.is_finished() {
                tasks_to_check.push(task_id.clone());
            }
        }
        
        // 处理已完成的任务
        for task_id in tasks_to_check {
            if let Some(task) = self.running_tasks.get_mut(&task_id) {
                // 获取任务结果
                match &mut task.join_handle {
                    join_handle => {
                        if let Ok(completion) = join_handle.now_or_never().unwrap() {
                            // 处理任务完成
                            match completion.result {
                                Ok(result) => {
                                    log::info!("Task {} completed successfully in {:?}", 
                                             task_id, completion.execution_time);
                                    
                                    // 存储任务结果
                                    self.store_task_result(&task_id, &completion.workflow_id, &result).await?;
                                }
                                Err(err) => {
                                    log::error!("Task {} failed: {}", task_id, err);
                                    
                                    // 处理任务错误
                                    self.handle_task_error(&task_id, &completion.workflow_id, err).await?;
                                }
                            }
                            
                            // 标记为已完成
                            completed.push(task_id);
                        }
                    }
                }
            }
        }
        
        Ok(completed)
    }
    
    /// 调度依赖任务
    async fn schedule_dependent_tasks(&mut self, completed_task_id: &TaskId) -> Result<(), SchedulerError> {
        // 获取所有依赖于此任务的后续任务
        let dependent_tasks = self.dependency_tracker.get_dependents(completed_task_id);
        
        for dependent_id in dependent_tasks {
            // 检查所有依赖是否已满足
            let all_dependencies_met = self.dependency_tracker.are_dependencies_met(
                &dependent_id, 
                &self.completed_tasks
            );
            
            if all_dependencies_met {
                // 获取任务定义
                if let Some(task_def) = self.dependency_tracker.get_task_definition(&dependent_id) {
                    // 创建待处理任务
                    let workflow_id = self.dependency_tracker.get_workflow_id(&dependent_id)
                        .ok_or_else(|| SchedulerError::TaskNotFound(dependent_id.clone()))?;
                    
                    let priority = self.task_priorities
                        .get(&dependent_id)
                        .copied()
                        .unwrap_or(0);
                    
                    let pending_task = PendingTask {
                        id: dependent_id,
                        workflow_id,
                        definition: task_def,
                        priority,
                    };
                    
                    // 添加到调度队列
                    self.task_queue.push(pending_task);
                    
                    log::debug!("Scheduled dependent task {}", dependent_id);
                }
            }
        }
        
        Ok(())
    }
    
    /// 调整调度策略
    async fn adjust_scheduling_strategy(&mut self) {
        // 根据当前系统负载和执行状态调整调度策略
        // 例如，动态调整任务优先级、资源分配策略等
        
        // 1. 检查系统负载
        let system_load = self.resource_provider.get_system_load().await.unwrap_or_default();
        
        // 2. 根据负载调整策略
        if system_load.cpu_usage > 0.8 {
            // CPU使用率高，降低并行度
            self.scheduler_context.max_parallel_tasks = self.scheduler_context.max_parallel_tasks.saturating_sub(1);
        } else if system_load.cpu_usage < 0.5 && self.running_tasks.len() == self.scheduler_context.max_parallel_tasks {
            // CPU使用率低且达到并行上限，增加并行度
            self.scheduler_context.max_parallel_tasks += 1;
        }
        
        // 3. 动态调整任务优先级
        self.adjust_task_priorities(&system_load);
    }
    
    /// 动态调整任务优先级
    fn adjust_task_priorities(&mut self, system_load: &SystemLoad) {
        // 根据系统负载调整优先级策略
        let priority_strategy = if system_load.memory_usage > 0.8 {
            // 内存使用率高，优先执行内存需求低的任务
            PriorityStrategy::MinimizeMemoryUsage
        } else if system_load.cpu_usage > 0.8 {
            // CPU使用率高，优先执行CPU需求低的任务
            PriorityStrategy::MinimizeCpuUsage
        } else {
            // 默认策略，按照预设优先级
            PriorityStrategy::Default
        };
        
        // 更新调度器上下文中的优先级策略
        self.scheduler_context.priority_strategy = priority_strategy;
        
        // 重新排序任务队列
        self.task_queue.resort();
    }
    
    /// 执行周期性维护任务
    async fn perform_maintenance(&mut self) {
        // 检查超时任务
        self.check_task_timeouts().await;
        
        // 清理过期资源分配
        self.cleanup_expired_allocations().await;
        
        // 执行健康检查
        self.perform_health_check().await;
    }
    
    /// 检查任务超时
    async fn check_task_timeouts(&mut self) {
        let now = Instant::now();
        let mut timed_out_tasks = Vec::new();
        
        for (task_id, task) in &self.running_tasks {
            // 检查是否超过任务超时时间
            if let Some(timeout) = task.get_timeout() {
                if now.duration_since(task.started_at) > timeout {
                    timed_out_tasks.push(task_id.clone());
                }
            }
        }
        
        // 处理超时任务
        for task_id in timed_out_tasks {
            if let Some(task) = self.running_tasks.get(&task_id) {
                log::warn!("Task {} timed out after {:?}", task_id, 
                          now.duration_since(task.started_at));
                
                // 中止任务执行
                task.abort_execution();
                
                // 标记为失败
                let workflow_id = task.workflow_id.clone();
                let error = TaskError::Timeout(
                    format!("Task execution exceeded timeout of {:?}", task.get_timeout())
                );
                
                self.handle_task_error(&task_id, &workflow_id, error).await
                    .unwrap_or_else(|e| log::error!("Failed to handle task timeout: {}", e));
            }
        }
    }
    
    /// 清理过期资源分配
    async fn cleanup_expired_allocations(&mut self) {
        let now = Instant::now();
        let mut expired_allocations = Vec::new();
        
        // 检查所有资源分配是否过期
        for (task_id, task) in &self.running_tasks {
            if !task.allocation.is_valid(now) {
                expired_allocations.push(task_id.clone());
            }
        }
        
        // 处理过期分配
        for task_id in expired_allocations {
            if let Some(task) = self.running_tasks.get(&task_id) {
                log::warn!("Resource allocation for task {} expired", task_id);
                
                // 中止任务执行
                task.abort_execution();
                
                // 标记为失败
                let workflow_id = task.workflow_id.clone();
                let error = TaskError::ResourceExpired(
                    "Resource allocation expired before task completion".to_string()
                );
                
                self.handle_task_error(&task_id, &workflow_id, error).await
                    .unwrap_or_else(|e| log::error!("Failed to handle expired allocation: {}", e));
            }
        }
    }
}

/// 运行中的任务
pub struct RunningTask {
    id: TaskId,
    workflow_id: WorkflowId,
    allocation: ResourceAllocation,
    join_handle: JoinHandle<TaskCompletion>,
    started_at: Instant,
}

impl RunningTask {
    /// 获取任务超时
    pub fn get_timeout(&self) -> Option<Duration> {
        None // 从任务定义中获取
    }
    
    /// 中止任务执行
    pub fn abort_execution(&self) {
        self.join_handle.abort();
    }
}

/// 任务完成信息
pub struct TaskCompletion {
    task_id: TaskId,
    workflow_id: WorkflowId,
    result: Result<TaskResult, TaskError>,
    execution_time: Duration,
}

/// 调度器上下文
#[derive(Clone)]
pub struct SchedulerContext {
    max_parallel_tasks: usize,
    priority_strategy: PriorityStrategy,
}

/// 优先级策略
#[derive(Clone, Copy, PartialEq)]
pub enum PriorityStrategy {
    Default,
    MinimizeMemoryUsage,
    MinimizeCpuUsage,
    MaximizeThroughput,
}
```

### 3.3 错误处理

错误处理系统负责管理工作流执行过程中的各种错误情况，包括重试、补偿和降级策略。

#### 3.3.1 错误分类与重试策略

```rust
/// 工作流错误
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum WorkflowError {
    // 暂时性错误，可能通过重试解决
    Transient(TransientError),
    // 永久性错误，通常需要人工干预
    Permanent(PermanentError),
    // 系统错误
    System(SystemError),
    // 业务逻辑错误
    Business(BusinessError),
}

impl WorkflowError {
    /// 检查错误是否可重试
    pub fn is_retriable(&self) -> bool {
        match self {
            WorkflowError::Transient(_) => true,
            WorkflowError::System(sys_err) => sys_err.is_retriable(),
            WorkflowError::Business(biz_err) => biz_err.is_retriable(),
            WorkflowError::Permanent(_) => false,
        }
    }
    
    /// 获取建议的重试延迟
    pub fn suggested_retry_delay(&self) -> Option<Duration> {
        match self {
            WorkflowError::Transient(err) => Some(err.suggested_delay),
            WorkflowError::System(err) => err.suggested_retry_delay(),
            WorkflowError::Business(err) => err.suggested_retry_delay(),
            WorkflowError::Permanent(_) => None,
        }
    }
}

/// 重试策略
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetryStrategy {
    /// 最大重试次数
    pub max_retries: u32,
    /// 初始重试间隔
    pub initial_delay: Duration,
    /// 最大重试间隔
    pub max_delay: Duration,
    /// 退避乘数
    pub backoff_multiplier: f64,
    /// 重试条件
    pub retry_on: Vec<ErrorCondition>,
    /// 最大重试持续时间
    pub max_retry_duration: Option<Duration>,
    /// 重置重试计数的条件
    pub reset_retry_count_after: Option<Duration>,
}

impl RetryStrategy {
    /// 创建指数退避重试策略
    pub fn exponential_backoff(max_retries: u32) -> Self {
        Self {
            max_retries,
            initial_delay: Duration::from_secs(1),
            max_delay: Duration::from_secs(60),
            backoff_multiplier: 2.0,
            retry_on: vec![ErrorCondition::Any],
            max_retry_duration: None,
            reset_retry_count_after: None,
        }
    }
    
    /// 创建固定间隔重试策略
    pub fn fixed_interval(max_retries: u32, interval: Duration) -> Self {
        Self {
            max_retries,
            initial_delay: interval,
            max_delay: interval,
            backoff_multiplier: 1.0,
            retry_on: vec![ErrorCondition::Any],
            max_retry_duration: None,
            reset_retry_count_after: None,
        }
    }
    
    /// 计算下一次重试延迟
    pub fn next_delay(&self, attempt: u32) -> Duration {
        let multiplier = self.backoff_multiplier.powi(attempt as i32);
        let delay = self.initial_delay.mul_f64(multiplier);
        
        if delay > self.max_delay {
            self.max_delay
        } else {
            delay
        }
    }
    
    /// 检查是否应该重试
    pub fn should_retry(
        &self,
        error: &WorkflowError,
        attempt: u32,
        first_failure_time: Option<DateTime<Utc>>,
    ) -> bool {
        // 超过最大重试次数
        if attempt >= self.max_retries {
            return false;
        }
        
        // 检查错误是否可重试
        if !error.is_retriable() {
            return false;
        }
        
        // 检查是否超过最大重试持续时间
        if let (Some(max_duration), Some(first_time)) = (self.max_retry_duration, first_failure_time) {
            let now = Utc::now();
            if now - first_time > max_duration.to_std().unwrap() {
                return false;
            }
        }
        
        // 检查重试条件
        if self.retry_on.is_empty() {
            return true; // 没有指定条件，默认重试所有可重试错误
        }
        
        self.retry_on.iter().any(|condition| condition.matches(error))
    }
}

/// 错误条件
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ErrorCondition {
    /// 任何错误
    Any,
    /// 特定错误代码
    Code(String),
    /// 错误类别
    Category(ErrorCategory),
    /// 错误来源
    Source(ErrorSource),
}

impl ErrorCondition {
    /// 检查错误是否匹配条件
    pub fn matches(&self, error: &WorkflowError) -> bool {
        match self {
            ErrorCondition::Any => true,
            ErrorCondition::Code(code) => error.code() == code,
            ErrorCondition::Category(category) => error.category() == *category,
            ErrorCondition::Source(source) => error.source() == *source,
        }
    }
}
```

#### 3.3.2 错误处理器

```rust
/// 错误处理器
pub struct ErrorHandler {
    /// 重试管理器
    retry_manager: RetryManager,
    /// 补偿操作注册表
    compensation_registry: CompensationRegistry,
    /// 错误分类器
    error_classifier: ErrorClassifier,
}

impl ErrorHandler {
    /// 处理任务错误
    pub async fn handle_task_error(
        &self,
        task: &TaskDefinition,
        error: WorkflowError,
        attempt: u32,
        first_failure_time: Option<DateTime<Utc>>,
        context: &TaskContext,
    ) -> Result<ErrorHandlingAction, HandlingError> {
        // 1. 分类错误
        let error_class = self.error_classifier.classify(&error);
        log::info!("Classified error for task {}: {:?}", task.id, error_class);
        
        // 2. 检查是否应该重试
        if let Some(retry) = &task.retry_strategy {
            if retry.should_retry(&error, attempt, first_failure_time) {
                let delay = retry.next_delay(attempt);
                log::info!("Scheduling retry #{} for task {} after {:?}", 
                         attempt + 1, task.id, delay);
                
                return Ok(ErrorHandlingAction::Retry { 
                    delay, 
                    attempt: attempt + 1,
                    error: error.clone(),
                });
            }
        }
        
        // 3. 检查是否有补偿操作
        if let Some(compensation) = self.compensation_registry.get_compensation(task) {
            log::info!("Executing compensation for failed task {}", task.id);
            return Ok(ErrorHandlingAction::Compensate(compensation.clone()));
        }
        
        // 4. 如果没有补偿，检查是否有错误处理步骤
        if let Some(handler_id) = &task.error_handler {
            log::info!("Using error handler {} for task {}", handler_id, task.id);
            return Ok(ErrorHandlingAction::ExecuteHandler(handler_id.clone()));
        }
        
        // 5. 检查是否可以降级
        if self.can_degrade(task, &error) {
            log::info!("Degrading service for task {}", task.id);
            return Ok(ErrorHandlingAction::Degrade {
                fallback_result: task.default_result.clone(),
                error: error.clone(),
            });
        }
        
        // 6. 默认失败处理
        log::warn!("No recovery action available for task {}, failing", task.id);
        Ok(ErrorHandlingAction::Fail(error))
    }
    
    /// 检查是否可以降级服务
    fn can_degrade(&self, task: &TaskDefinition, error: &WorkflowError) -> bool {
        // 检查任务是否有默认结果配置
        if task.default_result.is_none() {
            return false;
        }
        
        // 检查任务是否允许降级
        if !task.allow_degraded_execution {
            return false;
        }
        
        // 检查错误类型是否适合降级
        match error {
            WorkflowError::Transient(_) => true, // 暂时性错误可以降级
            WorkflowError::System(sys_err) => sys_err.is_external(), // 外部系统错误可以降级
            _ => false, // 其他类型不降级
        }
    }
    
    /// 处理工作流错误
    pub async fn handle_workflow_error(
        &self,
        workflow: &WorkflowDefinition,
        error: WorkflowError,
        context: &WorkflowContext,
    ) -> Result<WorkflowHandlingAction, HandlingError> {
        // 根据工作流错误处理配置决定处理方式
        if let Some(config) = &workflow.error_handling_config {
            // 检查是否应该重试整个工作流
            if let Some(retry) = &config.retry_strategy {
                let attempt = context.get_attempt_count();
                let first_failure = context.get_first_failure_time();
                
                if retry.should_retry(&error, attempt, first_failure) {
                    let delay = retry.next_delay(attempt);
                    log::info!("Scheduling workflow retry #{} after {:?}", 
                             attempt + 1, delay);
                    
                    return Ok(WorkflowHandlingAction::RetryWorkflow { 
                        delay, 
                        attempt: attempt + 1,
                        error: error.clone(),
                    });
                }
            }
            
            // 检查是否有替代工作流
            if let Some(alt_workflow_id) = &config.fallback_workflow {
                log::info!("Using fallback workflow {} for failed workflow {}", 
                         alt_workflow_id, workflow.id);
                
                return Ok(WorkflowHandlingAction::UseFallbackWorkflow {
                    fallback_workflow_id: alt_workflow_id.clone(),
                    error: error.clone(),
                });
            }
        }
        
        // 默认失败处理
        Ok(WorkflowHandlingAction::FailWorkflow(error))
    }
}

/// 错误处理动作
pub enum ErrorHandlingAction {
    /// 重试任务
    Retry { 
        delay: Duration, 
        attempt: u32,
        error: WorkflowError,
    },
    /// 执行补偿操作
    Compensate(CompensationTask),
    /// 执行错误处理步骤
    ExecuteHandler(TaskId),
    /// 降级服务
    Degrade {
        fallback_result: Option<TaskResult>,
        error: WorkflowError,
    },
    /// 标记任务失败并传播错误
    Fail(WorkflowError),
}

/// 工作流错误处理动作
pub enum WorkflowHandlingAction {
    /// 重试整个工作流
    RetryWorkflow {
        delay: Duration,
        attempt: u32,
        error: WorkflowError,
    },
    /// 使用替代工作流
    UseFallbackWorkflow {
        fallback_workflow_id: String,
        error: WorkflowError,
    },
    /// 标记工作流失败
    FailWorkflow(WorkflowError),
}
```

#### 3.3.3 补偿事务

```rust
/// 补偿任务
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CompensationTask {
    /// 补偿ID
    pub id: String,
    /// 原始任务ID
    pub original_task_id: TaskId,
    /// 补偿操作
    pub action: CompensationAction,
    /// 补偿优先级
    pub priority: i32,
    /// 失败时的重试策略
    pub retry_strategy: Option<RetryStrategy>,
}

/// 补偿操作
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum CompensationAction {
    /// 撤销操作
    Undo {
        /// 撤销操作定义
        operation: String,
        /// 撤销参数
        parameters: HashMap<String, Value>,
    },
    /// 执行另一个任务
    ExecuteTask {
        /// 任务定义
        task_def: TaskDefinition,
    },
    /// 发送通知
    Notify {
        /// 通知类型
        notification_type: String,
        /// 接收者
        recipients: Vec<String>,
        /// 通知内容
        content: String,
    },
    /// 自定义补偿操作
    Custom {
        /// 操作类型
        action_type: String,
        /// 操作参数
        parameters: HashMap<String, Value>,
    },
}

/// 补偿操作注册表
pub struct CompensationRegistry {
    /// 补偿操作映射
    compensations: RwLock<HashMap<TaskId, CompensationTask>>,
}

impl CompensationRegistry {
    /// 创建新的补偿注册表
    pub fn new() -> Self {
        Self {
            compensations: RwLock::new(HashMap::new()),
        }
    }
    
    /// 注册补偿操作
    pub async fn register_compensation(
        &self,
        task_id: TaskId,
        compensation: CompensationTask,
    ) {
        let mut compensations = self.compensations.write().await;
        compensations.insert(task_id, compensation);
    }
    
    /// 获取任务的补偿操作
    pub async fn get_compensation(&self, task: &TaskDefinition) -> Option<CompensationTask> {
        let compensations = self.compensations.read().await;
        compensations.get(&task.id).cloned()
    }
    
    /// 执行补偿操作
    pub async fn execute_compensation(
        &self,
        compensation: &CompensationTask,
        context: &TaskContext,
    ) -> Result<(), CompensationError> {
        log::info!("Executing compensation task {} for original task {}", 
                 compensation.id, compensation.
                original_task_id);
                
                // 根据补偿操作类型执行不同的逻辑
                match &compensation.action {
                    CompensationAction::Undo { operation, parameters } => {
                        log::info!("Executing undo operation: {}", operation);
                        self.execute_undo_operation(operation, parameters, context).await?;
                    },
                    CompensationAction::ExecuteTask { task_def } => {
                        log::info!("Executing compensation task: {}", task_def.id);
                        
                        // 获取执行器
                        let executor = TaskExecutorRegistry::global()
                            .get_executor(&task_def.executor_type)
                            .ok_or_else(|| CompensationError::NoExecutorFound(task_def.executor_type.clone()))?;
                        
                        // 执行补偿任务
                        executor.execute(task_def, context).await?;
                    },
                    CompensationAction::Notify { notification_type, recipients, content } => {
                        log::info!("Sending notification: {}", notification_type);
                        
                        // 获取通知服务
                        let notifier = NotificationService::global();
                        
                        // 发送通知
                        notifier.send_notification(
                            notification_type,
                            recipients,
                            content,
                            context,
                        ).await?;
                    },
                    CompensationAction::Custom { action_type, parameters } => {
                        log::info!("Executing custom compensation: {}", action_type);
                        
                        // 获取自定义补偿处理器
                        let handler = CustomCompensationRegistry::global()
                            .get_handler(action_type)
                            .ok_or_else(|| CompensationError::NoHandlerFound(action_type.clone()))?;
                        
                        // 执行自定义补偿
                        handler.handle(parameters, context).await?;
                    },
                }
                
                Ok(())
            }
            
    /// 执行撤销操作
    async fn execute_undo_operation(
        &self,
        operation: &str,
        parameters: &HashMap<String, Value>,
        context: &TaskContext,
    ) -> Result<(), CompensationError> {
        // 根据操作类型执行不同的撤销逻辑
        match operation {
            "database_rollback" => {
                let transaction_id = parameters.get("transaction_id")
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| CompensationError::MissingParameter("transaction_id".to_string()))?;
                
                // 获取数据库服务
                let db_service = DatabaseService::global();
                
                // 执行回滚
                db_service.rollback_transaction(transaction_id).await
                    .map_err(|e| CompensationError::OperationFailed(format!("Failed to rollback: {}", e)))?;
            },
            "message_retraction" => {
                let message_id = parameters.get("message_id")
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| CompensationError::MissingParameter("message_id".to_string()))?;
                
                // 获取消息服务
                let message_service = MessageService::global();
                
                // 撤回消息
                message_service.retract_message(message_id).await
                    .map_err(|e| CompensationError::OperationFailed(format!("Failed to retract message: {}", e)))?;
            },
            "resource_release" => {
                let resource_id = parameters.get("resource_id")
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| CompensationError::MissingParameter("resource_id".to_string()))?;
                
                // 获取资源管理器
                let resource_manager = ResourceManager::global();
                
                // 释放资源
                resource_manager.release_resource(resource_id).await
                    .map_err(|e| CompensationError::OperationFailed(format!("Failed to release resource: {}", e)))?;
            },
            _ => {
                return Err(CompensationError::UnsupportedOperation(operation.to_string()));
            }
        }
        
        Ok(())
    }
}

/// 补偿错误
#[derive(Debug, thiserror::Error)]
pub enum CompensationError {
    #[error("Missing parameter: {0}")]
    MissingParameter(String),
    
    #[error("Unsupported operation: {0}")]
    UnsupportedOperation(String),
    
    #[error("Operation failed: {0}")]
    OperationFailed(String),
    
    #[error("No executor found for type: {0}")]
    NoExecutorFound(String),
    
    #[error("No handler found for type: {0}")]
    NoHandlerFound(String),
    
    #[error("Task execution error: {0}")]
    TaskExecutionError(#[from] TaskError),
    
    #[error("Notification error: {0}")]
    NotificationError(#[from] NotificationError),
}

/// 错误分类器
pub struct ErrorClassifier {
    /// 错误模式匹配规则
    patterns: Vec<ErrorPattern>,
    /// 默认错误类型
    default_category: ErrorCategory,
}

impl ErrorClassifier {
    /// 创建新的错误分类器
    pub fn new(default_category: ErrorCategory) -> Self {
        Self {
            patterns: Vec::new(),
            default_category,
        }
    }
    
    /// 添加错误模式匹配规则
    pub fn add_pattern(&mut self, pattern: ErrorPattern) {
        self.patterns.push(pattern);
    }
    
    /// 分类错误
    pub fn classify(&self, error: &WorkflowError) -> ErrorCategory {
        // 检查错误是否匹配任何模式
        for pattern in &self.patterns {
            if pattern.matches(error) {
                return pattern.category;
            }
        }
        
        // 使用默认分类
        self.default_category
    }
}

/// 错误模式
#[derive(Clone)]
pub struct ErrorPattern {
    /// 错误类别
    pub category: ErrorCategory,
    /// 匹配条件
    pub condition: ErrorPatternCondition,
}

impl ErrorPattern {
    /// 检查错误是否匹配模式
    pub fn matches(&self, error: &WorkflowError) -> bool {
        match &self.condition {
            ErrorPatternCondition::Code(code) => error.code() == code,
            ErrorPatternCondition::Message(pattern) => error.message().contains(pattern),
            ErrorPatternCondition::Source(source) => error.source() == *source,
            ErrorPatternCondition::Type(error_type) => match (error, error_type) {
                (WorkflowError::Transient(_), ErrorType::Transient) => true,
                (WorkflowError::Permanent(_), ErrorType::Permanent) => true,
                (WorkflowError::System(_), ErrorType::System) => true,
                (WorkflowError::Business(_), ErrorType::Business) => true,
                _ => false,
            },
            ErrorPatternCondition::Custom(predicate) => predicate(error),
        }
    }
}

/// 错误模式匹配条件
#[derive(Clone)]
pub enum ErrorPatternCondition {
    /// 匹配错误代码
    Code(String),
    /// 匹配错误消息
    Message(String),
    /// 匹配错误来源
    Source(ErrorSource),
    /// 匹配错误类型
    Type(ErrorType),
    /// 自定义匹配逻辑
    Custom(Arc<dyn Fn(&WorkflowError) -> bool + Send + Sync>),
}

/// 错误类型
#[derive(Clone, Copy, PartialEq, Eq)]
pub enum ErrorType {
    Transient,
    Permanent,
    System,
    Business,
}

/// 错误类别
#[derive(Clone, Copy, PartialEq, Eq)]
pub enum ErrorCategory {
    /// 连接错误
    Connection,
    /// 超时错误
    Timeout,
    /// 资源不足
    ResourceExhaustion,
    /// 权限错误
    Permission,
    /// 验证错误
    Validation,
    /// 业务规则冲突
    BusinessRuleViolation,
    /// 数据不一致
    DataInconsistency,
    /// 外部系统错误
    ExternalSystem,
    /// 内部错误
    Internal,
    /// 未知错误
    Unknown,
}

/// 错误来源
#[derive(Clone, Copy, PartialEq, Eq)]
pub enum ErrorSource {
    /// 网络来源
    Network,
    /// 数据库来源
    Database,
    /// 文件系统来源
    FileSystem,
    /// API来源
    Api,
    /// 用户来源
    User,
    /// 系统来源
    System,
    /// 未知来源
    Unknown,
}
```

### 3.4 流程监控与分析

工作流监控与分析系统负责跟踪工作流执行状态、收集性能指标，并提供分析功能。

#### 3.4.1 工作流监控

```rust
use std::collections::{HashMap, VecDeque};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};

/// 工作流监控
pub struct WorkflowMonitor {
    /// 活动工作流
    active_workflows: RwLock<HashMap<WorkflowId, WorkflowMonitoringInfo>>,
    /// 历史工作流（最近完成）
    recent_workflows: RwLock<VecDeque<WorkflowMonitoringInfo>>,
    /// 最大历史记录数量
    max_history_size: usize,
    /// 指标收集器
    metrics_collector: Arc<MetricsCollector>,
    /// 警报管理器
    alert_manager: Arc<AlertManager>,
    /// 事件处理器
    event_handler: Arc<EventHandler>,
}

impl WorkflowMonitor {
    /// 创建新的工作流监控
    pub fn new(
        max_history_size: usize,
        metrics_collector: Arc<MetricsCollector>,
        alert_manager: Arc<AlertManager>,
        event_handler: Arc<EventHandler>,
    ) -> Self {
        Self {
            active_workflows: RwLock::new(HashMap::new()),
            recent_workflows: RwLock::new(VecDeque::with_capacity(max_history_size)),
            max_history_size,
            metrics_collector,
            alert_manager,
            event_handler,
        }
    }
    
    /// 注册工作流开始
    pub async fn register_workflow_start(
        &self,
        workflow_id: WorkflowId,
        workflow_name: String,
        workflow_type: String,
        parameters: HashMap<String, Value>,
    ) {
        let start_time = Utc::now();
        let info = WorkflowMonitoringInfo {
            id: workflow_id.clone(),
            name: workflow_name,
            workflow_type,
            state: WorkflowState::Running,
            parameters,
            start_time,
            end_time: None,
            duration: None,
            tasks: RwLock::new(HashMap::new()),
            errors: RwLock::new(Vec::new()),
            metrics: RwLock::new(HashMap::new()),
            tags: RwLock::new(HashMap::new()),
        };
        
        // 记录活动工作流
        {
            let mut active = self.active_workflows.write().await;
            active.insert(workflow_id.clone(), info);
        }
        
        // 发布工作流启动事件
        let event = WorkflowEvent::Started {
            workflow_id: workflow_id.clone(),
            workflow_name: workflow_name.clone(),
            workflow_type: workflow_type.clone(),
            start_time,
        };
        
        self.event_handler.handle_event(event).await;
        
        // 记录工作流启动指标
        self.metrics_collector.record_workflow_started(workflow_id, workflow_type).await;
    }
    
    /// 更新工作流状态
    pub async fn update_workflow_state(
        &self,
        workflow_id: &WorkflowId,
        state: WorkflowState,
    ) -> Result<(), MonitoringError> {
        let mut active = self.active_workflows.write().await;
        
        if let Some(info) = active.get_mut(workflow_id) {
            info.state = state.clone();
            
            // 发布工作流状态变更事件
            let event = WorkflowEvent::StateChanged {
                workflow_id: workflow_id.clone(),
                workflow_name: info.name.clone(),
                previous_state: info.state.clone(), // 注意：这里应该是旧的状态
                new_state: state,
                timestamp: Utc::now(),
            };
            
            drop(active); // 释放锁，避免可能的死锁
            
            self.event_handler.handle_event(event).await;
            
            Ok(())
        } else {
            Err(MonitoringError::WorkflowNotFound(workflow_id.clone()))
        }
    }
    
    /// 注册任务开始
    pub async fn register_task_start(
        &self,
        workflow_id: &WorkflowId,
        task_id: TaskId,
        task_name: String,
        task_type: String,
    ) -> Result<(), MonitoringError> {
        let active = self.active_workflows.read().await;
        
        if let Some(info) = active.get(workflow_id) {
            let start_time = Utc::now();
            let task_info = TaskMonitoringInfo {
                id: task_id.clone(),
                name: task_name.clone(),
                task_type: task_type.clone(),
                state: TaskState::Running,
                start_time,
                end_time: None,
                duration: None,
                result: None,
                error: None,
                metrics: HashMap::new(),
                resource_usage: None,
            };
            
            // 更新任务信息
            {
                let mut tasks = info.tasks.write().await;
                tasks.insert(task_id.clone(), task_info);
            }
            
            // 发布任务开始事件
            let event = WorkflowEvent::TaskStarted {
                workflow_id: workflow_id.clone(),
                task_id: task_id.clone(),
                task_name,
                task_type: task_type.clone(),
                start_time,
            };
            
            drop(active); // 释放锁，避免可能的死锁
            
            self.event_handler.handle_event(event).await;
            
            // 记录任务启动指标
            self.metrics_collector.record_task_started(workflow_id, &task_id, &task_type).await;
            
            Ok(())
        } else {
            Err(MonitoringError::WorkflowNotFound(workflow_id.clone()))
        }
    }
    
    /// 注册任务完成
    pub async fn register_task_completion(
        &self,
        workflow_id: &WorkflowId,
        task_id: &TaskId,
        result: Option<TaskResult>,
        resource_usage: Option<ResourceUsage>,
    ) -> Result<(), MonitoringError> {
        let active = self.active_workflows.read().await;
        
        if let Some(info) = active.get(workflow_id) {
            let mut tasks = info.tasks.write().await;
            
            if let Some(task_info) = tasks.get_mut(task_id) {
                let end_time = Utc::now();
                let duration = end_time - task_info.start_time;
                
                // 更新任务信息
                task_info.state = TaskState::Completed;
                task_info.end_time = Some(end_time);
                task_info.duration = Some(duration);
                task_info.result = result.clone();
                task_info.resource_usage = resource_usage.clone();
                
                let task_name = task_info.name.clone();
                let task_type = task_info.task_type.clone();
                
                drop(tasks); // 释放锁
                drop(active); // 释放锁
                
                // 发布任务完成事件
                let event = WorkflowEvent::TaskCompleted {
                    workflow_id: workflow_id.clone(),
                    task_id: task_id.clone(),
                    task_name,
                    duration,
                    result: result.clone(),
                    resource_usage: resource_usage.clone(),
                };
                
                self.event_handler.handle_event(event).await;
                
                // 记录任务完成指标
                self.metrics_collector.record_task_completed(
                    workflow_id, 
                    task_id, 
                    &task_type,
                    duration,
                    resource_usage,
                ).await;
                
                Ok(())
            } else {
                Err(MonitoringError::TaskNotFound(task_id.clone()))
            }
        } else {
            Err(MonitoringError::WorkflowNotFound(workflow_id.clone()))
        }
    }
    
    /// 注册任务失败
    pub async fn register_task_failure(
        &self,
        workflow_id: &WorkflowId,
        task_id: &TaskId,
        error: TaskError,
        resource_usage: Option<ResourceUsage>,
    ) -> Result<(), MonitoringError> {
        let active = self.active_workflows.read().await;
        
        if let Some(info) = active.get(workflow_id) {
            let mut tasks = info.tasks.write().await;
            
            if let Some(task_info) = tasks.get_mut(task_id) {
                let end_time = Utc::now();
                let duration = end_time - task_info.start_time;
                
                // 更新任务信息
                task_info.state = TaskState::Failed;
                task_info.end_time = Some(end_time);
                task_info.duration = Some(duration);
                task_info.error = Some(error.clone());
                task_info.resource_usage = resource_usage.clone();
                
                let task_name = task_info.name.clone();
                
                // 记录工作流错误
                {
                    let mut errors = info.errors.write().await;
                    errors.push(WorkflowErrorInfo {
                        timestamp: end_time,
                        task_id: Some(task_id.clone()),
                        error: error.clone().into(),
                    });
                }
                
                drop(tasks); // 释放锁
                drop(active); // 释放锁
                
                // 发布任务失败事件
                let event = WorkflowEvent::TaskFailed {
                    workflow_id: workflow_id.clone(),
                    task_id: task_id.clone(),
                    task_name,
                    error: error.clone(),
                    duration,
                    resource_usage,
                };
                
                self.event_handler.handle_event(event).await;
                
                // 检查是否需要发出警报
                self.check_alert_conditions(workflow_id, task_id, &error).await;
                
                // 记录任务失败指标
                self.metrics_collector.record_task_failed(
                    workflow_id, 
                    task_id,
                    &error,
                    duration,
                ).await;
                
                Ok(())
            } else {
                Err(MonitoringError::TaskNotFound(task_id.clone()))
            }
        } else {
            Err(MonitoringError::WorkflowNotFound(workflow_id.clone()))
        }
    }
}
```

#### 3.4.2 性能分析

```rust
/// 性能分析器
pub struct PerformanceAnalyzer {
    /// 历史性能数据
    historical_data: Arc<PerformanceDatabase>,
    /// 预测模型
    prediction_models: HashMap<String, Box<dyn PredictionModel>>,
    /// 性能瓶颈分析器
    bottleneck_analyzer: BottleneckAnalyzer,
}

impl PerformanceAnalyzer {
    /// 创建新的性能分析器
    pub fn new(
        historical_data: Arc<PerformanceDatabase>,
        bottleneck_analyzer: BottleneckAnalyzer,
    ) -> Self {
        Self {
            historical_data,
            prediction_models: HashMap::new(),
            bottleneck_analyzer,
        }
    }
    
    /// 注册预测模型
    pub fn register_model(&mut self, workflow_type: String, model: Box<dyn PredictionModel>) {
        self.prediction_models.insert(workflow_type, model);
    }
    
    /// 分析工作流性能
    pub async fn analyze_workflow_performance(
        &self,
        workflow_id: &WorkflowId,
        monitor: &WorkflowMonitor,
    ) -> Result<PerformanceReport, AnalysisError> {
        // 获取工作流信息
        let workflow_info = monitor.get_workflow_info(workflow_id).await?;
        
        // 收集任务性能数据
        let task_performances = self.collect_task_performances(&workflow_info).await?;
        
        // 识别性能瓶颈
        let bottlenecks = self.bottleneck_analyzer.identify_bottlenecks(&task_performances);
        
        // 比较历史性能
        let historical_comparison = self.compare_with_historical_data(
            &workflow_info.workflow_type,
            &task_performances,
        ).await?;
        
        // 生成建议
        let recommendations = self.generate_recommendations(
            &workflow_info,
            &bottlenecks,
            &historical_comparison,
        );
        
        // 创建性能报告
        let report = PerformanceReport {
            workflow_id: workflow_id.clone(),
            workflow_type: workflow_info.workflow_type.clone(),
            execution_time: workflow_info.duration
                .map(|d| d.to_std().unwrap_or_default())
                .unwrap_or_default(),
            task_performances,
            bottlenecks,
            historical_comparison,
            recommendations,
            timestamp: Utc::now(),
        };
        
        Ok(report)
    }
    
    /// 收集任务性能数据
    async fn collect_task_performances(
        &self,
        workflow_info: &WorkflowMonitoringInfo,
    ) -> Result<Vec<TaskPerformance>, AnalysisError> {
        let tasks = workflow_info.tasks.read().await;
        let mut performances = Vec::new();
        
        for (task_id, task_info) in tasks.iter() {
            // 只处理已完成或失败的任务
            if task_info.state == TaskState::Completed || task_info.state == TaskState::Failed {
                if let (Some(duration), Some(end_time)) = (task_info.duration, task_info.end_time) {
                    let performance = TaskPerformance {
                        task_id: task_id.clone(),
                        task_name: task_info.name.clone(),
                        task_type: task_info.task_type.clone(),
                        execution_time: duration.to_std().unwrap_or_default(),
                        state: task_info.state.clone(),
                        completion_time: end_time,
                        resource_usage: task_info.resource_usage.clone(),
                    };
                    
                    performances.push(performance);
                }
            }
        }
        
        // 按照完成时间排序
        performances.sort_by(|a, b| a.completion_time.cmp(&b.completion_time));
        
        Ok(performances)
    }
    
    /// 与历史数据比较
    async fn compare_with_historical_data(
        &self,
        workflow_type: &str,
        current_performances: &[TaskPerformance],
    ) -> Result<HistoricalComparison, AnalysisError> {
        // 获取历史性能数据
        let historical_data = self.historical_data
            .get_workflow_performance_history(workflow_type, 10)
            .await?;
        
        if historical_data.is_empty() {
            return Ok(HistoricalComparison {
                average_improvement: 0.0,
                task_comparisons: HashMap::new(),
                trend: PerformanceTrend::Stable,
            });
        }
        
        // 计算每个任务的历史平均执行时间
        let mut historical_avg = HashMap::new();
        for history in &historical_data {
            for task in &history.task_performances {
                let entry = historical_avg
                    .entry(task.task_type.clone())
                    .or_insert_with(Vec::new);
                
                entry.push(task.execution_time);
            }
        }
        
        // 计算平均值
        let mut avg_task_times = HashMap::new();
        for (task_type, times) in historical_avg {
            let total = times.iter().sum::<Duration>();
            let avg = total / times.len() as u32;
            avg_task_times.insert(task_type, avg);
        }
        
        // 比较当前与历史
        let mut task_comparisons = HashMap::new();
        let mut total_improvement = 0.0;
        let mut comparison_count = 0;
        
        for task in current_performances {
            if let Some(historical_avg) = avg_task_times.get(&task.task_type) {
                let current = task.execution_time;
                
                if current.as_nanos() == 0 || historical_avg.as_nanos() == 0 {
                    continue;
                }
                
                // 计算改进百分比 (正值表示性能提升)
                let improvement = (historical_avg.as_secs_f64() - current.as_secs_f64()) / 
                                  historical_avg.as_secs_f64() * 100.0;
                
                task_comparisons.insert(task.task_id.clone(), TaskComparison {
                    task_name: task.task_name.clone(),
                    current_execution_time: current,
                    historical_average: *historical_avg,
                    improvement_percentage: improvement,
                });
                
                total_improvement += improvement;
                comparison_count += 1;
            }
        }
        
        let average_improvement = if comparison_count > 0 {
            total_improvement / comparison_count as f64
        } else {
            0.0
        };
        
        // 确定趋势
        let trend = if average_improvement > 5.0 {
            PerformanceTrend::Improving
        } else if average_improvement < -5.0 {
            PerformanceTrend::Degrading
        } else {
            PerformanceTrend::Stable
        };
        
        Ok(HistoricalComparison {
            average_improvement,
            task_comparisons,
            trend,
        })
    }
    
    /// 生成性能改进建议
    fn generate_recommendations(
        &self,
        workflow_info: &WorkflowMonitoringInfo,
        bottlenecks: &[PerformanceBottleneck],
        comparison: &HistoricalComparison,
    ) -> Vec<PerformanceRecommendation> {
        let mut recommendations = Vec::new();
        
        // 针对每个瓶颈生成建议
        for bottleneck in bottlenecks {
            match bottleneck.resource_type {
                ResourceType::Cpu => {
                    recommendations.push(PerformanceRecommendation {
                        target: RecommendationTarget::Task(bottleneck.task_id.clone()),
                        description: format!("优化任务 '{}' 的CPU密集型操作", bottleneck.task_name),
                        priority: RecommendationPriority::from_severity(bottleneck.severity),
                        expected_improvement: Some(30.0),
                        implementation_complexity: ImplementationComplexity::Medium,
                    });
                },
                ResourceType::Memory => {
                    recommendations.push(PerformanceRecommendation {
                        target: RecommendationTarget::Task(bottleneck.task_id.clone()),
                        description: format!("减少任务 '{}' 的内存使用量", bottleneck.task_name),
                        priority: RecommendationPriority::from_severity(bottleneck.severity),
                        expected_improvement: Some(25.0),
                        implementation_complexity: ImplementationComplexity::Medium,
                    });
                },
                ResourceType::Disk => {
                    recommendations.push(PerformanceRecommendation {
                        target: RecommendationTarget::Task(bottleneck.task_id.clone()),
                        description: format!("优化任务 '{}' 的磁盘I/O操作", bottleneck.task_name),
                        priority: RecommendationPriority::from_severity(bottleneck.severity),
                        expected_improvement: Some(20.0),
                        implementation_complexity: ImplementationComplexity::Medium,
                    });
                },
                ResourceType::Network => {
                    recommendations.push(PerformanceRecommendation {
                        target: RecommendationTarget::Task(bottleneck.task_id.clone()),
                        description: format!("减少任务 '{}' 的网络通信量或优化网络请求", bottleneck.task_name),
                        priority: RecommendationPriority::from_severity(bottleneck.severity),
                        expected_improvement: Some(35.0),
                        implementation_complexity: ImplementationComplexity::Medium,
                                            implementation_complexity: ImplementationComplexity::Hard,
                    });
                },
            }
        }
        
        // 如果性能明显下降，添加整体建议
        if comparison.average_improvement < -10.0 {
            recommendations.push(PerformanceRecommendation {
                target: RecommendationTarget::Workflow,
                description: "工作流整体性能下降，建议进行全面性能分析和优化".to_string(),
                priority: RecommendationPriority::High,
                expected_improvement: Some(15.0),
                implementation_complexity: ImplementationComplexity::High,
            });
        }
        
        // 并行化建议
        let tasks = workflow_info.tasks.read().unwrap();
        if tasks.len() > 3 {
            recommendations.push(PerformanceRecommendation {
                target: RecommendationTarget::Workflow,
                description: "考虑增加并行执行的任务数量，提高资源利用率".to_string(),
                priority: RecommendationPriority::Medium,
                expected_improvement: Some(20.0),
                implementation_complexity: ImplementationComplexity::Medium,
            });
        }
        
        // 资源分配建议
        recommendations.push(PerformanceRecommendation {
            target: RecommendationTarget::Workflow,
            description: "优化资源分配策略，根据任务优先级和资源需求动态调整资源".to_string(),
            priority: RecommendationPriority::Medium,
            expected_improvement: Some(15.0),
            implementation_complexity: ImplementationComplexity::Medium,
        });
        
        recommendations
    }
    
    /// 预测工作流执行性能
    pub async fn predict_workflow_performance(
        &self,
        workflow_type: &str,
        tasks: &[TaskDefinition],
        resource_pool: &ResourcePool,
    ) -> Result<PerformancePrediction, AnalysisError> {
        // 获取预测模型
        let model = self.prediction_models.get(workflow_type).ok_or_else(|| {
            AnalysisError::ModelNotFound(format!("No prediction model for workflow type: {}", workflow_type))
        })?;
        
        // 预测各任务执行时间
        let mut task_predictions = Vec::new();
        for task in tasks {
            let predicted_time = model.predict_task_execution_time(task);
            
            task_predictions.push(TaskPrediction {
                task_id: task.id.clone(),
                task_name: task.name.clone(),
                task_type: task.task_type.clone(),
                predicted_execution_time: predicted_time,
            });
        }
        
        // 预测总体执行时间
        let total_time = model.predict_workflow_execution_time(tasks, resource_pool);
        
        // 预测资源使用
        let resource_predictions = model.predict_resource_usage(tasks, resource_pool);
        
        Ok(PerformancePrediction {
            workflow_type: workflow_type.to_string(),
            total_execution_time: total_time,
            task_predictions,
            resource_predictions,
            confidence_level: model.get_confidence_level(),
            prediction_model: model.get_model_name(),
        })
    }
}
```

### 3.5 智能调度与优化系统

为了进一步提高工作流管理系统的效率和资源利用率，我们实现了智能调度与优化系统。它基于历史执行数据、资源状态和性能预测，动态调整执行计划。

#### 3.5.1 智能调度器

```rust
/// 智能调度器
pub struct IntelligentScheduler {
    /// 调度策略提供者
    strategy_provider: Box<dyn SchedulingStrategyProvider>,
    /// 资源监控器
    resource_monitor: Arc<ResourceMonitor>,
    /// 负载均衡器
    load_balancer: Arc<LoadBalancer>,
    /// 性能预测器
    performance_predictor: Arc<PerformancePredictor>,
    /// 工作流拆分器
    workflow_splitter: Arc<WorkflowSplitter>,
    /// 调度决策缓存
    decision_cache: RwLock<LruCache<WorkflowId, SchedulingPlan>>,
}

impl IntelligentScheduler {
    /// 创建新的智能调度器
    pub fn new(
        strategy_provider: Box<dyn SchedulingStrategyProvider>,
        resource_monitor: Arc<ResourceMonitor>,
        load_balancer: Arc<LoadBalancer>,
        performance_predictor: Arc<PerformancePredictor>,
        workflow_splitter: Arc<WorkflowSplitter>,
        cache_size: usize,
    ) -> Self {
        Self {
            strategy_provider,
            resource_monitor,
            load_balancer,
            performance_predictor,
            workflow_splitter,
            decision_cache: RwLock::new(LruCache::new(cache_size)),
        }
    }
    
    /// 为工作流生成调度计划
    pub async fn generate_scheduling_plan(
        &self,
        workflow: &WorkflowDefinition,
        context: &SchedulingContext,
    ) -> Result<SchedulingPlan, SchedulingError> {
        // 检查缓存
        {
            let cache = self.decision_cache.read().await;
            if let Some(plan) = cache.get(&workflow.id) {
                // 检查计划是否仍然有效
                if is_plan_still_valid(plan, context).await {
                    return Ok(plan.clone());
                }
            }
        }
        
        // 获取当前策略
        let strategy = self.strategy_provider.get_strategy(workflow, context).await?;
        
        // 收集当前资源状态
        let resources = self.resource_monitor.get_resource_state().await?;
        
        // 预测工作流性能需求
        let performance_prediction = self.performance_predictor
            .predict_workflow_performance(workflow, context)
            .await?;
        
        // 尝试拆分工作流
        let subworkflows = if context.enable_splitting {
            self.workflow_splitter.split_workflow(workflow, &performance_prediction).await?
        } else {
            vec![workflow.clone()]
        };
        
        // 为每个(子)工作流生成执行计划
        let mut execution_plans = Vec::new();
        
        for (index, subworkflow) in subworkflows.iter().enumerate() {
            let is_subworkflow = subworkflows.len() > 1;
            
            // 针对主工作流或子工作流创建执行计划
            let execution_plan = strategy.create_execution_plan(
                subworkflow,
                &resources,
                &performance_prediction,
                context,
            ).await?;
            
            // 将执行计划添加到列表
            execution_plans.push(ExecutionPlan {
                id: if is_subworkflow {
                    format!("{}-subflow-{}", workflow.id, index)
                } else {
                    workflow.id.clone()
                },
                workflow_id: subworkflow.id.clone(),
                steps: execution_plan.steps,
                target_executors: execution_plan.target_executors,
                resource_allocations: execution_plan.resource_allocations,
                estimated_execution_time: execution_plan.estimated_execution_time,
                is_subworkflow,
                parent_workflow_id: if is_subworkflow {
                    Some(workflow.id.clone())
                } else {
                    None
                },
            });
        }
        
        // 创建最终调度计划
        let scheduling_plan = SchedulingPlan {
            id: Uuid::new_v4().to_string(),
            workflow_id: workflow.id.clone(),
            execution_plans,
            scheduling_strategy: strategy.get_name().to_string(),
            creation_time: Utc::now(),
            valid_until: Utc::now() + Duration::minutes(15), // 计划有效期15分钟
            is_split: subworkflows.len() > 1,
        };
        
        // 将计划放入缓存
        {
            let mut cache = self.decision_cache.write().await;
            cache.put(workflow.id.clone(), scheduling_plan.clone());
        }
        
        Ok(scheduling_plan)
    }
    
    /// 执行调度计划
    pub async fn execute_scheduling_plan(
        &self,
        plan: &SchedulingPlan,
        context: &SchedulingContext,
    ) -> Result<Vec<WorkflowExecutionId>, SchedulingError> {
        let mut execution_ids = Vec::new();
        
        // 处理每个执行计划
        for execution_plan in &plan.execution_plans {
            // 使用负载均衡器选择最终执行节点
            let final_executors = self.load_balancer
                .balance_load(
                    &execution_plan.target_executors,
                    &execution_plan.resource_allocations,
                    context,
                )
                .await?;
            
            // 提交执行计划
            let execution_id = self.submit_execution_plan(
                execution_plan,
                &final_executors,
                context,
            ).await?;
            
            execution_ids.push(execution_id);
        }
        
        Ok(execution_ids)
    }
    
    /// 提交执行计划
    async fn submit_execution_plan(
        &self,
        plan: &ExecutionPlan,
        executors: &HashMap<StepId, ExecutorId>,
        context: &SchedulingContext,
    ) -> Result<WorkflowExecutionId, SchedulingError> {
        // 创建执行上下文
        let execution_context = ExecutionContext {
            workflow_id: plan.workflow_id.clone(),
            execution_id: Uuid::new_v4().to_string(),
            parent_execution_id: if plan.is_subworkflow {
                plan.parent_workflow_id.clone()
            } else {
                None
            },
            step_executors: executors.clone(),
            resource_allocations: plan.resource_allocations.clone(),
            created_at: Utc::now(),
            priority: context.priority,
            timeout: context.timeout,
            retry_policy: context.retry_policy.clone(),
        };
        
        // 发送到执行引擎
        let execution_engine = get_execution_engine();
        let execution_id = execution_engine.start_execution(
            &plan.workflow_id,
            &execution_context,
        ).await?;
        
        Ok(execution_id)
    }
    
    /// 重新调度失败的工作流执行
    pub async fn reschedule_failed_workflow(
        &self,
        failed_execution_id: &WorkflowExecutionId,
        context: &SchedulingContext,
    ) -> Result<WorkflowExecutionId, SchedulingError> {
        // 获取失败的执行信息
        let execution_engine = get_execution_engine();
        let failed_execution = execution_engine
            .get_execution_details(failed_execution_id)
            .await?;
        
        // 获取工作流定义
        let workflow_registry = get_workflow_registry();
        let workflow = workflow_registry
            .get_workflow(&failed_execution.workflow_id)
            .await?;
        
        // 分析失败原因
        let failure_analyzer = FailureAnalyzer::new();
        let failure_analysis = failure_analyzer
            .analyze_failure(failed_execution_id)
            .await?;
        
        // 创建新的调度上下文，包含失败信息
        let mut new_context = context.clone();
        new_context.failure_information = Some(failure_analysis);
        
        // 生成新的调度计划
        let plan = self.generate_scheduling_plan(&workflow, &new_context).await?;
        
        // 执行新的调度计划
        let execution_ids = self.execute_scheduling_plan(&plan, &new_context).await?;
        
        if execution_ids.is_empty() {
            return Err(SchedulingError::ExecutionFailed(
                "无法重新调度工作流，执行引擎未返回有效的执行ID".to_string(),
            ));
        }
        
        // 返回新的执行ID
        Ok(execution_ids[0].clone())
    }
}
```

#### 3.5.2 自适应优化器

```rust
/// 自适应优化器
pub struct AdaptiveOptimizer {
    /// 历史执行数据存储
    execution_history: Arc<ExecutionHistoryStorage>,
    /// 资源监控器
    resource_monitor: Arc<ResourceMonitor>,
    /// 性能分析器
    performance_analyzer: Arc<PerformanceAnalyzer>,
    /// 学习模型
    learning_model: Box<dyn AdaptiveLearningModel>,
    /// 优化规则引擎
    rule_engine: Arc<OptimizationRuleEngine>,
    /// 优化配置
    config: AdaptiveOptimizerConfig,
    /// 最后一次全局优化时间
    last_global_optimization: RwLock<DateTime<Utc>>,
}

impl AdaptiveOptimizer {
    /// 创建新的自适应优化器
    pub fn new(
        execution_history: Arc<ExecutionHistoryStorage>,
        resource_monitor: Arc<ResourceMonitor>,
        performance_analyzer: Arc<PerformanceAnalyzer>,
        learning_model: Box<dyn AdaptiveLearningModel>,
        rule_engine: Arc<OptimizationRuleEngine>,
        config: AdaptiveOptimizerConfig,
    ) -> Self {
        Self {
            execution_history,
            resource_monitor,
            performance_analyzer,
            learning_model,
            rule_engine,
            config,
            last_global_optimization: RwLock::new(Utc::now()),
        }
    }
    
    /// 优化特定工作流类型的执行
    pub async fn optimize_workflow_type(
        &self,
        workflow_type: &str,
    ) -> Result<OptimizationReport, OptimizationError> {
        // 收集历史执行数据
        let history = self.execution_history
            .get_workflow_type_history(workflow_type, self.config.history_window_size)
            .await?;
        
        if history.is_empty() {
            return Err(OptimizationError::InsufficientData(
                format!("工作流类型 {} 没有足够的历史数据进行优化", workflow_type)
            ));
        }
        
        // 分析执行数据
        let analysis = self.analyze_execution_data(&history).await?;
        
        // 学习最优参数
        let optimization_params = self.learning_model
            .learn_optimal_parameters(workflow_type, &history, &analysis)
            .await?;
        
        // 应用优化规则
        let rule_suggestions = self.rule_engine
            .apply_rules(workflow_type, &analysis, &optimization_params)
            .await?;
        
        // 生成优化建议
        let optimization_suggestions = self.generate_optimization_suggestions(
            workflow_type,
            &analysis,
            &optimization_params,
            &rule_suggestions,
        ).await?;
        
        // 应用自动优化
        let applied_optimizations = if self.config.enable_auto_optimization {
            self.apply_automatic_optimizations(
                workflow_type,
                &optimization_suggestions,
            ).await?
        } else {
            vec![]
        };
        
        // 生成报告
        let report = OptimizationReport {
            workflow_type: workflow_type.to_string(),
            timestamp: Utc::now(),
            analysis,
            suggestions: optimization_suggestions,
            applied_optimizations,
            new_parameters: optimization_params,
        };
        
        Ok(report)
    }
    
    /// 分析执行数据
    async fn analyze_execution_data(
        &self,
        history: &[WorkflowExecution],
    ) -> Result<ExecutionAnalysis, OptimizationError> {
        // 计算平均执行时间
        let total_execution_time: Duration = history.iter()
            .filter_map(|exec| {
                if let (Some(start), Some(end)) = (exec.start_time, exec.end_time) {
                    Some(end - start)
                } else {
                    None
                }
            })
            .sum();
        
        let avg_execution_time = if !history.is_empty() {
            total_execution_time / history.len() as u32
        } else {
            Duration::seconds(0)
        };
        
        // 计算成功率
        let success_count = history.iter()
            .filter(|exec| exec.status == WorkflowStatus::Completed)
            .count();
        
        let success_rate = if !history.is_empty() {
            success_count as f64 / history.len() as f64
        } else {
            0.0
        };
        
        // 识别瓶颈任务
        let mut task_stats: HashMap<String, Vec<TaskExecution>> = HashMap::new();
        
        for exec in history {
            for task in &exec.tasks {
                let entry = task_stats.entry(task.task_type.clone()).or_default();
                entry.push(task.clone());
            }
        }
        
        let mut bottleneck_tasks = Vec::new();
        
        for (task_type, tasks) in task_stats {
            let total_time: Duration = tasks.iter()
                .filter_map(|t| {
                    if let (Some(start), Some(end)) = (t.start_time, t.end_time) {
                        Some(end - start)
                    } else {
                        None
                    }
                })
                .sum();
            
            let avg_time = if !tasks.is_empty() {
                total_time / tasks.len() as u32
            } else {
                Duration::seconds(0)
            };
            
            let failure_count = tasks.iter()
                .filter(|t| t.status == TaskStatus::Failed)
                .count();
            
            let failure_rate = if !tasks.is_empty() {
                failure_count as f64 / tasks.len() as f64
            } else {
                0.0
            };
            
            // 检查是否是瓶颈
            let is_bottleneck = avg_time > avg_execution_time * 0.2 || failure_rate > 0.1;
            
            if is_bottleneck {
                bottleneck_tasks.push(BottleneckTask {
                    task_type,
                    avg_execution_time: avg_time.to_std().unwrap_or_default(),
                    failure_rate,
                    resource_usage: calculate_avg_resource_usage(&tasks),
                });
            }
        }
        
        // 资源利用率分析
        let resource_utilization = self.analyze_resource_utilization(history).await?;
        
        // 并行度分析
        let parallelism_analysis = self.analyze_parallelism(history).await?;
        
        Ok(ExecutionAnalysis {
            avg_execution_time: avg_execution_time.to_std().unwrap_or_default(),
            success_rate,
            bottleneck_tasks,
            resource_utilization,
            parallelism_analysis,
            execution_count: history.len(),
        })
    }
    
    /// 分析资源利用率
    async fn analyze_resource_utilization(
        &self,
        history: &[WorkflowExecution],
    ) -> Result<ResourceUtilizationAnalysis, OptimizationError> {
        // 收集所有资源使用数据
        let mut cpu_usage = Vec::new();
        let mut memory_usage = Vec::new();
        let mut disk_usage = Vec::new();
        let mut network_usage = Vec::new();
        
        for exec in history {
            for task in &exec.tasks {
                if let Some(resource) = &task.resource_usage {
                    if let Some(cpu) = resource.cpu_usage {
                        cpu_usage.push(cpu);
                    }
                    
                    if let Some(memory) = resource.memory_usage {
                        memory_usage.push(memory);
                    }
                    
                    if let Some(disk) = resource.disk_usage {
                        disk_usage.push(disk);
                    }
                    
                    if let Some(network) = resource.network_usage {
                        network_usage.push(network);
                    }
                }
            }
        }
        
        // 计算平均值和峰值
        let avg_cpu = if !cpu_usage.is_empty() {
            cpu_usage.iter().sum::<f64>() / cpu_usage.len() as f64
        } else {
            0.0
        };
        
        let peak_cpu = cpu_usage.iter().fold(0.0, |a, &b| a.max(b));
        
        let avg_memory = if !memory_usage.is_empty() {
            memory_usage.iter().sum::<f64>() / memory_usage.len() as f64
        } else {
            0.0
        };
        
        let peak_memory = memory_usage.iter().fold(0.0, |a, &b| a.max(b));
        
        let avg_disk = if !disk_usage.is_empty() {
            disk_usage.iter().sum::<f64>() / disk_usage.len() as f64
        } else {
            0.0
        };
        
        let peak_disk = disk_usage.iter().fold(0.0, |a, &b| a.max(b));
        
        let avg_network = if !network_usage.is_empty() {
            network_usage.iter().sum::<f64>() / network_usage.len() as f64
        } else {
            0.0
        };
        
        let peak_network = network_usage.iter().fold(0.0, |a, &b| a.max(b));
        
        Ok(ResourceUtilizationAnalysis {
            avg_cpu_usage: avg_cpu,
            peak_cpu_usage: peak_cpu,
            avg_memory_usage: avg_memory,
            peak_memory_usage: peak_memory,
            avg_disk_usage: avg_disk,
            peak_disk_usage: peak_disk,
            avg_network_usage: avg_network,
            peak_network_usage: peak_network,
        })
    }
    
    /// 分析并行度
    async fn analyze_parallelism(
        &self,
        history: &[WorkflowExecution],
    ) -> Result<ParallelismAnalysis, OptimizationError> {
        let mut max_observed_parallelism = 0;
        let mut avg_parallelism_sum = 0.0;
        let mut count = 0;
        
        for exec in history {
            if let Some(parallelism) = calc_workflow_parallelism(exec) {
                max_observed_parallelism = max_observed_parallelism.max(parallelism.max_parallelism);
                avg_parallelism_sum += parallelism.avg_parallelism;
                count += 1;
            }
        }
        
        let avg_parallelism = if count > 0 {
            avg_parallelism_sum / count as f64
        } else {
            0.0
        };
        
        Ok(ParallelismAnalysis {
            max_observed_parallelism,
            avg_parallelism,
            optimal_parallelism_estimate: estimate_optimal_parallelism(history),
        })
    }
    
    /// 生成优化建议
    async fn generate_optimization_suggestions(
        &self,
        workflow_type: &str,
        analysis: &ExecutionAnalysis,
        optimization_params: &OptimizationParameters,
        rule_suggestions: &[RuleSuggestion],
    ) -> Result<Vec<OptimizationSuggestion>, OptimizationError> {
        let mut suggestions = Vec::new();
        
        // 基于瓶颈任务的建议
        for bottleneck in &analysis.bottleneck_tasks {
            // 资源分配建议
            if bottleneck.resource_usage.cpu_percentage > 80.0 {
                suggestions.push(OptimizationSuggestion {
                    target: OptimizationTarget::TaskType(bottleneck.task_type.clone()),
                    suggestion_type: SuggestionType::ResourceAllocation,
                    description: format!("增加任务 {} 的CPU分配, 当前使用率为 {:.1}%", 
                                          bottleneck.task_type, bottleneck.resource_usage.cpu_percentage),
                    expected_improvement: 15.0,
                    confidence: 0.8,
                    automated: true,
                });
            }
            
            if bottleneck.resource_usage.memory_percentage > 85.0 {
                suggestions.push(OptimizationSuggestion {
                    target: OptimizationTarget::TaskType(bottleneck.task_type.clone()),
                    suggestion_type: SuggestionType::ResourceAllocation,
                    description: format!("增加任务 {} 的内存分配, 当前使用率为 {:.1}%", 
                                          bottleneck.task_type, bottleneck.resource_usage.memory_percentage),
                    expected_improvement: 12.0,
                    confidence: 0.8,
                    automated: true,
                });
            }
            
            // 失败率建议
            if bottleneck.failure_rate > 0.05 {
                suggestions.push(OptimizationSuggestion {
                    target: OptimizationTarget::TaskType(bottleneck.task_type.clone()),
                    suggestion_type: SuggestionType::Reliability,
                    description: format!("提高任务 {} 的可靠性, 当前失败率为 {:.1}%", 
                                          bottleneck.task_type, bottleneck.failure_rate * 100.0),
                    expected_improvement: 10.0,
                    confidence: 0.7,
                    automated: false,
                });
            }
        }
        
        // 并行度建议
        if let Some(optimal) = analysis.parallelism_analysis.optimal_parallelism_estimate {
            if optimal > analysis.parallelism_analysis.max_observed_parallelism {
                suggestions.push(OptimizationSuggestion {
                    target: OptimizationTarget::WorkflowType(workflow_type.to_string()),
                    suggestion_type: SuggestionType::Parallelism,
                    description: format!("增加工作流并行度从 {} 到 {}", 
                                          analysis.parallelism_analysis.max_observed_parallelism, optimal),
                    expected_improvement: 25.0,
                    confidence: 0.75,
                    automated: true,
                });
            }
        }
        
        // 资源池建议
        if analysis.resource_utilization.peak_cpu_usage > 90.0 {
            suggestions.push(OptimizationSuggestion {
                target: OptimizationTarget::ResourcePool,
                suggestion_type: SuggestionType::ResourceScaling,
                description: "增加CPU资源池容量, 当前峰值使用率超过90%".to_string(),
                expected_improvement: 20.0,
                confidence: 0.85,
                automated: true,
            });
        }
        
        if analysis.resource_utilization.peak_memory_usage > 90.0 {
            suggestions.push(OptimizationSuggestion {
                target: OptimizationTarget::ResourcePool,
                suggestion_type: SuggestionType::ResourceScaling,
                description: "增加内存资源池容量, 当前峰值使用率超过90%".to_string(),
                expected_improvement: 15.0,
                confidence: 0.85,
                automated: true,
            });
        }
        
        // 添加规则引擎建议
        for rule_suggestion in rule_suggestions {
            suggestions.push(OptimizationSuggestion {
                target: rule_suggestion.target.clone(),
                suggestion_type: rule_suggestion.suggestion_type.clone(),
                description: rule_suggestion.description.clone(),
                expected_improvement: rule_suggestion.expected_improvement,
                confidence: rule_suggestion.confidence,
                automated: rule_suggestion.can_automate,
            });
        }
        
        // 对建议进行排序，优先级高的在前
        suggestions.sort_by(|a, b| {
            let a_score = a.expected_improvement * a.confidence;
            let b_score = b.expected_improvement * b.confidence;
            b_score.partial_cmp(&a_score).unwrap_or(std::cmp::Ordering::Equal)
        });
        
        Ok(suggestions)
    }
    
    /// 应用自动优化
    async fn apply_automatic_optimizations(
        &self,
        workflow_type: &str,
        suggestions: &[OptimizationSuggestion],
    ) -> Result<Vec<AppliedOptimization>, OptimizationError> {
        let mut applied = Vec::new();
        
        // 获取可以自动应用的建议
        let auto_suggestions: Vec<&OptimizationSuggestion> = suggestions.iter()
            .filter(|s| s.automated && s.confidence >= self.config.min_confidence_for_auto_apply)
            .collect();
        
        // 应用资源分配优化
        for suggestion in &auto_suggestions {
            if suggestion.suggestion_type == SuggestionType::ResourceAllocation {
                if let OptimizationTarget::TaskType(task_type) = &suggestion.target {
                    // 获取当前分配
                    let resource_manager = get_resource_manager();
                    let current_allocation = resource_manager
                        .get_task_type_allocation(task_type)
                        .await?;
                    
                    // 计算新的分配
                    let new_allocation = calculate_new_allocation(&current_allocation);
                    
                // 计算新的分配
                let new_allocation = calculate_new_allocation(&current_allocation);
                
                // 应用新的资源分配
                let updated = resource_manager
                    .update_task_type_allocation(task_type, &new_allocation)
                    .await?;
                
                if updated {
                    applied.push(AppliedOptimization {
                        target: suggestion.target.clone(),
                        description: format!("为任务类型 {} 调整资源分配: {:?} -> {:?}", 
                                            task_type, current_allocation, new_allocation),
                        timestamp: Utc::now(),
                    });
                }
            }
        }
        
        // 应用并行度优化
        for suggestion in &auto_suggestions {
            if suggestion.suggestion_type == SuggestionType::Parallelism {
                if let OptimizationTarget::WorkflowType(wf_type) = &suggestion.target {
                    if wf_type == workflow_type {
                        // 获取当前配置
                        let workflow_config_service = get_workflow_config_service();
                        let current_config = workflow_config_service
                            .get_workflow_type_config(workflow_type)
                            .await?;
                        
                        // 创建新配置
                        let mut new_config = current_config.clone();
                        new_config.max_parallelism = analysis.parallelism_analysis
                            .optimal_parallelism_estimate
                            .unwrap_or(analysis.parallelism_analysis.max_observed_parallelism + 2);
                        
                        // 应用新配置
                        let updated = workflow_config_service
                            .update_workflow_type_config(workflow_type, &new_config)
                            .await?;
                        
                        if updated {
                            applied.push(AppliedOptimization {
                                target: suggestion.target.clone(),
                                description: format!("为工作流类型 {} 调整并行度: {} -> {}", 
                                                     workflow_type, current_config.max_parallelism, new_config.max_parallelism),
                                timestamp: Utc::now(),
                            });
                        }
                    }
                }
            }
        }
        
        // 应用资源池扩展优化
        for suggestion in &auto_suggestions {
            if suggestion.suggestion_type == SuggestionType::ResourceScaling {
                if let OptimizationTarget::ResourcePool = &suggestion.target {
                    // 获取资源池管理器
                    let resource_pool_manager = get_resource_pool_manager();
                    
                    // 获取当前资源池大小
                    let current_pool = resource_pool_manager.get_resource_pool().await?;
                    
                    // 计算新的资源池大小
                    let new_pool = calculate_new_resource_pool(&current_pool);
                    
                    // 应用新的资源池大小
                    let updated = resource_pool_manager
                        .scale_resource_pool(&new_pool)
                        .await?;
                    
                    if updated {
                        applied.push(AppliedOptimization {
                            target: suggestion.target.clone(),
                            description: format!("扩展资源池: CPU: {} -> {}, 内存: {} -> {}", 
                                                 current_pool.cpu_capacity, new_pool.cpu_capacity,
                                                 current_pool.memory_capacity, new_pool.memory_capacity),
                            timestamp: Utc::now(),
                        });
                    }
                }
            }
        }
        
        Ok(applied)
    }
}
```

#### 3.5.3 性能分析和优化工具

```rust
/// 性能分析和优化工具
pub struct PerformanceOptimizationTool {
    /// 历史性能数据存储
    history_storage: Arc<PerformanceHistoryStorage>,
    /// 性能模型
    model: Box<dyn PerformanceModel>,
    /// 优化引擎
    optimization_engine: Arc<OptimizationEngine>,
    /// 分析配置
    config: AnalysisConfig,
}

impl PerformanceOptimizationTool {
    /// 创建新的性能分析和优化工具
    pub fn new(
        history_storage: Arc<PerformanceHistoryStorage>,
        model: Box<dyn PerformanceModel>,
        optimization_engine: Arc<OptimizationEngine>,
        config: AnalysisConfig,
    ) -> Self {
        Self {
            history_storage,
            model,
            optimization_engine,
            config,
        }
    }
    
    /// 分析工作流类型的性能历史
    pub async fn analyze_workflow_type_history(
        &self,
        workflow_type: &str,
        time_range: TimeRange,
    ) -> Result<PerformanceAnalysisReport, AnalysisError> {
        // 获取历史数据
        let history = self.history_storage
            .get_workflow_type_history(workflow_type, time_range)
            .await?;
        
        if history.is_empty() {
            return Err(AnalysisError::InsufficientData(
                format!("没有足够的历史数据分析工作流类型: {}", workflow_type)
            ));
        }
        
        // 计算统计指标
        let stats = self.calculate_statistics(&history);
        
        // 识别性能趋势
        let trends = self.identify_trends(&history);
        
        // 执行热点分析
        let hotspots = self.analyze_hotspots(&history);
        
        // 生成性能报告
        Ok(PerformanceAnalysisReport {
            workflow_type: workflow_type.to_string(),
            time_range,
            execution_count: history.len(),
            statistics: stats,
            trends,
            hotspots,
            generated_at: Utc::now(),
        })
    }
    
    /// 比较两个工作流实例的性能
    pub async fn compare_workflow_instances(
        &self,
        instance_a_id: &str,
        instance_b_id: &str,
    ) -> Result<PerformanceComparisonReport, AnalysisError> {
        // 获取两个实例的执行详情
        let instance_a = self.history_storage
            .get_workflow_instance(instance_a_id)
            .await?;
        
        let instance_b = self.history_storage
            .get_workflow_instance(instance_b_id)
            .await?;
        
        // 确保两个实例是同一类型的工作流
        if instance_a.workflow_type != instance_b.workflow_type {
            return Err(AnalysisError::InvalidComparison(
                format!("无法比较不同类型的工作流实例: {} vs {}", 
                        instance_a.workflow_type, instance_b.workflow_type)
            ));
        }
        
        // 计算性能差异
        let mut step_comparisons = Vec::new();
        
        for step_a in &instance_a.steps {
            if let Some(step_b) = instance_b.steps.iter().find(|s| s.step_id == step_a.step_id) {
                let execution_time_diff = (step_b.execution_time.as_millis() as f64 - 
                                         step_a.execution_time.as_millis() as f64) / 
                                        step_a.execution_time.as_millis() as f64 * 100.0;
                
                let resource_usage_diff = calculate_resource_usage_diff(&step_a.resource_usage, &step_b.resource_usage);
                
                step_comparisons.push(StepPerformanceComparison {
                    step_id: step_a.step_id.clone(),
                    step_name: step_a.step_name.clone(),
                    execution_time_diff_percent: execution_time_diff,
                    resource_usage_diff: resource_usage_diff,
                });
            }
        }
        
        // 计算总体差异
        let total_execution_time_a = instance_a.end_time.unwrap_or_else(Utc::now) - instance_a.start_time;
        let total_execution_time_b = instance_b.end_time.unwrap_or_else(Utc::now) - instance_b.start_time;
        
        let total_time_diff = (total_execution_time_b.num_milliseconds() as f64 - 
                              total_execution_time_a.num_milliseconds() as f64) / 
                             total_execution_time_a.num_milliseconds() as f64 * 100.0;
        
        // 生成比较报告
        Ok(PerformanceComparisonReport {
            workflow_type: instance_a.workflow_type.clone(),
            instance_a_id: instance_a_id.to_string(),
            instance_b_id: instance_b_id.to_string(),
            total_execution_time_diff_percent: total_time_diff,
            step_comparisons,
            generated_at: Utc::now(),
        })
    }
    
    /// 生成性能优化建议
    pub async fn generate_optimization_recommendations(
        &self,
        workflow_type: &str,
        performance_data: &PerformanceAnalysisReport,
    ) -> Result<Vec<OptimizationRecommendation>, AnalysisError> {
        // 使用优化引擎生成建议
        let recommendations = self.optimization_engine
            .generate_recommendations(workflow_type, performance_data)
            .await?;
        
        Ok(recommendations)
    }
    
    /// 预测工作流性能
    pub async fn predict_workflow_performance(
        &self,
        workflow_definition: &WorkflowDefinition,
        execution_context: &ExecutionContext,
    ) -> Result<PerformancePrediction, AnalysisError> {
        // 使用性能模型进行预测
        let prediction = self.model
            .predict_performance(workflow_definition, execution_context)
            .await?;
        
        Ok(prediction)
    }
    
    /// 计算统计指标
    fn calculate_statistics(
        &self,
        history: &[WorkflowExecutionRecord],
    ) -> PerformanceStatistics {
        let mut execution_times = Vec::new();
        let mut success_count = 0;
        let mut failure_count = 0;
        let mut resource_usages = Vec::new();
        
        for record in history {
            // 计算执行时间
            if let (Some(start), Some(end)) = (record.start_time, record.end_time) {
                let duration = end - start;
                execution_times.push(duration);
            }
            
            // 统计成功/失败次数
            match record.status {
                WorkflowStatus::Completed => success_count += 1,
                WorkflowStatus::Failed => failure_count += 1,
                _ => {}
            }
            
            // 收集资源使用数据
            if let Some(usage) = &record.resource_usage {
                resource_usages.push(usage.clone());
            }
        }
        
        // 计算执行时间统计
        let avg_execution_time = if !execution_times.is_empty() {
            execution_times.iter().sum::<Duration>() / execution_times.len() as u32
        } else {
            Duration::seconds(0)
        };
        
        execution_times.sort();
        let median_execution_time = if !execution_times.is_empty() {
            execution_times[execution_times.len() / 2]
        } else {
            Duration::seconds(0)
        };
        
        let min_execution_time = execution_times.first().cloned().unwrap_or_else(|| Duration::seconds(0));
        let max_execution_time = execution_times.last().cloned().unwrap_or_else(|| Duration::seconds(0));
        
        // 计算变异系数
        let mean_millis = avg_execution_time.num_milliseconds() as f64;
        let variance = execution_times.iter()
            .map(|t| {
                let diff = t.num_milliseconds() as f64 - mean_millis;
                diff * diff
            })
            .sum::<f64>() / execution_times.len() as f64;
        
        let std_dev = variance.sqrt();
        let coefficient_of_variation = if mean_millis > 0.0 {
            std_dev / mean_millis
        } else {
            0.0
        };
        
        // 计算资源使用统计
        let avg_cpu_usage = calculate_avg_resource_value(&resource_usages, |u| u.cpu_usage);
        let avg_memory_usage = calculate_avg_resource_value(&resource_usages, |u| u.memory_usage);
        let avg_disk_usage = calculate_avg_resource_value(&resource_usages, |u| u.disk_usage);
        let avg_network_usage = calculate_avg_resource_value(&resource_usages, |u| u.network_usage);
        
        PerformanceStatistics {
            avg_execution_time: avg_execution_time.to_std().unwrap_or_default(),
            median_execution_time: median_execution_time.to_std().unwrap_or_default(),
            min_execution_time: min_execution_time.to_std().unwrap_or_default(),
            max_execution_time: max_execution_time.to_std().unwrap_or_default(),
            success_rate: if history.len() > 0 {
                success_count as f64 / history.len() as f64
            } else {
                0.0
            },
            failure_rate: if history.len() > 0 {
                failure_count as f64 / history.len() as f64
            } else {
                0.0
            },
            coefficient_of_variation,
            avg_cpu_usage,
            avg_memory_usage,
            avg_disk_usage,
            avg_network_usage,
        }
    }
    
    /// 识别性能趋势
    fn identify_trends(
        &self,
        history: &[WorkflowExecutionRecord],
    ) -> Vec<PerformanceTrend> {
        let mut trends = Vec::new();
        
        // 确保历史记录按时间排序
        let mut sorted_history = history.to_vec();
        sorted_history.sort_by_key(|r| r.start_time);
        
        if sorted_history.len() < self.config.min_samples_for_trend {
            return trends;
        }
        
        // 提取时间序列数据
        let execution_times: Vec<(DateTime<Utc>, Duration)> = sorted_history.iter()
            .filter_map(|r| {
                if let (Some(start), Some(end)) = (r.start_time, r.end_time) {
                    Some((start, end - start))
                } else {
                    None
                }
            })
            .collect();
        
        if execution_times.len() < self.config.min_samples_for_trend {
            return trends;
        }
        
        // 计算执行时间趋势
        let trend = calculate_time_series_trend(&execution_times);
        
        if trend.abs() > self.config.trend_threshold {
            trends.push(PerformanceTrend {
                metric: "execution_time".to_string(),
                trend_coefficient: trend,
                description: if trend > 0.0 {
                    format!("执行时间呈上升趋势，系数为 {:.2}", trend)
                } else {
                    format!("执行时间呈下降趋势，系数为 {:.2}", trend)
                },
                severity: if trend > 0.0 {
                    TrendSeverity::Negative
                } else {
                    TrendSeverity::Positive
                },
            });
        }
        
        // 计算成功率趋势
        let success_rate_series: Vec<(DateTime<Utc>, f64)> = calculate_moving_success_rate(&sorted_history, 10);
        
        if success_rate_series.len() >= self.config.min_samples_for_trend {
            let success_trend = calculate_rate_trend(&success_rate_series);
            
            if success_trend.abs() > self.config.trend_threshold {
                trends.push(PerformanceTrend {
                    metric: "success_rate".to_string(),
                    trend_coefficient: success_trend,
                    description: if success_trend > 0.0 {
                        format!("成功率呈上升趋势，系数为 {:.2}", success_trend)
                    } else {
                        format!("成功率呈下降趋势，系数为 {:.2}", success_trend)
                    },
                    severity: if success_trend > 0.0 {
                        TrendSeverity::Positive
                    } else {
                        TrendSeverity::Negative
                    },
                });
            }
        }
        
        // 计算资源使用趋势 (CPU)
        let cpu_usage_series: Vec<(DateTime<Utc>, f64)> = sorted_history.iter()
            .filter_map(|r| {
                if let Some(usage) = &r.resource_usage {
                    if let Some(cpu) = usage.cpu_usage {
                        return Some((r.start_time, cpu));
                    }
                }
                None
            })
            .collect();
        
        if cpu_usage_series.len() >= self.config.min_samples_for_trend {
            let cpu_trend = calculate_rate_trend(&cpu_usage_series);
            
            if cpu_trend.abs() > self.config.trend_threshold {
                trends.push(PerformanceTrend {
                    metric: "cpu_usage".to_string(),
                    trend_coefficient: cpu_trend,
                    description: if cpu_trend > 0.0 {
                        format!("CPU使用率呈上升趋势，系数为 {:.2}", cpu_trend)
                    } else {
                        format!("CPU使用率呈下降趋势，系数为 {:.2}", cpu_trend)
                    },
                    severity: if cpu_trend > 0.0 {
                        TrendSeverity::Negative
                    } else {
                        TrendSeverity::Positive
                    },
                });
            }
        }
        
        trends
    }
    
    /// 执行热点分析
    fn analyze_hotspots(
        &self,
        history: &[WorkflowExecutionRecord],
    ) -> Vec<PerformanceHotspot> {
        let mut hotspots = Vec::new();
        
        // 收集所有步骤的执行时间
        let mut step_times: HashMap<String, Vec<Duration>> = HashMap::new();
        let mut step_names: HashMap<String, String> = HashMap::new();
        
        for record in history {
            for step in &record.steps {
                let entry = step_times.entry(step.step_id.clone()).or_default();
                entry.push(step.execution_time);
                
                step_names.insert(step.step_id.clone(), step.step_name.clone());
            }
        }
        
        // 计算每个步骤的平均执行时间
        let mut step_avg_times: Vec<(String, Duration)> = step_times.iter()
            .map(|(step_id, times)| {
                let avg_time = if !times.is_empty() {
                    times.iter().sum::<Duration>() / times.len() as u32
                } else {
                    Duration::seconds(0)
                };
                
                (step_id.clone(), avg_time)
            })
            .collect();
        
        // 按平均执行时间降序排序
        step_avg_times.sort_by(|a, b| b.1.cmp(&a.1));
        
        // 识别占总执行时间较大比例的步骤
        let total_avg_step_time: Duration = step_avg_times.iter()
            .map(|(_, time)| *time)
            .sum();
        
        for (step_id, avg_time) in step_avg_times {
            // 如果步骤执行时间占总时间的10%以上，认为是热点
            if total_avg_step_time.num_milliseconds() > 0 &&
               (avg_time.num_milliseconds() as f64 / total_avg_step_time.num_milliseconds() as f64) >= 0.1 {
                
                // 获取步骤的失败率
                let failure_rate = calculate_step_failure_rate(history, &step_id);
                
                // 获取步骤的资源使用情况
                let resource_usage = calculate_step_avg_resource_usage(history, &step_id);
                
                hotspots.push(PerformanceHotspot {
                    step_id: step_id.clone(),
                    step_name: step_names.get(&step_id).cloned().unwrap_or_default(),
                    avg_execution_time: avg_time.to_std().unwrap_or_default(),
                    percentage_of_total_time: (avg_time.num_milliseconds() as f64 / 
                                               total_avg_step_time.num_milliseconds() as f64) * 100.0,
                    failure_rate,
                    resource_usage,
                });
            }
        }
        
        hotspots
    }
}
```

### 3.6 实现高可靠性和故障恢复机制

为确保工作流执行的可靠性和故障恢复能力，我们实现了以下机制。

#### 3.6.1 故障检测和恢复控制器

```rust
/// 故障检测和恢复控制器
pub struct FaultRecoveryController {
    /// 心跳监控服务
    heartbeat_monitor: Arc<HeartbeatMonitor>,
    /// 故障检测器
    fault_detector: Arc<FaultDetector>,
    /// 恢复策略提供者
    recovery_strategy_provider: Box<dyn RecoveryStrategyProvider>,
    /// 状态存储
    state_storage: Arc<StateStorage>,
    /// 故障历史记录器
    fault_history: Arc<FaultHistoryRecorder>,
    /// 检测配置
    detection_config: FaultDetectionConfig,
}

impl FaultRecoveryController {
    /// 创建新的故障恢复控制器
    pub fn new(
        heartbeat_monitor: Arc<HeartbeatMonitor>,
        fault_detector: Arc<FaultDetector>,
        recovery_strategy_provider: Box<dyn RecoveryStrategyProvider>,
        state_storage: Arc<StateStorage>,
        fault_history: Arc<FaultHistoryRecorder>,
        detection_config: FaultDetectionConfig,
    ) -> Self {
        Self {
            heartbeat_monitor,
            fault_detector,
            recovery_strategy_provider,
            state_storage,
            fault_history,
            detection_config,
        }
    }
    
    /// 启动故障恢复控制器
    pub async fn start(&self, shutdown: mpsc::Receiver<()>) -> Result<(), ControllerError> {
        let mut detection_interval = tokio::time::interval(
            Duration::from_millis(self.detection_config.detection_interval_ms)
        );
        
        let mut shutdown_rx = shutdown;
        
        loop {
            tokio::select! {
                _ = detection_interval.tick() => {
                    // 检测故障
                    if let Err(e) = self.detect_and_recover_faults().await {
                        log::error!("故障检测和恢复过程中发生错误: {:?}", e);
                    }
                }
                _ = shutdown_rx.recv() => {
                    log::info!("故障恢复控制器收到关闭信号");
                    break;
                }
            }
        }
        
        Ok(())
    }
    
    /// 检测并恢复故障
    async fn detect_and_recover_faults(&self) -> Result<(), ControllerError> {
        // 检查节点故障
        let node_faults = self.detect_node_faults().await?;
        
        for fault in &node_faults {
            let strategy = self.recovery_strategy_provider
                .get_node_recovery_strategy(fault)
                .await?;
            
            // 应用恢复策略
            let recovery_result = self.apply_node_recovery_strategy(fault, &strategy).await;
            
            // 记录恢复结果
            self.record_recovery_result(fault, &strategy, &recovery_result).await?;
        }
        
        // 检查工作流执行故障
        let workflow_faults = self.detect_workflow_faults().await?;
        
        for fault in &workflow_faults {
            let strategy = self.recovery_strategy_provider
                .get_workflow_recovery_strategy(fault)
                .await?;
            
            // 应用恢复策略
            let recovery_result = self.apply_workflow_recovery_strategy(fault, &strategy).await;
            
            // 记录恢复结果
            self.record_recovery_result(fault, &strategy, &recovery_result).await?;
        }
        
        Ok(())
    }
    
    /// 检测节点故障
    async fn detect_node_faults(&self) -> Result<Vec<NodeFault>, ControllerError> {
        // 获取所有节点的最新心跳状态
        let heartbeat_statuses = self.heartbeat_monitor.get_all_node_statuses().await?;
        
        // 检测故障
        let node_faults = self.fault_detector
            .detect_node_faults(&heartbeat_statuses, self.detection_config.node_failure_threshold)
            .await?;
        
        Ok(node_faults)
    }
    
    /// 检测工作流执行故障
    async fn detect_workflow_faults(&self) -> Result<Vec<WorkflowFault>, ControllerError> {
        // 获取所有活跃执行的状态
        let active_executions = self.state_storage.get_active_executions().await?;
        
        // 检测故障
        let workflow_faults = self.fault_detector
            .detect_workflow_faults(
                &active_executions, 
                self.detection_config.workflow_timeout,
                self.detection_config.step_timeout,
            )
            .await?;
        
        Ok(workflow_faults)
    }
    
    /// 应用节点恢复策略
    async fn apply_node_recovery_strategy(
        &self,
        fault: &NodeFault,
        strategy: &NodeRecoveryStrategy,
    ) -> RecoveryResult {
        log::info!("应用节点恢复策略: 节点={}, 策略={:?}", fault.node_id, strategy.strategy_type);
        
        let start_time = Utc::now();
        
        let result = match &strategy.strategy_type {
            NodeRecoveryStrategyType::Restart => {
                // 重启节点
                self.restart_node(&fault.node_id).await
            }
            NodeRecoveryStrategyType::Replace => {
                // 替换节点
                self.replace_node(&fault.node_id).await
            }
            NodeRecoveryStrategyType::Exclude => {
                // 从集群中排除节点
                self.exclude_node(&fault.node_id).await
            }
            NodeRecoveryStrategyType::Rebalance => {
                // 重新平衡负载
                self.rebalance_workload(&fault.node_id).await
            }
        };
        
        let end_time = Utc::now();
        let recovery_time = end_time - start_time;
        
        match result {
            Ok(_) => RecoveryResult {
                fault_id: fault.fault_id.clone(),
                strategy_applied: strategy.strategy_type.to_string(),
                success: true,
                recovery_time: recovery_time.to_std().unwrap_or_default(),
                error_message: None,
                recovery_details: Some(json!({
                    "node_id": fault.node_id,
                    "fault_type": format!("{:?}", fault.fault_type),
                    "recovery_timestamp": end_time,
                })),
            },
            Err(e) => RecoveryResult {
                fault_id: fault.fault_id.clone(),
                strategy_applied: strategy.strategy_type.to_string(),
                success: false,
                recovery_time: recovery_time.to_std().unwrap_or_default(),
                error_message: Some(e.to_string()),
                recovery_details: Some(json!({
                    "node_id": fault.node_id,
                    "fault_type": format!("{:?}", fault.fault_type),
                    "error": e.to_string(),
                })),
            }
        }
    }
    
    /// 重启节点
    async fn restart_node(&self, node_id: &str) -> Result<(), ControllerError> {
        // 实现节点重启逻辑
        log::info!("正在重启节点: {}", node_id);
        
        // 获取节点管理器
        let node_manager = get_node_manager();
        
        // 重启节点
        node_manager.restart_node(node_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("重启节点失败: {}", e)))
    }
    
    /// 替换节点
    async fn replace_node(&self, node_id: &str) -> Result<(), ControllerError> {
        // 实现节点替换逻辑
        log::info!("正在替换节点: {}", node_id);
        
        // 获取节点管理器
        let node_manager = get_node_manager();
        
        // 获取集群管理器
        let cluster_manager = get_cluster_manager();
        
        // 请求分配新节点
        let new_node_id = cluster_manager.provision_new_node().await
            .map_err(|e| ControllerError::RecoveryFailed(format!("分配新节点失败: {}", e)))?;
        
        // 迁移工作负载
        node_manager.migrate_workloads(node_id, &new_node_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("迁移工作负载失败: {}", e)))?;
        
        // 从集群中移除故障节点
        cluster_manager.remove_node(node_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("移除故障节点失败: {}", e)))
    }
    
    /// 从集群中排除节点
    async fn exclude_node(&self, node_id: &str) -> Result<(), ControllerError> {
        // 实现节点排除逻辑
        log::info!("正在从集群中排除节点: {}", node_id);
        
        // 获取集群管理器
        let cluster_manager = get_cluster_manager();
        
        // 将节点标记为排除状态
        cluster_manager.mark_node_excluded(node_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("排除节点失败: {}", e)))
    }
    
    /// 重新平衡负载
    async fn rebalance_workload(&self, node_id: &str) -> Result<(), ControllerError> {
        // 实现负载重平衡逻辑
        log::info!("正在为节点重新平衡负载: {}", node_id);
        
        // 获取负载均衡器
        let load_balancer = get_load_balancer();
        
        // 重新平衡节点的负载
        load_balancer.rebalance_node_workload(node_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("重新平衡负载失败: {}", e)))
    }
    
    /// 应用工作流恢复策略
    async fn apply_workflow_recovery_strategy(
        &self,
        fault: &WorkflowFault,
        strategy: &WorkflowRecoveryStrategy,
    ) -> RecoveryResult {
        log::info!("应用工作流恢复策略: 工作流={}, 策略={:?}", 
                  fault.workflow_id, strategy.strategy_type);
        
        let start_time = Utc::now();
        
        let result = match &strategy.strategy_type {
            WorkflowRecoveryStrategyType::Retry => {
                // 重试工作流
                self.retry_workflow(&fault.workflow_id, strategy.max_retries).await
            }
            WorkflowRecoveryStrategyType::Restart => {
                // 重启工作流
                self.restart_workflow(&fault.workflow_id).await
            }
            WorkflowRecoveryStrategyType::Resume => {
                // 从故障点恢复工作流
                self.resume_workflow_from_failure(&fault.workflow_id, &fault.failure_point).await
            }
            WorkflowRecoveryStrategyType::Compensate => {
                // 执行补偿操作
                self.compensate_workflow(&fault.workflow_id).await
            }
        };
        
        let end_time = Utc::now();
        let recovery_time = end_time - start_time;
        
        match result {
            Ok(_) => RecoveryResult {
                fault_id: fault.fault_id.clone(),
                strategy_applied: strategy.strategy_type.to_string(),
                success: true,
                recovery_time: recovery_time.to_std().unwrap_or_default(),
                error_message: None,
                recovery_details: Some(json!({
                    "workflow_id": fault.workflow_id,
                    "fault_type": format!("{:?}", fault.fault_type),
                    "recovery_timestamp": end_time,
                })),
            },
            Err(e) => RecoveryResult {
                fault_id: fault.fault_id.clone(),
                strategy_applied: strategy.strategy_type.to_string(),
                success: false,
                recovery_time: recovery_time.to_std().unwrap_or_default(),
                error_message: Some(e.to_string()),
                recovery_details: Some(json!({
                    "workflow_id": fault.workflow_id,
                    "fault_type": format!("{:?}", fault.fault_type),
                    "error": e.to_string(),
                })),
            }
        }
    }
    
    /// 重试工作流
    async fn retry_workflow(&self, workflow_id: &str, max_retries: u32) -> Result<(), ControllerError> {
        // 实现工作流重试逻辑
        log::info!("正在重试工作流: {}, 最大重试次数: {}", workflow_id, max_retries);
        
        // 获取工作流执行器
        let workflow_executor = get_workflow_executor();
        
        // 重试工作流
        workflow_executor.retry_workflow(workflow_id, max_retries).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("重试工作流失败: {}", e)))
    }
    
    /// 重启工作流
    async fn restart_workflow(&self, workflow_id: &str) -> Result<(), ControllerError> {
        // 实现工作流重启逻辑
        log::info!("正在重启工作流: {}", workflow_id);
        
        // 获取工作流执行器
        let workflow_executor = get_workflow_executor();
        
        // 停止当前执行
        workflow_executor.stop_workflow(workflow_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("停止工作流失败: {}", e)))?;
        
        // 重新启动工作流
        workflow_executor.start_workflow(workflow_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("重启工作流失败: {}", e)))
    }
    
    /// 从故障点恢复工作流
    async fn resume_workflow_from_failure(
        &self, 
        workflow_id: &str,
        failure_point: &FailurePoint,
    ) -> Result<(), ControllerError> {
        // 实现从故障点恢复工作流的逻辑
        log::info!("正在从故障点恢复工作流: {}, 故障点: {:?}", workflow_id, failure_point);
        
        // 获取工作流执行器
        let workflow_executor = get_workflow_executor();
        
        // 从故障点恢复工作流
        workflow_executor.resume_workflow_from_point(workflow_id, &failure_point.step_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("从故障点恢复工作流失败: {}", e)))
    }
    
    /// 执行补偿操作
    async fn compensate_workflow(&self, workflow_id: &str) -> Result<(), ControllerError> {
        // 实现工作流补偿逻辑
        log::info!("正在为工作流执行补偿操作: {}", workflow_id);
        
        // 获取工作流执行器
        let workflow_executor = get_workflow_executor();
        
        // 执行补偿操作
        workflow_executor.compensate_workflow(workflow_id).await
            .map_err(|e| ControllerError::RecoveryFailed(format!("执行补偿操作失败: {}", e)))
    }
    
    /// 记录恢复结果
    async fn record_recovery_result<T>(
        &self,
        fault: &T,
        strategy: &impl ToString,
        result: &RecoveryResult,
    ) -> Result<(), ControllerError> 
    where
        T: Serialize + HasFaultId,
    {
        // 记录故障历史
        self.fault_history.record_recovery_attempt(
            &fault.get_fault_id(),
            strategy.to_string(),
            result.clone(),
        ).await.map_err(|e| ControllerError::HistoryRecordingFailed(e.to_string()))
    }
}

/// 检查是否有故障ID
trait HasFaultId {
    fn get_fault_id(&self) -> String;
}

impl HasFaultId for NodeFault {
    fn get_fault_id(&self) -> String {
        self.fault_id.clone()
    }
}

impl HasFaultId for WorkflowFault {
    fn get_fault_id(&self) -> String {
        self.fault_id.clone()
    }
}
```

#### 3.6.2 工作流快照和状态恢复

```rust
/// 工作流状态快照提供者
pub struct WorkflowSnapshotProvider {
    /// 状态存储
    state_storage: Arc<StateStorage>,
    /// 快照策略
    snapshot_policy: SnapshotPolicy,
    /// 快照压缩器
    compressor: Option<Box<dyn SnapshotCompressor>>,
    /// 快照加密器
    encryptor: Option<Box<dyn SnapshotEncryptor>>,
}

impl WorkflowSnapshotProvider {
    /// 创建新的工作流快照提供者
    pub fn new(
        state_storage: Arc<StateStorage>,
        snapshot_policy: SnapshotPolicy,
        compressor: Option<Box<dyn SnapshotCompressor>>,
        encryptor: Option<Box<dyn SnapshotEncryptor>>,
    ) -> Self {
        Self {
            state_storage,
            snapshot_policy,
            compressor,
            encryptor,
        }
    }
    
    /// 为工作流创建快照
    pub async fn create_snapshot(
        &self,
        workflow_id: &str,
        execution_id: &str,
    ) -> Result<SnapshotId, SnapshotError> {
        // 检查是否需要创建快照
        if !self.should_create_snapshot(workflow_id, execution_id).await? {
            return Err(SnapshotError::SnapshotNotNeeded);
        }
        
        // 获取工作流状态
        let workflow_state = self.state_storage.get_workflow_state(workflow_id, execution_id).await
            .map_err(|e| SnapshotError::StateRetrievalFailed(e.to_string()))?;
        
        // 序列化状态
        let serialized_state = serde_json::to_vec(&workflow_state)
            .map_err(|e| SnapshotError::SerializationFailed(e.to_string()))?;
        
        // 压缩状态(如果配置了压缩器)
        let compressed_state = if let Some(compressor) = &self.compressor {
            compressor.compress(&serialized_state)
                .map_err(|e| SnapshotError::CompressionFailed(e.to_string()))?
        } else {
            serialized_state
        };
        
        // 加密状态(如果配置了加密器)
        let protected_state = if let Some(encryptor) = &self.encryptor {
            encryptor.encrypt(&compressed_state)
                .map_err(|e| SnapshotError::EncryptionFailed(e.to_string()))?
        } else {
            compressed_state
        };
        
        // 创建快照元数据
        let snapshot_id = format!("{}-{}-{}", workflow_id, execution_id, Uuid::new_v4());
        let snapshot = WorkflowSnapshot {
            id: snapshot_id.clone(),
            workflow_id: workflow_id.to_string(),
            execution_id: execution_id.to_string(),
            created_at: Utc::now(),
            size_bytes: protected_state.len() as u64,
            checksum: calculate_checksum(&protected_state),
            is_compressed: self.compressor.is_some(),
            is_encrypted: self.encryptor.is_some(),
            metadata: HashMap::new(),
        };
        
        // 存储快照
        self.state_storage.store_snapshot(&snapshot_id, &protected_state, &snapshot).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
        
        log::info!("为工作流创建了快照: workflow_id={}, execution_id={}, snapshot_id={}", 
                  workflow_id, execution_id, snapshot_id);
        
        Ok(snapshot_id)
    }
    
    /// 从快照恢复工作流状态
    pub async fn restore_from_snapshot(
        &self,
        snapshot_id: &str,
    ) -> Result<WorkflowState, SnapshotError> {
        // 获取快照元数据
        let snapshot = self.state_storage.get_snapshot_metadata(snapshot_id).await
            .map_err(|e| SnapshotError::MetadataRetrievalFailed(e.to_string()))?;
        
        // 获取快照数据
        let protected_state = self.state_storage.get_snapshot_data(snapshot_id).await
            .map_err(|e| SnapshotError::DataRetrievalFailed(e.to_string()))?;
        
        // 验证校验和
        let calculated_checksum = calculate_checksum(&protected_state);
        if calculated_checksum != snapshot.checksum {
            return Err(SnapshotError::ChecksumMismatch(
                format!("校验和不匹配: 预期{}, 计算得到{}", 
                       snapshot.checksum, calculated_checksum)
            ));
        }
        
        // 解密数据(如果已加密)
        let decrypted_state = if snapshot.is_encrypted {
            if let Some(encryptor) = &self.encryptor {
                encryptor.decrypt(&protected_state)
                    .map_err(|e| SnapshotError::DecryptionFailed(e.to_string()))?
            } else {
                return Err(SnapshotError::DecryptionFailed(
                    "快照已加密但未提供解密器".to_string()
                ));
            }
        } else {
            protected_state
        };
        
        // 解压数据(如果已压缩)
        let serialized_state = if snapshot.is_compressed {
            if let Some(compressor) = &self.compressor {
                compressor.decompress(&decrypted_state)
                    .map_err(|e| SnapshotError::DecompressionFailed(e.to_string()))?
            } else {
                return Err(SnapshotError::DecompressionFailed(
                    "快照已压缩但未提供解压器".to_string()
                ));
            }
        } else {
            decrypted_state
        };
        
        // 反序列化状态
        let workflow_state: WorkflowState = serde_json::from_slice(&serialized_state)
            .map_err(|e| SnapshotError::DeserializationFailed(e.to_string()))?;
        
        log::info!("从快照恢复了工作流状态: snapshot_id={}, workflow_id={}, execution_id={}", 
                  snapshot_id, snapshot.workflow_id, snapshot.execution_id);
        
        Ok(workflow_state)
    }
    
    /// 检查是否应该创建快照
    async fn should_create_snapshot(
        &self,
        workflow_id: &str,
        execution_id: &str,
    ) -> Result<bool, SnapshotError> {
        match &self.snapshot_policy.trigger {
            SnapshotTrigger::Periodic { interval } => {
                // 获取最近的快照
                let latest_snapshot = self.state_storage
                    .get_latest_snapshot(workflow_id, execution_id).await
                    .map_err(|e| SnapshotError::MetadataRetrievalFailed(e.to_string()))?;
                
                // 检查是否过了指定的时间间隔
                if let Some(snapshot) = latest_snapshot {
                    let elapsed = Utc::now() - snapshot.created_at;
                    Ok(elapsed > *interval)
                } else {
                    // 如果没有快照，则应该创建
                    Ok(true)
                }
            },
            SnapshotTrigger::EventBased { events } => {
                // 获取工作流最近的事件
                let latest_events = self.state_storage
                    .get_recent_workflow_events(workflow_id, execution_id, 10).await
                    .map_err(|e| SnapshotError::EventRetrievalFailed(e.to_string()))?;
                
                // 检查是否有匹配的事件类型
                for event in latest_events {
                    if events.contains(&event.event_type) {
                        return Ok(true);
                    }
                }
                
                Ok(false)
            },
            SnapshotTrigger::StepBased { steps } => {
                // 获取工作流当前步骤
                let current_step = self.state_storage
                    .get_current_workflow_step(workflow_id, execution_id).await
                    .map_err(|e| SnapshotError::StateRetrievalFailed(e.to_string()))?;
                
                // 检查当前步骤是否是需要快照的步骤
                if let Some(step) = current_step {
                    Ok(steps.contains(&step.step_id))
                } else {
                    Ok(false)
                }
            },
            SnapshotTrigger::Always => Ok(true),
        }
    }
    
    /// 清理过期快照
    pub async fn cleanup_expired_snapshots(&self) -> Result<u32, SnapshotError> {
        let retention_period = self.snapshot_policy.retention_period;
        
        // 获取过期的快照
        let expired_snapshots = self.state_storage
            .get_snapshots_older_than(Utc::now() - retention_period).await
            .map_err(|e| SnapshotError::MetadataRetrievalFailed(e.to_string()))?;
        
        let mut deleted_count = 0;
        
        // 删除过期的快照
        for snapshot in expired_snapshots {
            if let Err(e) = self.state_storage.delete_snapshot(&snapshot.id).await {
                log::warn!("删除过期快照失败: snapshot_id={}, error={}", snapshot.id, e);
            } else {
                deleted_count += 1;
            }
        }
        
        log::info!("清理了{}个过期快照", deleted_count);
        
        Ok(deleted_count)
    }
}

/// 计算数据的校验和
fn calculate_checksum(data: &[u8]) -> String {
    let mut hasher = Sha256::new();
    hasher.update(data);
    let result = hasher.finalize();
    format!("{:x}", result)
}
```

#### 3.6.3 任务幂等性和重复执行检测

```rust
/// 幂等性管理器 - 确保任务只执行一次
pub struct IdempotencyManager {
    /// 幂等性记录存储
    record_storage: Arc<IdempotencyRecordStorage>,
    /// 幂等性配置
    config: IdempotencyConfig,
}

impl IdempotencyManager {
    /// 创建新的幂等性管理器
    pub fn new(
        record_storage: Arc<IdempotencyRecordStorage>,
        config: IdempotencyConfig,
    ) -> Self {
        Self {
            record_storage,
            config,
        }
    }
    
    /// 检查任务是否应该执行
    pub async fn should_execute(
        &self,
        workflow_id: &str,
        step_id: &str,
        execution_id: &str,
        idempotency_key: &str,
    ) -> Result<ShouldExecuteResult, IdempotencyError> {
        // 构建完整的幂等性键
        let full_key = if idempotency_key.is_empty() {
            // 如果未提供幂等性键，则使用组合键
            format!("{}:{}:{}", workflow_id, step_id, execution_id)
        } else {
            // 使用提供的幂等性键
            idempotency_key.to_string()
        };
        
        // 查找现有记录
        let existing_record = self.record_storage.get_record(&full_key).await?;
        
        if let Some(record) = existing_record {
            // 检查记录是否过期
            if self.is_record_expired(&record) {
                // 记录已过期，可以执行
                log::info!("幂等性记录已过期，允许执行: key={}", full_key);
                
                // 创建新的执行记录
                let new_record = IdempotencyRecord {
                    key: full_key,
                    workflow_id: workflow_id.to_string(),
                    step_id: step_id.to_string(),
                    execution_id: execution_id.to_string(),
                    status: IdempotencyStatus::InProgress,
                    result: None,
                    created_at: Utc::now(),
                    updated_at: Utc::now(),
                    expires_at: self.calculate_expiry(),
                };
                
                self.record_storage.create_record(&new_record).await?;
                
                Ok(ShouldExecuteResult {
                    should_execute: true,
                    record_id: new_record.key,
                    previous_result: None,
                })
            } else {
                // 根据记录状态确定是否应该执行
                match record.status {
                    IdempotencyStatus::Completed => {
                        // 任务已完成，返回之前的结果
                        log::info!("任务已完成，不执行: key={}", full_key);
                        
                        Ok(ShouldExecuteResult {
                            should_execute: false,
                            record_id: record.key,
                            previous_result: record.result,
                        })
                    },
                    IdempotencyStatus::Failed => {
                        // 任务之前失败了，根据配置决定是否重试
                        if self.config.retry_failed_tasks {
                            log::info!("任务之前失败，配置为重试: key={}", full_key);
                            
                            // 更新记录状态为进行中
                            let updated_record = IdempotencyRecord {
                                key: record.key.clone(),
                                workflow_id: record.workflow_id,
                                step_id: record.step_id,
                                execution_id: record.execution_id,
                                status: IdempotencyStatus::InProgress,
                                result: None,
                                created_at: record.created_at,
                                updated_at: Utc::now(),
                                expires_at: self.calculate_expiry(),
                            };
                            
                            self.record_storage.update_record(&updated_record).await?;
                            
                            Ok(ShouldExecuteResult {
                                should_execute: true,
                                record_id: record.key,
                                previous_result: None,
                            })
                        } else {
                            log::info!("任务之前失败，配置为不重试: key={}", full_key);
                            
                            Ok(ShouldExecuteResult {
                                should_execute: false,
                                record_id: record.key,
                                previous_result: record.result,
                            })
                        }
                    },
                    IdempotencyStatus::InProgress => {
                        // 任务正在进行中，检查是否已超时
                        let now = Utc::now();
                        let task_timeout = Duration::from_millis(self.config.in_progress_timeout_ms);
                        let timeout_threshold = record.updated_at + task_timeout;
                        
                        if now > timeout_threshold {
                            // 任务已超时，可以重新执行
                            log::info!("任务执行超时，允许重新执行: key={}", full_key);
                            
                            // 更新记录
                            let updated_record = IdempotencyRecord {
                                key: record.key.clone(),
                                workflow_id: record.workflow_id,
                                step_id: record.step_id,
                                execution_id: record.execution_id,
                                status: IdempotencyStatus::InProgress,
                                result: None,
                                created_at: record.created_at,
                                updated_at: now,
                                expires_at: self.calculate_expiry(),
                            };
                            
                            self.record_storage.update_record(&updated_record).await?;
                            
                            Ok(ShouldExecuteResult {
                                should_execute: true,
                                record_id: record.key,
                                previous_result: None,
                            })
                        } else {
                            // 任务正在进行中且未超时，不应执行
                            log::info!("任务正在进行中，不执行: key={}", full_key);
                            
                            Ok(ShouldExecuteResult {
                                should_execute: false,
                                record_id: record.key,
                                previous_result: None,
                            })
                        }
                    },
                }
            }
        } else {
            // 没有现有记录，创建新记录并执行
            log::info!("没有现有幂等性记录，创建新记录并执行: key={}", full_key);
            
            // 创建新的执行记录
            let new_record = IdempotencyRecord {
                key: full_key.clone(),
                workflow_id: workflow_id.to_string(),
                step_id: step_id.to_string(),
                execution_id: execution_id.to_string(),
                status: IdempotencyStatus::InProgress,
                result: None,
                created_at: Utc::now(),
                updated_at: Utc::now(),
                expires_at: self.calculate_expiry(),
            };
            
            self.record_storage.create_record(&new_record).await?;
            
            Ok(ShouldExecuteResult {
                should_execute: true,
                record_id: full_key,
                previous_result: None,
            })
        }
    }
    
    /// 记录任务执行结果
    pub async fn record_execution_result(
        &self,
        record_id: &str,
        success: bool,
        result: Option<serde_json::Value>,
    ) -> Result<(), IdempotencyError> {
        // 获取现有记录
        let existing_record = self.record_storage.get_record(record_id).await?;
        
        if let Some(mut record) = existing_record {
            // 更新记录状态
            record.status = if success {
                IdempotencyStatus::Completed
            } else {
                IdempotencyStatus::Failed
            };
            
            record.result = result;
            record.updated_at = Utc::now();
            
            // 更新记录
            self.record_storage.update_record(&record).await?;
            
            log::info!("已记录任务执行结果: key={}, success={}", record_id, success);
            
            Ok(())
        } else {
            Err(IdempotencyError::RecordNotFound(record_id.to_string()))
        }
    }
    
    /// 清理过期记录
    pub async fn cleanup_expired_records(&self) -> Result<u32, IdempotencyError> {
        let now = Utc::now();
        
        // 获取过期的记录
        let expired_records = self.record_storage
            .get_records_older_than(now).await?;
        
        let mut deleted_count = 0;
        
        // 删除过期的记录
        for record in expired_records {
            if let Err(e) = self.record_storage.delete_record(&record.key).await {
                log::warn!("删除过期幂等性记录失败: key={}, error={}", record.key, e);
            } else {
                deleted_count += 1;
            }
        }
        
        log::info!("清理了{}个过期幂等性记录", deleted_count);
        
        Ok(deleted_count)
    }
    
    /// 检查记录是否过期
    fn is_record_expired(&self, record: &IdempotencyRecord) -> bool {
        let now = Utc::now();
        record.expires_at <= now
    }
    
    /// 计算过期时间
    fn calculate_expiry(&self) -> DateTime<Utc> {
        Utc::now() + chrono::Duration::milliseconds(self.config.record_ttl_ms as i64)
    }
}

```

### 3.7 事件溯源机制的实现

事件溯源是现代工作流系统的核心模式，下面实现了事件溯源系统。

```rust
/// 事件溯源管理器
pub struct EventSourcedManager<T> 
where 
    T: Aggregate + Send + Sync + 'static,
{
    /// 事件存储
    event_store: Arc<dyn EventStore<T>>,
    /// 快照存储
    snapshot_store: Option<Arc<dyn SnapshotStore<T>>>,
    /// 投影
    projections: HashMap<String, Box<dyn Projection<T>>>,
    /// 命令处理器
    command_handlers: HashMap<String, Box<dyn CommandHandler<T>>>,
}

impl<T> EventSourcedManager<T> 
where 
    T: Aggregate + Send + Sync + 'static,
{
    /// 创建新的事件溯源管理器
    pub fn new(
        event_store: Arc<dyn EventStore<T>>,
        snapshot_store: Option<Arc<dyn SnapshotStore<T>>>,
    ) -> Self {
        Self {
            event_store,
            snapshot_store,
            projections: HashMap::new(),
            command_handlers: HashMap::new(),
        }
    }
    
    /// 注册投影
    pub fn register_projection(&mut self, name: &str, projection: Box<dyn Projection<T>>) {
        self.projections.insert(name.to_string(), projection);
    }
    
    /// 注册命令处理器
    pub fn register_command_handler(&mut self, command_type: &str, handler: Box<dyn CommandHandler<T>>) {
        self.command_handlers.insert(command_type.to_string(), handler);
    }
    
    /// 处理命令
    pub async fn handle_command(&self, command: Command) -> Result<AggregateId, EventSourcedError> {
        // 获取命令处理器
        let handler = self.command_handlers.get(&command.command_type)
            .ok_or_else(|| EventSourcedError::UnknownCommandType(command.command_type.clone()))?;
        
        // 获取聚合根ID
        let aggregate_id = command.aggregate_id.clone();
        
        // 加载聚合根
        let mut aggregate = self.load_aggregate(&aggregate_id).await?;
        
        // 处理命令
        handler.handle(&mut aggregate, &command).await
            .map_err(|e| EventSourcedError::CommandHandlingFailed(e.to_string()))?;
        
        // 保存聚合根
        self.save_aggregate(&aggregate).await?;
        
        // 更新投影
        for projection in self.projections.values() {
            // 获取未提交事件
            let events = aggregate.uncommitted_events();
            
            // 更新投影
            for event in events {
                projection.project(&event)
                    .await
                    .map_err(|e| EventSourcedError::ProjectionFailed(e.to_string()))?;
            }
        }
        
        Ok(aggregate_id)
    }
    
    /// 加载聚合根
    pub async fn load_aggregate(&self, aggregate_id: &str) -> Result<T, EventSourcedError> {
        // 首先尝试从快照加载
        let mut aggregate = if let Some(snapshot_store) = &self.snapshot_store {
            match snapshot_store.load_snapshot(aggregate_id).await {
                Ok(Some((snapshot, version))) => {
                    let mut aggregate = snapshot;
                    
                    // 加载快照版本之后的事件
                    let events = self.event_store.load_events(aggregate_id, version + 1, None).await
                        .map_err(|e| EventSourcedError::EventLoadFailed(e.to_string()))?;
                    
                    // 应用事件
                    for event in events {
                        aggregate.apply(&event.event);
                    }
                    
                    aggregate
                },
                Ok(None) => {
                    // 如果没有快照，创建新的聚合根
                    let aggregate = T::new(aggregate_id);
                    
                    // 加载所有事件
                    let events = self.event_store.load_events(aggregate_id, 0, None).await
                        .map_err(|e| EventSourcedError::EventLoadFailed(e.to_string()))?;
                    
                    // 如果没有事件，说明聚合根不存在
                    if events.is_empty() {
                        return Err(EventSourcedError::AggregateNotFound(aggregate_id.to_string()));
                    }
                    
                    // 应用事件
                    for event in events {
                        aggregate.apply(&event.event);
                    }
                    
                    aggregate
                },
                Err(e) => {
                    return Err(EventSourcedError::SnapshotLoadFailed(e.to_string()));
                }
            }
        } else {
            // 如果没有快照存储，创建新的聚合根
            let aggregate = T::new(aggregate_id);
            
            // 加载所有事件
            let events = self.event_store.load_events(aggregate_id, 0, None).await
                .map_err(|e| EventSourcedError::EventLoadFailed(e.to_string()))?;
            
            // 如果没有事件，说明聚合根不存在
            if events.is_empty() {
                return Err(EventSourcedError::AggregateNotFound(aggregate_id.to_string()));
            }
            
            // 应用事件
            for event in events {
                aggregate.apply(&event.event);
            }
            
            aggregate
        };
        
        Ok(aggregate)
    }
    
    /// 保存聚合根
    pub async fn save_aggregate(&self, aggregate: &T) -> Result<(), EventSourcedError> {
        // 获取未提交事件
        let events = aggregate.uncommitted_events();
        
        if events.is_empty() {
            return Ok(());
        }
        
        // 保存事件
        self.event_store.save_events(
            &aggregate.id(),
            events.clone(),
            aggregate.version(),
        ).await.map_err(|e| EventSourcedError::EventSaveFailed(e.to_string()))?;
        
        // 保存快照(如果需要)
        if let Some(snapshot_store) = &self.snapshot_store {
            let version = aggregate.version() + events.len() as u64;
            
            if self.should_create_snapshot(aggregate.id(), version) {
                snapshot_store.save_snapshot(
                    &aggregate.id(),
                    aggregate.clone(),
                    version,
                ).await.map_err(|e| EventSourcedError::SnapshotSaveFailed(e.to_string()))?;
            }
        }
        
        Ok(())
    }
    
    /// 决定是否应该创建快照
    fn should_create_snapshot(&self, _aggregate_id: &str, version: u64) -> bool {
        // 默认每10个事件创建一次快照
        version % 10 == 0 && version > 0
    }
}

/// 事件溯源错误
#[derive(Debug, thiserror::Error)]
pub enum EventSourcedError {
    #[error("未知命令类型: {0}")]
    UnknownCommandType(String),
    
    #[error("命令处理失败: {0}")]
    CommandHandlingFailed(String),
    
    #[error("事件加载失败: {0}")]
    EventLoadFailed(String),
    
    #[error("事件保存失败: {0}")]
    EventSaveFailed(String),
    
    #[error("快照加载失败: {0}")]
    SnapshotLoadFailed(String),
    
    #[error("快照保存失败: {0}")]
    SnapshotSaveFailed(String),
    
    #[error("投影更新失败: {0}")]
    ProjectionFailed(String),
    
    #[error("聚合根不存在: {0}")]
    AggregateNotFound(String),
}
```

### 3.8 分布式锁和协调机制

```rust

/// 分布式锁管理器
pub struct DistributedLockManager {
    /// 锁存储
    lock_storage: Arc<dyn LockStorage>,
    /// 锁配置
    config: LockManagerConfig,
    /// 当前持有的锁
    held_locks: Arc<Mutex<HashMap<String, LockEntry>>>,
    /// 锁续约线程
    renewal_handle: Option<JoinHandle<()>>,
    /// 运行状态
    running: Arc<AtomicBool>,
}

impl DistributedLockManager {
    /// 创建新的分布式锁管理器
    pub fn new(
        lock_storage: Arc<dyn LockStorage>,
        config: LockManagerConfig,
    ) -> Self {
        Self {
            lock_storage,
            config,
            held_locks: Arc::new(Mutex::new(HashMap::new())),
            renewal_handle: None,
            running: Arc::new(AtomicBool::new(false)),
        }
    }
    
    /// 启动锁管理器
    pub fn start(&mut self) {
        if self.running.load(Ordering::SeqCst) {
            return;
        }
        
        // 设置运行标志
        self.running.store(true, Ordering::SeqCst);
        
        // 启动锁续约线程
        let held_locks = self.held_locks.clone();
        let lock_storage = self.lock_storage.clone();
        let renewal_interval = self.config.renewal_interval;
        let running = self.running.clone();
        
        let handle = tokio::spawn(async move {
            let renewal_interval = Duration::from_millis(renewal_interval);
            let mut interval = tokio::time::interval(renewal_interval);
            
            while running.load(Ordering::SeqCst) {
                interval.tick().await;
                
                // 获取当前持有的锁
                let locks_to_renew = {
                    let guard = held_locks.lock().await;
                    guard.values().cloned().collect::<Vec<_>>()
                };
                
                // 续约锁
                for lock in locks_to_renew {
                    if let Err(e) = lock_storage.renew_lock(&lock.lock_id, &lock.owner_id, lock.ttl).await {
                        log::warn!("锁续约失败: lock_id={}, owner_id={}, error={}", 
                                  lock.lock_id, lock.owner_id, e);
                    } else {
                        log::debug!("续约锁成功: lock_id={}, owner_id={}", lock.lock_id, lock.owner_id);
                    }
                }
            }
        });
        
        self.renewal_handle = Some(handle);
    }
    
    /// 停止锁管理器
    pub async fn stop(&mut self) {
        if !self.running.load(Ordering::SeqCst) {
            return;
        }
        
        // 设置运行标志
        self.running.store(false, Ordering::SeqCst);
        
        // 等待锁续约线程结束
        if let Some(handle) = self.renewal_handle.take() {
            handle.abort();
        }
        
        // 释放所有锁
        let locks_to_release = {
            let mut guard = self.held_locks.lock().await;
            let locks = guard.values().cloned().collect::<Vec<_>>();
            guard.clear();
            locks
        };
        
        for lock in locks_to_release {
            if let Err(e) = self.lock_storage.release_lock(&lock.lock_id, &lock.owner_id).await {
                log::warn!("释放锁失败: lock_id={}, owner_id={}, error={}", 
                          lock.lock_id, lock.owner_id, e);
            }
        }
    }
    
    /// 获取锁
    pub async fn acquire_lock(&self, lock_id: &str) -> Result<LockGuard, LockError> {
        // 检查是否已持有锁
        {
            let guard = self.held_locks.lock().await;
            if let Some(lock) = guard.get(lock_id) {
                // 返回已持有的锁
                return Ok(LockGuard {
                    lock_id: lock.lock_id.clone(),
                    owner_id: lock.owner_id.clone(),
                    manager: self,
                    _drop_marker: PhantomData,
                });
            }
        }
        
        // 生成所有者ID
        let owner_id = Uuid::new_v4().to_string();
        
        // 计算锁的TTL
        let ttl = self.config.lock_ttl;
        
        // 尝试获取锁
        let mut attempts = 0;
        let max_attempts = self.config.max_acquire_attempts;
        let wait_interval = Duration::from_millis(self.config.acquire_wait_interval);
        
        while attempts < max_attempts {
            match self.lock_storage.acquire_lock(lock_id, &owner_id, ttl).await {
                Ok(true) => {
                    // 锁获取成功
                    let lock_entry = LockEntry {
                        lock_id: lock_id.to_string(),
                        owner_id: owner_id.clone(),
                        acquired_at: Utc::now(),
                        ttl,
                    };
                    
                    // 添加到持有的锁中
                    {
                        let mut guard = self.held_locks.lock().await;
                        guard.insert(lock_id.to_string(), lock_entry);
                    }
                    
                    log::debug!("获取锁成功: lock_id={}, owner_id={}, ttl={}ms", 
                               lock_id, owner_id, ttl);
                    
                    // 返回锁守卫
                    return Ok(LockGuard {
                        lock_id: lock_id.to_string(),
                        owner_id,
                        manager: self,
                        _drop_marker: PhantomData,
                    });
                }
                Ok(false) => {
                    // 锁被其他进程持有，等待一段时间后重试
                    attempts += 1;
                    log::debug!("锁被其他进程持有，等待后重试: lock_id={}, attempt={}/{}", 
                               lock_id, attempts, max_attempts);
                    
                    if attempts < max_attempts {
                        tokio::time::sleep(wait_interval).await;
                    }
                }
                Err(e) => {
                    return Err(LockError::AcquisitionFailed(e.to_string()));
                }
            }
        }
        
        Err(LockError::Timeout(format!("获取锁超时: lock_id={}, max_attempts={}", lock_id, max_attempts)))
    }
    
    /// 释放锁
    pub async fn release_lock(&self, lock_id: &str, owner_id: &str) -> Result<(), LockError> {
        // 检查是否持有锁
        {
            let mut guard = self.held_locks.lock().await;
            if let Some(lock) = guard.get(lock_id) {
                if lock.owner_id != owner_id {
                    return Err(LockError::NotOwner(
                        format!("锁不是由当前所有者持有: lock_id={}, expected_owner={}, actual_owner={}", 
                               lock_id, owner_id, lock.owner_id)));
                }
                
                // 从持有的锁中移除
                guard.remove(lock_id);
            } else {
                return Err(LockError::NotHeld(format!("锁未被持有: lock_id={}", lock_id)));
            }
        }
        
        // 释放锁
        match self.lock_storage.release_lock(lock_id, owner_id).await {
            Ok(true) => {
                log::debug!("释放锁成功: lock_id={}, owner_id={}", lock_id, owner_id);
                Ok(())
            }
            Ok(false) => {
                log::warn!("锁已被其他进程释放: lock_id={}, owner_id={}", lock_id, owner_id);
                Err(LockError::AlreadyReleased(format!("锁已被释放: lock_id={}", lock_id)))
            }
            Err(e) => {
                Err(LockError::ReleaseFailed(e.to_string()))
            }
        }
    }
}

/// 锁守卫 - 当被丢弃时自动释放锁
pub struct LockGuard<'a> {
    lock_id: String,
    owner_id: String,
    manager: &'a DistributedLockManager,
    _drop_marker: PhantomData<()>,
}

impl<'a> Drop for LockGuard<'a> {
    fn drop(&mut self) {
        // 创建一个运行时来执行异步释放锁操作
        let rt = tokio::runtime::Runtime::new().unwrap();
        let lock_id = self.lock_id.clone();
        let owner_id = self.owner_id.clone();
        let manager = self.manager;
        
        // 在运行时中执行释放锁操作
        rt.block_on(async {
            if let Err(e) = manager.release_lock(&lock_id, &owner_id).await {
                log::warn!("锁自动释放失败: lock_id={}, owner_id={}, error={}", 
                          lock_id, owner_id, e);
            } else {
                log::debug!("锁已自动释放: lock_id={}, owner_id={}", lock_id, owner_id);
            }
        });
    }
}
```

### 3.9 工作流重放和调试机制

```rust
/// 工作流调试器
pub struct WorkflowDebugger {
    /// 事件存储
    event_store: Arc<dyn EventStore<WorkflowInstance>>,
    /// 工作流引擎
    engine: Arc<dyn WorkflowEngine>,
    /// 执行状态观察器
    observers: Vec<Box<dyn WorkflowDebugObserver>>,
}

impl WorkflowDebugger {
    /// 创建新的工作流调试器
    pub fn new(
        event_store: Arc<dyn EventStore<WorkflowInstance>>,
        engine: Arc<dyn WorkflowEngine>,
    ) -> Self {
        Self {
            event_store,
            engine,
            observers: Vec::new(),
        }
    }
    
    /// 添加调试观察器
    pub fn add_observer(&mut self, observer: Box<dyn WorkflowDebugObserver>) {
        self.observers.push(observer);
    }
    
    /// 执行工作流重放
    pub async fn replay_workflow(
        &self,
        workflow_id: &str,
        start_time: Option<DateTime<Utc>>,
        end_time: Option<DateTime<Utc>>,
        config: ReplayConfig,
    ) -> Result<ReplayResult, DebuggerError> {
        log::info!(
            "开始重放工作流: workflow_id={}, start_time={:?}, end_time={:?}",
            workflow_id,
            start_time,
            end_time
        );
        
        // 获取工作流事件
        let events = self.load_workflow_events(workflow_id, start_time, end_time).await?;
        
        if events.is_empty() {
            return Err(DebuggerError::NoEventsFound(format!("找不到工作流事件: workflow_id={}", workflow_id)));
        }
        
        // 创建虚拟引擎
        let virtual_engine = self.create_virtual_engine(&config);
        
        // 保存原始工作流状态(如果需要)
        if config.save_original_state {
            let instance = self.load_workflow_instance(workflow_id).await?;
            self.notify_original_state(&instance);
        }
        
        // 执行重放
        let start = Instant::now();
        let mut events_processed = 0;
        let mut current_state = WorkflowInstance::new(workflow_id);
        
        for event in events {
            // 应用事件
            current_state.apply(&event.event);
            
            // 调试暂停点检查
            if self.is_breakpoint(&event.event, &config.breakpoints) {
                // 通知观察器遇到断点
                for observer in &self.observers {
                    observer.on_breakpoint(&current_state, &event.event).await;
                }
                
                // 如果需要交互，等待用户输入
                if config.interactive_breakpoints {
                    self.handle_interactive_debugging(&current_state, &event.event).await?;
                }
            }
            
            // 通知事件应用
            self.notify_event_applied(&current_state, &event.event);
            
            // 执行工作流步骤(如果需要)
            if config.execute_steps {
                self.execute_step(&virtual_engine, &current_state, &event.event).await?;
            }
            
            events_processed += 1;
            
            // 速度控制
            if let Some(speed) = config.replay_speed {
                if speed < 1.0 {
                    let delay = Duration::from_millis((1000.0 / speed) as u64);
                    tokio::time::sleep(delay).await;
                }
            }
        }
        
        let elapsed = start.elapsed();
        
        // 汇总结果
        let result = ReplayResult {
            workflow_id: workflow_id.to_string(),
            events_processed,
            execution_time: elapsed,
            final_state: current_state,
        };
        
        // 通知重放完成
        for observer in &self.observers {
            observer.on_replay_completed(&result).await;
        }
        
        log::info!(
            "工作流重放完成: workflow_id={}, events_processed={}, duration={:?}",
            workflow_id,
            events_processed,
            elapsed
        );
        
        Ok(result)
    }
    
    /// 执行工作流调试分析
    pub async fn analyze_workflow(
        &self,
        workflow_id: &str,
    ) -> Result<WorkflowAnalysis, DebuggerError> {
        log::info!("开始分析工作流: workflow_id={}", workflow_id);
        
        // 获取所有工作流事件
        let events = self.load_workflow_events(workflow_id, None, None).await?;
        
        if events.is_empty() {
            return Err(DebuggerError::NoEventsFound(format!("找不到工作流事件: workflow_id={}", workflow_id)));
        }
        
        // 执行分析
        let mut step_execution_times = HashMap::new();
        let mut step_execution_counts = HashMap::new();
        let mut state_transitions = Vec::new();
        let mut error_events = Vec::new();
        
        let mut last_task_start: Option<(String, DateTime<Utc>)> = None;
        let mut total_wait_time = Duration::default();
        let mut longest_wait_time = Duration::default();
        let mut previous_state: Option<String> = None;
        
        for event in &events {
            match &event.event {
                WorkflowEvent::TaskStarted { task_id, start_time, .. } => {
                    last_task_start = Some((task_id.clone(), *start_time));
                }
                WorkflowEvent::TaskCompleted { task_id, completion_time, .. } => {
                    if let Some((id, start_time)) = &last_task_start {
                        if id == task_id {
                            let execution_time = *completion_time - *start_time;
                            
                            // 更新执行时间统计
                            step_execution_times
                                .entry(task_id.clone())
                                .or_insert_with(Vec::new)
                                .push(execution_time);
                            
                            // 更新执行次数统计
                            *step_execution_counts
                                .entry(task_id.clone())
                                .or_insert(0) += 1;
                            
                            last_task_start = None;
                        }
                    }
                }
                WorkflowEvent::TaskFailed { task_id, error, failure_time, .. } => {
                    error_events.push(AnalysisError {
                        error_type: "TaskFailed".to_string(),
                        message: error.clone(),
                        time: *failure_time,
                        context: json!({
                            "task_id": task_id,
                        }),
                    });
                    
                    last_task_start = None;
                }
                WorkflowEvent::WorkflowFailed { error, failure_time, .. } => {
                    error_events.push(AnalysisError {
                        error_type: "WorkflowFailed".to_string(),
                        message: error.clone(),
                        time: *failure_time,
                        context: json!({}),
                    });
                }
                _ => {}
            }
            
            // 分析状态转换
            let current_state = self.extract_state_from_event(&event.event);
            if let Some(current) = &current_state {
                if let Some(previous) = &previous_state {
                    if current != previous {
                        state_transitions.push(StateTransition {
                            from: previous.clone(),
                            to: current.clone(),
                            time: self.extract_time_from_event(&event.event),
                            event_type: event.event.get_type(),
                        });
                    }
                }
                previous_state = current_state;
            }
            
            // 分析等待时间
            if let Some(wait_time) = self.calculate_wait_time(&events, &event) {
                total_wait_time += wait_time;
                if wait_time > longest_wait_time {
                    longest_wait_time = wait_time;
                }
            }
        }
        
        // 计算平均执行时间
        let mut step_average_times = HashMap::new();
        for (step_id, times) in &step_execution_times {
            let total = times.iter().sum::<chrono::Duration>();
            let count = times.len() as i32;
            let average = total / count;
            step_average_times.insert(step_id.clone(), average);
        }
        
        // 构建分析结果
        let analysis = WorkflowAnalysis {
            workflow_id: workflow_id.to_string(),
            events_analyzed: events.len(),
            execution_summary: ExecutionSummary {
                total_duration: if let (Some(first), Some(last)) = (events.first(), events.last()) {
                    self.extract_time_from_event(&last.event) - self.extract_time_from_event(&first.event)
                } else {
                    chrono::Duration::zero()
                },
                step_execution_times: step_average_times,
                step_execution_counts,
                total_wait_time,
                longest_wait_time,
            },
            state_transitions,
            error_events,
            optimization_suggestions: self.generate_optimization_suggestions(
                workflow_id,
                &step_execution_times,
                &state_transitions,
                &error_events,
            ).await?,
        };
        
        log::info!("工作流分析完成: workflow_id={}", workflow_id);
        
        Ok(analysis)
    }
    
    /// 获取工作流修复建议
    pub async fn get_repair_suggestions(
        &self,
        workflow_id: &str,
    ) -> Result<Vec<RepairSuggestion>, DebuggerError> {
        log::info!("开始为工作流生成修复建议: workflow_id={}", workflow_id);
        
        // 获取工作流分析结果
        let analysis = self.analyze_workflow(workflow_id).await?;
        
        // 生成修复建议
        let mut suggestions = Vec::new();
        
        // 基于错误事件生成建议
        for error in &analysis.error_events {
            let suggestion = self.generate_error_repair_suggestion(workflow_id, error).await?;
            suggestions.push(suggestion);
        }
        
        // 基于执行时间异常生成建议
        let execution_time_suggestions = self.generate_execution_time_suggestions(
            workflow_id,
            &analysis.execution_summary.step_execution_times,
        ).await?;
        
        suggestions.extend(execution_time_suggestions);
        
        // 基于状态转换生成建议
        let state_transition_suggestions = self.generate_state_transition_suggestions(
            workflow_id,
            &analysis.state_transitions,
        ).await?;
        
        suggestions.extend(state_transition_suggestions);
        
        log::info!("工作流修复建议生成完成: workflow_id={}, suggestions_count={}", 
                  workflow_id, suggestions.len());
        
        Ok(suggestions)
    }
}

/// 工作流调试观察器 - 用于接收调试事件通知
#[async_trait]
pub trait WorkflowDebugObserver: Send + Sync {
    /// 当遇到断点时调用
    async fn on_breakpoint(&self, current_state: &WorkflowInstance, event: &WorkflowEvent);
    
    /// 当事件被应用时调用
    async fn on_event_applied(&self, current_state: &WorkflowInstance, event: &WorkflowEvent);
    
    /// 当重放完成时调用
    async fn on_replay_completed(&self, result: &ReplayResult);
    
    /// 当原始状态被加载时调用
    async fn on_original_state_loaded(&self, instance: &WorkflowInstance);
}

/// 工作流调试器实现细节
impl WorkflowDebugger {
    /// 加载工作流事件
    async fn load_workflow_events(
        &self,
        workflow_id: &str,
        start_time: Option<DateTime<Utc>>,

3.10 工作流监控和仪表盘

```rust
/// 工作流监控系统
pub struct WorkflowMonitor {
    /// 事件存储
    event_store: Arc<dyn EventStore<WorkflowInstance>>,
    /// 统计数据聚合器
    stats_aggregator: Arc<dyn StatsAggregator>,
    /// 告警管理器
    alert_manager: Arc<dyn AlertManager>,
    /// 指标注册表
    metrics_registry: Arc<MetricsRegistry>,
    /// 实时通知发布者
    notification_publisher: Arc<dyn NotificationPublisher>,
    /// 监控间隔
    monitor_interval: Duration,
    /// 运行状态
    running: Arc<AtomicBool>,
    /// 监控任务句柄
    monitor_handle: Option<JoinHandle<()>>,
}

impl WorkflowMonitor {
    /// 创建工作流监控系统
    pub fn new(
        event_store: Arc<dyn EventStore<WorkflowInstance>>,
        stats_aggregator: Arc<dyn StatsAggregator>,
        alert_manager: Arc<dyn AlertManager>,
        metrics_registry: Arc<MetricsRegistry>,
        notification_publisher: Arc<dyn NotificationPublisher>,
        monitor_interval: Duration,
    ) -> Self {
        Self {
            event_store,
            stats_aggregator,
            alert_manager,
            metrics_registry,
            notification_publisher,
            monitor_interval,
            running: Arc::new(AtomicBool::new(false)),
            monitor_handle: None,
        }
    }
    
    /// 启动监控系统
    pub fn start(&mut self) {
        if self.running.load(Ordering::SeqCst) {
            return;
        }
        
        // 设置运行标志
        self.running.store(true, Ordering::SeqCst);
        
        // 启动监控任务
        let event_store = self.event_store.clone();
        let stats_aggregator = self.stats_aggregator.clone();
        let alert_manager = self.alert_manager.clone();
        let metrics_registry = self.metrics_registry.clone();
        let notification_publisher = self.notification_publisher.clone();
        let monitor_interval = self.monitor_interval;
        let running = self.running.clone();
        
        let handle = tokio::spawn(async move {
            let mut interval = tokio::time::interval(monitor_interval);
            
            while running.load(Ordering::SeqCst) {
                interval.tick().await;
                
                // 执行监控任务
                if let Err(e) = Self::monitor_workflows(
                    &event_store,
                    &stats_aggregator,
                    &alert_manager,
                    &metrics_registry,
                    &notification_publisher,
                ).await {
                    log::error!("执行工作流监控任务时发生错误: {}", e);
                }
            }
        });
        
        self.monitor_handle = Some(handle);
        
        log::info!("工作流监控系统已启动");
    }
    
    /// 停止监控系统
    pub async fn stop(&mut self) {
        if !self.running.load(Ordering::SeqCst) {
            return;
        }
        
        // 设置运行标志
        self.running.store(false, Ordering::SeqCst);
        
        // 等待监控任务结束
        if let Some(handle) = self.monitor_handle.take() {
            handle.abort();
        }
        
        log::info!("工作流监控系统已停止");
    }
    
    /// 获取工作流状态统计
    pub async fn get_workflow_stats(&self) -> Result<WorkflowStats, MonitorError> {
        self.stats_aggregator.get_workflow_stats().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 获取任务执行统计
    pub async fn get_task_stats(&self) -> Result<TaskStats, MonitorError> {
        self.stats_aggregator.get_task_stats().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 获取资源使用统计
    pub async fn get_resource_stats(&self) -> Result<ResourceStats, MonitorError> {
        self.stats_aggregator.get_resource_stats().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 获取活跃工作流实例
    pub async fn get_active_workflows(&self) -> Result<Vec<WorkflowSummary>, MonitorError> {
        self.stats_aggregator.get_active_workflows().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 获取最近失败的工作流
    pub async fn get_failed_workflows(&self) -> Result<Vec<WorkflowSummary>, MonitorError> {
        self.stats_aggregator.get_failed_workflows().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 获取长时间运行的工作流
    pub async fn get_long_running_workflows(&self) -> Result<Vec<WorkflowSummary>, MonitorError> {
        self.stats_aggregator.get_long_running_workflows().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 获取工作流执行趋势
    pub async fn get_workflow_trends(
        &self,
        period: TrendPeriod,
    ) -> Result<WorkflowTrends, MonitorError> {
        self.stats_aggregator.get_workflow_trends(period).await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 获取系统健康状态
    pub async fn get_system_health(&self) -> Result<SystemHealth, MonitorError> {
        self.stats_aggregator.get_system_health().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))
    }
    
    /// 执行监控任务
    async fn monitor_workflows(
        event_store: &Arc<dyn EventStore<WorkflowInstance>>,
        stats_aggregator: &Arc<dyn StatsAggregator>,
        alert_manager: &Arc<dyn AlertManager>,
        metrics_registry: &Arc<MetricsRegistry>,
        notification_publisher: &Arc<dyn NotificationPublisher>,
    ) -> Result<(), MonitorError> {
        // 1. 更新工作流统计信息
        stats_aggregator.update_stats().await
            .map_err(|e| MonitorError::StatsUpdateFailed(e.to_string()))?;
        
        // 2. 获取需要检查的工作流实例
        let active_workflows = stats_aggregator.get_active_workflows().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))?;
        
        // 3. 检查工作流状态并生成告警
        for workflow in active_workflows {
            // 获取工作流实例
            let events = event_store.load_events(&workflow.id, 0, None).await
                .map_err(|e| MonitorError::EventLoadFailed(e.to_string()))?;
                
            if events.is_empty() {
                continue;
            }
            
            // 重建工作流状态
            let mut instance = WorkflowInstance::new(&workflow.id);
            for event in &events {
                instance.apply(&event.event);
            }
            
            // 检查工作流是否已超时
            if let Some(started_at) = instance.started_at {
                let now = Utc::now();
                let duration = now.signed_duration_since(started_at);
                
                if let Some(timeout) = instance.definition.as_ref().and_then(|d| d.timeout) {
                    if duration > timeout {
                        // 创建超时告警
                        let alert = Alert {
                            id: Uuid::new_v4().to_string(),
                            alert_type: AlertType::WorkflowTimeout,
                            workflow_id: instance.workflow_id.clone(),
                            message: format!("工作流已运行 {} 秒，超过超时时间 {} 秒", 
                                           duration.num_seconds(), timeout.num_seconds()),
                            severity: AlertSeverity::High,
                            timestamp: now,
                            metadata: json!({
                                "workflow_type": instance.definition.as_ref().map(|d| d.workflow_type.clone()).unwrap_or_default(),
                                "started_at": started_at,
                                "duration": duration.num_seconds(),
                                "timeout": timeout.num_seconds(),
                            }),
                        };
                        
                        // 发送告警
                        alert_manager.trigger_alert(alert).await
                            .map_err(|e| MonitorError::AlertTriggerFailed(e.to_string()))?;
                    }
                }
            }
            
            // 检查工作流步骤是否有异常
            if let Some(steps) = instance.steps.as_ref() {
                for (step_id, step) in steps {
                    if step.retry_count > 3 {
                        // 创建重试过多告警
                        let alert = Alert {
                            id: Uuid::new_v4().to_string(),
                            alert_type: AlertType::StepTooManyRetries,
                            workflow_id: instance.workflow_id.clone(),
                            message: format!("步骤 {} 已重试 {} 次，超过阈值", step_id, step.retry_count),
                            severity: AlertSeverity::Medium,
                            timestamp: Utc::now(),
                            metadata: json!({
                                "step_id": step_id,
                                "step_type": step.step_type,
                                "retry_count": step.retry_count,
                                "last_error": step.last_error,
                            }),
                        };
                        
                        // 发送告警
                        alert_manager.trigger_alert(alert).await
                            .map_err(|e| MonitorError::AlertTriggerFailed(e.to_string()))?;
                    }
                }
            }
            
            // 更新工作流指标
            metrics_registry.record_workflow_duration(
                &instance.workflow_id,
                instance.definition.as_ref().map(|d| d.workflow_type.clone()).unwrap_or_default(),
                instance.started_at.map(|s| Utc::now().signed_duration_since(s).to_std().unwrap_or_default()),
            );
        }
        
        // 4. 检查长时间运行的工作流
        let long_running = stats_aggregator.get_long_running_workflows().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))?;
            
        if !long_running.is_empty() {
            // 发送长时间运行工作流通知
            let notification = Notification {
                id: Uuid::new_v4().to_string(),
                notification_type: NotificationType::LongRunningWorkflows,
                title: "存在长时间运行的工作流实例".to_string(),
                message: format!("当前有 {} 个工作流实例运行时间超过阈值", long_running.len()),
                timestamp: Utc::now(),
                severity: NotificationSeverity::Warning,
                metadata: json!({
                    "workflows": long_running,
                }),
            };
            
            notification_publisher.publish(notification).await
                .map_err(|e| MonitorError::NotificationPublishFailed(e.to_string()))?;
        }
        
        // 5. 检查系统健康状态
        let health = stats_aggregator.get_system_health().await
            .map_err(|e| MonitorError::StatsAggregationFailed(e.to_string()))?;
            
        if health.status != HealthStatus::Healthy {
            // 创建系统健康告警
            let alert = Alert {
                id: Uuid::new_v4().to_string(),
                alert_type: AlertType::SystemUnhealthy,
                workflow_id: "system".to_string(),
                message: format!("系统健康状态异常: {}", health.status),
                severity: AlertSeverity::Critical,
                timestamp: Utc::now(),
                metadata: json!({
                    "health_status": health.status.to_string(),
                    "components": health.components,
                    "message": health.message,
                }),
            };
            
            // 发送告警
            alert_manager.trigger_alert(alert).await
                .map_err(|e| MonitorError::AlertTriggerFailed(e.to_string()))?;
        }
        
        Ok(())
    }
}

/// 仪表盘服务
pub struct DashboardService {
    /// 工作流监控
    monitor: Arc<WorkflowMonitor>,
    /// 仪表盘数据缓存
    cache: Arc<RwLock<DashboardCache>>,
    /// 缓存刷新间隔
    refresh_interval: Duration,
    /// 运行状态
    running: Arc<AtomicBool>,
    /// 缓存刷新任务句柄
    refresh_handle: Option<JoinHandle<()>>,
}

impl DashboardService {
    /// 创建仪表盘服务
    pub fn new(
        monitor: Arc<WorkflowMonitor>,
        refresh_interval: Duration,
    ) -> Self {
        Self {
            monitor,
            cache: Arc::new(RwLock::new(DashboardCache::default())),
            refresh_interval,
            running: Arc::new(AtomicBool::new(false)),
            refresh_handle: None,
        }
    }
    
    /// 启动仪表盘服务
    pub fn start(&mut self) {
        if self.running.load(Ordering::SeqCst) {
            return;
        }
        
        // 设置运行标志
        self.running.store(true, Ordering::SeqCst);
        
        // 启动缓存刷新任务
        let monitor = self.monitor.clone();
        let cache = self.cache.clone();
        let refresh_interval = self.refresh_interval;
        let running = self.running.clone();
        
        let handle = tokio::spawn(async move {
            let mut interval = tokio::time::interval(refresh_interval);
            
            while running.load(Ordering::SeqCst) {
                interval.tick().await;
                
                // 刷新仪表盘数据
                if let Err(e) = Self::refresh_dashboard_data(&monitor, &cache).await {
                    log::error!("刷新仪表盘数据时发生错误: {}", e);
                }
            }
        });
        
        self.refresh_handle = Some(handle);
        
        log::info!("仪表盘服务已启动");
    }
    
    /// 停止仪表盘服务
    pub async fn stop(&mut self) {
        if !self.running.load(Ordering::SeqCst) {
            return;
        }
        
        // 设置运行标志
        self.running.store(false, Ordering::SeqCst);
        
        // 等待缓存刷新任务结束
        if let Some(handle) = self.refresh_handle.take() {
            handle.abort();
        }
        
        log::info!("仪表盘服务已停止");
    }
    
    /// 获取仪表盘概览数据
    pub async fn get_dashboard_overview(&self) -> Result<DashboardOverview, DashboardError> {
        let cache = self.cache.read().await;
        Ok(cache.overview.clone())
    }
    
    /// 获取工作流执行趋势
    pub async fn get_workflow_trends(
        &self,
        period: TrendPeriod,
    ) -> Result<WorkflowTrends, DashboardError> {
        // 从监控系统获取趋势数据
        self.monitor.get_workflow_trends(period).await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))
    }
    
    /// 获取活跃工作流列表
    pub async fn get_active_workflows(&self) -> Result<Vec<WorkflowSummary>, DashboardError> {
        let cache = self.cache.read().await;
        Ok(cache.active_workflows.clone())
    }
    
    /// 获取失败工作流列表
    pub async fn get_failed_workflows(&self) -> Result<Vec<WorkflowSummary>, DashboardError> {
        let cache = self.cache.read().await;
        Ok(cache.failed_workflows.clone())
    }
    
    /// 获取工作流类型分布
    pub async fn get_workflow_type_distribution(&self) -> Result<HashMap<String, usize>, DashboardError> {
        let cache = self.cache.read().await;
        Ok(cache.workflow_type_distribution.clone())
    }
    
    /// 获取任务执行时间分布
    pub async fn get_task_execution_time_distribution(&self) -> Result<HashMap<String, Vec<Duration>>, DashboardError> {
        let cache = self.cache.read().await;
        Ok(cache.task_execution_times.clone())
    }
    
    /// 获取系统资源使用情况
    pub async fn get_system_resource_usage(&self) -> Result<SystemResourceUsage, DashboardError> {
        let cache = self.cache.read().await;
        Ok(cache.resource_usage.clone())
    }
    
    /// 获取最近的告警
    pub async fn get_recent_alerts(&self) -> Result<Vec<Alert>, DashboardError> {
        let cache = self.cache.read().await;
        Ok(cache.recent_alerts.clone())
    }
    
    /// 获取工作流详情
    pub async fn get_workflow_details(
        &self,
        workflow_id: &str,
    ) -> Result<WorkflowDetails, DashboardError> {
        // 从监控系统获取详情数据
        // 这部分数据不缓存，每次实时获取
        let instance = self.monitor.event_store.load_aggregate(workflow_id).await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        let stats = self.monitor.stats_aggregator.get_workflow_details(workflow_id).await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        Ok(WorkflowDetails {
            workflow_id: workflow_id.to_string(),
            workflow_type: instance.definition
                .as_ref()
                .map(|def| def.workflow_type.clone())
                .unwrap_or_default(),
            status: instance.stage,
            started_at: instance.started_at,
            completed_at: instance.completed_at,
            steps: instance.steps.unwrap_or_default(),
            variables: instance.variables.unwrap_or_default(),
            execution_stats: stats,
        })
    }
    
    /// 刷新仪表盘数据
    async fn refresh_dashboard_data(
        monitor: &Arc<WorkflowMonitor>,
        cache: &Arc<RwLock<DashboardCache>>,
    ) -> Result<(), DashboardError> {
        // 获取工作流统计
        let workflow_stats = monitor.get_workflow_stats().await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        // 获取任务统计
        let task_stats = monitor.get_task_stats().await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        // 获取资源统计
        let resource_stats = monitor.get_resource_stats().await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        // 获取活跃工作流
        let active_workflows = monitor.get_active_workflows().await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        // 获取失败工作流
        let failed_workflows = monitor.get_failed_workflows().await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        // 获取系统健康状态
        let system_health = monitor.get_system_health().await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        // 构建工作流类型分布
        let mut workflow_type_distribution = HashMap::new();
        for workflow in &active_workflows {
            *workflow_type_distribution
                .entry(workflow.workflow_type.clone())
                .or_insert(0) += 1;
        }
        
        // 更新仪表盘概览
        let overview = DashboardOverview {
            total_workflows: workflow_stats.total_workflows,
            active_workflows: workflow_stats.active_workflows,
            completed_workflows: workflow_stats.completed_workflows,
            failed_workflows: workflow_stats.failed_workflows,
            average_execution_time: workflow_stats.average_execution_time,
            total_tasks: task_stats.total_tasks,
            active_tasks: task_stats.active_tasks,
            completed_tasks: task_stats.completed_tasks,
            failed_tasks: task_stats.failed_tasks,
            system_health: system_health.status,
            resource_utilization: resource_stats.average_utilization,
        };
        
        // 构建系统资源使用情况
        let resource_usage = SystemResourceUsage {
            cpu_usage: resource_stats.cpu_usage,
            memory_usage: resource_stats.memory_usage,
            disk_usage: resource_stats.disk_usage,
            network_usage: resource_stats.network_usage,
        };
        
        // 获取最近的告警
        let recent_alerts = monitor.alert_manager.get_recent_alerts(10).await
            .map_err(|e| DashboardError::DataFetchFailed(e.to_string()))?;
            
        // 更新缓存
        let mut cache_writer = cache.write().await;
        cache_writer.overview = overview;
        cache_writer.active_workflows = active_workflows;
        cache_writer.failed_workflows = failed_workflows;
        cache_writer.workflow_type_distribution = workflow_type_distribution;
        cache_writer.task_execution_times = task_stats.execution_time_distribution;
        cache_writer.resource_usage = resource_usage;
        cache_writer.recent_alerts = recent_alerts;
        cache_writer.last_updated = Utc::now();
        
        Ok(())
    }
}

/// 投影模块实现
pub struct WorkflowProjection {
    /// 数据库连接池
    db_pool: Arc<PgPool>,
}

impl WorkflowProjection {
    /// 创建工作流投影
    pub fn new(db_pool: Arc<PgPool>) -> Self {
        Self { db_pool }
    }
    
    /// 处理工作流创建事件
    pub async fn on_workflow_created(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::WorkflowCreated { workflow_id, definition, .. } = event {
            // 插入工作流记录
            sqlx::query(r#"
                INSERT INTO workflow_instances (
                    workflow_id, 
                    workflow_type, 
                    status, 
                    created_at
                ) VALUES ($1, $2, $3, $4)
                ON CONFLICT (workflow_id) DO UPDATE SET
                    workflow_type = $2,
                    status = $3,
                    updated_at = NOW()
            "#)
            .bind(workflow_id.to_string())
            .bind(&definition.workflow_type)
            .bind("CREATED")
            .bind(Utc::now())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 工作流创建 workflow_id={}", workflow_id);
        }
        
        Ok(())
    }
    
    /// 处理工作流开始事件
    pub async fn on_workflow_started(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::WorkflowStarted { workflow_id, start_time, .. } = event {
            // 更新工作流状态
            sqlx::query(r#"
                UPDATE workflow_instances
                SET status = $1, started_at = $2, updated_at = NOW()
                WHERE workflow_id = $3
            "#)
            .bind("RUNNING")
            .bind(start_time)
            .bind(workflow_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 工作流开始 workflow_id={}", workflow_id);
        }
        
        Ok(())
    }
    
    /// 处理工作流完成事件
    pub async fn on_workflow_completed(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::WorkflowCompleted { workflow_id, completion_time, .. } = event {
            // 更新工作流状态
            sqlx::query(r#"
                UPDATE workflow_instances
                SET status = $1, completed_at = $2, updated_at = NOW()
                WHERE workflow_id = $3
            "#)
            .bind("COMPLETED")
            .bind(completion_time)
            .bind(workflow_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            // 更新统计信息
            sqlx::query(r#"
                INSERT INTO workflow_statistics (
                    date, 
                    workflow_type, 
                    status, 
                    count
                )
                SELECT 
                    DATE(completed_at), 
                    workflow_type, 
                    'COMPLETED', 
                    1
                FROM workflow_instances
                WHERE workflow_id = $1
                ON CONFLICT (date, workflow_type, status)
                DO UPDATE SET count = workflow_statistics.count + 1
            "#)
            .bind(workflow_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 工作流完成 workflow_id={}", workflow_id);
        }
        
        Ok(())
    }
    
    /// 处理工作流失败事件
    pub async fn on_workflow_failed(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::WorkflowFailed { workflow_id, error, failure_time, .. } = event {
            // 更新工作流状态
            sqlx::query(r#"
                UPDATE workflow_instances
                SET status = $1, error = $2, completed_at = $3, updated_at = NOW()
                WHERE workflow_id = $4
            "#)
            .bind("FAILED")
            .bind(error.to_string())
            .bind(failure_time)
            .bind(workflow_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            // 更新统计信息
            sqlx::query(r#"
                INSERT INTO workflow_statistics (
                    date, 
                    workflow_type, 
                    status, 
                    count
                )
                SELECT 
                    DATE(completed_at), 
                    workflow_type, 
                    'FAILED', 
                    1
                FROM workflow_instances
                WHERE workflow_id = $1
                ON CONFLICT (date, workflow_type, status)
                DO UPDATE SET count = workflow_statistics.count + 1
            "#)
            .bind(workflow_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 工作流失败 workflow_id={}", workflow_id);
        }
        
        Ok(())
    }
    
    /// 处理任务调度事件
    pub async fn on_task_scheduled(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::TaskScheduled { task_id, workflow_id, task_def, .. } = event {
            // 插入任务记录
            sqlx::query(r#"
                INSERT INTO workflow_tasks (
                    task_id, 
                    workflow_id, 
                    task_type, 
                    status, 
                    created_at
                ) VALUES ($1, $2, $3, $4, NOW())
                ON CONFLICT (task_id) DO UPDATE SET
                    status = $4,
                    updated_at =
    /// 处理任务调度事件
    pub async fn on_task_scheduled(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::TaskScheduled { task_id, workflow_id, task_def, .. } = event {
            // 插入任务记录
            sqlx::query(r#"
                INSERT INTO workflow_tasks (
                    task_id, 
                    workflow_id, 
                    task_type, 
                    status, 
                    created_at
                ) VALUES ($1, $2, $3, $4, NOW())
                ON CONFLICT (task_id) DO UPDATE SET
                    status = $4,
                    updated_at = NOW()
            "#)
            .bind(task_id.to_string())
            .bind(workflow_id.to_string())
            .bind(&task_def.task_type)
            .bind("SCHEDULED")
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            // 更新统计信息
            sqlx::query(r#"
                INSERT INTO task_statistics (
                    date, 
                    task_type, 
                    status, 
                    count
                ) VALUES (CURRENT_DATE, $1, $2, 1)
                ON CONFLICT (date, task_type, status)
                DO UPDATE SET count = task_statistics.count + 1
            "#)
            .bind(&task_def.task_type)
            .bind("SCHEDULED")
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 任务调度 task_id={}", task_id);
        }
        
        Ok(())
    }
    
    /// 处理任务开始事件
    pub async fn on_task_started(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::TaskStarted { task_id, start_time, .. } = event {
            // 更新任务状态
            sqlx::query(r#"
                UPDATE workflow_tasks
                SET status = $1, started_at = $2, updated_at = NOW()
                WHERE task_id = $3
            "#)
            .bind("RUNNING")
            .bind(start_time)
            .bind(task_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 任务开始 task_id={}", task_id);
        }
        
        Ok(())
    }
    
    /// 处理任务完成事件
    pub async fn on_task_completed(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::TaskCompleted { task_id, result, completion_time, .. } = event {
            // 更新任务状态
            sqlx::query(r#"
                UPDATE workflow_tasks
                SET 
                    status = $1, 
                    completed_at = $2, 
                    result = $3, 
                    updated_at = NOW(),
                    execution_time_ms = EXTRACT(EPOCH FROM ($2 - started_at)) * 1000
                WHERE task_id = $4
            "#)
            .bind("COMPLETED")
            .bind(completion_time)
            .bind(serde_json::to_value(result).unwrap_or(serde_json::Value::Null))
            .bind(task_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            // 更新统计信息
            sqlx::query(r#"
                WITH task_type_query AS (
                    SELECT task_type FROM workflow_tasks WHERE task_id = $1
                )
                INSERT INTO task_statistics (
                    date, 
                    task_type, 
                    status, 
                    count
                ) 
                SELECT 
                    CURRENT_DATE, 
                    task_type, 
                    'COMPLETED', 
                    1
                FROM task_type_query
                ON CONFLICT (date, task_type, status)
                DO UPDATE SET count = task_statistics.count + 1
            "#)
            .bind(task_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 任务完成 task_id={}", task_id);
        }
        
        Ok(())
    }
    
    /// 处理任务失败事件
    pub async fn on_task_failed(
        &self,
        event: &WorkflowEvent,
    ) -> Result<(), ProjectionError> {
        if let WorkflowEvent::TaskFailed { task_id, error, failure_time, .. } = event {
            // 更新任务状态
            sqlx::query(r#"
                UPDATE workflow_tasks
                SET 
                    status = $1, 
                    completed_at = $2, 
                    error = $3, 
                    updated_at = NOW(),
                    execution_time_ms = EXTRACT(EPOCH FROM ($2 - started_at)) * 1000
                WHERE task_id = $4
            "#)
            .bind("FAILED")
            .bind(failure_time)
            .bind(error.to_string())
            .bind(task_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            // 更新统计信息
            sqlx::query(r#"
                WITH task_type_query AS (
                    SELECT task_type FROM workflow_tasks WHERE task_id = $1
                )
                INSERT INTO task_statistics (
                    date, 
                    task_type, 
                    status, 
                    count
                ) 
                SELECT 
                    CURRENT_DATE, 
                    task_type, 
                    'FAILED', 
                    1
                FROM task_type_query
                ON CONFLICT (date, task_type, status)
                DO UPDATE SET count = task_statistics.count + 1
            "#)
            .bind(task_id.to_string())
            .execute(&*self.db_pool)
            .await
            .map_err(|e| ProjectionError::DatabaseError(e.to_string()))?;
            
            log::debug!("投影: 任务失败 task_id={}", task_id);
        }
        
        Ok(())
    }
}

/// 事件处理器
pub struct EventHandler {
    /// 投影管理器
    projections: Vec<Arc<dyn Projection>>,
}

impl EventHandler {
    /// 创建事件处理器
    pub fn new() -> Self {
        Self {
            projections: Vec::new(),
        }
    }
    
    /// 注册投影
    pub fn register_projection(&mut self, projection: Arc<dyn Projection>) {
        self.projections.push(projection);
    }
    
    /// 处理事件
    pub async fn handle_event(&self, event: &WorkflowEvent) -> Result<(), EventHandlerError> {
        // 并行处理每个投影
        let futures: Vec<_> = self.projections.iter()
            .map(|p| p.handle_event(event))
            .collect();
            
        // 等待所有投影完成
        let results = futures::future::join_all(futures).await;
        
        // 检查结果
        for result in results {
            if let Err(e) = result {
                return Err(EventHandlerError::ProjectionError(e.to_string()));
            }
        }
        
        Ok(())
    }
}

/// 仪表盘API服务
pub struct DashboardApiService {
    dashboard_service: Arc<DashboardService>,
}

impl DashboardApiService {
    /// 创建仪表盘API服务
    pub fn new(dashboard_service: Arc<DashboardService>) -> Self {
        Self {
            dashboard_service,
        }
    }
    
    /// 启动API服务
    pub async fn start(self, addr: SocketAddr) -> Result<(), std::io::Error> {
        let app = Router::new()
            // 仪表盘概览
            .route("/api/dashboard/overview", get(Self::get_dashboard_overview))
            // 工作流趋势
            .route("/api/dashboard/trends", get(Self::get_workflow_trends))
            // 活跃工作流
            .route("/api/dashboard/workflows/active", get(Self::get_active_workflows))
            // 失败工作流
            .route("/api/dashboard/workflows/failed", get(Self::get_failed_workflows))
            // 工作流类型分布
            .route("/api/dashboard/workflows/types", get(Self::get_workflow_type_distribution))
            // 任务执行时间分布
            .route("/api/dashboard/tasks/execution-times", get(Self::get_task_execution_time_distribution))
            // 系统资源使用情况
            .route("/api/dashboard/system/resources", get(Self::get_system_resource_usage))
            // 最近的告警
            .route("/api/dashboard/alerts/recent", get(Self::get_recent_alerts))
            // 工作流详情
            .route("/api/dashboard/workflows/:id", get(Self::get_workflow_details))
            // 工作流可视化数据
            .route("/api/dashboard/workflows/:id/visualization", get(Self::get_workflow_visualization))
            // 设置共享状态
            .with_state(self.dashboard_service);
            
        // 启动服务器
        axum::Server::bind(&addr)
            .serve(app.into_make_service())
            .await
    }
    
    /// 获取仪表盘概览
    async fn get_dashboard_overview(
        State(dashboard_service): State<Arc<DashboardService>>,
    ) -> Result<Json<DashboardOverview>, StatusCode> {
        dashboard_service.get_dashboard_overview().await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取工作流趋势
    async fn get_workflow_trends(
        State(dashboard_service): State<Arc<DashboardService>>,
        Query(params): Query<TrendParams>,
    ) -> Result<Json<WorkflowTrends>, StatusCode> {
        dashboard_service.get_workflow_trends(params.period).await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取活跃工作流
    async fn get_active_workflows(
        State(dashboard_service): State<Arc<DashboardService>>,
    ) -> Result<Json<Vec<WorkflowSummary>>, StatusCode> {
        dashboard_service.get_active_workflows().await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取失败工作流
    async fn get_failed_workflows(
        State(dashboard_service): State<Arc<DashboardService>>,
    ) -> Result<Json<Vec<WorkflowSummary>>, StatusCode> {
        dashboard_service.get_failed_workflows().await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取工作流类型分布
    async fn get_workflow_type_distribution(
        State(dashboard_service): State<Arc<DashboardService>>,
    ) -> Result<Json<HashMap<String, usize>>, StatusCode> {
        dashboard_service.get_workflow_type_distribution().await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取任务执行时间分布
    async fn get_task_execution_time_distribution(
        State(dashboard_service): State<Arc<DashboardService>>,
    ) -> Result<Json<HashMap<String, Vec<Duration>>>, StatusCode> {
        dashboard_service.get_task_execution_time_distribution().await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取系统资源使用情况
    async fn get_system_resource_usage(
        State(dashboard_service): State<Arc<DashboardService>>,
    ) -> Result<Json<SystemResourceUsage>, StatusCode> {
        dashboard_service.get_system_resource_usage().await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取最近的告警
    async fn get_recent_alerts(
        State(dashboard_service): State<Arc<DashboardService>>,
    ) -> Result<Json<Vec<Alert>>, StatusCode> {
        dashboard_service.get_recent_alerts().await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取工作流详情
    async fn get_workflow_details(
        State(dashboard_service): State<Arc<DashboardService>>,
        Path(id): Path<String>,
    ) -> Result<Json<WorkflowDetails>, StatusCode> {
        dashboard_service.get_workflow_details(&id).await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
    
    /// 获取工作流可视化数据
    async fn get_workflow_visualization(
        State(dashboard_service): State<Arc<DashboardService>>,
        Path(id): Path<String>,
    ) -> Result<Json<WorkflowVisualization>, StatusCode> {
        dashboard_service.get_workflow_visualization(&id).await
            .map(Json)
            .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)
    }
}

/// 工作流可视化引擎
pub struct VisualizationEngine {
    /// 事件存储
    event_store: Arc<dyn EventStore<WorkflowInstance>>,
}

impl VisualizationEngine {
    /// 创建工作流可视化引擎
    pub fn new(event_store: Arc<dyn EventStore<WorkflowInstance>>) -> Self {
        Self {
            event_store,
        }
    }
    
    /// 创建工作流可视化数据
    pub async fn create_workflow_visualization(
        &self,
        workflow_id: &str,
        config: VisualizationConfig,
    ) -> Result<WorkflowVisualization, VisualizationError> {
        // 加载工作流事件
        let events = self.event_store.load_events(workflow_id, 0, None).await
            .map_err(|e| VisualizationError::EventLoadFailed(e.to_string()))?;
            
        if events.is_empty() {
            return Err(VisualizationError::WorkflowNotFound(workflow_id.to_string()));
        }
        
        // 重建工作流状态
        let mut instance = WorkflowInstance::new(workflow_id);
        for event in &events {
            instance.apply(&event.event);
        }
        
        match config.format {
            VisualizationFormat::Graphviz => self.create_graphviz(&instance, &config),
            VisualizationFormat::Mermaid => self.create_mermaid(&instance, &config),
            VisualizationFormat::Json => self.create_json(&instance, &config),
            VisualizationFormat::Html => self.create_html(&instance, &config),
        }
    }
    
    /// 创建Graphviz可视化
    fn create_graphviz(
        &self,
        instance: &WorkflowInstance,
        config: &VisualizationConfig,
    ) -> Result<WorkflowVisualization, VisualizationError> {
        let mut dot = String::from("digraph workflow {\n");
        dot.push_str("  rankdir=LR;\n");
        dot.push_str("  node [shape=box, style=filled, color=black];\n\n");
        
        // 添加节点
        if let Some(definition) = &instance.definition {
            for step in &definition.steps {
                let color = match instance.steps.as_ref().and_then(|steps| steps.get(&step.id)) {
                    Some(step_state) => match step_state.status {
                        StepStatus::Completed => "green",
                        StepStatus::Failed => "red",
                        StepStatus::Running => "blue",
                        StepStatus::Pending => "gray",
                        StepStatus::Scheduled => "yellow",
                    },
                    None => "white",
                };
                
                let label = format!("{} ({})", step.name, step.step_type);
                dot.push_str(&format!("  \"{}\" [label=\"{}\", fillcolor={}];\n", 
                                      step.id, label, color));
            }
            
            // 添加边
            for step in &definition.steps {
                for next in &step.next_steps {
                    dot.push_str(&format!("  \"{}\" -> \"{}\";\n", step.id, next));
                }
            }
        }
        
        dot.push_str("}\n");
        
        Ok(WorkflowVisualization {
            workflow_id: instance.workflow_id.clone(),
            format: VisualizationFormat::Graphviz,
            content: dot,
            metadata: Some(json!({
                "workflow_type": instance.definition.as_ref().map(|d| d.workflow_type.clone()).unwrap_or_default(),
                "status": instance.stage.to_string(),
                "started_at": instance.started_at,
                "completed_at": instance.completed_at,
            })),
        })
    }
    
    /// 创建Mermaid可视化
    fn create_mermaid(
        &self,
        instance: &WorkflowInstance,
        config: &VisualizationConfig,
    ) -> Result<WorkflowVisualization, VisualizationError> {
        let mut mermaid = String::from("graph LR\n");
        
        // 添加节点
        if let Some(definition) = &instance.definition {
            for step in &definition.steps {
                let status_class = match instance.steps.as_ref().and_then(|steps| steps.get(&step.id)) {
                    Some(step_state) => match step_state.status {
                        StepStatus::Completed => "classDef completed fill:green",
                        StepStatus::Failed => "classDef failed fill:red",
                        StepStatus::Running => "classDef running fill:blue",
                        StepStatus::Pending => "classDef pending fill:gray",
                        StepStatus::Scheduled => "classDef scheduled fill:yellow",
                    },
                    None => "classDef default fill:white",
                };
                
                mermaid.push_str(&format!("    {}[{}]\n", step.id, step.name));
                mermaid.push_str(&format!("    {} {}\n", status_class, step.id));
            }
            
            // 添加边
            for step in &definition.steps {
                for next in &step.next_steps {
                    mermaid.push_str(&format!("    {} --> {}\n", step.id, next));
                }
            }
        }
        
        Ok(WorkflowVisualization {
            workflow_id: instance.workflow_id.clone(),
            format: VisualizationFormat::Mermaid,
            content: mermaid,
            metadata: Some(json!({
                "workflow_type": instance.definition.as_ref().map(|d| d.workflow_type.clone()).unwrap_or_default(),
                "status": instance.stage.to_string(),
                "started_at": instance.started_at,
                "completed_at": instance.completed_at,
            })),
        })
    }
    
    /// 创建JSON可视化
    fn create_json(
        &self,
        instance: &WorkflowInstance,
        config: &VisualizationConfig,
    ) -> Result<WorkflowVisualization, VisualizationError> {
        let mut nodes = Vec::new();
        let mut edges = Vec::new();
        
        // 添加节点
        if let Some(definition) = &instance.definition {
            for step in &definition.steps {
                let status = match instance.steps.as_ref().and_then(|steps| steps.get(&step.id)) {
                    Some(step_state) => step_state.status.to_string(),
                    None => "UNKNOWN".to_string(),
                };
                
                // 创建节点
                let node = json!({
                    "id": step.id,
                    "name": step.name,
                    "type": step.step_type,
                    "status": status,
                    "is_critical": step.is_critical,
                });
                
                nodes.push(node);
                
                // 创建边
                for next in &step.next_steps {
                    let edge = json!({
                        "source": step.id,
                        "target": next,
                    });
                    
                    edges.push(edge);
                }
            }
        }
        
        // 创建完整图表
        let graph = json!({
            "workflow_id": instance.workflow_id,
            "workflow_type": instance.definition.as_ref().map(|d| d.workflow_type.clone()).unwrap_or_default(),
            "status": instance.stage.to_string(),
            "started_at": instance.started_at,
            "completed_at": instance.completed_at,
            "nodes": nodes,
            "edges": edges,
        });
        
        Ok(WorkflowVisualization {
            workflow_id: instance.workflow_id.clone(),
            format: VisualizationFormat::Json,
            content: serde_json::to_string_pretty(&graph).unwrap_or_default(),
            metadata: Some(json!({
                "node_count": nodes.len(),
                "edge_count": edges.len(),
            })),
        })
    }
    
    /// 创建HTML可视化
    fn create_html(
        &self,
        instance: &WorkflowInstance,
        config: &VisualizationConfig,
    ) -> Result<WorkflowVisualization, VisualizationError> {
        // 先创建JSON数据
        let json_result = self.create_json(instance, config)?;
        let graph_data = json_result.content;
        
        // 构建HTML模板
        let html = format!(r#"
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>工作流可视化 - {}</title>
            <script src="https://cdn.jsdelivr.net/npm/d3@7"></script>
            <style>
                body {{ margin: 0; font-family: Arial, sans-serif; }}
                #container {{ width: 100%; height: 100vh; }}
                .node {{ cursor: pointer; }}
                .node circle {{ stroke: #fff; stroke-width: 2px; }}
                .node text {{ font-size: 12px; }}
                .link {{ fill: none; stroke: #999; stroke-opacity: 0.6; }}
                .status-completed {{ fill: #4CAF50; }}
                .status-failed {{ fill: #F44336; }}
                .status-running {{ fill: #2196F3; }}
                .status-pending {{ fill: #9E9E9E; }}
                .status-scheduled {{ fill: #FFC107; }}
                .tooltip {{ 
                    position: absolute;
                    background: #fff;
                    border: 1px solid #ddd;
                    border-radius: 4px;
                    padding: 10px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.2);
                    font-size: 12px;
                    pointer-events: none;
                    opacity: 0;
                    transition: opacity 0.2s;
                }}
                .tooltip table {{ border-collapse: collapse; }}
                .tooltip td {{ padding: 3px 8px; }}
                .tooltip td:first-child {{ font-weight: bold; }}
            </style>
        </head>
        <body>
            <div id="container"></div>
            <div id="tooltip" class="tooltip"></div>
            
            <script>
                // 工作流数据
                const workflowData = {graph_data};
                
                // 创建力导向图
                const width = window.innerWidth;
                const height = window.innerHeight;
                
                const svg = d3.select('#container')
                    .append('svg')
                    .attr('width', width)
                    .attr('height', height);
                    
                const g = svg.append('g');
                
                // 添加缩放功能
                const zoom = d3.zoom()
                    .scaleExtent([0.1, 4])
                    .on('zoom', (event) => {{
                        g.attr('transform', event.transform);
                    }});
                
                svg.call(zoom);
                
                // 创建力导向布局
                const simulation = d3.forceSimulation(workflowData.nodes)
                    .force('link', d3.forceLink(workflowData.edges).id(d => d.id).distance(100))
                    .force('charge', d3.forceManyBody().strength(-500))
                    .force('center', d3.forceCenter(width / 2, height / 2))
                    .force('collide', d3.forceCollide(50));
                
                // 创建链接
                const link = g.selectAll('.link')
                    .data(workflowData.edges)
                    .enter()
                    .append('path')
                    .attr('class', 'link')
                    .attr('marker-end', 'url(#arrow)');
                
                // 创建箭头标记
                svg.append('defs').append('marker')
                    .attr('id', 'arrow')
                    .attr('viewBox', '0 -5 10 10')
                    .attr('refX', 20)
                    .attr('refY', 0)
                    .attr('markerWidth', 6)
                    .attr('markerHeight', 6)
                    .attr('orient', 'auto')
                    .append('path')
                    .attr('d', 'M0,-5L10,0L0,5')
                    .attr('fill', '#999');
                
                // 创建节点组
                const node = g.selectAll('.node')
                    .data(workflowData.nodes)
                    .enter()
                    .append('g')
                    .attr('class', 'node')
                    .call(d3.drag()
                        .on('start', dragStarted)
                        .on('drag', dragged)
                        .on('end', dragEnded));
                
                // 添加节点圆形
                node.append('circle')
                    .attr('r', 30)
                    .attr('class', d => `status-${{d.status.toLowerCase()}}`)
                    .on('mouseover', showTooltip)
                    .on('mouseout', hideTooltip);
                
                // 添加节点文本
                node.append('text')
                    .attr('dy', '.35em')
                    .attr('text-anchor', 'middle')
                    .text(d => d.name.length > 10 ? d.name.substring(0, 10) + '...' : d.name)
                    .attr('fill', '#000');
                
                // 定义拖拽行为
                function dragStarted(event, d) {{
                    if (!event.active) simulation.alphaTarget(0.3).restart();
                    d.fx = d.x;
                    d.fy = d.y;
                }}
                
                function dragged(event, d) {{
                    d.fx = event.x;
                    d.fy = event.y;
                }}
                
                function dragEnded(event, d) {{
                    if (!event.active) simulation.alphaTarget(0);
                    d.fx = null;
                    d.fy = null;
                }}
                
                // 定义提示框行为
                function showTooltip(event, d) {{
                    const tooltip = d3.select('#tooltip');
                    
                    tooltip.style('opacity', 1)
                        .style('left', (event.pageX + 10) + 'px')
                        .style('top', (event.pageY + 10) + 'px')
                        .html(`
                            <table>
                                <tr><td>ID:</td><td>${{d.id}}</td></tr>
                                <tr><td>名称:</td><td>${{d.name}}</td></tr>
                                <tr><td>类型:</td><td>${{d.type}}</td></tr>
                                <tr><td>状态:</td><td>${{d.status}}</td></tr>
                                <tr><td>关键步骤:</td><td>${{d.is_critical ? '是' : '否'}}</td></tr>
                            </table>
                        `);
                }}
                
                function hideTooltip() {{
                    d3.select('#tooltip').style('opacity', 0);
                }}
                
                // 更新布局
                simulation.on('tick', () => {{
                    link.attr('d', d => {{
                        const dx = d.target.x - d.source.x;
                        const dy = d.target.y - d.source.y;
                        const dr = Math.sqrt(dx
                                        const dx = d.target.x - d.source.x;
                const dy = d.target.y - d.source.y;
                const dr = Math.sqrt(dx * dx + dy * dy);
                return `M${d.source.x},${d.source.y}A${dr},${dr} 0 0,1 ${d.target.x},${d.target.y}`;
            }});
                
            node.attr('transform', d => `translate(${d.x}, ${d.y})`);
        });
                
        // 添加工作流信息面板
        const infoPanel = d3.select('#container')
            .append('div')
            .attr('class', 'info-panel')
            .style('position', 'absolute')
            .style('top', '10px')
            .style('left', '10px')
            .style('background', 'rgba(255,255,255,0.9)')
            .style('padding', '10px')
            .style('border-radius', '4px')
            .style('border', '1px solid #ddd')
            .style('font-size', '14px')
            .html(`
                <h3>${workflowData.workflow_type || '未知工作流'}</h3>
                <table>
                    <tr><td>ID:</td><td>${workflowData.workflow_id}</td></tr>
                    <tr><td>状态:</td><td>${workflowData.status}</td></tr>
                    <tr><td>开始时间:</td><td>${new Date(workflowData.started_at).toLocaleString()}</td></tr>
                    ${workflowData.completed_at ? 
                        `<tr><td>完成时间:</td><td>${new Date(workflowData.completed_at).toLocaleString()}</td></tr>` : ''}
                    <tr><td>节点数:</td><td>${workflowData.nodes.length}</td></tr>
                </table>
            `);
            </script>
        </body>
        </html>
        "#, instance.workflow_id);
        
        Ok(WorkflowVisualization {
            workflow_id: instance.workflow_id.clone(),
            format: VisualizationFormat::Html,
            content: html,
            metadata: None,
        })
    }
}

/// 仪表盘前端组件
pub struct DashboardFrontend {
    /// 静态文件服务
    static_file_service: StaticFileService,
    /// API服务基础URL
    api_base_url: String,
}

impl DashboardFrontend {
    /// 创建仪表盘前端
    pub fn new(static_files_path: &str, api_base_url: &str) -> Self {
        Self {
            static_file_service: StaticFileService::new(static_files_path),
            api_base_url: api_base_url.to_string(),
        }
    }
    
    /// 提供前端静态文件
    pub fn serve_frontend(&self, req: &HttpRequest) -> Result<StaticFileResponse, std::io::Error> {
        let path = req.path();
        
        // 如果请求根路径，则返回主页
        let file_path = if path == "/" {
            "index.html"
        } else {
            // 移除开头的斜杠
            &path[1..]
        };
        
        self.static_file_service.serve_file(file_path)
    }
    
    /// 提供主页
    pub fn serve_index(&self) -> Result<String, std::io::Error> {
        let mut index_html = include_str!("../static/index.html").to_string();
        
        // 替换API基础URL
        index_html = index_html.replace("__API_BASE_URL__", &self.api_base_url);
        
        Ok(index_html)
    }
}

/// 仪表盘WebSocket处理器
pub struct DashboardWebsocketHandler {
    /// 工作流服务
    workflow_service: Arc<WorkflowService>,
    /// 指标收集器
    metrics_collector: Arc<MetricsCollector>,
    /// 事件总线
    event_bus: Arc<EventBus>,
    /// 会话管理器
    session_manager: Arc<SessionManager>,
    /// 会话ID
    session_id: String,
    /// 用户ID
    user_id: String,
    /// 订阅主题
    subscribed_topics: HashSet<String>,
    /// 订阅的工作流ID
    subscribed_workflows: HashSet<String>,
}

impl DashboardWebsocketHandler {
    /// 创建WebSocket处理器
    pub fn new(
        workflow_service: Arc<WorkflowService>,
        metrics_collector: Arc<MetricsCollector>,
        event_bus: Arc<EventBus>,
        session_manager: Arc<SessionManager>,
        session_id: String,
        user_id: String,
    ) -> Self {
        Self {
            workflow_service,
            metrics_collector,
            event_bus,
            session_manager,
            session_id,
            user_id,
            subscribed_topics: HashSet::new(),
            subscribed_workflows: HashSet::new(),
        }
    }
    
    /// 处理客户端消息
    pub async fn handle_message(&mut self, message: String) -> Result<Option<String>, WebSocketError> {
        let request: WebSocketRequest = serde_json::from_str(&message)
            .map_err(|e| WebSocketError::InvalidRequest(e.to_string()))?;
            
        match request.action.as_str() {
            "subscribe" => {
                self.handle_subscribe(&request).await
            },
            "unsubscribe" => {
                self.handle_unsubscribe(&request).await
            },
            "get_workflow" => {
                self.handle_get_workflow(&request).await
            },
            "get_dashboard_overview" => {
                self.handle_get_dashboard_overview(&request).await
            },
            "get_workflow_visualization" => {
                self.handle_get_workflow_visualization(&request).await
            },
            _ => {
                Err(WebSocketError::UnknownAction(request.action))
            }
        }
    }
    
    /// 处理订阅请求
    async fn handle_subscribe(&mut self, request: &WebSocketRequest) -> Result<Option<String>, WebSocketError> {
        if let Some(topic) = request.data.get("topic") {
            let topic = topic.as_str()
                .ok_or_else(|| WebSocketError::InvalidParameter("topic must be a string".to_string()))?;
                
            // 检查主题类型
            if topic.starts_with("workflow.") {
                // 订阅特定工作流
                let parts: Vec<&str> = topic.split('.').collect();
                if parts.len() >= 2 {
                    let workflow_id = parts[1];
                    self.subscribe_to_workflow(workflow_id).await?;
                }
            } else {
                // 订阅一般主题
                self.subscribe_to_topic(topic).await?;
            }
            
            // 返回成功响应
            let response = WebSocketResponse {
                correlation_id: request.correlation_id.clone(),
                status: "success".to_string(),
                data: json!({
                    "message": format!("Subscribed to {}", topic)
                }),
            };
            
            return Ok(Some(serde_json::to_string(&response)?));
        }
        
        Err(WebSocketError::MissingParameter("topic".to_string()))
    }
    
    /// 处理取消订阅请求
    async fn handle_unsubscribe(&mut self, request: &WebSocketRequest) -> Result<Option<String>, WebSocketError> {
        if let Some(topic) = request.data.get("topic") {
            let topic = topic.as_str()
                .ok_or_else(|| WebSocketError::InvalidParameter("topic must be a string".to_string()))?;
                
            // 检查主题类型
            if topic.starts_with("workflow.") {
                // 取消订阅特定工作流
                let parts: Vec<&str> = topic.split('.').collect();
                if parts.len() >= 2 {
                    let workflow_id = parts[1];
                    self.unsubscribe_from_workflow(workflow_id).await?;
                }
            } else {
                // 取消订阅一般主题
                self.unsubscribe_from_topic(topic).await?;
            }
            
            // 返回成功响应
            let response = WebSocketResponse {
                correlation_id: request.correlation_id.clone(),
                status: "success".to_string(),
                data: json!({
                    "message": format!("Unsubscribed from {}", topic)
                }),
            };
            
            return Ok(Some(serde_json::to_string(&response)?));
        }
        
        Err(WebSocketError::MissingParameter("topic".to_string()))
    }
    
    /// 处理获取工作流请求
    async fn handle_get_workflow(&self, request: &WebSocketRequest) -> Result<Option<String>, WebSocketError> {
        if let Some(workflow_id) = request.data.get("workflow_id") {
            let workflow_id = workflow_id.as_str()
                .ok_or_else(|| WebSocketError::InvalidParameter("workflow_id must be a string".to_string()))?;
                
            // 查询工作流详情
            let include_tasks = request.data.get("include_tasks")
                .and_then(|v| v.as_bool())
                .unwrap_or(true);
                
            let include_variables = request.data.get("include_variables")
                .and_then(|v| v.as_bool())
                .unwrap_or(false);
                
            let workflow = self.workflow_service.get_workflow_details(workflow_id, include_tasks, include_variables)
                .await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?;
                
            // 返回成功响应
            let response = WebSocketResponse {
                correlation_id: request.correlation_id.clone(),
                status: "success".to_string(),
                data: serde_json::to_value(workflow)?,
            };
            
            return Ok(Some(serde_json::to_string(&response)?));
        }
        
        Err(WebSocketError::MissingParameter("workflow_id".to_string()))
    }
    
    /// 处理获取仪表盘概览请求
    async fn handle_get_dashboard_overview(&self, request: &WebSocketRequest) -> Result<Option<String>, WebSocketError> {
        // 获取仪表盘概览数据
        let overview = DashboardOverview {
            active_workflows: self.workflow_service.count_active_workflows().await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            completed_workflows: self.workflow_service.count_completed_workflows().await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            failed_workflows: self.workflow_service.count_failed_workflows().await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            scheduled_tasks: self.workflow_service.count_scheduled_tasks().await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            active_tasks: self.workflow_service.count_active_tasks().await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            completed_tasks_today: self.workflow_service.count_completed_tasks_today().await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            failed_tasks_today: self.workflow_service.count_failed_tasks_today().await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            system_health: self.get_system_health().await,
            recent_errors: self.workflow_service.get_recent_errors(5).await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
            latest_workflows: self.workflow_service.get_latest_workflows(5).await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?,
        };
        
        // 返回成功响应
        let response = WebSocketResponse {
            correlation_id: request.correlation_id.clone(),
            status: "success".to_string(),
            data: serde_json::to_value(overview)?,
        };
        
        Ok(Some(serde_json::to_string(&response)?))
    }
    
    /// 处理获取工作流可视化请求
    async fn handle_get_workflow_visualization(&self, request: &WebSocketRequest) -> Result<Option<String>, WebSocketError> {
        if let Some(workflow_id) = request.data.get("workflow_id") {
            let workflow_id = workflow_id.as_str()
                .ok_or_else(|| WebSocketError::InvalidParameter("workflow_id must be a string".to_string()))?;
                
            // 获取可视化配置
            let format = request.data.get("format")
                .and_then(|v| v.as_str())
                .unwrap_or("json");
                
            let format = match format {
                "graphviz" => VisualizationFormat::Graphviz,
                "mermaid" => VisualizationFormat::Mermaid,
                "html" => VisualizationFormat::Html,
                _ => VisualizationFormat::Json,
            };
            
            let include_execution_status = request.data.get("include_execution_status")
                .and_then(|v| v.as_bool())
                .unwrap_or(true);
                
            let include_data = request.data.get("include_data")
                .and_then(|v| v.as_bool())
                .unwrap_or(false);
                
            let include_timing = request.data.get("include_timing")
                .and_then(|v| v.as_bool())
                .unwrap_or(true);
                
            let include_metrics = request.data.get("include_metrics")
                .and_then(|v| v.as_bool())
                .unwrap_or(true);
                
            let show_unexecuted_steps = request.data.get("show_unexecuted_steps")
                .and_then(|v| v.as_bool())
                .unwrap_or(true);
                
            let layout_algorithm = request.data.get("layout_algorithm")
                .and_then(|v| v.as_str())
                .unwrap_or("dagre")
                .to_string();
                
            let theme = request.data.get("theme")
                .and_then(|v| v.as_str())
                .map(|t| match t {
                    "dark" => VisualizationTheme::Dark,
                    _ => VisualizationTheme::Light,
                })
                .unwrap_or(VisualizationTheme::Light);
                
            let config = VisualizationConfig {
                format,
                include_execution_status,
                include_data,
                include_timing,
                include_metrics,
                show_unexecuted_steps,
                layout_algorithm,
                theme,
                custom_config: HashMap::new(),
            };
            
            // 创建可视化引擎
            let visualization = self.create_workflow_visualization(workflow_id, config).await
                .map_err(|e| WebSocketError::ServiceError(e.to_string()))?;
                
            // 返回成功响应
            let response = WebSocketResponse {
                correlation_id: request.correlation_id.clone(),
                status: "success".to_string(),
                data: serde_json::to_value(visualization)?,
            };
            
            return Ok(Some(serde_json::to_string(&response)?));
        }
        
        Err(WebSocketError::MissingParameter("workflow_id".to_string()))
    }
    
    /// 订阅主题
    async fn subscribe_to_topic(&mut self, topic: &str) -> Result<(), WebSocketError> {
        if self.subscribed_topics.contains(topic) {
            // 已经订阅过，直接返回
            return Ok(());
        }
        
        // 注册到事件总线
        let session_id = self.session_id.clone();
        self.event_bus.subscribe(topic, move |event| {
            // 转发事件到会话
            self.session_manager.send_message(&session_id, event)
                .map_err(|e| EventBusError::DeliveryFailed(e.to_string()))
        })
        .await
        .map_err(|e| WebSocketError::SubscriptionError(e.to_string()))?;
        
        // 添加到已订阅主题
        self.subscribed_topics.insert(topic.to_string());
        
        Ok(())
    }
    
    /// 取消订阅主题
    async fn unsubscribe_from_topic(&mut self, topic: &str) -> Result<(), WebSocketError> {
        if !self.subscribed_topics.contains(topic) {
            // 未订阅，直接返回
            return Ok(());
        }
        
        // 从事件总线取消订阅
        self.event_bus.unsubscribe(topic, &self.session_id)
            .await
            .map_err(|e| WebSocketError::SubscriptionError(e.to_string()))?;
        
        // 从已订阅主题删除
        self.subscribed_topics.remove(topic);
        
        Ok(())
    }
    
    /// 订阅工作流
    async fn subscribe_to_workflow(&mut self, workflow_id: &str) -> Result<(), WebSocketError> {
        if self.subscribed_workflows.contains(workflow_id) {
            // 已经订阅过，直接返回
            return Ok(());
        }
        
        // 订阅工作流相关主题
        let workflow_topic = format!("workflow.{}", workflow_id);
        self.subscribe_to_topic(&workflow_topic).await?;
        
        // 订阅任务主题
        let tasks_topic = format!("workflow.{}.tasks", workflow_id);
        self.subscribe_to_topic(&tasks_topic).await?;
        
        // 添加到已订阅工作流
        self.subscribed_workflows.insert(workflow_id.to_string());
        
        Ok(())
    }
    
    /// 取消订阅工作流
    async fn unsubscribe_from_workflow(&mut self, workflow_id: &str) -> Result<(), WebSocketError> {
        if !self.subscribed_workflows.contains(workflow_id) {
            // 未订阅，直接返回
            return Ok(());
        }
        
        // 取消订阅工作流相关主题
        let workflow_topic = format!("workflow.{}", workflow_id);
        self.unsubscribe_from_topic(&workflow_topic).await?;
        
        // 取消订阅任务主题
        let tasks_topic = format!("workflow.{}.tasks", workflow_id);
        self.unsubscribe_from_topic(&tasks_topic).await?;
        
        // 从已订阅工作流删除
        self.subscribed_workflows.remove(workflow_id);
        
        Ok(())
    }
    
    /// 获取系统健康状态
    async fn get_system_health(&self) -> SystemHealth {
        // 获取节点健康状态
        let nodes = self.workflow_service.get_node_health_status()
            .await
            .unwrap_or_default();
            
        // 计算系统整体健康状态
        let overall_status = if nodes.iter().any(|n| n.status == "DOWN") {
            "DEGRADED"
        } else if nodes.iter().all(|n| n.status == "UP") {
            "HEALTHY"
        } else {
            "WARNING"
        };
        
        SystemHealth {
            status: overall_status.to_string(),
            nodes,
            last_checked: Utc::now(),
        }
    }
    
    /// 创建工作流可视化
    async fn create_workflow_visualization(&self, workflow_id: &str, config: VisualizationConfig) -> Result<WorkflowVisualization, ServiceError> {
        // 获取可视化引擎
        let visualization_engine = self.workflow_service.get_visualization_engine();
        
        // 创建可视化
        visualization_engine.create_workflow_visualization(workflow_id, config)
            .await
            .map_err(|e| ServiceError::InternalError(e.to_string()))
    }
}

/// 前端React组件定义
pub static DASHBOARD_REACT_APP: &str = r#"
// 工作流仪表盘React应用

import React, { useState, useEffect, useCallback } from 'react';
import { 
  Container, Grid, Paper, Typography, Box, CircularProgress,
  Table, TableBody, TableCell, TableContainer, TableHead, TableRow,
  Card, CardContent, CardHeader, Divider, Button, Chip, IconButton,
  List, ListItem, ListItemText, ListItemIcon, AppBar, Toolbar, Tabs, Tab,
  LinearProgress, Select, MenuItem, FormControl, InputLabel
} from '@mui/material';
import {
  Refresh as RefreshIcon,
  CheckCircle as SuccessIcon,
  Cancel as FailedIcon,
  HourglassEmpty as PendingIcon,
  PlayArrow as RunningIcon,
  Warning as WarningIcon,
  Timeline as TimelineIcon,
  Visibility as VisibilityIcon,
  Dashboard as DashboardIcon,
  List as ListIcon,
  Settings as SettingsIcon,
  Notifications as NotificationsIcon,
  Assessment as AssessmentIcon
} from '@mui/icons-material';
import { BarChart, Bar, LineChart, Line, PieChart, Pie, ResponsiveContainer,
  XAxis, YAxis, CartesianGrid, Tooltip, Legend, Cell } from 'recharts';
import { useParams, useNavigate, Routes, Route, Link } from 'react-router-dom';

// 颜色配置
const COLORS = {
  primary: '#2196f3',
  success: '#4caf50',
  warning: '#ff9800',
  error: '#f44336',
  info: '#00bcd4',
  pending: '#9e9e9e',
  running: '#2196f3',
  completed: '#4caf50',
  failed: '#f44336',
  scheduled: '#ff9800',
};

// 状态图标映射
const StatusIcon = ({ status }) => {
  switch (status?.toUpperCase()) {
    case 'COMPLETED':
    case 'SUCCESS':
      return <SuccessIcon style={{ color: COLORS.success }} />;
    case 'FAILED':
    case 'ERROR':
      return <FailedIcon style={{ color: COLORS.error }} />;
    case 'RUNNING':
      return <RunningIcon style={{ color: COLORS.running }} />;
    case 'PENDING':
      return <PendingIcon style={{ color: COLORS.pending }} />;
    case 'SCHEDULED':
      return <PendingIcon style={{ color: COLORS.scheduled }} />;
    default:
      return <WarningIcon style={{ color: COLORS.warning }} />;
  }
};

// 主应用组件
function App() {
  return (
    <div className="App">
      <AppBar position="static">
        <Toolbar>
          <DashboardIcon sx={{ mr: 2 }} />
          <Typography variant="h6" component="div" sx={{ flexGrow: 1 }}>
            工作流仪表盘
          </Typography>
          <IconButton color="inherit">
            <NotificationsIcon />
          </IconButton>
          <IconButton color="inherit">
            <SettingsIcon />
          </IconButton>
        </Toolbar>
      </AppBar>

      <Box sx={{ display: 'flex' }}>
        <Box
          component="nav"
          sx={{ width: 240, flexShrink: 0 }}
        >
          <List>
            <ListItem button component={Link} to="/">
              <ListItemIcon>
                <DashboardIcon />
              </ListItemIcon>
              <ListItemText primary="仪表盘" />
            </ListItem>
            <ListItem button component={Link} to="/workflows">
              <ListItemIcon>
                <ListIcon />
              </ListItemIcon>
              <ListItemText primary="工作流列表" />
            </ListItem>
            <ListItem button component={Link} to="/analytics">
              <ListItemIcon>
                <AssessmentIcon />
              </ListItemIcon>
              <ListItemText primary="分析" />
            </ListItem>
          </List>
        </Box>

        <Box component="main" sx={{ flexGrow: 1, p: 3 }}>
          <Routes>
            <Route path="/" element={<Dashboard />} />
            <Route path="/workflows" element={<WorkflowList />} />
            <Route path="/workflows/:id" element={<WorkflowDetails />} />
            <Route path="/analytics" element={<Analytics />} />
          </Routes>
        </Box>
      </Box>
    </div>
  );
}

// 仪表盘组件
function Dashboard() {
  const [loading, setLoading] = useState(true);
  const [overview, setOverview] = useState(null);
  const [error, setError] = useState(null);

  const fetchDashboardData = useCallback(async () => {
    setLoading(true);
    try {
      const response = await fetch('/api/dashboard/overview');
      if (!response.ok) {
        throw new Error('获取仪表盘数据失败');
      }
      const data = await response.json();
      setOverview(data);
      setError(null);
    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  }, []);

  useEffect(() => {
    fetchDashboardData();
    
    // 每分钟刷新一次
    const interval = setInterval(fetchDashboardData, 60000);
    return () => clearInterval(interval);
  }, [fetchDashboardData]);

  if (loading && !overview) {
    return (
      <Box sx={{ display: 'flex', justifyContent: 'center', mt: 4 }}>
        <CircularProgress />
      </Box>
    );
  }

  if (error) {
    return (
      <Box sx={{ mt: 2 }}>
        <Typography color="error">{error}</Typography>
        <Button 
          startIcon={<RefreshIcon />} 
          variant="contained" 
          onClick={fetchDashboardData}
          sx={{ mt: 2 }}
        >
          重试
        </Button>
      </Box>
    );
  }

  return (
    <Container maxWidth="lg">
      <Box sx={{ display: 'flex', justifyContent: 'space-between', mb: 3 }}>
        <Typography variant="h4" component="h1">
          仪表盘概览
        </Typography>
        <Button 
          startIcon={<RefreshIcon />} 
          variant="outlined" 
          onClick={fetchDashboardData}
        >
          刷新
        </Button>
      </Box>

      <Grid container spacing={3}>
        {/* 状态卡片 */}
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="活跃工作流" 
            value={overview?.active_workflows || 0} 
            icon={<RunningIcon />} 
            color={COLORS.running} 
          />
        </Grid>
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="已完成工作流" 
            value={overview?.completed_workflows || 0} 
            icon={<SuccessIcon />} 
            color={COLORS.success} 
          />
        </Grid>
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="失败工作流" 
            value={overview?.failed_workflows || 0} 
            icon={<FailedIcon />} 
            color={COLORS.error} 
          />
        </Grid>
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="待调度任务" 
            value={overview?.scheduled_tasks || 0} 
            icon={<PendingIcon />} 
            color={COLORS.scheduled} 
          />
        </Grid>

        {/* 系统健康 */}
        <Grid item xs={12} md={6}>
          <Paper sx={{ p: 2, height: '100%' }}>
            <Typography variant="h6" gutterBottom>
              系统健康
            </Typography>
            <Box sx={{ display: 'flex', alignItems: 'center', mb: 2 }}>
              <Chip 
                icon={getHealthIcon(overview?.system_health?.status)} 
                label={getHealthStatusText(overview?.system_health?.status)}
                color={getHealthColor(overview?.system_health?.status)}
                sx={{ mr: 2 }}
              />
              <Typography variant="body2" color="textSecondary">
                最后检查: {formatDateTime(overview?.system_health?.last_checked)}
              </Typography>
            </Box>
            
            <TableContainer>
              <Table size="small">
                <TableHead>
                  <TableRow>
                    <TableCell>节点</TableCell>
                    <TableCell>状态</TableCell>
                    <TableCell>负载</TableCell>
                  </TableRow>
                </TableHead>
                <TableBody>
                  {overview?.system_health?.nodes?.map((node) => (
                    <TableRow key={node.id}>
                      <TableCell>{node.name}</TableCell>
                      <TableCell>
                        <Chip 
                          size="small"
                          label={node.status}
                          color={node.status === 'UP' ? 'success' : 'error'}
                        />
                      </TableCell>
                      <TableCell>
                        <LinearProgress 
                          variant="determinate" 
                          value={node.load || 0} 
                          color={getLoadColor(node.load)} 
                        />
                        <Typography variant="caption">{node.load}%</Typography>
                      </TableCell>
                    </TableRow>
                  ))}
                </TableBody>
              </Table>
            </TableContainer>
          </Paper>
        </Grid>

        {/* 最近错误 */}
        <Grid item xs={12} md={6}>
          <Paper sx={{ p: 2, height: '100%' }}>
            <Typography variant="h6" gutterBottom>
              最近错误
            </Typography>
            {overview?.recent_errors?.length > 0 ? (
              <List>
                {overview.recent_errors.map((error, index) => (
                  <ListItem key={index} divider={index < overview.recent_errors.length - 1}>
                    <ListItemIcon>
                      <FailedIcon color="error" />
                    </ListItemIcon>
                    <ListItemText
                      primary={error.message}
                      secondary={
                        <>
                          {error.workflow_id && (
                            <Typography variant="body2" component="span">
                              工作流: {error.workflow_id}
                            </Typography>
                          )}
                          <Typography variant="body2" component="span" sx={{ ml: error.workflow_id ? 2 : 0 }}>
                            时间: {formatDateTime(error.timestamp)}
                          </Typography>
                        </>
                      }
                    />
                  </ListItem>
                ))}
              </List>
            ) : (
              <Box sx={{ py: 2, textAlign: 'center' }}>
                <Typography variant="body2" color="textSecondary">
                  没有最近错误
                </Typography>
              </Box>
            )}
          </Paper>
        </Grid>

        {/* 状态趋势图 */}
        <Grid item xs={12}>
          <Paper sx={{ p: 2 }}>
            <Typography variant="h6" gutterBottom>
              工作流趋势
            </Typography>
            <Box sx={{ height: 300 }}>
              <ResponsiveContainer width="100%" height="100%">
                <LineChart data={overview?.workflow_trends || []}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis dataKey="time" />
                  <YAxis />
                  <Tooltip />
                  <Legend />
                  <Line type="monotone" dataKey="completed" stroke={COLORS.success} name="已完成" />
                  <Line type="monotone" dataKey="running" stroke={COLORS.running} name="运行中" />
                  <Line type="monotone" dataKey="failed" stroke={COLORS.error} name="失败" />
                </LineChart>
              </ResponsiveContainer>
            </Box>
          </Paper>
        </Grid>

        {/* 最新工作流 */}
        <Grid item xs={12}>
          <Paper>
            <TableContainer>
              <Table>
                <TableHead>
                  <TableRow>
                    <TableCell>ID</TableCell>
                    <TableCell>类型</TableCell>
                    <TableCell>状态</TableCell>
                    <TableCell>开始时间</TableCell>
                    <TableCell>持续时间</TableCell>
                    <TableCell>操作</TableCell>
                  </TableRow>
                </TableHead>
                <TableBody>
                  {overview?.latest_workflows?.map((workflow) => (
                    <TableRow key={workflow.id}>
                      <TableCell>{workflow.id}</TableCell>
                      <TableCell>{workflow.type}</TableCell>
                      <TableCell>
                        <Box sx={{ display: 'flex', alignItems: 'center' }}>
                          <StatusIcon status={workflow.status} />
                          <Typography variant="body2" sx={{ ml: 1 }}>
                            {workflow.status}
                          </Typography>
                        </Box>
                      </TableCell>
                      <TableCell>{formatDateTime(workflow.started_at)}</TableCell>
                      <TableCell>{formatDuration(workflow.duration)}</TableCell>
                      <TableCell>
                        <IconButton
                          component={Link}
                          to={`/workflows/${workflow.id}`}
                          size="small"
                          title="查看详情"
                        >
                          <VisibilityIcon fontSize="small" />
                        </IconButton>
                      </TableCell>
                    </TableRow>
                  ))}
                </TableBody>
              </Table>
            </TableContainer>
            <Box sx={{ textAlign: 'center', p: 1 }}>
              <Button
                component={Link}
                to="/workflows"
                color="primary"
              >
                查看全部工作流
              </Button>
            </Box>
          </Paper>
        </Grid>
      </Grid>
    </Container>
  );
}

// 指标卡片组件
function MetricCard({ title, value, icon, color }) {
  return (
    <Card sx={{ height: '100%' }}>
      <CardContent>
        <Box sx={{ display: 'flex', alignItems: 'center', mb: 2 }}>
          <Box sx={{ 
            bgcolor: `${color}22`,
            borderRadius: '50%',
            p: 1,
            mr: 2,
            display: 'flex'
          }}>
            {React.cloneElement(icon, { style: { color } })}
          </Box>
          <Typography variant="h6" component="div">
            {title}
          </Typography>
        </Box>
        <Typography variant="h4" component="div">
          {value}
        </Typography>
      </CardContent>
    </Card>
  );
}

// 工作流列表组件
function WorkflowList() {
  const [loading, setLoading] = useState(true);
  const [workflows, setWorkflows] = useState([]);
  const [error, setError] = useState(null);
  const [page, setPage] = useState(0);
  const [pageSize, setPageSize] = useState(10);
  const [totalCount, setTotalCount] = useState(0);
  const [filters, setFilters] = useState({
    status: '',
    type: '',
    timeRange: '24h'
  });

  const fetchWorkflows = useCallback(async () => {
    setLoading(true);
    try {
      const queryParams = new URLSearchParams({
        page: page.toString(),
        page_size: pageSize.toString(),
        ...(filters.status && { status: filters.status }),
        ...(filters.type && { type: filters.type }),
        ...(filters.timeRange && { time_range: filters.timeRange })
      });
      
      const response = await fetch(`/api/workflows?${queryParams}`);
      if (!response.ok) {
        throw new Error('获取工作流列表失败');
      }
      
      const data = await response.json();
      setWorkflows(data.items || []);
      setTotalCount(data.total_count || 0);
      setError(null);
    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  }, [page, pageSize, filters]);

  useEffect(() => {
    fetchWorkflows();
  }, [fetchWorkflows]);

  const handlePageChange = (event, newPage) => {
    setPage(newPage);
  };

  const handlePageSizeChange = (event) => {
    setPageSize(parseInt(event.target.value, 10));
    setPage(0);
  };

  const handleFilterChange = (key, value) => {
    setFilters(prev => ({
      ...prev,
      [key]: value
    }));
    setPage(0);
  };

  return (
    <Container maxWidth="lg">
      <Box sx={{ display: 'flex', justifyContent: 'space-between', mb: 3 }}>
        <Typography variant="h4" component="h1">
          工作流列表
        </Typography>
        <Button 
          startIcon={<RefreshIcon />} 
          variant="outlined" 
          onClick={fetchWorkflows}
        >
          刷新
        </Button>
      </Box>

      {/* 筛选器 */}
      <Paper sx={{ p: 2, mb: 3 }}>
        <Grid container spacing={2} alignItems="center">
          <Grid item xs={12} sm={4} md={3}>
            <FormControl fullWidth size="small">
              <InputLabel id="status-filter-label">状态</InputLabel>
              <Select
                labelId="status-filter-label"
                value={filters.status}
                label="状态"
                onChange={(e) => handleFilterChange('status', e.target.value)}
              >
                <MenuItem value="">全部</MenuItem>
                <MenuItem value="RUNNING">运行中</MenuItem>
                <MenuItem value="COMPLETED">已完成</MenuItem>
                <MenuItem value="FAILED">失败</MenuItem>
                <MenuItem value="SCHEDULED">已调度</MenuItem>
              </Select>
            </FormControl>
          </Grid>
          <Grid item xs={12} sm={4} md={3}>
            <FormControl fullWidth size="small">
              <InputLabel id="type-filter-label">工作流类型</InputLabel>
              <Select
                labelId="type-filter-label"
                value={filters.type}
                label="工作流类型"
                onChange={(e) => handleFilterChange('type', e.target.value)}
              >
                <MenuItem value="">全部</MenuItem>
                <MenuItem value="ORDER_PROCESSING">订单处理</MenuItem>
                <MenuItem value="DATA_PROCESSING">数据处理</MenuItem>
                <MenuItem value="SERVICE_DEPLOYMENT">服务部署</MenuItem>
              </Select>
            </FormControl>
          </Grid>
          <Grid item xs={12} sm={4} md={3}>
            <FormControl fullWidth size="small">
              <InputLabel id="time-range-filter-label">时间范围</InputLabel>
              <Select
                labelId="time-range-filter-label"
                value={filters.timeRange}
                label="时间范围"
                onChange={(e) => handleFilterChange('timeRange', e.target.value)}
              >
                <MenuItem value="1h">最近1小时</MenuItem>
                <MenuItem value="6h">最近6小时</MenuItem>
                <MenuItem value="24h">最近24小时</MenuItem>
                <MenuItem value="7d">最近7天</MenuItem>
                <MenuItem value="30d">最近30天</MenuItem>
              </Select>
            </FormControl>
          </Grid>
        </Grid>
      </Paper>

      {/* 工作流列表 */}
      <Paper>
        {loading && (
          <LinearProgress />
        )}
        <TableContainer>
          <Table>
            <TableHead>
              <TableRow>
                <TableCell>ID</TableCell>
                <TableCell>类型</TableCell>
                <TableCell>状态</TableCell>
                <TableCell>开始时间</TableCell>
                <TableCell>完成时间</TableCell>
                <TableCell>持续时间</TableCell>
                <TableCell>节点</TableCell>
                <TableCell>操作</TableCell>
              </TableRow>
            </TableHead>
            <TableBody>
              {workflows.map((workflow) => (
                <TableRow key={workflow.id}>
                  <TableCell>{workflow.id}</TableCell>
                  <TableCell>{workflow.type}</TableCell>
                  <TableCell>
                    <Box sx={{ display: 'flex', alignItems: 'center' }}>
                      <StatusIcon status={workflow.status} />
                      <Typography variant="body2" sx={{ ml: 1 }}>
                        {workflow.status}
                      </Typography>
                    </Box>
                  </TableCell>
                  <TableCell>{formatDateTime(workflow.started_at)}</TableCell>
                  <TableCell>{workflow.completed_at ? formatDateTime(workflow.completed_at) : '-'}</TableCell>
                  <TableCell>{formatDuration(workflow.duration)}</TableCell>
                  <TableCell>
                    <Box sx={{ display: 'flex', alignItems: 'center' }}>
                      <Typography variant="body2">
                        {workflow.completed_nodes} / {workflow.total_nodes}
                      </Typography>
                      <LinearProgress 
                        variant="determinate" 
                        value={(workflow.completed_nodes / workflow.total_nodes) * 100} 
                        sx={{ ml: 1, width: '50px' }}
                      />
                    </Box>
                  </TableCell>
                  <TableCell>
                    <IconButton
                      component={Link}
                      to={`/workflows/${workflow.id}`}
                      size="small"
                      title="查看详情"
                    >
                      <VisibilityIcon fontSize="small" />
                    </IconButton>
                  </TableCell>
                </TableRow>
              ))}
              {workflows.length === 0 && !loading && (
                <TableRow>
                  <TableCell colSpan={8} align="center" sx={{ py: 3 }}>
                    <Typography variant="body2" color="textSecondary">
                      {error ? `错误: ${error}` : '没有找到工作流'}
                    </Typography>
                  </TableCell>
                </TableRow>
              )}
            </TableBody>
          </Table>
        </TableContainer>
        
        {/* 分页 */}
        <Box sx={{ p: 2, display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
          <FormControl variant="outlined" size="small">
            <Select
              value={pageSize}
              onChange={handlePageSizeChange}
            >
              <MenuItem value={10}>10 条/页</MenuItem>
              <MenuItem value={25}>25 条/页</MenuItem>
              <MenuItem value={50}>50 条/页</MenuItem>
              <MenuItem value={100}>100 条/页</MenuItem>
            </Select>
          </FormControl>
          <Pagination 
            count={Math.ceil(totalCount / pageSize)} 
            page={page + 1} 
            onChange={(e, p) => handlePageChange(e, p - 1)}
            color="primary" 
          />
        </Box>
      </Paper>
    </Container>
  );
}

// 工作流详情组件
function WorkflowDetails() {
  const { id } = useParams();
  const [loading, setLoading] = useState(true);
  const [workflow, setWorkflow] = useState(null);
  const [error, setError] = useState(null);
  const [activeTab, setActiveTab] = useState(0);
  const [visualizationConfig, setVisualizationConfig] = useState({
    format: 'svg',
    theme: 'light',
    showData: false,
    showTiming: true,
    layoutAlgorithm: 'dagre'
  });
  const [visualization, setVisualization] = useState(null);
  const visualizationRef = useRef(null);
  const websocketRef = useRef(null);

  // 获取工作流详情
  const fetchWorkflowDetails = useCallback(async () => {
    setLoading(true);
    try {
      const response = await fetch(`/api/workflows/${id}`);
      if (!response.ok) {
        throw new Error('获取工作流详情失败');
      }
      
      const data = await response.json();
      setWorkflow(data);
      setError(null);
    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  }, [id]);

  // 获取工作流可视化
  const fetchWorkflowVisualization = useCallback(async () => {
    try {
      const response = await fetch(`/api/workflows/${id}/visualization`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          format: visualizationConfig.format,
          include_data: visualizationConfig.showData,
          include_timing: visualizationConfig.showTiming,
          layout_algorithm: visualizationConfig.layoutAlgorithm,
          theme: visualizationConfig.theme
        })
      });
      
      if (!response.ok) {
        throw new Error('获取工作流可视化数据失败');
      }
      
      const data = await response.json();
      setVisualization(data);
      
      // 如果是SVG或HTML格式，渲染到DOM
      if (['svg', 'html'].includes(visualizationConfig.format) && visualizationRef.current) {
        visualizationRef.current.innerHTML = data.content;
      }
    } catch (err) {
      console.error('可视化加载错误:', err);
    }
  }, [id, visualizationConfig]);

  // 连接WebSocket获取实时更新
  const connectWebSocket = useCallback(() => {
    // 关闭已有的连接
    if (websocketRef.current) {
      websocketRef.current.close();
    }
    
    // 创建新连接
    const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const wsUrl = `${wsProtocol}//${window.location.host}/ws/workflow/${id}`;
    
    const ws = new WebSocket(wsUrl);
    
    ws.onopen = () => {
      console.log('WebSocket已连接，订阅工作流更新');
      ws.send(JSON.stringify({
        action: 'subscribe',
        correlation_id: Date.now().toString(),
        data: {
          topic: `workflow.${id}`
        }
      }));
    };
    
    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data);
        
        // 处理工作流状态更新
        if (data.type === 'workflow_update') {
          setWorkflow(prev => ({
            ...prev,
            ...data.workflow
          }));
        }
        
        // 处理任务更新
        if (data.type === 'task_update' && workflow) {
          setWorkflow(prev => {
            if (!prev) return prev;
            
            const updatedTasks = [...(prev.tasks || [])];
            const taskIndex = updatedTasks.findIndex(t => t.id === data.task.id);
            
            if (taskIndex >= 0) {
              updatedTasks[taskIndex] = {
                ...updatedTasks[taskIndex],
                ...data.task
              };
            } else {
              updatedTasks.push(data.task);
            }
            
            return {
              ...prev,
              tasks: updatedTasks
            };
          });
        }
      } catch (err) {
        console.error('解析WebSocket消息失败:', err);
      }
    };
    
    ws.onerror = (error) => {
      console.error('WebSocket错误:', error);
    };
    
    ws.onclose = () => {
      console.log('WebSocket连接已关闭');
      // 如果工作流仍在运行，5秒后尝试重连
      if (workflow && workflow.status === 'RUNNING') {
        setTimeout(connectWebSocket, 5000);
      }
    };
    
    websocketRef.current = ws;
  }, [id, workflow]);

  useEffect(() => {
    fetchWorkflowDetails();
  }, [fetchWorkflowDetails]);

  useEffect(() => {
    if (workflow && activeTab === 1) {
      fetchWorkflowVisualization();
    }
  }, [workflow, activeTab, fetchWorkflowVisualization]);

  useEffect(() => {
    if (workflow && workflow.status === 'RUNNING') {
      connectWebSocket();
      
      // 定期刷新详情（作为WebSocket的备份机制）
      const interval = setInterval(fetchWorkflowDetails, 30000);
      return () => clearInterval(interval);
    }
  }, [workflow, connectWebSocket, fetchWorkflowDetails]);

  // 清理WebSocket连接
  useEffect(() => {
    return () => {
      if (websocketRef.current) {
        websocketRef.current.close();
      }
    };
  }, []);

  const handleTabChange = (event, newValue) => {
    setActiveTab(newValue);
  };

  const handleVisualizationConfigChange = (key, value) => {
    setVisualizationConfig(prev => ({
      ...prev,
      [key]: value
    }));
  };

  if (loading && !workflow) {
    return (
      <Box sx={{ display: 'flex', justifyContent: 'center', mt: 4 }}>
        <CircularProgress />
      </Box>
    );
  }

  if (error) {
    return (
      <Box sx={{ mt: 2 }}>
        <Typography color="error">{error}</Typography>
        <Button 
          startIcon={<RefreshIcon />} 
          variant="contained" 
          onClick={fetchWorkflowDetails}
          sx={{ mt: 2 }}
        >
          重试
        </Button>
      </Box>
    );
  }

  return (
    <Container maxWidth="lg">
      <Box sx={{ mb: 3 }}>
        <Button 
          component={Link}
          to="/workflows"
          sx={{ mb: 2 }}
        >
          返回工作流列表
        </Button>
        
        {/* 工作流头部信息 */}
        <Paper sx={{ p: 3, mb: 3 }}>
          <Grid container spacing={2}>
            <Grid item xs={12} sm={6}>
              <Typography variant="h4" gutterBottom>
                {workflow?.type || '未知工作流类型'}
              </Typography>
              <Typography variant="body2" color="textSecondary" gutterBottom>
                ID: {workflow?.id}
              </Typography>
              
              <Box sx={{ display: 'flex', alignItems: 'center', mt: 2 }}>
                <Chip 
                  icon={<StatusIcon status={workflow?.status} />}
                  label={workflow?.status}
                  color={getStatusColor(workflow?.status)}
                  sx={{ mr: 2 }}
                />
                
                {workflow?.status === 'RUNNING' && (
                  <LinearProgress 
                    variant="determinate" 
                    value={(workflow?.completed_nodes / workflow?.total_nodes) * 100} 
                    sx={{ width: '100px', mr: 1 }} 
                  />
                )}
                
                <Typography variant="body2">
                  {workflow?.completed_nodes || 0} / {workflow?.total_nodes || 0} 节点完成
                </Typography>
              </Box>
            </Grid>
            
            <Grid item xs={12} sm={6}>
              <Box sx={{ display: 'flex', flexDirection: 'column', alignItems: 'flex-end' }}>
                <Box sx={{ display: 'flex', mb: 1 }}>
                  <Typography variant="body2" color="textSecondary" sx={{ mr: 1 }}>
                    开始时间:
                  </Typography>
                  <Typography variant="body2">
                    {formatDateTime(workflow?.started_at)}
                  </Typography>
                </Box>
                
                {workflow?.completed_at && (
                  <Box sx={{ display: 'flex', mb: 1 }}>
                    <Typography variant="body2" color="textSecondary" sx={{ mr: 1 }}>
                      完成时间:
                    </Typography>
                    <Typography variant="body2">
                      {formatDateTime(workflow?.completed_at)}
                    </Typography>
                  </Box>
                )}
                
                <Box sx={{ display: 'flex', mb: 1 }}>
                  <Typography variant="body2" color="textSecondary" sx={{ mr: 1 }}>
                    持续时间:
                  </Typography>
                  <Typography variant="body2">
                    {formatDuration(workflow?.duration)}
                  </Typography>
                </Box>
                
                {workflow?.status === 'RUNNING' && workflow?.estimated_remaining_time && (
                  <Box sx={{ display: 'flex' }}>
                    <Typography variant="body2" color="textSecondary" sx={{ mr: 1 }}>
                      预计剩余时间:
                    </Typography>
                    <Typography variant="body2">
                      {formatDuration(workflow?.estimated_remaining_time)}
                    </Typography>
                  </Box>
                )}
              </Box>
            </Grid>
          </Grid>
        </Paper>
"#;

/// 实现工作流可视化工具的后端组件
pub struct WorkflowVisualizationEngine {
    /// 工作流执行引擎
    workflow_engine: Arc<WorkflowExecutionEngine>,
    /// 事件仓库
    event_store: Arc<EventStore>,
    /// 指标收集器
    metrics_collector: Arc<MetricsCollector>,
}

impl WorkflowVisualizationEngine {
    /// 创建可视化引擎
    pub fn new(
        workflow_engine: Arc<WorkflowExecutionEngine>,
        event_store: Arc<EventStore>,
        metrics_collector: Arc<MetricsCollector>,
    ) -> Self {
        Self {
            workflow_engine,
            event_store,
            metrics_collector,
        }
    }

    /// 创建工作流可视化
    pub async fn create_workflow_visualization(
        &self,
        workflow_id: &str,
        config: VisualizationConfig,
    ) -> Result<WorkflowVisualization, VisualizationError> {
        let instance = self.workflow_engine.get_workflow_instance(workflow_id)
            .await
            .map_err(|e| VisualizationError::DataFetchError(e.to_string()))?;
            
        let definition = self.workflow_engine.get_workflow_definition(&instance.workflow_type, &instance.version)
            .await
            .map_err(|e| VisualizationError::DataFetchError(e.to_string()))?;
            
        let tasks = match config.include_execution_status {
            true => Some(self.workflow_engine.get_workflow_tasks(workflow_id)
                .await
                .map_err(|e| VisualizationError::DataFetchError(e.to_string()))?),
            false => None,
        };
        
        let metrics = match config.include_metrics {
            true => Some(self.metrics_collector.get_workflow_metrics(workflow_id)
                .await
                .map_err(|e| VisualizationError::DataFetchError(e.to_string()))?),
            false => None,
        };
        
        match config.format {
            VisualizationFormat::Json => self.generate_json_visualization(&instance, &definition, tasks, metrics),
            VisualizationFormat::Graphviz => self.generate_graphviz_visualization(&instance, &definition, tasks, metrics, &config),
            VisualizationFormat::Mermaid => self.generate_mermaid_visualization(&instance, &definition, tasks, metrics, &config),
            VisualizationFormat::Html => self.generate_html_visualization(&instance, &definition, tasks, metrics, &config),
        }
    }
    
    /// 创建工作流实时可视化WebSocket处理
    pub fn create_visualization_handler(&self, workflow_id: String, user_id: String) -> VisualizationWebSocketHandler {
        VisualizationWebSocketHandler::new(
            Arc::new(self.clone()),
            workflow_id,
            user_id,
        )
    }
}

/// 工作流可视化WebSocket处理器
pub struct VisualizationWebSocketHandler {
    /// 可视化引擎
    visualization_engine: Arc<WorkflowVisualizationEngine>,
    /// 工作流ID
    workflow_id: String,
    /// 用户ID
    user_id: String,
    /// 客户端连接
    clients: HashMap<String, mpsc::UnboundedSender<String>>,
    /// 事件订阅
    event_subscription: Option<Subscription>,
}

impl VisualizationWebSocketHandler {
    /// 创建可视化WebSocket处理器
    pub fn new(
        visualization_engine: Arc<WorkflowVisualizationEngine>,
        workflow_id: String,
        user_id: String,
    ) -> Self {
        Self {
            visualization_engine,
            workflow_id,
            user_id,
            clients: HashMap::new(),
            event_subscription: None,
        }
    }
    
    /// 注册客户端连接
    pub fn register_client(&mut self, client_id: String, sender: mpsc::UnboundedSender<String>) {
        self.clients.insert(client_id, sender);
        
        // 如果是第一个客户端，开始订阅工作流事件
        if self.clients.len() == 1 {
            self.subscribe_to_workflow_events();
        }
    }
    
    /// 注销客户端连接
    pub fn unregister_client(&mut self, client_id: &str) {
        self.clients.remove(client_id);
        
        // 如果没有更多客户端，取消事件订阅
        if self.clients.is_empty() {
            self.unsubscribe_from_workflow_events();
        }
    }
    
    /// 订阅工作流事件
    fn subscribe_to_workflow_events(&mut self) {
        let workflow_id = self.workflow_id.clone();
        let visualization_engine = self.visualization_engine.clone();
        let clients = self.clients.clone();
        
        // TODO: 实现具体的事件订阅
    }
    
    /// 取消工作流事件订阅
    fn unsubscribe_from_workflow_events(&mut self) {
        if let Some(subscription) = self.event_subscription.take() {
            // TODO: 取消订阅
        }
    }
    
    /// 广播消息到所有客户端
    fn broadcast_message(&self, message: &str) {
        for (client_id, sender) in &self
    /// 向所有客户端广播消息
    fn broadcast_message(&self, message: &str) {
        for (client_id, sender) in &self.clients {
            if sender.send(message.to_string()).is_err() {
                log::warn!("向客户端 {} 发送消息失败", client_id);
            }
        }
    }
    
    /// 处理来自客户端的消息
    pub async fn handle_client_message(&self, client_id: &str, message: &str) -> Result<(), VisualizationError> {
        // 解析消息
        let request: VisualizationRequest = match serde_json::from_str(message) {
            Ok(req) => req,
            Err(e) => {
                return Err(VisualizationError::InvalidRequest(format!("消息解析失败: {}", e)));
            }
        };
        
        match request.request_type.as_str() {
            "get_full_view" => {
                // 获取完整视图
                let config = VisualizationConfig {
                    format: VisualizationFormat::Json,
                    include_metrics: request.include_metrics.unwrap_or(true),
                    include_execution_status: true,
                    layout_algorithm: request.layout_algorithm.unwrap_or_else(|| "dagre".to_string()),
                    theme: request.theme.unwrap_or_else(|| "light".to_string()),
                    ..Default::default()
                };
                
                let visualization = self.visualization_engine
                    .create_workflow_visualization(&self.workflow_id, config)
                    .await?;
                
                if let Some(sender) = self.clients.get(client_id) {
                    let response = serde_json::json!({
                        "type": "full_view",
                        "view_data": visualization,
                        "timestamp": chrono::Utc::now().to_rfc3339()
                    });
                    
                    if sender.send(response.to_string()).is_err() {
                        log::warn!("向客户端 {} 发送完整视图失败", client_id);
                    }
                }
            },
            "update_view_config" => {
                // 更新视图配置
                // 这里可以处理客户端请求更改视图配置的情况
                log::info!("客户端 {} 请求更新视图配置", client_id);
            },
            _ => {
                return Err(VisualizationError::InvalidRequest(format!("未知请求类型: {}", request.request_type)));
            }
        }
        
        Ok(())
    }
}

/// 实现WebSocket处理中间件
pub struct VisualizationWebsocketMiddleware {
    /// 可视化引擎
    visualization_engine: Arc<WorkflowVisualizationEngine>,
    /// 活跃的工作流可视化处理器
    visualization_handlers: RwLock<HashMap<String, Arc<Mutex<VisualizationWebSocketHandler>>>>,
}

impl VisualizationWebsocketMiddleware {
    /// 创建WebSocket中间件
    pub fn new(visualization_engine: Arc<WorkflowVisualizationEngine>) -> Self {
        Self {
            visualization_engine,
            visualization_handlers: RwLock::new(HashMap::new()),
        }
    }
    
    /// 获取工作流的WebSocket处理器
    pub async fn get_or_create_handler(&self, workflow_id: &str, user_id: &str) -> Arc<Mutex<VisualizationWebSocketHandler>> {
        let mut handlers = self.visualization_handlers.write().await;
        
        if let Some(handler) = handlers.get(workflow_id) {
            return handler.clone();
        }
        
        // 创建新的处理器
        let handler = Arc::new(Mutex::new(self.visualization_engine.create_visualization_handler(
            workflow_id.to_string(),
            user_id.to_string(),
        )));
        
        handlers.insert(workflow_id.to_string(), handler.clone());
        handler
    }
    
    /// 处理WebSocket连接
    pub async fn handle_connection(
        &self,
        websocket: WebSocket,
        workflow_id: String,
        user_id: String,
    ) {
        // 生成唯一客户端ID
        let client_id = format!("{}:{}", user_id, uuid::Uuid::new_v4());
        
        // 获取处理器
        let handler = self.get_or_create_handler(&workflow_id, &user_id).await;
        
        // 分割WebSocket
        let (ws_sender, mut ws_receiver) = websocket.split();
        
        // 创建消息通道
        let (tx, rx) = mpsc::unbounded_channel();
        
        // 注册客户端
        {
            let mut handler_lock = handler.lock().await;
            handler_lock.register_client(client_id.clone(), tx.clone());
        }
        
        // 发送确认消息
        let welcome_msg = serde_json::json!({
            "type": "connection_established",
            "client_id": client_id,
            "workflow_id": workflow_id,
            "timestamp": chrono::Utc::now().to_rfc3339()
        });
        
        if tx.send(welcome_msg.to_string()).is_err() {
            log::error!("发送欢迎消息失败");
            return;
        }
        
        // 转发接收到的消息
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(30));
            
            loop {
                tokio::select! {
                    // 接收来自WebSocket的消息
                    msg = ws_receiver.next() => {
                        match msg {
                            Some(Ok(ws::Message::Text(text))) => {
                                // 处理客户端消息
                                let handler_clone = handler.clone();
                                let client_id_clone = client_id.clone();
                                
                                tokio::spawn(async move {
                                    let handler_lock = handler_clone.lock().await;
                                    if let Err(e) = handler_lock.handle_client_message(&client_id_clone, &text).await {
                                        log::error!("处理客户端消息失败: {}", e);
                                    }
                                });
                            },
                            Some(Ok(ws::Message::Ping(bytes))) => {
                                if let Err(e) = tx.send(Ok(ws::Message::Pong(bytes)).to_string()) {
                                    log::error!("发送pong响应失败: {}", e);
                                    break;
                                }
                            },
                            Some(Ok(ws::Message::Close(_))) => {
                                log::info!("客户端 {} 关闭连接", client_id);
                                break;
                            },
                            Some(Err(e)) => {
                                log::error!("WebSocket错误: {}", e);
                                break;
                            },
                            None => {
                                log::info!("WebSocket连接已关闭");
                                break;
                            },
                            _ => {}
                        }
                    },
                    // 发送心跳
                    _ = interval.tick() => {
                        if tx.send(Ok(ws::Message::Ping(vec![])).to_string()).is_err() {
                            log::error!("发送心跳失败");
                            break;
                        }
                    }
                }
            }
            
            // 客户端断开连接，注销客户端
            let mut handler_lock = handler.lock().await;
            handler_lock.unregister_client(&client_id);
        });
        
        // 转发发送给客户端的消息
        tokio::spawn(rx.map(Ok).forward(ws_sender).map(|result| {
            if let Err(e) = result {
                log::error!("转发消息到WebSocket失败: {}", e);
            }
        }));
    }
    
    /// 创建WebSocket路由
    pub fn routes(&self) -> impl Filter<Extract = impl warp::Reply, Error = warp::Rejection> + Clone {
        let visualization_engine = self.visualization_engine.clone();
        let self_clone = Arc::new(self.clone());
        
        // 工作流可视化WebSocket路由
        warp::path!("ws" / "visualize" / String)
            .and(warp::ws())
            .and(warp::header::optional("authorization"))
            .map(move |workflow_id: String, ws: warp::ws::Ws, auth: Option<String>| {
                let self_clone = self_clone.clone();
                
                // 验证授权(在实际应用中应该解析令牌)
                let user_id = auth.map(|token| {
                    // 这里应该验证token并提取user_id
                    "anonymous".to_string()
                }).unwrap_or_else(|| "anonymous".to_string());
                
                ws.on_upgrade(move |websocket| async move {
                    self_clone.handle_connection(websocket, workflow_id, user_id).await;
                })
            })
    }
}

/// 为工作流监控系统实现React组件
/// 以下是完整的React前端组件代码
#[derive(Debug, Clone)]
struct WorkflowMonitoringFrontend {
    /// API服务
    api_service: Arc<ApiService>,
    /// WebSocket服务
    websocket_service: Arc<WebSocketService>,
    /// 前端静态文件服务
    static_files_service: Arc<StaticFilesService>,
}

impl WorkflowMonitoringFrontend {
    /// 创建前端服务
    pub fn new(
        api_service: Arc<ApiService>,
        websocket_service: Arc<WebSocketService>,
        static_files_service: Arc<StaticFilesService>,
    ) -> Self {
        Self {
            api_service,
            websocket_service,
            static_files_service,
        }
    }
    
    /// 启动前端服务
    pub async fn start(&self, port: u16) -> Result<(), Error> {
        // 组合API路由、WebSocket路由和静态文件路由
        let routes = self.api_service.routes()
            .or(self.websocket_service.routes())
            .or(self.static_files_service.routes());
        
        // 启动服务器
        warp::serve(routes)
            .run(([0, 0, 0, 0], port))
            .await;
        
        Ok(())
    }
}

/// 前端React应用结构
/// 目录结构:
/// /src
///   /components
///     /Dashboard.jsx - 仪表盘组件
///     /WorkflowList.jsx - 工作流列表组件
///     /WorkflowDetails.jsx - 工作流详情组件
///     /WorkflowVisualization.jsx - 工作流可视化组件
///     /MonitoringStatistics.jsx - 监控统计组件
///   /services
///     /api.js - API服务
///     /websocket.js - WebSocket服务
///   /utils
///     /formatters.js - 格式化工具
///     /colors.js - 颜色常量
///   /App.jsx - 主应用组件
///   /index.jsx - 入口文件

/// WebSocket客户端服务示例
/**
 * WebSocket服务
 */
class WebSocketService {
  constructor() {
    this.connections = new Map();
    this.listeners = new Map();
  }
  
  /**
   * 连接到工作流可视化WebSocket
   * @param {string} workflowId - 工作流ID
   * @returns {WebSocket} WebSocket连接
   */
  connectToWorkflowVisualization(workflowId) {
    // 检查是否已有连接
    if (this.connections.has(`workflow:${workflowId}`)) {
      return this.connections.get(`workflow:${workflowId}`);
    }
    
    // 创建WebSocket连接
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const wsUrl = `${protocol}//${window.location.host}/ws/visualize/${workflowId}`;
    
    const ws = new WebSocket(wsUrl);
    
    // 设置事件处理器
    ws.onopen = () => {
      console.log(`工作流 ${workflowId} 的WebSocket连接已建立`);
      this.notifyListeners(`workflow:${workflowId}`, 'connection', { status: 'connected' });
    };
    
    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data);
        this.notifyListeners(`workflow:${workflowId}`, data.type || 'message', data);
      } catch (e) {
        console.error('解析WebSocket消息失败:', e);
      }
    };
    
    ws.onerror = (error) => {
      console.error(`工作流 ${workflowId} 的WebSocket错误:`, error);
      this.notifyListeners(`workflow:${workflowId}`, 'error', { error });
    };
    
    ws.onclose = () => {
      console.log(`工作流 ${workflowId} 的WebSocket连接已关闭`);
      this.connections.delete(`workflow:${workflowId}`);
      this.notifyListeners(`workflow:${workflowId}`, 'connection', { status: 'disconnected' });
      
      // 5秒后尝试重新连接
      setTimeout(() => {
        if (this.hasListeners(`workflow:${workflowId}`)) {
          this.connectToWorkflowVisualization(workflowId);
        }
      }, 5000);
    };
    
    // 保存连接
    this.connections.set(`workflow:${workflowId}`, ws);
    
    return ws;
  }
  
  /**
   * 断开WebSocket连接
   * @param {string} workflowId - 工作流ID
   */
  disconnect(workflowId) {
    const key = `workflow:${workflowId}`;
    if (this.connections.has(key)) {
      const ws = this.connections.get(key);
      ws.close();
      this.connections.delete(key);
    }
  }
  
  /**
   * 发送WebSocket消息
   * @param {string} workflowId - 工作流ID
   * @param {object} message - 要发送的消息
   */
  sendMessage(workflowId, message) {
    const key = `workflow:${workflowId}`;
    if (this.connections.has(key)) {
      const ws = this.connections.get(key);
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify(message));
        return true;
      }
    }
    return false;
  }
  
  /**
   * 添加WebSocket事件监听器
   * @param {string} workflowId - 工作流ID
   * @param {string} eventType - 事件类型
   * @param {function} listener - 监听器函数
   */
  addListener(workflowId, eventType, listener) {
    const key = `workflow:${workflowId}`;
    
    if (!this.listeners.has(key)) {
      this.listeners.set(key, new Map());
    }
    
    const workflowListeners = this.listeners.get(key);
    
    if (!workflowListeners.has(eventType)) {
      workflowListeners.set(eventType, new Set());
    }
    
    workflowListeners.get(eventType).add(listener);
    
    // 如果添加了监听器但没有连接，则创建连接
    if (!this.connections.has(key)) {
      this.connectToWorkflowVisualization(workflowId);
    }
  }
  
  /**
   * 移除WebSocket事件监听器
   * @param {string} workflowId - 工作流ID
   * @param {string} eventType - 事件类型
   * @param {function} listener - 监听器函数
   */
  removeListener(workflowId, eventType, listener) {
    const key = `workflow:${workflowId}`;
    
    if (!this.listeners.has(key)) {
      return;
    }
    
    const workflowListeners = this.listeners.get(key);
    
    if (!workflowListeners.has(eventType)) {
      return;
    }
    
    workflowListeners.get(eventType).delete(listener);
    
    // 如果没有更多监听器，则断开连接
    if (this.hasListeners(key)) {
      this.disconnect(workflowId);
    }
  }
  
  /**
   * 检查是否有监听器
   * @param {string} key - 连接键
   * @returns {boolean} 是否有监听器
   */
  hasListeners(key) {
    if (!this.listeners.has(key)) {
      return false;
    }
    
    const workflowListeners = this.listeners.get(key);
    
    for (const [_, listeners] of workflowListeners.entries()) {
      if (listeners.size > 0) {
        return true;
      }
    }
    
    return false;
  }
  
  /**
   * 通知所有监听器
   * @param {string} key - 连接键
   * @param {string} eventType - 事件类型
   * @param {object} data - 事件数据
   */
  notifyListeners(key, eventType, data) {
    if (!this.listeners.has(key)) {
      return;
    }
    
    const workflowListeners = this.listeners.get(key);
    
    if (!workflowListeners.has(eventType)) {
      return;
    }
    
    for (const listener of workflowListeners.get(eventType)) {
      try {
        listener(data);
      } catch (e) {
        console.error('执行监听器时发生错误:', e);
      }
    }
  }
}

/**
 * 工作流可视化组件
 */
const WorkflowVisualization = ({ workflowId, config }) => {
  const [status, setStatus] = useState('loading');
  const [error, setError] = useState(null);
  const [visualization, setVisualization] = useState(null);
  const visRef = useRef(null);
  const wsService = useContext(WebSocketContext);
  
  useEffect(() => {
    // 添加WebSocket事件监听器
    const handleFullView = (data) => {
      setVisualization(data.view_data);
      setStatus('loaded');
    };
    
    const handleError = (data) => {
      setError(data.error);
      setStatus('error');
    };
    
    const handleConnection = (data) => {
      if (data.status === 'connected') {
        // 请求完整视图
        wsService.sendMessage(workflowId, {
          request_type: 'get_full_view',
          include_metrics: config?.showMetrics !== false,
          layout_algorithm: config?.layoutAlgorithm || 'dagre',
          theme: config?.theme || 'light'
        });
      }
    };
    
    wsService.addListener(workflowId, 'full_view', handleFullView);
    wsService.addListener(workflowId, 'error', handleError);
    wsService.addListener(workflowId, 'connection', handleConnection);
    
    // 清理函数
    return () => {
      wsService.removeListener(workflowId, 'full_view', handleFullView);
      wsService.removeListener(workflowId, 'error', handleError);
      wsService.removeListener(workflowId, 'connection', handleConnection);
    };
  }, [workflowId, config, wsService]);
  
  useEffect(() => {
    // 当可视化数据可用时，渲染可视化
    if (status === 'loaded' && visualization && visRef.current) {
      renderVisualization(visRef.current, visualization, config);
    }
  }, [status, visualization, config]);
  
  // 渲染可视化的辅助函数
  const renderVisualization = (container, data, config) => {
    // 这里使用D3.js或其他库渲染可视化
    // 具体实现取决于可视化的格式和需求
  };
  
  return (
    <div className="workflow-visualization">
      {status === 'loading' && (
        <div className="loading-indicator">
          <CircularProgress />
          <Typography variant="body2">加载工作流可视化...</Typography>
        </div>
      )}
      
      {status === 'error' && (
        <div className="error-container">
          <Typography color="error">加载失败: {error}</Typography>
          <Button 
            variant="contained" 
            onClick={() => {
              setStatus('loading');
              wsService.sendMessage(workflowId, {
                request_type: 'get_full_view',
                include_metrics: config?.showMetrics !== false
              });
            }}
          >
            重试
          </Button>
        </div>
      )}
      
      <div className="visualization-container" ref={visRef}>
        {/* 可视化将在这里渲染 */}
      </div>
    </div>
  );
};

// 输出React完整实现
export default {
  WebSocketService,
  WorkflowVisualization
};

/**
 * 工作流指标收集与展示组件
 */
import React, { useState, useEffect, useRef } from 'react';
import { 
  Box, Typography, Grid, Paper, CircularProgress, 
  Table, TableBody, TableCell, TableContainer, TableHead, TableRow,
  Card, CardContent, CardHeader, Divider, Chip, Button,
  List, ListItem, ListItemText, ListItemIcon, ListItemSecondaryAction,
  IconButton, Tooltip
} from '@mui/material';
import { 
  Timeline, Assessment, Error, CheckCircle, PlayArrow,
  Pause, Refresh, MoreVert, AccessTime, Memory, Speed
} from '@mui/icons-material';
import { Line, Bar, Pie } from 'react-chartjs-2';

/**
 * 工作流统计数据Dashboard组件
 */
const WorkflowStatisticsDashboard = ({ wsService }) => {
  const [stats, setStats] = useState({
    overall: {
      activeWorkflows: 0,
      completedWorkflows: 0,
      failedWorkflows: 0,
      avgExecutionTime: 0,
      successRate: 0,
      totalActivities: 0
    },
    topWorkflows: [],
    recentErrors: [],
    resourceUsage: {
      memory: 0,
      cpu: 0,
      connections: 0
    },
    trends: {
      workflowsOverTime: [],
      executionTimeOverTime: [],
      errorRateOverTime: []
    }
  });
  
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  
  useEffect(() => {
    // 添加统计数据WebSocket监听器
    const handleStatsUpdate = (data) => {
      setStats(prevStats => ({
        ...prevStats,
        ...data.statistics
      }));
      setLoading(false);
    };
    
    const handleError = (data) => {
      setError(data.error);
      setLoading(false);
    };
    
    wsService.addListener('global', 'statistics', handleStatsUpdate);
    wsService.addListener('global', 'error', handleError);
    
    // 请求统计数据
    wsService.connectToGlobalStats();
    
    // 定期刷新数据
    const interval = setInterval(() => {
      wsService.sendMessage('global', {
        request_type: 'refresh_statistics'
      });
    }, 30000); // 每30秒刷新一次
    
    // 清理函数
    return () => {
      clearInterval(interval);
      wsService.removeListener('global', 'statistics', handleStatsUpdate);
      wsService.removeListener('global', 'error', handleError);
      wsService.disconnectFromGlobalStats();
    };
  }, [wsService]);
  
  if (loading) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="300px">
        <CircularProgress />
        <Typography variant="body1" sx={{ ml: 2 }}>加载工作流统计数据...</Typography>
      </Box>
    );
  }
  
  if (error) {
    return (
      <Box>
        <Typography color="error">{error}</Typography>
        <Button 
          variant="contained" 
          onClick={() => {
            setLoading(true);
            setError(null);
            wsService.connectToGlobalStats();
          }}
        >
          重试
        </Button>
      </Box>
    );
  }
  
  // 图表数据
  const workflowStatusData = {
    labels: ['活跃', '已完成', '已失败'],
    datasets: [{
      data: [
        stats.overall.activeWorkflows, 
        stats.overall.completedWorkflows, 
        stats.overall.failedWorkflows
      ],
      backgroundColor: ['#4caf50', '#2196f3', '#f44336'],
      borderColor: ['#388e3c', '#1976d2', '#d32f2f'],
      borderWidth: 1,
    }]
  };
  
  const executionTimeData = {
    labels: stats.trends.executionTimeOverTime.map(d => d.time),
    datasets: [{
      label: '平均执行时间 (ms)',
      data: stats.trends.executionTimeOverTime.map(d => d.value),
      fill: false,
      backgroundColor: '#2196f3',
      borderColor: '#1976d2',
      tension: 0.1
    }]
  };
  
  const errorRateData = {
    labels: stats.trends.errorRateOverTime.map(d => d.time),
    datasets: [{
      label: '错误率 (%)',
      data: stats.trends.errorRateOverTime.map(d => d.value),
      fill: false,
      backgroundColor: '#f44336',
      borderColor: '#d32f2f',
      tension: 0.1
    }]
  };
  
  return (
    <Box sx={{ flexGrow: 1, p: 3 }}>
      <Typography variant="h5" gutterBottom>
        工作流监控指标
        <Tooltip title="刷新">
          <IconButton 
            size="small" 
            sx={{ ml: 1 }}
            onClick={() => {
              setLoading(true);
              wsService.sendMessage('global', {
                request_type: 'refresh_statistics'
              });
            }}
          >
            <Refresh />
          </IconButton>
        </Tooltip>
      </Typography>
      
      {/* 指标卡片 */}
      <Grid container spacing={3} sx={{ mb: 3 }}>
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="活跃工作流"
            value={stats.overall.activeWorkflows}
            icon={<PlayArrow />}
            color="#4caf50"
          />
        </Grid>
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="已完成工作流"
            value={stats.overall.completedWorkflows}
            icon={<CheckCircle />}
            color="#2196f3"
          />
        </Grid>
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="失败率"
            value={`${stats.overall.successRate ? (100 - stats.overall.successRate).toFixed(1) : 0}%`}
            icon={<Error />}
            color="#f44336"
          />
        </Grid>
        <Grid item xs={12} sm={6} md={3}>
          <MetricCard 
            title="平均执行时间"
            value={`${stats.overall.avgExecutionTime.toFixed(0)} ms`}
            icon={<AccessTime />}
            color="#ff9800"
          />
        </Grid>
      </Grid>
      
      {/* 图表区域 */}
      <Grid container spacing={3}>
        <Grid item xs={12} md={4}>
          <Card>
            <CardHeader title="工作流状态分布" />
            <CardContent>
              <Box height={250}>
                <Pie data={workflowStatusData} options={{ maintainAspectRatio: false }} />
              </Box>
            </CardContent>
          </Card>
        </Grid>
        <Grid item xs={12} md={8}>
          <Card>
            <CardHeader title="执行时间趋势" />
            <CardContent>
              <Box height={250}>
                <Line data={executionTimeData} options={{ 
                  maintainAspectRatio: false,
                  scales: {
                    y: {
                      beginAtZero: true,
                      title: {
                        display: true,
                        text: '执行时间 (ms)'
                      }
                    },
                    x: {
                      title: {
                        display: true,
                        text: '时间'
                      }
                    }
                  }
                }} />
              </Box>
            </CardContent>
          </Card>
        </Grid>
        <Grid item xs={12} md={6}>
          <Card>
            <CardHeader title="错误率趋势" />
            <CardContent>
              <Box height={250}>
                <Line data={errorRateData} options={{ 
                  maintainAspectRatio: false,
                  scales: {
                    y: {
                      beginAtZero: true,
                      title: {
                        display: true,
                        text: '错误率 (%)'
                      }
                    }
                  }
                }} />
              </Box>
            </CardContent>
          </Card>
        </Grid>
        <Grid item xs={12} md={6}>
          <Card>
            <CardHeader title="资源使用率" />
            <CardContent>
              <Grid container spacing={2}>
                <Grid item xs={4}>
                  <Box textAlign="center">
                    <Typography variant="body2">内存</Typography>
                    <CircularProgressWithLabel value={stats.resourceUsage.memory} color="primary" />
                  </Box>
                </Grid>
                <Grid item xs={4}>
                  <Box textAlign="center">
                    <Typography variant="body2">CPU</Typography>
                    <CircularProgressWithLabel value={stats.resourceUsage.cpu} color="success" />
                  </Box>
                </Grid>
                <Grid item xs={4}>
                  <Box textAlign="center">
                    <Typography variant="body2">连接数</Typography>
                    <CircularProgressWithLabel value={stats.resourceUsage.connections} color="warning" />
                  </Box>
                </Grid>
              </Grid>
            </CardContent>
          </Card>
        </Grid>
      </Grid>
      
      {/* 表格区域 */}
      <Grid container spacing={3} sx={{ mt: 1 }}>
        <Grid item xs={12} md={7}>
          <Card>
            <CardHeader title="热门工作流" />
            <CardContent>
              <TableContainer>
                <Table size="small">
                  <TableHead>
                    <TableRow>
                      <TableCell>工作流名称</TableCell>
                      <TableCell align="right">实例数</TableCell>
                      <TableCell align="right">平均执行时间</TableCell>
                      <TableCell align="right">成功率</TableCell>
                      <TableCell align="right">状态</TableCell>
                    </TableRow>
                  </TableHead>
                  <TableBody>
                    {stats.topWorkflows.map((wf) => (
                      <TableRow key={wf.id}>
                        <TableCell>{wf.name}</TableCell>
                        <TableCell align="right">{wf.instances}</TableCell>
                        <TableCell align="right">{wf.avgExecutionTime} ms</TableCell>
                        <TableCell align="right">{wf.successRate}%</TableCell>
                        <TableCell align="right">
                          <Chip 
                            size="small"
                            label={wf.status}
                            color={
                              wf.status === "活跃" ? "success" : 
                              wf.status === "完成" ? "primary" : "error"
                            }
                          />
                        </TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </TableContainer>
            </CardContent>
          </Card>
        </Grid>
        <Grid item xs={12} md={5}>
          <Card>
            <CardHeader title="最近错误" />
            <CardContent>
              <List dense>
                {stats.recentErrors.map((error, index) => (
                  <ListItem key={index} divider={index < stats.recentErrors.length - 1}>
                    <ListItemIcon>
                      <Error color="error" />
                    </ListItemIcon>
                    <ListItemText
                      primary={`${error.workflowName} - ${error.errorType}`}
                      secondary={
                        <>
                          <Typography variant="caption" component="span" color="text.secondary">
                            {new Date(error.timestamp).toLocaleString()}
                          </Typography>
                          <br />
                          <Typography variant="body2" component="span" color="text.secondary">
                            {error.message}
                          </Typography>
                        </>
                      }
                    />
                  </ListItem>
                ))}
                {stats.recentErrors.length === 0 && (
                  <ListItem>
                    <ListItemText primary="没有最近的错误" />
                  </ListItem>
                )}
              </List>
            </CardContent>
          </Card>
        </Grid>
      </Grid>
    </Box>
  );
};

/**
 * 指标卡片组件
 */
const MetricCard = ({ title, value, icon, color }) => {
  return (
    <Paper
      sx={{
        p: 2,
        display: 'flex',
        flexDirection: 'column',
        height: 140,
        borderTop: `4px solid ${color}`
      }}
    >
      <Box display="flex" alignItems="center" mb={1}>
        <Box sx={{ color }}>
          {icon}
        </Box>
        <Typography variant="h6" component="div" sx={{ ml: 1 }}>
          {title}
        </Typography>
      </Box>
      <Typography variant="h3" component="div" sx={{ flexGrow: 1, textAlign: 'center', my: 'auto' }}>
        {value}
      </Typography>
    </Paper>
  );
};

/**
 * 带标签的圆形进度条
 */
const CircularProgressWithLabel = ({ value, color }) => {
  return (
    <Box position="relative" display="inline-flex">
      <CircularProgress variant="determinate" value={value} color={color} size={80} />
      <Box
        top={0}
        left={0}
        bottom={0}
        right={0}
        position="absolute"
        display="flex"
        alignItems="center"
        justifyContent="center"
      >
        <Typography variant="caption" component="div" color="text.secondary">
          {`${Math.round(value)}%`}
        </Typography>
      </Box>
    </Box>
  );
};

/**
 * 工作流实时监控组件
 */
const WorkflowRealTimeMonitor = ({ workflowId, wsService }) => {
  const [monitoringData, setMonitoringData] = useState({
    workflow: {
      id: workflowId,
      name: '',
      status: '',
      startTime: '',
      duration: 0,
      progress: 0
    },
    steps: [],
    metrics: {
      cpuUsage: 0,
      memoryUsage: 0,
      networkUsage: 0
    },
    events: []
  });
  
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  const [showDetails, setShowDetails] = useState(false);
  
  useEffect(() => {
    // 添加WebSocket事件监听器
    const handleMonitoringData = (data) => {
      setMonitoringData(prevData => ({
        ...prevData,
        ...data.monitoring_data
      }));
      setLoading(false);
    };
    
    const handleError = (data) => {
      setError(data.error);
      setLoading(false);
    };
    
    wsService.addListener(workflowId, 'monitoring_data', handleMonitoringData);
    wsService.addListener(workflowId, 'error', handleError);
    
    // 发送请求获取初始监控数据
    wsService.connectToWorkflowMonitoring(workflowId);
    
    // 清理函数
    return () => {
      wsService.removeListener(workflowId, 'monitoring_data', handleMonitoringData);
      wsService.removeListener(workflowId, 'error', handleError);
      wsService.disconnectFromWorkflowMonitoring(workflowId);
    };
  }, [workflowId, wsService]);
  
  if (loading) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="200px">
        <CircularProgress />
        <Typography variant="body1" sx={{ ml: 2 }}>加载工作流监控数据...</Typography>
      </Box>
    );
  }
  
  if (error) {
    return (
      <Box>
        <Typography color="error">{error}</Typography>
        <Button 
          variant="contained" 
          onClick={() => {
            setLoading(true);
            setError(null);
            wsService.connectToWorkflowMonitoring(workflowId);
          }}
        >
          重试
        </Button>
      </Box>
    );
  }
  
  return (
    <Box>
      <Card>
        <CardHeader 
          title={`工作流监控: ${monitoringData.workflow.name || workflowId}`}
          subheader={`状态: ${monitoringData.workflow.status} | 开始时间: ${new Date(monitoringData.workflow.startTime).toLocaleString()}`}
          action={
            <Tooltip title={showDetails ? "隐藏详情" : "显示详情"}>
              <IconButton onClick={() => setShowDetails(!showDetails)}>
                <MoreVert />
              </IconButton>
            </Tooltip>
          }
        />
        <CardContent>
          <Box mb={2}>
            <Typography variant="body2" gutterBottom>
              执行进度:
            </Typography>
            <Box display="flex" alignItems="center">
              <Box width="100%" mr={1}>
                <LinearProgressWithLabel value={monitoringData.workflow.progress} />
              </Box>
              <Box minWidth={35}>
                <Typography variant="body2" color="text.secondary">
                  {`${Math.round(monitoringData.workflow.progress)}%`}
                </Typography>
              </Box>
            </Box>
          </Box>
          
          <Box display="flex" justifyContent="space-between" mb={2}>
            <Box textAlign="center">
              <Typography variant="body2" color="text.secondary">执行时间</Typography>
              <Typography variant="h6">
                {formatDuration(monitoringData.workflow.duration)}
              </Typography>
            </Box>
            <Box textAlign="center">
              <Typography variant="body2" color="text.secondary">活跃步骤</Typography>
              <Typography variant="h6">
                {monitoringData.steps.filter(s => s.status === 'running').length}
              </Typography>
            </Box>
            <Box textAlign="center">
              <Typography variant="body2" color="text.secondary">内存使用</Typography>
              <Typography variant="h6">
                {formatBytes(monitoringData.metrics.memoryUsage)}
              </Typography>
            </Box>
          </Box>
          
          {showDetails && (
            <>
              <Divider sx={{ my: 2 }} />
              
              <Typography variant="subtitle1" gutterBottom>
                步骤执行状态
              </Typography>
              <TableContainer component={Paper} sx={{ mb: 2 }}>
                <Table size="small">
                  <TableHead>
                    <TableRow>
                      <TableCell>步骤名称</TableCell>
                      <TableCell align="right">状态</TableCell>
                      <TableCell align="right">开始时间</TableCell>
                      <TableCell align="right">执行时间</TableCell>
                    </TableRow>
                  </TableHead>
                  <TableBody>
                    {monitoringData.steps.map((step) => (
                      <TableRow key={step.id}>
                        <TableCell>{step.name}</TableCell>
                        <TableCell align="right">
                          <Chip 
                            size="small"
                            label={step.status}
                            color={
                              step.status === "running" ? "warning" : 
                              step.status === "completed" ? "success" : 
                              step.status === "waiting" ? "info" : "error"
                            }
                          />
                        </TableCell>
                        <TableCell align="right">
                          {step.startTime ? new Date(step.startTime).toLocaleTimeString() : '-'}
                        </TableCell>
                        <TableCell align="right">
                          {step.duration ? formatDuration(step.duration) : '-'}
                        </TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </TableContainer>
              
              <Typography variant="subtitle1" gutterBottom>
                最近事件
              </Typography>
              <List dense sx={{ bgcolor: 'background.paper' }}>
                {monitoringData.events.slice(0, 5).map((event, index) => (
                  <ListItem key={index} divider={index < Math.min(monitoringData.events.length, 5) - 1}>
                    <ListItemText
                      primary={event.type}
                      secondary={
                        <>
                          <Typography variant="caption" component="span">
                            {new Date(event.timestamp).toLocaleTimeString()}
                          </Typography>
                          <br />
                          <Typography variant="body2" component="span">
                            {event.message}
                          </Typography>
                        </>
                      }
                    />
                  </ListItem>
                ))}
                {monitoringData.events.length === 0 && (
                  <ListItem>
                    <ListItemText primary="没有记录事件" />
                  </ListItem>
                )}
              </List>
            </>
          )}
        </CardContent>
      </Card>
    </Box>
  );
};

/**
 * 带标签的线性进度条
 */
const LinearProgressWithLabel = ({ value }) => {
  return (
    <Box display="flex" alignItems="center">
      <Box width="100%" mr={1}>
        <LinearProgress variant="determinate" value={value} />
      </Box>
      <Box minWidth={35}>
        <Typography variant="body2" color="text.secondary">{`${Math.round(value)}%`}</Typography>
      </Box>
    </Box>
  );
};

/**
 * 格式化持续时间
 * @param {number} ms - 毫秒数
 * @returns {string} 格式化后的时间
 */
const formatDuration = (ms) => {
  const seconds = Math.floor(ms / 1000);
  const minutes = Math.floor(seconds / 60);
  const hours = Math.floor(minutes / 60);
  
  if (hours > 0) {
    return `${hours}h ${minutes % 60}m`;
  } else if (minutes > 0) {
    return `${minutes}m ${seconds % 60}s`;
  } else {
    return `${seconds}s`;
  }
};

/**
 * 格式化字节数
 * @param {number} bytes - 字节数
 * @returns {string} 格式化后的大小
 */
const formatBytes = (bytes) => {
  if (bytes === 0) return '0 B';
  
  const k = 1024;
  const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  
  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
};

// 将组件导出
export default {
  WorkflowStatisticsDashboard,
  WorkflowRealTimeMonitor,
  MetricCard
};

/**
 * 工作流指标收集服务 - 后端实现
 */
pub struct WorkflowMetricsCollector {
    /// 工作流执行引擎引用
    workflow_engine: Arc<WorkflowExecutionEngine>,
    /// 指标存储
    metrics_store: Arc<RwLock<WorkflowMetricsStore>>,
    /// 指标监控WebSocket处理器
    ws_handler: Arc<MetricsWebSocketHandler>,
    /// 指标收集间隔
    collection_interval: Duration,
    /// 活跃的收集任务
    collection_task: Arc<AtomicBool>,
}

impl WorkflowMetricsCollector {
    /// 创建新的指标收集器
    pub fn new(
        workflow_engine: Arc<WorkflowExecutionEngine>,
        ws_handler: Arc<MetricsWebSocketHandler>,
        collection_interval: Duration,
    ) -> Self {
        Self {
            workflow_engine,
            metrics_store: Arc::new(RwLock::new(WorkflowMetricsStore::new())),
            ws_handler,
            collection_interval,
            collection_task: Arc::new(AtomicBool::new(false)),
        }
    }
    
    /// 启动指标收集
    pub async fn start(&self) -> Result<(), Error> {
        if self.collection_task.load(Ordering::SeqCst) {
            return Err(Error::AlreadyRunning("指标收集器已经在运行".into()));
        }
        
        self.collection_task.store(true, Ordering::SeqCst);
        
        let engine = self.workflow_engine.clone();
        let store = self.metrics_store.clone();
        let handler = self.ws_handler.clone();
        let interval = self.collection_interval;
        let is_running = self.collection_task.clone();
        
        tokio::spawn(async move {
            let mut collection_interval = tokio::time::interval(interval);
            
            while is_running.load(Ordering::SeqCst) {
                collection_interval.tick().await;
                
                if let Err(e) = Self::collect_metrics(engine.clone(), store.clone()).await {
                    log::error!("收集工作流指标时发生错误: {}", e);
                }
                
                // 广播指标更新
                if let Ok(metrics) = store.read().await.get_overall_statistics().await {
                    let _ = handler.broadcast_metrics(metrics).await;
                }
            }
        });
        
        Ok(())
    }
    
    /// 停止指标收集
    pub fn stop(&self) {
        self.collection_task.store(false, Ordering::SeqCst);
    }
    
    /// 收集工作流指标
    async fn collect_metrics(
        engine: Arc<WorkflowExecutionEngine>,
        store: Arc<RwLock<WorkflowMetricsStore>>,
    ) -> Result<(), Error> {
        // 收集活跃工作流数量
        let active_workflows = engine.get_active_workflow_count().await?;
        
        // 收集已完成工作流数量
        let completed_workflows = engine.get_completed_workflow_count().await?;
        
        // 收集失败工作流数量
        let failed_workflows = engine.get_failed_workflow_count().await?;
        
        // 收集平均执行时间
        let avg_execution_time = engine.get_average_execution_time().await?;
        
        // 收集成功率
        let total = completed_workflows + failed_workflows;
        let success_rate = if total > 0 {
            (completed_workflows as f64 / total as f64) * 100.0
        } else {
            100.0
        };
        
        // 收集资源使用情况
        let resource_usage = engine.get_resource_usage().await?;
        
        // 收集热门工作流
        let top_workflows = engine.get_top_workflows(10).await?;
        
        // 收集最近错误
        let recent_errors = engine.get_recent_errors(10).await?;
        
        // 更新指标存储
        let mut store = store.write().await;
        store.update_overall_metrics(
            active_workflows,
            completed_workflows,
            failed_workflows,
            avg_execution_time,
            success_rate,
        ).await?;
        
        store.update_resource_usage(
            resource_usage.memory_usage,
            resource_usage.cpu_usage,
            resource_usage.connection_count,
        ).await?;
        
        store.update_top_workflows(top_workflows).await?;
        store.update_recent_errors(recent_errors).await?;
        
        // 添加趋势数据点
        store.add_trend_data_point(
            chrono::Utc::now(),
            active_workflows,
            avg_execution_time,
            100.0 - success_rate,
        ).await?;
        
        Ok(())
    }
    
    /// 获取当前所有指标
    pub async fn get_metrics(&self) -> Result<WorkflowStatistics, Error> {
        let store = self.metrics_store.read().await;
        store.get_overall_statistics().await
    }
}

/// 指标存储
pub struct WorkflowMetricsStore {
    /// 总体指标
    overall: WorkflowOverallMetrics,
    /// 资源使用情况
    resource_usage: ResourceUsage,
    /// 热门工作流
    top_workflows: Vec<TopWorkflowData>,
    /// 最近错误
    recent_errors: Vec<WorkflowError>,
    /// 历史趋势数据
    trends: WorkflowTrends,
}

impl WorkflowMetricsStore {
    /// 创建新的指标存储
    pub fn new() -> Self {
        Self {
            overall: WorkflowOverallMetrics::default(),
            resource_usage: ResourceUsage::default(),
            top_workflows: Vec::new(),
            recent_errors: Vec::new(),
            trends: WorkflowTrends::new(100), // 保留100个数据点
        }
    }
    
    /// 更新总体指标
    pub async fn update_overall_metrics(
        &mut self,
        active_workflows: u64,
        completed_workflows: u64,
        failed_workflows: u64,
        avg_execution_time
pub async fn update_overall_metrics(
    &mut self,
    active_workflows: u64,
    completed_workflows: u64,
    failed_workflows: u64,
    avg_execution_time: f64,
    success_rate: f64,
) -> Result<(), Error> {
    self.overall.active_workflows = active_workflows;
    self.overall.completed_workflows = completed_workflows;
    self.overall.failed_workflows = failed_workflows;
    self.overall.avg_execution_time = avg_execution_time;
    self.overall.success_rate = success_rate;
    self.overall.last_updated = chrono::Utc::now();
    
    Ok(())
}

/// 更新资源使用情况
pub async fn update_resource_usage(
    &mut self,
    memory_usage: f64,
    cpu_usage: f64,
    connection_count: u64,
) -> Result<(), Error> {
    self.resource_usage.memory_usage = memory_usage;
    self.resource_usage.cpu_usage = cpu_usage;
    self.resource_usage.connection_count = connection_count;
    
    Ok(())
}

/// 更新热门工作流
pub async fn update_top_workflows(
    &mut self,
    workflows: Vec<TopWorkflowData>,
) -> Result<(), Error> {
    self.top_workflows = workflows;
    
    Ok(())
}

/// 更新最近错误
pub async fn update_recent_errors(
    &mut self,
    errors: Vec<WorkflowError>,
) -> Result<(), Error> {
    self.recent_errors = errors;
    
    Ok(())
}

/// 添加趋势数据点
pub async fn add_trend_data_point(
    &mut self,
    timestamp: chrono::DateTime<chrono::Utc>,
    active_workflows: u64,
    avg_execution_time: f64,
    error_rate: f64,
) -> Result<(), Error> {
    self.trends.add_data_point(
        timestamp,
        active_workflows,
        avg_execution_time,
        error_rate,
    );
    
    Ok(())
}

/// 获取所有统计数据
pub async fn get_overall_statistics(&self) -> Result<WorkflowStatistics, Error> {
    Ok(WorkflowStatistics {
        overall: self.overall.clone(),
        resource_usage: self.resource_usage.clone(),
        top_workflows: self.top_workflows.clone(),
        recent_errors: self.recent_errors.clone(),
        trends: self.trends.get_data(),
    })
}
}

/// 工作流异常检测服务
pub struct WorkflowAnomalyDetector {
    /// 工作流引擎引用
    workflow_engine: Arc<WorkflowExecutionEngine>,
    /// 指标收集器
    metrics_collector: Arc<WorkflowMetricsCollector>,
    /// 异常检测模型
    anomaly_model: Arc<dyn AnomalyDetectionModel>,
    /// 异常阈值设置
    thresholds: AnomalyThresholds,
    /// 检测间隔
    detection_interval: Duration,
    /// 通知处理器
    notification_sender: mpsc::Sender<AnomalyNotification>,
    /// 活跃的检测任务
    detection_task: Arc<AtomicBool>,
}

impl WorkflowAnomalyDetector {
    /// 创建新的异常检测器
    pub fn new(
        workflow_engine: Arc<WorkflowExecutionEngine>,
        metrics_collector: Arc<WorkflowMetricsCollector>,
        anomaly_model: Arc<dyn AnomalyDetectionModel>,
        thresholds: AnomalyThresholds,
        detection_interval: Duration,
    ) -> (Self, mpsc::Receiver<AnomalyNotification>) {
        let (sender, receiver) = mpsc::channel(100);
        
        (Self {
            workflow_engine,
            metrics_collector,
            anomaly_model,
            thresholds,
            detection_interval,
            notification_sender: sender,
            detection_task: Arc::new(AtomicBool::new(false)),
        }, receiver)
    }
    
    /// 启动异常检测
    pub async fn start(&self) -> Result<(), Error> {
        if self.detection_task.load(Ordering::SeqCst) {
            return Err(Error::AlreadyRunning("异常检测器已经在运行".into()));
        }
        
        self.detection_task.store(true, Ordering::SeqCst);
        
        let engine = self.workflow_engine.clone();
        let metrics = self.metrics_collector.clone();
        let model = self.anomaly_model.clone();
        let thresholds = self.thresholds.clone();
        let interval = self.detection_interval;
        let sender = self.notification_sender.clone();
        let is_running = self.detection_task.clone();
        
        tokio::spawn(async move {
            let mut detection_interval = tokio::time::interval(interval);
            
            while is_running.load(Ordering::SeqCst) {
                detection_interval.tick().await;
                
                // 获取活跃工作流
                match engine.get_active_workflows().await {
                    Ok(active_workflows) => {
                        // 检测每个工作流的异常
                        for workflow in active_workflows {
                            if let Err(e) = Self::detect_workflow_anomalies(
                                engine.clone(),
                                metrics.clone(),
                                model.clone(),
                                &thresholds,
                                &workflow,
                                &sender,
                            ).await {
                                log::error!("检测工作流 {} 异常时发生错误: {}", workflow.id, e);
                            }
                        }
                    }
                    Err(e) => {
                        log::error!("获取活跃工作流时发生错误: {}", e);
                    }
                }
            }
        });
        
        Ok(())
    }
    
    /// 停止异常检测
    pub fn stop(&self) {
        self.detection_task.store(false, Ordering::SeqCst);
    }
    
    /// 检测单个工作流的异常
    async fn detect_workflow_anomalies(
        engine: Arc<WorkflowExecutionEngine>,
        metrics: Arc<WorkflowMetricsCollector>,
        model: Arc<dyn AnomalyDetectionModel>,
        thresholds: &AnomalyThresholds,
        workflow: &WorkflowInstance,
        sender: &mpsc::Sender<AnomalyNotification>,
    ) -> Result<(), Error> {
        // 获取工作流执行指标
        let workflow_metrics = engine.get_workflow_metrics(&workflow.id).await?;
        
        // 提取特征
        let features = Self::extract_features(workflow, &workflow_metrics)?;
        
        // 检测异常
        let anomalies = model.detect_anomalies(&features).await?;
        
        // 过滤超过阈值的异常
        let significant_anomalies = anomalies.into_iter()
            .filter(|anomaly| {
                match anomaly.anomaly_type {
                    AnomalyType::ExecutionDelay => 
                        anomaly.severity > thresholds.execution_delay_threshold,
                    AnomalyType::ResourceUsage => 
                        anomaly.severity > thresholds.resource_usage_threshold,
                    AnomalyType::ErrorRate => 
                        anomaly.severity > thresholds.error_rate_threshold,
                    AnomalyType::StateTransitionAnomaly => 
                        anomaly.severity > thresholds.state_transition_threshold,
                    AnomalyType::DataVolatility => 
                        anomaly.severity > thresholds.data_volatility_threshold,
                }
            })
            .collect::<Vec<_>>();
        
        // 发送通知
        for anomaly in significant_anomalies {
            let notification = AnomalyNotification {
                workflow_id: workflow.id.clone(),
                workflow_name: workflow.name.clone(),
                anomaly_type: anomaly.anomaly_type,
                severity: anomaly.severity,
                detected_at: chrono::Utc::now(),
                description: anomaly.description,
                affected_components: anomaly.affected_components,
                recommended_action: Self::generate_recommendation(&anomaly, workflow).await?,
            };
            
            if let Err(e) = sender.send(notification).await {
                log::error!("发送异常通知时发生错误: {}", e);
            }
        }
        
        Ok(())
    }
    
    /// 提取特征
    fn extract_features(
        workflow: &WorkflowInstance,
        metrics: &WorkflowMetrics,
    ) -> Result<AnomalyFeatures, Error> {
        // 计算执行时间比例
        let expected_duration = workflow.expected_duration.unwrap_or(Duration::from_secs(300));
        let actual_duration = chrono::Utc::now()
            .signed_duration_since(workflow.start_time)
            .to_std()
            .unwrap_or(Duration::from_secs(0));
        
        let execution_time_ratio = if expected_duration.as_secs() > 0 {
            actual_duration.as_secs_f64() / expected_duration.as_secs_f64()
        } else {
            1.0
        };
        
        // 计算错误率
        let error_rate = if metrics.total_tasks > 0 {
            metrics.failed_tasks as f64 / metrics.total_tasks as f64
        } else {
            0.0
        };
        
        // 计算资源使用率
        let resource_usage_ratio = metrics.resource_usage.values().fold(0.0, |acc, &val| acc.max(val)) / 100.0;
        
        // 收集状态转换特征
        let state_transitions = workflow.state_transitions.clone();
        let state_transition_count = state_transitions.len();
        
        // 计算平均步骤执行时间偏差
        let avg_step_duration_deviation = if metrics.step_durations.len() > 0 {
            let mean_duration = metrics.step_durations.values().sum::<f64>() / metrics.step_durations.len() as f64;
            
            metrics.step_durations.values()
                .map(|&duration| (duration - mean_duration).powi(2))
                .sum::<f64>() / metrics.step_durations.len() as f64
        } else {
            0.0
        };
        
        Ok(AnomalyFeatures {
            workflow_type: workflow.workflow_type.clone(),
            execution_time_ratio,
            progress_percentage: metrics.completion_rate,
            error_rate,
            resource_usage_ratio,
            active_step_count: metrics.active_steps,
            state_transition_count,
            avg_step_duration_deviation,
            data_volume: metrics.data_processed_bytes as f64,
            worker_load_variance: metrics.worker_load_variance,
            task_queue_length: metrics.task_queue_length as f64,
        })
    }
    
    /// 生成建议
    async fn generate_recommendation(
        anomaly: &AnomalyData,
        workflow: &WorkflowInstance,
    ) -> Result<String, Error> {
        // 基于异常类型和严重性生成不同的建议
        let recommendation = match anomaly.anomaly_type {
            AnomalyType::ExecutionDelay => {
                if anomaly.severity > 0.8 {
                    format!("工作流执行严重延迟，建议检查资源分配或考虑取消执行。")
                } else {
                    format!("工作流执行延迟，建议增加资源或检查潜在瓶颈。")
                }
            },
            AnomalyType::ResourceUsage => {
                if anomaly.severity > 0.8 {
                    format!("资源使用率异常高，建议立即扩展资源或调整工作流优先级。")
                } else {
                    format!("资源使用率较高，建议监控系统负载并准备扩展资源。")
                }
            },
            AnomalyType::ErrorRate => {
                if anomaly.severity > 0.8 {
                    format!("错误率极高，建议暂停工作流并检查错误日志以解决系统问题。")
                } else {
                    format!("错误率提高，建议查看错误日志并修复常见失败原因。")
                }
            },
            AnomalyType::StateTransitionAnomaly => {
                format!("状态转换模式异常，可能表明工作流定义或输入数据存在问题。")
            },
            AnomalyType::DataVolatility => {
                format!("数据波动性异常，建议验证输入数据质量或调整处理策略。")
            },
        };
        
        Ok(recommendation)
    }
}

/// 异常检测数据结构
#[derive(Debug, Clone)]
pub struct AnomalyThresholds {
    pub execution_delay_threshold: f64,
    pub resource_usage_threshold: f64,
    pub error_rate_threshold: f64,
    pub state_transition_threshold: f64,
    pub data_volatility_threshold: f64,
}

impl Default for AnomalyThresholds {
    fn default() -> Self {
        Self {
            execution_delay_threshold: 0.7,
            resource_usage_threshold: 0.8,
            error_rate_threshold: 0.3,
            state_transition_threshold: 0.6,
            data_volatility_threshold: 0.7,
        }
    }
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum AnomalyType {
    ExecutionDelay,
    ResourceUsage,
    ErrorRate,
    StateTransitionAnomaly,
    DataVolatility,
}

#[derive(Debug, Clone)]
pub struct AnomalyData {
    pub anomaly_type: AnomalyType,
    pub severity: f64,
    pub description: String,
    pub affected_components: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct AnomalyNotification {
    pub workflow_id: String,
    pub workflow_name: String,
    pub anomaly_type: AnomalyType,
    pub severity: f64,
    pub detected_at: chrono::DateTime<chrono::Utc>,
    pub description: String,
    pub affected_components: Vec<String>,
    pub recommended_action: String,
}

#[derive(Debug, Clone)]
pub struct AnomalyFeatures {
    pub workflow_type: String,
    pub execution_time_ratio: f64,
    pub progress_percentage: f64,
    pub error_rate: f64,
    pub resource_usage_ratio: f64,
    pub active_step_count: u64,
    pub state_transition_count: usize,
    pub avg_step_duration_deviation: f64,
    pub data_volume: f64,
    pub worker_load_variance: f64,
    pub task_queue_length: f64,
}

/// 异常检测模型接口
#[async_trait]
pub trait AnomalyDetectionModel: Send + Sync {
    /// 检测异常
    async fn detect_anomalies(&self, features: &AnomalyFeatures) -> Result<Vec<AnomalyData>, Error>;
    
    /// 训练模型
    async fn train(&self, training_data: &[TrainingRecord]) -> Result<(), Error>;
}

/// 基本统计模型实现
pub struct StatisticalAnomalyModel {
    /// 工作流类型正常范围
    normal_ranges: RwLock<HashMap<String, NormalRange>>,
    /// 异常检测规则
    rules: Vec<AnomalyRule>,
    /// 模型训练状态
    training_state: RwLock<TrainingState>,
}

impl StatisticalAnomalyModel {
    pub fn new() -> Self {
        Self {
            normal_ranges: RwLock::new(HashMap::new()),
            rules: Self::default_rules(),
            training_state: RwLock::new(TrainingState {
                last_training: None,
                training_count: 0,
                model_version: 0,
            }),
        }
    }
    
    fn default_rules() -> Vec<AnomalyRule> {
        vec![
            AnomalyRule {
                name: "执行时间异常",
                feature: "execution_time_ratio".to_string(),
                threshold: 1.5,
                anomaly_type: AnomalyType::ExecutionDelay,
                description: "工作流执行时间显著超过预期".to_string(),
            },
            AnomalyRule {
                name: "资源使用异常",
                feature: "resource_usage_ratio".to_string(),
                threshold: 0.8,
                anomaly_type: AnomalyType::ResourceUsage,
                description: "工作流资源使用率异常高".to_string(),
            },
            AnomalyRule {
                name: "错误率异常",
                feature: "error_rate".to_string(),
                threshold: 0.3,
                anomaly_type: AnomalyType::ErrorRate,
                description: "工作流错误率异常高".to_string(),
            },
            AnomalyRule {
                name: "状态转换异常",
                feature: "state_transition_count".to_string(),
                threshold: 10.0,
                anomaly_type: AnomalyType::StateTransitionAnomaly,
                description: "工作流状态转换次数异常".to_string(),
            },
            AnomalyRule {
                name: "数据波动异常",
                feature: "data_volume".to_string(),
                threshold: 2.0,
                anomaly_type: AnomalyType::DataVolatility,
                description: "工作流处理数据量异常波动".to_string(),
            },
        ]
    }
}

/// 工作流预测服务
pub struct WorkflowPredictionService {
    /// 历史数据存储
    history_store: Arc<WorkflowHistoryStore>,
    /// 执行时间预测器
    time_predictor: Arc<dyn ExecutionTimePredictor>,
    /// 资源使用预测器
    resource_predictor: Arc<dyn ResourceUsagePredictor>,
    /// 异常预测器
    anomaly_predictor: Arc<dyn AnomalyPredictor>,
    /// 模型训练器
    model_trainer: Arc<ModelTrainer>,
}

impl WorkflowPredictionService {
    /// 创建新的预测服务
    pub fn new(
        history_store: Arc<WorkflowHistoryStore>,
        time_predictor: Arc<dyn ExecutionTimePredictor>,
        resource_predictor: Arc<dyn ResourceUsagePredictor>,
        anomaly_predictor: Arc<dyn AnomalyPredictor>,
        model_trainer: Arc<ModelTrainer>,
    ) -> Self {
        Self {
            history_store,
            time_predictor,
            resource_predictor,
            anomaly_predictor,
            model_trainer,
        }
    }
    
    /// 预测工作流执行时间
    pub async fn predict_execution_time(
        &self,
        workflow_type: &str,
        input_params: &serde_json::Value,
        context: &ExecutionContext,
    ) -> Result<PredictionResult<Duration>, Error> {
        // 提取特征
        let features = self.extract_time_prediction_features(
            workflow_type,
            input_params,
            context,
        ).await?;
        
        // 执行预测
        let prediction = self.time_predictor.predict(&features).await?;
        
        Ok(prediction)
    }
    
    /// 预测工作流资源使用
    pub async fn predict_resource_usage(
        &self,
        workflow_type: &str,
        input_params: &serde_json::Value,
        context: &ExecutionContext,
    ) -> Result<PredictionResult<ResourceEstimate>, Error> {
        // 提取特征
        let features = self.extract_resource_prediction_features(
            workflow_type,
            input_params,
            context,
        ).await?;
        
        // 执行预测
        let prediction = self.resource_predictor.predict(&features).await?;
        
        Ok(prediction)
    }
    
    /// 预测工作流可能出现的异常
    pub async fn predict_anomalies(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        execution_context: &ExecutionContext,
    ) -> Result<Vec<PredictedAnomaly>, Error> {
        // 获取工作流当前状态
        let workflow_state = match self.get_workflow_state(workflow_id).await {
            Ok(state) => state,
            Err(_) => {
                // 如果工作流尚未启动，使用初始状态
                WorkflowState {
                    id: workflow_id.to_string(),
                    workflow_type: workflow_type.to_string(),
                    status: WorkflowStatus::Initial,
                    steps: Vec::new(),
                    start_time: None,
                    current_duration: Duration::from_secs(0),
                    progress: 0.0,
                }
            }
        };
        
        // 提取特征
        let features = self.extract_anomaly_prediction_features(
            &workflow_state,
            execution_context,
        ).await?;
        
        // 执行预测
        let predictions = self.anomaly_predictor.predict_anomalies(&features).await?;
        
        Ok(predictions)
    }
    
    /// 定期训练预测模型
    pub async fn train_models(&self) -> Result<(), Error> {
        // 获取训练数据
        let training_data = self.history_store.get_training_data().await?;
        
        // 训练执行时间预测模型
        self.model_trainer.train_execution_time_model(&training_data.time_data).await?;
        
        // 训练资源使用预测模型
        self.model_trainer.train_resource_usage_model(&training_data.resource_data).await?;
        
        // 训练异常预测模型
        self.model_trainer.train_anomaly_model(&training_data.anomaly_data).await?;
        
        Ok(())
    }
    
    /// 提取时间预测特征
    async fn extract_time_prediction_features(
        &self,
        workflow_type: &str,
        input_params: &serde_json::Value,
        context: &ExecutionContext,
    ) -> Result<TimePredictionFeatures, Error> {
        // 获取历史执行数据
        let history = self.history_store
            .get_workflow_execution_history(workflow_type, 50)
            .await?;
        
        // 估计输入复杂度
        let input_complexity = self.estimate_input_complexity(input_params)?;
        
        // 计算平均执行时间和标准差
        let mut total_time = Duration::from_secs(0);
        let mut times = Vec::new();
        
        for record in &history {
            total_time += record.execution_time;
            times.push(record.execution_time.as_secs_f64());
        }
        
        let avg_time = if !history.is_empty() {
            total_time.div_f64(history.len() as f64)
        } else {
            Duration::from_secs(60) // 默认1分钟
        };
        
        let std_dev = if !times.is_empty() {
            let mean = avg_time.as_secs_f64();
            (times.iter().map(|&t| (t - mean).powi(2)).sum::<f64>() / times.len() as f64).sqrt()
        } else {
            0.0
        };
        
        // 提取特征
        Ok(TimePredictionFeatures {
            workflow_type: workflow_type.to_string(),
            input_complexity,
            params_hash: self.hash_params(input_params)?,
            historical_avg_time: avg_time.as_secs_f64(),
            historical_std_dev: std_dev,
            similar_workflow_times: self.find_similar_workflow_times(
                workflow_type,
                input_params,
                &history,
            )?,
            context_features: self.extract_context_features(context)?,
        })
    }
    
    // [其他提取特征和预测方法的实现]
}
```

### 前端异常监控组件实现

```jsx
/**
 * 工作流异常监控组件
 */
import React, { useState, useEffect } from 'react';
import { 
  Box, Typography, Paper, Card, CardContent, CardHeader,
  List, ListItem, ListItemText, ListItemIcon, Grid,
  Chip, Button, Dialog, DialogTitle, DialogContent, DialogActions,
  Alert, Snackbar, Divider, IconButton, Tooltip
} from '@mui/material';
import { 
  Warning, Error, Info, ArrowUpward, ArrowDownward, 
  Refresh, AssignmentLate, Memory, Speed, DataUsage, Transform,
  SettingsBackupRestore, Done, Close
} from '@mui/icons-material';

const AnomalyMonitor = ({ wsService }) => {
  const [anomalies, setAnomalies] = useState([]);
  const [selectedAnomaly, setSelectedAnomaly] = useState(null);
  const [dialogOpen, setDialogOpen] = useState(false);
  const [snackbarOpen, setSnackbarOpen] = useState(false);
  const [snackbarMessage, setSnackbarMessage] = useState('');
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  
  useEffect(() => {
    // 添加WebSocket事件监听器
    const handleAnomalyUpdate = (data) => {
      if (data.anomalies) {
        setAnomalies(prevAnomalies => {
          // 合并新的异常，避免重复
          const existingIds = new Set(prevAnomalies.map(a => a.id));
          const newAnomalies = data.anomalies.filter(a => !existingIds.has(a.id));
          return [...prevAnomalies, ...newAnomalies].sort((a, b) => 
            b.detected_at.localeCompare(a.detected_at)
          );
        });
      }
      setLoading(false);
    };
    
    const handleNewAnomaly = (data) => {
      if (data.anomaly) {
        setAnomalies(prevAnomalies => {
          const newList = [data.anomaly, ...prevAnomalies];
          return newList;
        });
        
        // 显示通知
        setSnackbarMessage(`检测到新异常: ${data.anomaly.description}`);
        setSnackbarOpen(true);
      }
    };
    
    const handleAnomalyResolved = (data) => {
      if (data.anomaly_id) {
        setAnomalies(prevAnomalies => 
          prevAnomalies.filter(a => a.id !== data.anomaly_id)
        );
        
        // 显示通知
        setSnackbarMessage(`异常已解决`);
        setSnackbarOpen(true);
      }
    };
    
    const handleError = (data) => {
      setError(data.error);
      setLoading(false);
    };
    
    wsService.addListener('anomalies', 'anomaly_update', handleAnomalyUpdate);
    wsService.addListener('anomalies', 'new_anomaly', handleNewAnomaly);
    wsService.addListener('anomalies', 'anomaly_resolved', handleAnomalyResolved);
    wsService.addListener('anomalies', 'error', handleError);
    
    // 请求初始异常数据
    wsService.connectToAnomalyMonitor();
    
    // 清理函数
    return () => {
      wsService.removeListener('anomalies', 'anomaly_update', handleAnomalyUpdate);
      wsService.removeListener('anomalies', 'new_anomaly', handleNewAnomaly);
      wsService.removeListener('anomalies', 'anomaly_resolved', handleAnomalyResolved);
      wsService.removeListener('anomalies', 'error', handleError);
      wsService.disconnectFromAnomalyMonitor();
    };
  }, [wsService]);
  
  const handleAnomalyClick = (anomaly) => {
    setSelectedAnomaly(anomaly);
    setDialogOpen(true);
  };
  
  const handleAcknowledge = () => {
    if (selectedAnomaly) {
      wsService.sendMessage('anomalies', {
        action: 'acknowledge',
        anomaly_id: selectedAnomaly.id
      });
      
      // 更新已确认状态
      setAnomalies(prevAnomalies => 
        prevAnomalies.map(a => 
          a.id === selectedAnomaly.id ? {...a, acknowledged: true} : a
        )
      );
      
      setDialogOpen(false);
      setSelectedAnomaly(null);
    }
  };
  
  const handleResolve = () => {
    if (selectedAnomaly) {
      wsService.sendMessage('anomalies', {
        action: 'resolve',
        anomaly_id: selectedAnomaly.id
      });
      
      setDialogOpen(false);
      setSelectedAnomaly(null);
    }
  };
  
  const getAnomalyIcon = (type) => {
    switch (type) {
      case 'EXECUTION_DELAY':
        return <AssignmentLate />;
      case 'RESOURCE_USAGE':
        return <Memory />;
      case 'ERROR_RATE':
        return <Error />;
      case 'STATE_TRANSITION_ANOMALY':
        return <Transform />;
      case 'DATA_VOLATILITY':
        return <DataUsage />;
      default:
        return <Warning />;
    }
  };
  
  const getSeverityColor = (severity) => {
    if (severity > 0.8) return 'error';
    if (severity > 0.5) return 'warning';
    return 'info';
  };
  
  const formatTime = (dateString) => {
    const date = new Date(dateString);
    return date.toLocaleString();
  };
  
  if (loading) {
    return (
      <Box sx={{ display: 'flex', justifyContent: 'center', alignItems: 'center', minHeight: '200px' }}>
        <Typography>加载异常监控数据...</Typography>
      </Box>
    );
  }
  
  if (error) {
    return (
      <Box sx={{ p: 2 }}>
        <Alert severity="error">{error}</Alert>
      </Box>
    );
  }
  
  return (
    <Box>
      <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', mb: 2 }}>
        <Typography variant="h6">工作流异常监控</Typography>
        <Box>
          <Tooltip title="刷新">
            <IconButton onClick={() => wsService.reconnectAnomalyMonitor()}>
              <Refresh />
            </IconButton>
          </Tooltip>
        </Box>
      </Box>
      
      {anomalies.length === 0 ? (
        <Paper sx={{ p: 3, textAlign: 'center' }}>
          <Typography variant="body1" color="textSecondary">
            当前没有检测到异常
          </Typography>
        </Paper>
      ) : (
        <List>
          {anomalies.map((anomaly) => (
            <Paper
              key={anomaly.id}
              sx={{ 
                mb: 2, 
                borderLeft: `4px solid ${getSeverityColor(anomaly.severity) === 'error' ? '#f44336' : 
                             getSeverityColor(anomaly.severity) === 'warning' ? '#ff9800' : '#2196f3'}` 
              }}
            >
              <ListItem 
                button 
                onClick={() => handleAnomalyClick(anomaly)}
                sx={{ 
                  opacity: anomaly.acknowledged ? 0.7 : 1,
                  bgcolor: anomaly.acknowledged ? 'rgba(0, 0, 0, 0.05)' : 'transparent'
                }}
              >
                <ListItemIcon>
                  {getAnomalyIcon(anomaly.anomaly_type)}
                </ListItemIcon>
                <ListItemText
                  primary={
                    <Box sx={{ display: 'flex', alignItems: 'center' }}>
                      <Typography variant="subtitle1" component="span">
                        {anomaly.description}
                      </Typography>
                      {anomaly.acknowledged && (
                        <Chip 
                          size="small" 
                          label="已确认" 
                          sx={{ ml: 1, fontSize: '0.7rem' }}
                        />
                      )}
                    </Box>
                  }
                  secondary={
                    <React.Fragment>
                      <Typography variant="body2" component="span" color="textSecondary">
                        工作流: {anomaly.workflow_name} ({anomaly.workflow_id})
                      </Typography>
                      <br />
                      <Typography variant="body2" component="span" color="textSecondary">
                        检测时间: {formatTime(anomaly.detected_at)}
                      </Typography>
                    </React.Fragment>
                  }
                />
                <Chip 
                  label={`严重程度: ${(anomaly.severity * 100).toFixed(0)}%`}
                  color={getSeverityColor(anomaly.severity)}
                  size="small"
                />
              </ListItem>
            </Paper>
          ))}
        </List>
      )}
      
      {selectedAnomaly && (
        <Dialog open={dialogOpen} onClose={() => setDialogOpen(false)} maxWidth="md" fullWidth>
          <DialogTitle>
            异常详情
          </DialogTitle>
          <DialogContent dividers>
            <Grid container spacing={2}>
              <Grid item xs={12}>
                <Card>
                  <CardHeader 
                    title="异常信息"
                    avatar={getAnomalyIcon(selectedAnomaly.anomaly_type)}
                  />
                  <CardContent>
                    <Typography variant="h6" gutterBottom>
                      {selectedAnomaly.description}
                    </Typography>
                    <Typography variant="body2" color="textSecondary" paragraph>
                      检测时间: {formatTime(selectedAnomaly.detected_at)}
                    </Typography>
                    <Typography variant="body1" gutterBottom>
                      严重程度: {(selectedAnomaly.severity * 100).toFixed(0)}%
                    </Typography>
                    <Divider sx={{ my: 2 }} />
                    <Typography variant="subtitle1" gutterBottom>
                      工作流信息
                    </Typography>
                    <Typography variant="body2" paragraph>
                      工作流名称: {selectedAnomaly.workflow_name}
                      <br />
                      工作流ID: {selectedAnomaly.workflow_id}
                    </Typography>
                    <Divider sx={{ my: 2 }} />
                    <Typography variant="subtitle1" gutterBottom>
                      受影响组件
                    </Typography>
                    {selectedAnomaly.affected_components.length > 0 ? (
                      <ul>
                        {selectedAnomaly.affected_components.map((component, index) => (
                          <li key={index}>
                            <Typography variant="body2">{component}</Typography>
                          </li>
                        ))}
                      </ul>
                    ) : (
                      <Typography variant="body2" color="textSecondary">
                        未指定受影响组件
                      </Typography>
                    )}
                    <Divider sx={{ my: 2 }} />
                    <Typography variant="subtitle1" gutterBottom>
                      建议操作
                    </Typography>
                    <Alert severity="info" sx={{ mt: 1 }}>
                      {selectedAnomaly.recommended_action}
                    </Alert>
                  </CardContent>
                </Card>
              </Grid>
            </Grid>
          </DialogContent>
          <DialogActions>
            <Button 
              onClick={() => setDialogOpen(false)} 
              startIcon={<Close />}
              variant="outlined"
            >
              关闭
            </Button>
            {!selectedAnomaly.acknowledged && (
              <Button 
                onClick={handleAcknowledge}
                color="primary"
                startIcon={<Done />}
              >
                确认
              </Button>
            )}
            <Button 
              onClick={handleResolve}
              color="primary"
              variant="contained"
              startIcon={<SettingsBackupRestore />}
            >
              解决
            </Button>
          </DialogActions>
        </Dialog>
      )}
      
      <Snackbar
        open={snackbarOpen}
        autoHideDuration={6000}
        onClose={() => setSnackbarOpen(false)}
        message={snackbarMessage}
      />
    </Box>
  );
};

export default AnomalyMonitor;
```

现在实现工作流自适应调度器：

```rust
/// 自适应工作流调度器
pub struct AdaptiveWorkflowScheduler {
    // 基础调度器类型
    base_schedulers: HashMap<SchedulingStrategy, Box<dyn WorkflowScheduler>>,
    
    // 当前活跃工作流的调度策略
    active_strategies: RwLock<HashMap<String, SchedulingStrategy>>,
    
    // 工作流历史执行数据
    execution_history: Arc<WorkflowHistoryStore>,
    
    // 资源监控器
    resource_monitor: Arc<ResourceMonitor>,
    
    // 预测引擎
    prediction_engine: Arc<WorkflowPredictionService>,
    
    // 策略选择器
    strategy_selector: Box<dyn StrategySelector>,
    
    // 学习引擎
    learning_engine: Arc<AdaptiveLearningEngine>,
    
    // 系统状态
    system_state: Arc<AtomicSystemState>,
    
    // 配置
    config: AdaptiveSchedulerConfig,
}

impl AdaptiveWorkflowScheduler {
    /// 创建新的自适应调度器
    pub fn new(
        execution_history: Arc<WorkflowHistoryStore>,
        resource_monitor: Arc<ResourceMonitor>,
        prediction_engine: Arc<WorkflowPredictionService>,
        learning_engine: Arc<AdaptiveLearningEngine>,
        config: AdaptiveSchedulerConfig,
    ) -> Self {
        let mut base_schedulers = HashMap::new();
        
        // 创建各种基础调度器
        base_schedulers.insert(
            SchedulingStrategy::RoundRobin,
            Box::new(RoundRobinScheduler::new()) as Box<dyn WorkflowScheduler>,
        );
        
        base_schedulers.insert(
            SchedulingStrategy::ResourceAware,
            Box::new(ResourceAwareScheduler::new()) as Box<dyn WorkflowScheduler>,
        );
        
        base_schedulers.insert(
            SchedulingStrategy::PriorityBased,
            Box::new(PriorityScheduler::new()) as Box<dyn WorkflowScheduler>,
        );
        
        base_schedulers.insert(
            SchedulingStrategy::DataLocality,
            Box::new(DataLocalityScheduler::new()) as Box<dyn WorkflowScheduler>,
        );
        
        base_schedulers.insert(
            SchedulingStrategy::DeadlineAware,
            Box::new(DeadlineAwareScheduler::new()) as Box<dyn WorkflowScheduler>,
        );
        
        Self {
            base_schedulers,
            active_strategies: RwLock::new(HashMap::new()),
            execution_history,
            resource_monitor,
            prediction_engine,
            strategy_selector: Box::new(MLStrategySelector::new()),
            learning_engine,
            system_state: Arc::new(AtomicSystemState::new()),
            config,
        }
    }
    
    /// 调度工作流任务
    pub async fn schedule_workflow_task(
        &self,
        workflow_id: &str,
        task: WorkflowTask,
        context: &ExecutionContext,
    ) -> Result<SchedulingDecision, SchedulingError> {
        // 1. 获取或选择此工作流的调度策略
        let strategy = self.get_or_select_strategy(workflow_id, &task, context).await?;
        
        // 2. 获取对应的调度器
        let scheduler = self.base_schedulers.get(&strategy)
            .ok_or_else(|| SchedulingError::StrategyNotFound(format!("策略 {:?} 未找到", strategy)))?;
        
        // 3. 使用对应的调度器进行调度
        let decision = scheduler.schedule_task(&task, context).await?;
        
        // 4. 记录调度决策
        self.record_scheduling_decision(workflow_id, &task, &strategy, &decision).await;
        
        // 5. 更新系统状态
        self.update_system_state().await;
        
        Ok(decision)
    }
    
    /// 获取或为工作流选择调度策略
    async fn get_or_select_strategy(
        &self,
        workflow_id: &str,
        task: &WorkflowTask,
        context: &ExecutionContext,
    ) -> Result<SchedulingStrategy, SchedulingError> {
        // 首先检查是否已有活跃策略
        {
            let active_strategies = self.active_strategies.read().await;
            if let Some(strategy) = active_strategies.get(workflow_id) {
                // 如果已有策略,可以直接返回
                if !self.config.enable_strategy_switching {
                    return Ok(*strategy);
                }
                
                // 检查是否应该切换策略(基于配置的策略切换间隔)
                if let Some(last_changed) = self.get_strategy_last_changed(workflow_id).await {
                    let now = Instant::now();
                    if now.duration_since(last_changed) < self.config.strategy_switch_interval {
                        return Ok(*strategy);
                    }
                }
            }
        }
        
        // 需要选择新的策略
        let strategy = self.select_best_strategy(workflow_id, task, context).await?;
        
        // 更新活跃策略
        {
            let mut active_strategies = self.active_strategies.write().await;
            active_strategies.insert(workflow_id.to_string(), strategy);
        }
        
        // 记录策略变更时间
        self.record_strategy_change(workflow_id).await;
        
        Ok(strategy)
    }
    
    /// 选择最佳调度策略
    async fn select_best_strategy(
        &self,
        workflow_id: &str,
        task: &WorkflowTask,
        context: &ExecutionContext,
    ) -> Result<SchedulingStrategy, SchedulingError> {
        // 1. 获取工作流类型
        let workflow_type = &task.workflow_type;
        
        // 2. 获取工作流历史执行信息
        let history = self.execution_history
            .get_workflow_execution_history(workflow_type, 20)
            .await
            .unwrap_or_default();
        
        // 3. 收集特征
        let features = SchedulingFeatures {
            workflow_type: workflow_type.clone(),
            task_type: task.task_type.clone(),
            resource_requirements: task.resource_requirements.clone(),
            execution_history: history,
            system_load: self.resource_monitor.get_system_load().await?,
            data_dependencies: task.data_dependencies.clone(),
            priority: task.priority,
            has_deadline: task.deadline.is_some(),
            workflow_stage: context.workflow_progress,
        };
        
        // 4. 使用策略选择器选择最佳策略
        let strategy = self.strategy_selector
            .select_strategy(&features)
            .await?;
            
        // 5. 记录用于学习
        self.learning_engine
            .observe_strategy_selection(workflow_id, workflow_type, &features, &strategy)
            .await;
            
        Ok(strategy)
    }
    
    /// 记录调度决策
    async fn record_scheduling_decision(
        &self,
        workflow_id: &str,
        task: &WorkflowTask,
        strategy: &SchedulingStrategy,
        decision: &SchedulingDecision,
    ) {
        let record = SchedulingRecord {
            workflow_id: workflow_id.to_string(),
            workflow_type: task.workflow_type.clone(),
            task_id: task.id.clone(),
            task_type: task.task_type.clone(),
            strategy: *strategy,
            decision: decision.clone(),
            timestamp: chrono::Utc::now(),
            system_state: self.system_state.get().clone(),
        };
        
        if let Err(e) = self.execution_history.add_scheduling_record(record).await {
            log::error!("记录调度决策失败: {}", e);
        }
    }
    
    /// 启动自优化循环
    pub async fn start_optimization_loop(self: Arc<Self>) -> Result<(), SchedulingError> {
        let scheduler = self.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(scheduler.config.optimization_interval);
            
            loop {
                interval.tick().await;
                
                // 1. 收集系统指标
                if let Err(e) = scheduler.collect_metrics().await {
                    log::error!("收集系统指标失败: {}", e);
                    continue;
                }
                
                // 2. 分析调度性能
                if let Err(e) = scheduler.analyze_scheduling_performance().await {
                    log::error!("分析调度性能失败: {}", e);
                    continue;
                }
                
                // 3. 优化调度参数
                if let Err(e) = scheduler.optimize_scheduling_parameters().await {
                    log::error!("优化调度参数失败: {}", e);
                    continue;
                }
                
                // 4. 训练预测模型
                if scheduler.config.enable_model_training && 
                   scheduler.should_train_models().await {
                    if let Err(e) = scheduler.prediction_engine.train_models().await {
                        log::error!("训练预测模型失败: {}", e);
                    }
                }
                
                // 5. 重新评估活跃工作流策略
                if scheduler.config.enable_strategy_switching {
                    if let Err(e) = scheduler.reevaluate_active_strategies().await {
                        log::error!("重新评估活跃工作流策略失败: {}", e);
                    }
                }
            }
        });
        
        Ok(())
    }
    
    /// 收集系统指标
    async fn collect_metrics(&self) -> Result<(), SchedulingError> {
        // 1. 获取系统资源使用情况
        let system_metrics = self.resource_monitor.get_system_metrics().await?;
        
        // 2. 获取工作流执行指标
        let workflow_metrics = self.execution_history.get_recent_workflow_metrics().await?;
        
        // 3. 更新系统状态
        let state = SystemState {
            cpu_load: system_metrics.cpu_usage,
            memory_usage: system_metrics.memory_usage,
            io_load: system_metrics.io_usage,
            network_load: system_metrics.network_usage,
            active_workflows: workflow_metrics.active_workflow_count,
            pending_tasks: workflow_metrics.pending_task_count,
            avg_task_wait_time: workflow_metrics.avg_task_wait_time,
            avg_task_processing_time: workflow_metrics.avg_task_processing_time,
        };
        
        self.system_state.set(state);
        
        Ok(())
    }
    
    /// 分析调度性能
    async fn analyze_scheduling_performance(&self) -> Result<PerformanceAnalysis, SchedulingError> {
        // 获取最近的调度记录
        let recent_records = self.execution_history.get_recent_scheduling_records(1000).await?;
        
        // 按策略分组分析
        let mut strategy_performance = HashMap::new();
        for record in &recent_records {
            let stats = strategy_performance
                .entry(record.strategy)
                .or_insert_with(StrategyStats::default);
                
            stats.record_count += 1;
            
            // 基于决策结果更新统计
            if let Some(execution_time) = record.decision.estimated_execution_time {
                stats.total_execution_time += execution_time.as_secs_f64();
            }
            
            if let Some(wait_time) = record.decision.wait_time {
                stats.total_wait_time += wait_time.as_secs_f64();
            }
            
            if record.decision.successful {
                stats.success_count += 1;
            }
        }
        
        // 计算每种策略的平均指标
        let mut strategy_metrics = HashMap::new();
        for (strategy, stats) in strategy_performance {
            if stats.record_count > 0 {
                let avg_execution_time = stats.total_execution_time / stats.record_count as f64;
                let avg_wait_time = stats.total_wait_time / stats.record_count as f64;
                let success_rate = stats.success_count as f64 / stats.record_count as f64;
                
                strategy_metrics.insert(strategy, StrategyMetrics {
                    avg_execution_time,
                    avg_wait_time,
                    success_rate,
                });
            }
        }
        
        // 计算系统整体性能
        let total_records = recent_records.len();
        let successful_records = recent_records.iter().filter(|r| r.decision.successful).count();
        let success_rate = if total_records > 0 {
            successful_records as f64 / total_records as f64
        } else {
            0.0
        };
        
        let total_execution_time: f64 = recent_records.iter()
            .filter_map(|r| r.decision.estimated_execution_time.map(|t| t.as_secs_f64()))
            .sum();
        let avg_execution_time = if total_records > 0 {
            total_execution_time / total_records as f64
        } else {
            0.0
        };
        
        Ok(PerformanceAnalysis {
            strategy_metrics,
            overall_success_rate: success_rate,
            overall_avg_execution_time: avg_execution_time,
            sample_size: total_records,
            timestamp: chrono::Utc::now(),
        })
    }
    
    /// 优化调度参数
    async fn optimize_scheduling_parameters(&self) -> Result<(), SchedulingError> {
        // 1. 获取性能分析
        let analysis = self.analyze_scheduling_performance().await?;
        
        // 2. 根据分析结果优化各调度器的参数
        for (strategy, scheduler) in &self.base_schedulers {
            match strategy {
                SchedulingStrategy::ResourceAware => {
                    if let Some(resource_scheduler) = scheduler.as_any().downcast_ref::<ResourceAwareScheduler>() {
                        // 基于性能分析优化资源参数
                        let mut scheduler = resource_scheduler.to_owned();
                        
                        // 获取此策略的性能指标
                        if let Some(metrics) = analysis.strategy_metrics.get(strategy) {
                            // 动态调整资源权重
                            if metrics.avg_execution_time > analysis.overall_avg_execution_time {
                                // 如果该策略的执行时间比平均值高，增加CPU权重
                                scheduler.update_resource_weights(1.2, 0.9, 0.9);
                            } else {
                                // 否则使用平衡权重
                                scheduler.update_resource_weights(1.0, 1.0, 1.0);
                            }
                        }
                    }
                },
                SchedulingStrategy::DeadlineAware => {
                    if let Some(deadline_scheduler) = scheduler.as_any().downcast_ref::<DeadlineAwareScheduler>() {
                        // 基于性能分析优化截止时间参数
                        let mut scheduler = deadline_scheduler.to_owned();
                        
                        // 获取当前系统负载
                        let system_state = self.system_state.get();
                        
                        // 根据系统负载调整截止时间余量
                        if system_state.cpu_load > 0.8 {
                            // 高负载下增加更多余量
                            scheduler.set_deadline_margin(1.3);
                        } else if system_state.cpu_load > 0.5 {
                            // 中等负载使用适中余量
                            scheduler.set_deadline_margin(1.2);
                        } else {
                            // 低负载使用较小余量
                            scheduler.set_deadline_margin(1.1);
                        }
                    }
                },
                // 其他调度器的参数优化...
                _ => {}
            }
        }
        
        Ok(())
    }
    
    /// 重新评估活跃工作流的调度策略
    async fn reevaluate_active_strategies(&self) -> Result<(), SchedulingError> {
        // 获取所有活跃工作流及其任务
        let active_workflows = self.get_active_workflows().await?;
        
        // 重新评估每个工作流的策略
        for (workflow_id, workflow_info) in active_workflows {
            // 跳过最近刚切换策略的工作流
            if let Some(last_changed) = self.get_strategy_last_changed(&workflow_id).await {
                let now = Instant::now();
                if now.duration_since(last_changed) < self.config.strategy_switch_interval {
                    continue;
                }
            }
            
            // 使用当前最优策略重新评估
            let context = ExecutionContext {
                resource_state: self.resource_monitor.get_resource_state().await?,
                workflow_progress: workflow_info.progress,
                priority_level: workflow_info.priority,
                deadline: workflow_info.deadline,
            };
            
            if let Some(current_task) = workflow_info.current_task {
                // 选择新的最佳策略
                match self.select_best_strategy(&workflow_id, &current_task, &context).await {
                    Ok(new_strategy) => {
                        // 获取当前策略
                        let current_strategy = {
                            let active_strategies = self.active_strategies.read().await;
                            active_strategies.get(&workflow_id).cloned()
                        };
                        
                        // 如果策略不同，更新策略
                        if current_strategy.is_none() || current_strategy.unwrap() != new_strategy {
                            let mut active_strategies = self.active_strategies.write().await;
                            active_strategies.insert(workflow_id.clone(), new_strategy);
                            
                            // 记录策略变更
                            self.record_strategy_change(&workflow_id).await;
                            
                            log::info!(
                                "为工作流 {} 切换调度策略: {:?} -> {:?}",
                                workflow_id, 
                                current_strategy.unwrap_or(SchedulingStrategy::Default),
                                new_strategy
                            );
                        }
                    },
                    Err(e) => {
                        log::error!("为工作流 {} 重新评估策略失败: {}", workflow_id, e);
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// 判断是否应该训练模型
    async fn should_train_models(&self) -> bool {
        // 获取上次训练时间
        if let Some(last_training) = self.learning_engine.get_last_training_time().await {
            let now = Instant::now();
            // 如果距离上次训练时间超过配置的间隔，则进行训练
            now.duration_since(last_training) >= self.config.model_training_interval
        } else {
            // 从未训练过，应该训练
            true
        }
    }
}

/// 调度策略选择器特征
#[async_trait]
pub trait StrategySelector: Send + Sync {
    /// 选择最佳调度策略
    async fn select_strategy(&self, features: &SchedulingFeatures) -> Result<SchedulingStrategy, SchedulingError>;
}

/// 机器学习策略选择器
pub struct MLStrategySelector {
    // 分类模型
    model: Arc<dyn ClassificationModel>,
    
    // 特征转换器
    feature_transformer: Box<dyn FeatureTransformer>,
    
    // 默认策略
    default_strategy: SchedulingStrategy,
}

impl MLStrategySelector {
    pub fn new() -> Self {
        Self {
            model: Arc::new(RandomForestClassifier::new()),
            feature_transformer: Box::new(StandardFeatureTransformer::new()),
            default_strategy: SchedulingStrategy::ResourceAware,
        }
    }
}

#[async_trait]
impl StrategySelector for MLStrategySelector {
    async fn select_strategy(&self, features: &SchedulingFeatures) -> Result<SchedulingStrategy, SchedulingError> {
        // 转换特征为模型可用格式
        let transformed_features = self.feature_transformer.transform(features)?;
        
        // 使用模型预测
        match self.model.predict(&transformed_features).await {
            Ok(strategy) => Ok(strategy),
            Err(e) => {
                log::warn!("策略预测失败，使用默认策略: {}", e);
                Ok(self.default_strategy)
            }
        }
    }
}

/// 自适应调度器配置
#[derive(Clone, Debug)]
pub struct AdaptiveSchedulerConfig {
    // 是否启用策略切换
    pub enable_strategy_switching: bool,
    
    // 策略切换最小间隔
    pub strategy_switch_interval: Duration,
    
    // 参数优化间隔
    pub optimization_interval: Duration,
    
    // 是否启用模型训练
    pub enable_model_training: bool,
    
    // 模型训练间隔
    pub model_training_interval: Duration,
}

impl Default for AdaptiveSchedulerConfig {
    fn default() -> Self {
        Self {
            enable_strategy_switching: true,
            strategy_switch_interval: Duration::from_secs(60),
            optimization_interval: Duration::from_secs(300),
            enable_model_training: true,
    model_training_interval: Duration::from_secs(3600), // 每小时训练一次模型
        }
    }
}

/// 工作流预测服务
pub struct WorkflowPredictionService {
    /// 历史数据存储
    history_store: Arc<WorkflowHistoryStore>,
    
    /// 执行时间预测器
    time_predictor: Box<dyn ExecutionTimePredictor>,
    
    /// 资源使用预测器
    resource_predictor: Box<dyn ResourceUsagePredictor>,
    
    /// 异常预测器
    anomaly_predictor: Box<dyn AnomalyPredictor>,
    
    /// 负载预测器
    load_predictor: Box<dyn LoadPredictor>,
    
    /// 模型管理器
    model_manager: Arc<ModelManager>,
    
    /// 特征提取器
    feature_extractor: Box<dyn FeatureExtractor>,
    
    /// 模型训练配置
    training_config: TrainingConfig,
}

impl WorkflowPredictionService {
    /// 创建新的预测服务
    pub fn new(
        history_store: Arc<WorkflowHistoryStore>,
        model_manager: Arc<ModelManager>,
        feature_extractor: Box<dyn FeatureExtractor>,
        config: TrainingConfig,
    ) -> Self {
        Self {
            history_store,
            time_predictor: Box::new(MLExecutionTimePredictor::new(model_manager.clone())),
            resource_predictor: Box::new(MLResourceUsagePredictor::new(model_manager.clone())),
            anomaly_predictor: Box::new(MLAnomalyPredictor::new(model_manager.clone())),
            load_predictor: Box::new(MLLoadPredictor::new(model_manager.clone())),
            model_manager,
            feature_extractor,
            training_config: config,
        }
    }
    
    /// 预测工作流执行时间
    pub async fn predict_execution_time(
        &self,
        workflow_type: &str,
        input_params: &serde_json::Value,
        context: &ExecutionContext,
    ) -> Result<PredictionResult<Duration>, PredictionError> {
        // 提取时间预测特征
        let features = self.feature_extractor
            .extract_time_prediction_features(workflow_type, input_params, context)
            .await?;
        
        // 执行预测
        let prediction = self.time_predictor.predict(&features).await?;
        
        log::debug!(
            "预测工作流 {} 执行时间为 {:?}，置信度: {:.2}",
            workflow_type,
            prediction.value,
            prediction.confidence
        );
        
        Ok(prediction)
    }
    
    /// 预测工作流资源使用情况
    pub async fn predict_resource_usage(
        &self,
        workflow_type: &str,
        input_params: &serde_json::Value,
        context: &ExecutionContext,
    ) -> Result<PredictionResult<ResourceUsage>, PredictionError> {
        // 提取资源预测特征
        let features = self.feature_extractor
            .extract_resource_prediction_features(workflow_type, input_params, context)
            .await?;
        
        // 执行预测
        let prediction = self.resource_predictor.predict(&features).await?;
        
        log::debug!(
            "预测工作流 {} 资源使用: CPU={:.2}核, 内存={:.2}MB, 网络I/O={:.2}MB",
            workflow_type,
            prediction.value.cpu_cores,
            prediction.value.memory_mb,
            (prediction.value.network_in + prediction.value.network_out) / (1024 * 1024)
        );
        
        Ok(prediction)
    }
    
    /// 预测未来系统负载
    pub async fn predict_future_load(
        &self,
        prediction_window: Duration,
        granularity: Duration,
    ) -> Result<PredictionResult<Vec<SystemLoad>>, PredictionError> {
        // 获取历史负载数据
        let history = self.history_store.get_system_load_history(prediction_window * 3).await?;
        
        // 提取特征
        let features = self.feature_extractor
            .extract_load_prediction_features(&history, prediction_window, granularity)
            .await?;
        
        // 执行预测
        let prediction = self.load_predictor.predict(&features).await?;
        
        log::debug!(
            "预测未来 {:?} 的系统负载，共 {} 个数据点",
            prediction_window,
            prediction.value.len()
        );
        
        Ok(prediction)
    }
    
    /// 检测潜在的异常
    pub async fn detect_potential_anomalies(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        current_state: &WorkflowState,
    ) -> Result<Vec<AnomalyPrediction>, PredictionError> {
        // 提取异常检测特征
        let features = self.feature_extractor
            .extract_anomaly_detection_features(workflow_id, workflow_type, current_state)
            .await?;
        
        // 执行预测
        let predictions = self.anomaly_predictor.predict_anomalies(&features).await?;
        
        if !predictions.is_empty() {
            log::info!(
                "为工作流 {} 检测到 {} 个潜在异常",
                workflow_id,
                predictions.len()
            );
            
            for prediction in &predictions {
                log::debug!(
                    "异常类型: {:?}, 概率: {:.2}, 可能影响: {:?}",
                    prediction.anomaly_type,
                    prediction.probability,
                    prediction.affected_components
                );
            }
        }
        
        Ok(predictions)
    }
    
    /// 获取最佳并行度
    pub async fn get_optimal_parallelism(
        &self,
        workflow_type: &str,
        input_params: &serde_json::Value,
        context: &ExecutionContext,
    ) -> Result<u32, PredictionError> {
        // 首先预测资源使用情况
        let resource_prediction = self.predict_resource_usage(
            workflow_type, 
            input_params, 
            context
        ).await?;
        
        // 获取当前系统资源状态
        let system_resources = context.resource_state.available_resources.clone();
        
        // 计算基于CPU的并行度
        let cpu_parallelism = if resource_prediction.value.cpu_cores > 0.0 {
            (system_resources.cpu_cores as f64 / resource_prediction.value.cpu_cores) as u32
        } else {
            1
        };
        
        // 计算基于内存的并行度
        let memory_parallelism = if resource_prediction.value.memory_mb > 0 {
            (system_resources.memory_mb / resource_prediction.value.memory_mb) as u32
        } else {
            1
        };
        
        // 取最小值作为资源限制下的并行度
        let resource_limited_parallelism = cpu_parallelism.min(memory_parallelism);
        
        // 考虑工作流特定的最佳并行度（可能来自历史数据分析）
        let workflow_stats = self.history_store.get_workflow_stats(workflow_type).await?;
        let workflow_optimal_parallelism = workflow_stats
            .map(|stats| stats.optimal_parallelism)
            .unwrap_or(1);
        
        // 平衡资源限制和工作流最佳并行度
        let optimal_parallelism = resource_limited_parallelism
            .min(workflow_optimal_parallelism)
            .max(1) // 至少1个
            .min(16); // 最多16个（防止过度并行）
        
        log::debug!(
            "为工作流 {} 计算得出最佳并行度: {} (资源限制: {}, 工作流最佳: {})",
            workflow_type,
            optimal_parallelism,
            resource_limited_parallelism,
            workflow_optimal_parallelism
        );
        
        Ok(optimal_parallelism)
    }
    
    /// 训练预测模型
    pub async fn train_models(&self) -> Result<TrainingReport, TrainingError> {
        log::info!("开始训练工作流预测模型");
        
        let training_start = Instant::now();
        let mut report = TrainingReport::default();
        
        // 1. 获取训练数据
        let training_data = self.history_store
            .get_training_data(self.training_config.training_window)
            .await?;
        
        log::info!(
            "收集了 {} 个工作流执行记录用于训练",
            training_data.workflow_executions.len()
        );
        
        // 2. 准备各模型的训练数据集
        let time_prediction_dataset = self.feature_extractor
            .prepare_time_prediction_dataset(&training_data)?;
            
        let resource_prediction_dataset = self.feature_extractor
            .prepare_resource_prediction_dataset(&training_data)?;
            
        let anomaly_detection_dataset = self.feature_extractor
            .prepare_anomaly_detection_dataset(&training_data)?;
            
        let load_prediction_dataset = self.feature_extractor
            .prepare_load_prediction_dataset(&training_data)?;
            
        // 3. 训练各模型
        if !time_prediction_dataset.is_empty() {
            let time_result = self.model_manager
                .train_model(
                    "execution_time_predictor",
                    ModelType::Regression,
                    &time_prediction_dataset,
                    &self.training_config.time_prediction_params,
                )
                .await?;
                
            report.model_results.insert(
                "execution_time_predictor".to_string(), 
                time_result
            );
            
            log::info!(
                "执行时间预测模型训练完成: 精度={:.4}, 样本数={}",
                time_result.accuracy,
                time_result.sample_count
            );
        }
        
        if !resource_prediction_dataset.is_empty() {
            let resource_result = self.model_manager
                .train_model(
                    "resource_usage_predictor",
                    ModelType::Regression,
                    &resource_prediction_dataset,
                    &self.training_config.resource_prediction_params,
                )
                .await?;
                
            report.model_results.insert(
                "resource_usage_predictor".to_string(), 
                resource_result
            );
            
            log::info!(
                "资源使用预测模型训练完成: 精度={:.4}, 样本数={}",
                resource_result.accuracy,
                resource_result.sample_count
            );
        }
        
        if !anomaly_detection_dataset.is_empty() {
            let anomaly_result = self.model_manager
                .train_model(
                    "anomaly_detector",
                    ModelType::BinaryClassification,
                    &anomaly_detection_dataset,
                    &self.training_config.anomaly_detection_params,
                )
                .await?;
                
            report.model_results.insert(
                "anomaly_detector".to_string(), 
                anomaly_result
            );
            
            log::info!(
                "异常检测模型训练完成: 精度={:.4}, 样本数={}",
                anomaly_result.accuracy,
                anomaly_result.sample_count
            );
        }
        
        if !load_prediction_dataset.is_empty() {
            let load_result = self.model_manager
                .train_model(
                    "load_predictor",
                    ModelType::TimeSeries,
                    &load_prediction_dataset,
                    &self.training_config.load_prediction_params,
                )
                .await?;
                
            report.model_results.insert(
                "load_predictor".to_string(), 
                load_result
            );
            
            log::info!(
                "负载预测模型训练完成: 精度={:.4}, 样本数={}",
                load_result.accuracy,
                load_result.sample_count
            );
        }
        
        // 4. 完成报告
        report.training_duration = training_start.elapsed();
        report.timestamp = chrono::Utc::now();
        
        // 5. 存储训练报告
        self.history_store.save_training_report(&report).await?;
        
        log::info!(
            "所有预测模型训练完成，用时: {:?}",
            report.training_duration
        );
        
        Ok(report)
    }
}

/// 资源管理器，负责为工作流分配和管理资源
pub struct ResourceManager {
    // 可用资源池
    resource_pool: RwLock<ResourcePool>,
    
    // 资源分配跟踪
    allocations: RwLock<HashMap<String, ResourceAllocation>>,
    
    // 资源监控
    resource_monitor: Arc<ResourceMonitor>,
    
    // 资源规划器
    resource_planner: Box<dyn ResourcePlanner>,
    
    // 弹性控制器
    elasticity_controller: Box<dyn ElasticityController>,
    
    // 队列管理
    queue_manager: Box<dyn QueueManager>,
    
    // 负载均衡器
    load_balancer: Box<dyn LoadBalancer>,
    
    // 资源策略
    resource_policies: Vec<Box<dyn ResourcePolicy>>,
    
    // 度量收集器
    metrics_collector: Arc<MetricsCollector>,
    
    // 配置
    config: ResourceManagerConfig,
}

impl ResourceManager {
    /// 创建新的资源管理器
    pub fn new(
        resource_monitor: Arc<ResourceMonitor>,
        resource_planner: Box<dyn ResourcePlanner>,
        elasticity_controller: Box<dyn ElasticityController>,
        queue_manager: Box<dyn QueueManager>,
        load_balancer: Box<dyn LoadBalancer>,
        metrics_collector: Arc<MetricsCollector>,
        config: ResourceManagerConfig,
    ) -> Self {
        let resource_policies = vec![
            Box::new(FairSharePolicy::new()) as Box<dyn ResourcePolicy>,
            Box::new(PriorityBasedPolicy::new()) as Box<dyn ResourcePolicy>,
            Box::new(QuotaEnforcementPolicy::new()) as Box<dyn ResourcePolicy>,
        ];
        
        Self {
            resource_pool: RwLock::new(ResourcePool::new()),
            allocations: RwLock::new(HashMap::new()),
            resource_monitor,
            resource_planner,
            elasticity_controller,
            queue_manager,
            load_balancer,
            resource_policies,
            metrics_collector,
            config,
        }
    }
    
    /// 初始化资源池
    pub async fn initialize_resource_pool(
        &self,
        resources: Vec<ResourceDefinition>,
    ) -> Result<(), ResourceError> {
        log::info!("初始化资源池，资源定义数量: {}", resources.len());
        
        // 清空现有资源池
        {
            let mut pool = self.resource_pool.write().await;
            pool.clear();
        }
        
        // 创建初始资源分配
        for resource in resources {
            let allocations = self.resource_planner.create_initial_allocations(&resource)?;
            
            let mut pool = self.resource_pool.write().await;
            pool.add_resource(resource.resource_type.clone(), allocations);
            
            log::debug!(
                "添加资源类型: {}, 初始容量: {:?}",
                resource.resource_type,
                resource.capacity
            );
        }
        
        // 启动资源监控
        self.resource_monitor.start_monitoring().await?;
        
        // 启动弹性控制
        self.elasticity_controller.start(
            Arc::new(self.clone()),
            self.config.scaling_config.clone(),
        ).await?;
        
        log::info!("资源池初始化成功");
        
        Ok(())
    }
    
    /// 为工作流分配资源
    pub async fn allocate_resources(
        &self,
        workflow_id: &str,
        requirements: &ResourceRequirements,
    ) -> Result<ResourceAllocation, ResourceError> {
        log::debug!("为工作流 {} 分配资源", workflow_id);
        
        // 检查队列状态
        if self.queue_manager.should_queue(workflow_id, requirements).await? {
            log::info!("工作流 {} 被加入队列等待资源", workflow_id);
            self.queue_manager.enqueue(workflow_id, requirements.clone()).await?;
            return Err(ResourceError::ResourcesUnavailable("资源不足，已加入队列".to_string()));
        }
        
        // 应用资源策略
        let adjusted_requirements = self.apply_resource_policies(workflow_id, requirements).await?;
        
        // 查找最佳资源匹配
        let allocation = self.find_best_resource_match(&adjusted_requirements).await?;
        
        // 更新资源分配
        {
            let mut allocations = self.allocations.write().await;
            allocations.insert(workflow_id.to_string(), allocation.clone());
        }
        
        // 更新资源池
        {
            let mut pool = self.resource_pool.write().await;
            pool.allocate_resources(&allocation.resource_type, &allocation.resource_amount)?;
        }
        
        // 记录分配
        self.metrics_collector
            .record_resource_allocation(workflow_id, &allocation)
            .await;
            
        log::info!(
            "已为工作流 {} 分配资源: {:?}",
            workflow_id,
            allocation.resource_amount
        );
        
        Ok(allocation)
    }
    
    /// 释放工作流资源
    pub async fn release_resources(
        &self,
        workflow_id: &str,
    ) -> Result<(), ResourceError> {
        log::debug!("释放工作流 {} 的资源", workflow_id);
        
        // 查找分配
        let allocation = {
            let allocations = self.allocations.read().await;
            match allocations.get(workflow_id) {
                Some(allocation) => allocation.clone(),
                None => {
                    log::warn!("尝试释放未分配资源的工作流: {}", workflow_id);
                    return Ok(());
                }
            }
        };
        
        // 更新资源池
        {
            let mut pool = self.resource_pool.write().await;
            pool.release_resources(&allocation.resource_type, &allocation.resource_amount)?;
        }
        
        // 移除分配记录
        {
            let mut allocations = self.allocations.write().await;
            allocations.remove(workflow_id);
        }
        
        // 记录释放
        self.metrics_collector
            .record_resource_release(workflow_id, &allocation)
            .await;
            
        // 从队列中选择下一个工作流（如果有）
        if let Some(queued_workflow) = self.queue_manager.dequeue().await? {
            // 尝试为队列中的工作流分配资源
            match self.allocate_resources(&queued_workflow.workflow_id, &queued_workflow.requirements).await {
                Ok(allocation) => {
                    log::info!("为队列中的工作流 {} 分配了资源", queued_workflow.workflow_id);
                    self.queue_manager.notify_allocated(&queued_workflow.workflow_id, &allocation).await?;
                },
                Err(e) => {
                    log::warn!("无法为队列中的工作流 {} 分配资源: {}", queued_workflow.workflow_id, e);
                    self.queue_manager.enqueue(&queued_workflow.workflow_id, queued_workflow.requirements).await?;
                }
            }
        }
        
        log::info!("已释放工作流 {} 的资源", workflow_id);
        
        Ok(())
    }
}

/// 工作流执行服务 - 整合各个组件
pub struct WorkflowExecutionService {
    // 工作流存储
    workflow_store: Arc<WorkflowStore>,
    
    // 工作流引擎
    workflow_engine: Arc<WorkflowEngine>,
    
    // 调度器
    scheduler: Arc<AdaptiveWorkflowScheduler>,
    
    // 资源管理器
    resource_manager: Arc<ResourceManager>,
    
    // 预测服务
    prediction_service: Arc<WorkflowPredictionService>,
    
    // 执行历史
    history_store: Arc<WorkflowHistoryStore>,
    
    // 指标收集
    metrics_collector: Arc<MetricsCollector>,
    
    // 异常检测器
    anomaly_detector: Arc<AnomalyDetector>,
    
    // 配置
    config: ExecutionServiceConfig,
}

impl WorkflowExecutionService {
    /// 创建工作流执行服务
    pub fn new(
        workflow_store: Arc<WorkflowStore>,
        workflow_engine: Arc<WorkflowEngine>,
        scheduler: Arc<AdaptiveWorkflowScheduler>,
        resource_manager: Arc<ResourceManager>,
        prediction_service: Arc<WorkflowPredictionService>,
        history_store: Arc<WorkflowHistoryStore>,
        metrics_collector: Arc<MetricsCollector>,
        anomaly_detector: Arc<AnomalyDetector>,
        config: ExecutionServiceConfig,
    ) -> Self {
        Self {
            workflow_store,
            workflow_engine,
            scheduler,
            resource_manager,
            prediction_service,
            history_store,
            metrics_collector,
            anomaly_detector,
            config,
        }
    }
    
    /// 提交工作流执行
    pub async fn submit_workflow(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        input: serde_json::Value,
        options: ExecutionOptions,
    ) -> Result<SubmissionResult, ExecutionError> {
        log::info!(
            "提交工作流执行: id={}, type={}, 选项={:?}",
            workflow_id, 
            workflow_type,
            options
        );
        
        // 获取工作流定义
        let workflow_def = self.workflow_store
            .get_workflow_definition(workflow_type)
            .await?;
            
        // 1. 预测资源需求
        let context = ExecutionContext {
            resource_state: self.resource_manager.get_resource_state().await?,
            workflow_progress: 0.0,
            priority_level: options.priority,
            deadline: options.deadline,
        };
        
        let predicted_resources = match self.prediction_service
            .predict_resource_usage(workflow_type, &input, &context)
            .await
        {
            Ok(prediction) => prediction.value,
            Err(e) => {
                log::warn!("预测资源使用失败: {}, 使用默认值", e);
                ResourceUsage::default()
            }
        };
        
        let resource_requirements = ResourceRequirements {
            min_cpu: predicted_resources.cpu_cores * 0.8, // 保守估计
            preferred_cpu: predicted_resources.cpu_cores,
            min_memory: predicted_resources.memory_mb,
            preferred_memory: predicted_resources.memory_mb * 1.2, // 预留额外内存
            min_io: predicted_resources.io_throughput,
            preferred_io: predicted_resources.io_throughput * 1.2,
            min_network: predicted_resources.network_throughput,
            preferred_network: predicted_resources.network_throughput * 1.2,
        };
        
        // 2. 分配资源
        let resource_allocation = match self.resource_manager
            .allocate_resources(workflow_id, &resource_requirements)
            .await
        {
            Ok(allocation) => Some(allocation),
            Err(e) => {
                if matches!(e, ResourceError::ResourcesUnavailable(_)) {
                    log::info!("资源不足，工作流已加入队列");
                    None
                } else {
                    return Err(ExecutionError::ResourceAllocationFailed(e.to_string()));
                }
            }
        };
        
        // 3. 如果已分配资源，则准备工作流执行
        if let Some(allocation) = resource_allocation {
            // 预测执行时间
            let predicted_duration = match self.prediction_service
                .predict_execution_time(workflow_type, &input, &context)
                .await
            {
                Ok(prediction) => prediction.value,
                Err(e) => {
                    log::warn!("预测执行时间失败: {}, 使用默认值", e);
                    Duration::from_secs(60) // 默认1分钟
                }
            };
            
            // 创建工作流实例
            let instance = WorkflowInstance {
                id: workflow_id.to_string(),
                workflow_type: workflow_type.to_string(),
                definition: workflow_def,
                input,
                status: WorkflowStatus::Ready,
                created_at: chrono::Utc::now(),
                started_at: None,
                completed_at: None,
                resource_allocation: allocation.clone(),
                predicted_duration,
                options,
            };
            
            // 提交到引擎执行
            match self.workflow_engine.submit(instance).await {
                Ok(execution_id) => {
                    log::info!("工作流已提交到引擎，执行ID: {}", execution_id);
                    
                    // 开始异常检测
                    self.anomaly_detector.start_monitoring(workflow_id).await?;
                    
                    Ok(SubmissionResult {
                        workflow_id: workflow_id.to_string(),
                        execution_id,
                        status: WorkflowSubmissionStatus::Submitted,
                        estimated_start_time: Some(chrono::Utc::now()),
                        estimated_duration: Some(predicted_duration),
                        resource_allocation: Some(allocation),
                    })
                },
                Err(e) => {
                    // 释放已分配的资源
                    if let Err(release_err) = self.resource_manager.release_resources(workflow_id).await {
                        log::error!("释放资源失败: {}", release_err);
                    }
                    
                    Err(ExecutionError::SubmissionFailed(e.to_string()))
                }
            }
        } else {
            // 已加入队列
            Ok(SubmissionResult {
                workflow_id: workflow_id.to_string(),
                execution_id: String::new(), // 空ID表示尚未执行
                status: WorkflowSubmissionStatus::Queued,
                estimated_start_time: None,
                estimated_duration: None,
                resource_allocation: None,
            })
        }
    }
}
```

工作流监控和故障恢复

```rust
/// 工作流监控服务
pub struct WorkflowMonitoringService {
    /// 工作流状态存储
    state_storage: Arc<StateStorage>,
    
    /// 指标收集器
    metrics_collector: Arc<MetricsCollector>,
    
    /// 故障检测器
    fault_detector: Box<dyn FaultDetector>,
    
    /// 故障恢复控制器
    recovery_controller: Box<dyn RecoveryController>,
    
    /// 监控配置
    monitor_config: MonitoringConfig,
    
    /// 告警管理器
    alert_manager: Box<dyn AlertManager>,
    
    /// 健康检查器
    health_checker: Box<dyn HealthChecker>,
    
    /// 快照管理器
    snapshot_manager: Arc<SnapshotManager>,
    
    /// 故障历史记录
    fault_history: Arc<FaultHistory>,
    
    /// 监控工作器
    monitoring_worker: Option<JoinHandle<()>>,
    
    /// 关闭信号
    shutdown: Arc<AtomicBool>,
}

impl WorkflowMonitoringService {
    /// 创建新的工作流监控服务
    pub fn new(
        state_storage: Arc<StateStorage>,
        metrics_collector: Arc<MetricsCollector>,
        fault_detector: Box<dyn FaultDetector>,
        recovery_controller: Box<dyn RecoveryController>,
        alert_manager: Box<dyn AlertManager>,
        health_checker: Box<dyn HealthChecker>,
        snapshot_manager: Arc<SnapshotManager>,
        fault_history: Arc<FaultHistory>,
        config: MonitoringConfig,
    ) -> Self {
        Self {
            state_storage,
            metrics_collector,
            fault_detector,
            recovery_controller,
            monitor_config: config,
            alert_manager,
            health_checker,
            snapshot_manager,
            fault_history,
            monitoring_worker: None,
            shutdown: Arc::new(AtomicBool::new(false)),
        }
    }
    
    /// 启动监控服务
    pub async fn start(&mut self) -> Result<(), MonitoringError> {
        if self.monitoring_worker.is_some() {
            return Err(MonitoringError::AlreadyRunning("监控服务已在运行".to_string()));
        }
        
        log::info!("启动工作流监控服务");
        
        // 重置关闭信号
        self.shutdown.store(false, Ordering::SeqCst);
        
        // 初始化故障历史
        self.fault_history.initialize().await?;
        
        // 启动健康检查
        self.health_checker.start().await?;
        
        // 创建监控循环
        let shutdown = self.shutdown.clone();
        let fault_detector = Arc::new(Mutex::new(self.fault_detector.clone_box()));
        let recovery_controller = Arc::new(Mutex::new(self.recovery_controller.clone_box()));
        let state_storage = self.state_storage.clone();
        let alert_manager = Arc::new(Mutex::new(self.alert_manager.clone_box()));
        let snapshot_manager = self.snapshot_manager.clone();
        let fault_history = self.fault_history.clone();
        let monitor_interval = self.monitor_config.monitoring_interval;
        
        // 启动监控工作器
        let handle = tokio::spawn(async move {
            log::info!("工作流监控循环已启动");
            
            let mut last_snapshot_time = Instant::now();
            let snapshot_interval = Duration::from_secs(300); // 5分钟快照间隔
            
            while !shutdown.load(Ordering::SeqCst) {
                // 执行故障检测和恢复
                if let Err(e) = Self::run_monitoring_cycle(
                    fault_detector.clone(),
                    recovery_controller.clone(),
                    state_storage.clone(),
                    alert_manager.clone(),
                    fault_history.clone(),
                ).await {
                    log::error!("监控循环执行失败: {}", e);
                }
                
                // 检查是否需要创建快照
                let now = Instant::now();
                if now.duration_since(last_snapshot_time) >= snapshot_interval {
                    if let Err(e) = snapshot_manager.create_periodic_snapshots().await {
                        log::error!("创建定期快照失败: {}", e);
                    }
                    last_snapshot_time = now;
                }
                
                // 等待至下一个监控周期
                tokio::time::sleep(monitor_interval).await;
            }
            
            log::info!("工作流监控循环已停止");
        });
        
        self.monitoring_worker = Some(handle);
        
        log::info!("工作流监控服务已启动");
        Ok(())
    }
    
    /// 停止监控服务
    pub async fn stop(&mut self) -> Result<(), MonitoringError> {
        if self.monitoring_worker.is_none() {
            return Ok(());
        }
        
        log::info!("停止工作流监控服务");
        
        // 设置关闭信号
        self.shutdown.store(true, Ordering::SeqCst);
        
        // 等待工作器完成
        if let Some(worker) = self.monitoring_worker.take() {
            match tokio::time::timeout(Duration::from_secs(10), worker).await {
                Ok(result) => {
                    if let Err(e) = result {
                        log::error!("监控工作器意外终止: {}", e);
                    }
                },
                Err(_) => {
                    log::warn!("监控工作器停止超时，强制中断");
                    // 任务将被废弃
                }
            }
        }
        
        // 停止健康检查
        self.health_checker.stop().await?;
        
        log::info!("工作流监控服务已停止");
        Ok(())
    }
    
    /// 运行单次监控循环
    async fn run_monitoring_cycle(
        fault_detector: Arc<Mutex<Box<dyn FaultDetector>>>,
        recovery_controller: Arc<Mutex<Box<dyn RecoveryController>>>,
        state_storage: Arc<StateStorage>,
        alert_manager: Arc<Mutex<Box<dyn AlertManager>>>,
        fault_history: Arc<FaultHistory>,
    ) -> Result<(), MonitoringError> {
        // 获取活跃工作流执行
        let active_executions = state_storage.get_active_executions().await?;
        
        // 获取节点状态
        let node_statuses = state_storage.get_all_node_statuses().await?;
        
        // 检测工作流故障
        let workflow_faults = {
            let detector = fault_detector.lock().await;
            detector.detect_workflow_faults(&active_executions).await?
        };
        
        // 检测节点故障
        let node_faults = {
            let detector = fault_detector.lock().await;
            detector.detect_node_faults(&node_statuses).await?
        };
        
        // 处理工作流故障
        for fault in workflow_faults {
            // 记录故障
            fault_history.record_fault(&fault).await?;
            
            // 发送告警
            {
                let alert_mgr = alert_manager.lock().await;
                alert_mgr.send_workflow_fault_alert(&fault).await?;
            }
            
            // 应用恢复策略
            {
                let mut controller = recovery_controller.lock().await;
                match controller.recover_workflow_fault(&fault).await {
                    Ok(result) => {
                        // 记录恢复结果
                        fault_history.record_recovery_result(&fault.fault_id, &result).await?;
                        
                        if result.success {
                            log::info!(
                                "工作流故障恢复成功: {} ({})",
                                fault.workflow_id,
                                fault.fault_type
                            );
                        } else {
                            log::error!(
                                "工作流故障恢复失败: {} ({}): {}",
                                fault.workflow_id,
                                fault.fault_type,
                                result.error_message.unwrap_or_default()
                            );
                        }
                    },
                    Err(e) => {
                        log::error!(
                            "工作流故障恢复出错: {} ({}): {}",
                            fault.workflow_id,
                            fault.fault_type,
                            e
                        );
                    }
                }
            }
        }
        
        // 处理节点故障
        for fault in node_faults {
            // 记录故障
            fault_history.record_fault(&fault).await?;
            
            // 发送告警
            {
                let alert_mgr = alert_manager.lock().await;
                alert_mgr.send_node_fault_alert(&fault).await?;
            }
            
            // 应用恢复策略
            {
                let mut controller = recovery_controller.lock().await;
                match controller.recover_node_fault(&fault).await {
                    Ok(result) => {
                        // 记录恢复结果
                        fault_history.record_recovery_result(&fault.fault_id, &result).await?;
                        
                        if result.success {
                            log::info!(
                                "节点故障恢复成功: {} ({})",
                                fault.node_id,
                                fault.fault_type
                            );
                        } else {
                            log::error!(
                                "节点故障恢复失败: {} ({}): {}",
                                fault.node_id,
                                fault.fault_type,
                                result.error_message.unwrap_or_default()
                            );
                        }
                    },
                    Err(e) => {
                        log::error!(
                            "节点故障恢复出错: {} ({}): {}",
                            fault.node_id,
                            fault.fault_type,
                            e
                        );
                    }
                }
            }
        }
        
        Ok(())
    }
}

/// 故障恢复控制器
pub struct FaultRecoveryController {
    /// 状态存储
    state_storage: Arc<StateStorage>,
    
    /// 工作流引擎
    workflow_engine: Arc<WorkflowEngine>,
    
    /// 节点管理器
    node_manager: Arc<NodeManager>,
    
    /// 快照管理器
    snapshot_manager: Arc<SnapshotManager>,
    
    /// 恢复策略提供者
    strategy_provider: Box<dyn RecoveryStrategyProvider>,
    
    /// 工作流恢复处理器集合
    workflow_recovery_handlers: HashMap<WorkflowFaultType, Box<dyn WorkflowRecoveryHandler>>,
    
    /// 节点恢复处理器集合
    node_recovery_handlers: HashMap<NodeFaultType, Box<dyn NodeRecoveryHandler>>,
    
    /// 度量收集器
    metrics: Arc<MetricsCollector>,
    
    /// 恢复配置
    config: RecoveryConfig,
}

impl FaultRecoveryController {
    /// 创建新的故障恢复控制器
    pub fn new(
        state_storage: Arc<StateStorage>,
        workflow_engine: Arc<WorkflowEngine>,
        node_manager: Arc<NodeManager>,
        snapshot_manager: Arc<SnapshotManager>,
        strategy_provider: Box<dyn RecoveryStrategyProvider>,
        metrics: Arc<MetricsCollector>,
        config: RecoveryConfig,
    ) -> Self {
        let mut controller = Self {
            state_storage,
            workflow_engine,
            node_manager,
            snapshot_manager,
            strategy_provider,
            workflow_recovery_handlers: HashMap::new(),
            node_recovery_handlers: HashMap::new(),
            metrics,
            config,
        };
        
        // 注册默认工作流故障处理器
        controller.register_default_workflow_handlers();
        
        // 注册默认节点故障处理器
        controller.register_default_node_handlers();
        
        controller
    }
    
    /// 注册默认工作流故障处理器
    fn register_default_workflow_handlers(&mut self) {
        // 注册超时处理器
        self.register_workflow_handler(
            WorkflowFaultType::Timeout,
            Box::new(TimeoutRecoveryHandler::new(
                self.workflow_engine.clone(),
                self.config.max_workflow_retries,
            )),
        );
        
        // 注册步骤失败处理器
        self.register_workflow_handler(
            WorkflowFaultType::StepFailed,
            Box::new(StepFailureRecoveryHandler::new(
                self.workflow_engine.clone(),
                self.snapshot_manager.clone(),
                self.config.max_step_retries,
            )),
        );
        
        // 注册资源不足处理器
        self.register_workflow_handler(
            WorkflowFaultType::ResourceExhausted,
            Box::new(ResourceExhaustionRecoveryHandler::new(
                self.workflow_engine.clone(),
                self.node_manager.clone(),
            )),
        );
        
        // 注册状态损坏处理器
        self.register_workflow_handler(
            WorkflowFaultType::StateCorruption,
            Box::new(StateCorruptionRecoveryHandler::new(
                self.workflow_engine.clone(),
                self.snapshot_manager.clone(),
            )),
        );
    }
    
    /// 注册默认节点故障处理器
    fn register_default_node_handlers(&mut self) {
        // 注册节点崩溃处理器
        self.register_node_handler(
            NodeFaultType::Crashed,
            Box::new(NodeCrashRecoveryHandler::new(
                self.node_manager.clone(),
                self.workflow_engine.clone(),
            )),
        );
        
        // 注册节点超载处理器
        self.register_node_handler(
            NodeFaultType::Overloaded,
            Box::new(NodeOverloadRecoveryHandler::new(
                self.node_manager.clone(),
            )),
        );
        
        // 注册网络分区处理器
        self.register_node_handler(
            NodeFaultType::NetworkPartitioned,
            Box::new(NetworkPartitionRecoveryHandler::new(
                self.node_manager.clone(),
            )),
        );
        
        // 注册磁盘空间不足处理器
        self.register_node_handler(
            NodeFaultType::DiskSpaceExhausted,
            Box::new(DiskSpaceRecoveryHandler::new(
                self.node_manager.clone(),
            )),
        );
    }
    
    /// 注册工作流故障处理器
    pub fn register_workflow_handler(
        &mut self,
        fault_type: WorkflowFaultType,
        handler: Box<dyn WorkflowRecoveryHandler>,
    ) {
        self.workflow_recovery_handlers.insert(fault_type, handler);
    }
    
    /// 注册节点故障处理器
    pub fn register_node_handler(
        &mut self,
        fault_type: NodeFaultType,
        handler: Box<dyn NodeRecoveryHandler>,
    ) {
        self.node_recovery_handlers.insert(fault_type, handler);
    }
}

impl RecoveryController for FaultRecoveryController {
    /// 恢复工作流故障
    async fn recover_workflow_fault(
        &mut self,
        fault: &WorkflowFault,
    ) -> Result<RecoveryResult, RecoveryError> {
        // 记录恢复尝试
        self.metrics.recovery_attempt(&fault.fault_id, "workflow");
        let start_time = Instant::now();
        
        log::info!(
            "开始恢复工作流故障: {} ({})",
            fault.workflow_id,
            fault.fault_type
        );
        
        // 获取恢复策略
        let strategy = self.strategy_provider
            .get_workflow_recovery_strategy(fault)
            .await?;
            
        log::debug!(
            "为工作流故障 {} 选择恢复策略: {:?}",
            fault.workflow_id,
            strategy.strategy_type
        );
        
        // 获取处理器
        let handler = match self.workflow_recovery_handlers.get_mut(&fault.fault_type) {
            Some(handler) => handler,
            None => {
                return Err(RecoveryError::UnsupportedFaultType(
                    format!("不支持的工作流故障类型: {:?}", fault.fault_type)
                ));
            }
        };
        
        // 执行恢复
        let result = handler.recover(fault, &strategy).await;
        
        // 记录恢复结果
        let recovery_time = start_time.elapsed();
        match &result {
            Ok(recovery_result) => {
                if recovery_result.success {
                    self.metrics.recovery_success(
                        &fault.fault_id,
                        "workflow",
                        recovery_time.as_millis() as u64,
                    );
                    
                    log::info!(
                        "工作流故障恢复成功: {} ({}) 耗时: {:?}",
                        fault.workflow_id,
                        fault.fault_type,
                        recovery_time
                    );
                } else {
                    self.metrics.recovery_failure(
                        &fault.fault_id,
                        "workflow",
                        recovery_result.error_message.as_deref().unwrap_or("未知错误"),
                    );
                    
                    log::warn!(
                        "工作流故障恢复失败: {} ({}): {} 耗时: {:?}",
                        fault.workflow_id,
                        fault.fault_type,
                        recovery_result.error_message.as_deref().unwrap_or("未知错误"),
                        recovery_time
                    );
                }
            },
            Err(e) => {
                self.metrics.recovery_failure(
                    &fault.fault_id,
                    "workflow",
                    &e.to_string(),
                );
                
                log::error!(
                    "工作流故障恢复出错: {} ({}): {} 耗时: {:?}",
                    fault.workflow_id,
                    fault.fault_type,
                    e,
                    recovery_time
                );
            }
        }
        
        result
    }
    
    /// 恢复节点故障
    async fn recover_node_fault(
        &mut self,
        fault: &NodeFault,
    ) -> Result<RecoveryResult, RecoveryError> {
        // 记录恢复尝试
        self.metrics.recovery_attempt(&fault.fault_id, "node");
        let start_time = Instant::now();
        
        log::info!(
            "开始恢复节点故障: {} ({})",
            fault.node_id,
            fault.fault_type
        );
        
        // 获取恢复策略
        let strategy = self.strategy_provider
            .get_node_recovery_strategy(fault)
            .await?;
            
        log::debug!(
            "为节点故障 {} 选择恢复策略: {:?}",
            fault.node_id,
            strategy.strategy_type
        );
        
        // 获取处理器
        let handler = match self.node_recovery_handlers.get_mut(&fault.fault_type) {
            Some(handler) => handler,
            None => {
                return Err(RecoveryError::UnsupportedFaultType(
                    format!("不支持的节点故障类型: {:?}", fault.fault_type)
                ));
            }
        };
        
        // 执行恢复
        let result = handler.recover(fault, &strategy).await;
        
        // 记录恢复结果
        let recovery_time = start_time.elapsed();
        match &result {
            Ok(recovery_result) => {
                if recovery_result.success {
                    self.metrics.recovery_success(
                        &fault.fault_id,
                        "node",
                        recovery_time.as_millis() as u64,
                    );
                    
                    log::info!(
                        "节点故障恢复成功: {} ({}) 耗时: {:?}",
                        fault.node_id,
                        fault.fault_type,
                        recovery_time
                    );
                } else {
                    self.metrics.recovery_failure(
                        &fault.fault_id,
                        "node",
                        recovery_result.error_message.as_deref().unwrap_or("未知错误"),
                    );
                    
                    log::warn!(
                        "节点故障恢复失败: {} ({}): {} 耗时: {:?}",
                        fault.node_id,
                        fault.fault_type,
                        recovery_result.error_message.as_deref().unwrap_or("未知错误"),
                        recovery_time
                    );
                }
            },
            Err(e) => {
                self.metrics.recovery_failure(
                    &fault.fault_id,
                    "node",
                    &e.to_string(),
                );
                
                log::error!(
                    "节点故障恢复出错: {} ({}): {} 耗时: {:?}",
                    fault.node_id,
                    fault.fault_type,
                    e,
                    recovery_time
                );
            }
        }
        
        result
    }
}

/// 工作流快照管理器
pub struct SnapshotManager {
    /// 状态存储
    state_storage: Arc<StateStorage>,
    
    /// 快照存储
    snapshot_storage: Box<dyn SnapshotStorage>,
    
    /// 快照策略提供者
    snapshot_policy_provider: Box<dyn SnapshotPolicyProvider>,
    
    /// 指标收集器
    metrics: Arc<MetricsCollector>,
    
    /// 快照配置
    config: SnapshotConfig,
    
    /// 快照压缩器
    compressor: Option<Box<dyn SnapshotCompressor>>,
    
    /// 快照加密器
    encryptor: Option<Box<dyn SnapshotEncryptor>>,
}

impl SnapshotManager {
    /// 创建新的快照管理器
    pub fn new(
        state_storage: Arc<StateStorage>,
        snapshot_storage: Box<dyn SnapshotStorage>,
        snapshot_policy_provider: Box<dyn SnapshotPolicyProvider>,
        metrics: Arc<MetricsCollector>,
        config: SnapshotConfig,
        compressor: Option<Box<dyn SnapshotCompressor>>,
        encryptor: Option<Box<dyn SnapshotEncryptor>>,
    ) -> Self {
        Self {
            state_storage,
            snapshot_storage,
            snapshot_policy_provider,
            metrics,
            config,
            compressor,
            encryptor,
        }
    }
    
    /// 为工作流创建快照
    pub async fn create_workflow_snapshot(
        &self,
        workflow_id: &str,
    ) -> Result<SnapshotId, SnapshotError> {
        log::debug!("为工作流 {} 创建快照", workflow_id);
        
        // 获取工作流状态
        let workflow_state = self.state_storage
            .get_workflow_state(workflow_id)
            .await?;
            
        // 序列化状态
        let serialized_state = serde_json::to_vec(&workflow_state)
            .map_err(|e| SnapshotError::SerializationFailed(e.to_string()))?;
            
        // 压缩状态（如果配置了压缩器）
        let compressed_state = if let Some(compressor) = &self.compressor {
            compressor.compress(&serialized_state)
                .map_err(|e| SnapshotError::CompressionFailed(e.to_string()))?
        } else {
            serialized_state
        };
        
        // 加密状态（如果配置了加密器）
        let final_state = if let Some(encryptor) = &self.encryptor {
            encryptor.encrypt(&compressed_state)
                .map_err(|e| SnapshotError::EncryptionFailed(e.to_string()))?
        } else {
            compressed_state
        };
        
        // 创建快照元数据
        let snapshot_metadata = SnapshotMetadata {
            workflow_id: workflow_id.to_string(),
            timestamp: chrono::Utc::now(),
            size_bytes: final_state.len() as u64,
            compressed: self.compressor.is_some(),
            encrypted: self.encryptor.is_some(),
            snapshot_type: SnapshotType::Manual,
            tags: HashMap::new(),
        };
        
        // 存储快照
        let snapshot_id = self.snapshot_storage
            .store_snapshot(&final_state, &snapshot_metadata)
            .await?;
            
        // 记录快照创建
        self.metrics.snapshot_created(
            workflow_id,
            &snapshot_id,
            snapshot_metadata.size_bytes,
        );
        
        log::info!(
            "工作流 {} 快照创建成功，ID: {}, 大小: {} 字节",
            workflow_id,
            snapshot_id,
            snapshot_metadata.size_bytes
        );
        
        Ok(snapshot_id)
    }
    
    /// 从快照恢复工作流
    pub async fn restore_workflow_from_snapshot(
        &self,
        workflow_id: &str,
        snapshot_id: &str,
    ) -> Result<(), SnapshotError> {
        log::info!("从快照 {} 恢复工作流 {}", snapshot_id, workflow_id);
        
        // 获取快照
        let (snapshot_data, metadata) = self.snapshot_storage
            .retrieve_snapshot(snapshot_id)
            .await?;
            
        // 解密（如果需要）
        let decrypted_data = if metadata.encrypted {
            if let Some(encryptor) = &self.encryptor {
                encryptor.decrypt(&snapshot_data)
                    .map_err(|e| SnapshotError::DecryptionFailed(e.to_string()))?
            } else {
                return Err(SnapshotError::DecryptionFailed(
                    "快照已加密但未提供解密器".to_string()
                ));
            }
        } else {
            snapshot_data
        };
        
        // 解压（如果需要）
        let decompressed_data = if metadata.compressed {
            if let Some(compressor) = &self.compressor {
                compressor.decompress(&decrypted_data)
                    .map_err(|e| SnapshotError::DecompressionFailed(e.to_string()))?
            } else {
                return Err(SnapshotError::DecompressionFailed(
                    "快照已压缩但未提供解压器".to_string()
                ));
            }
        } else {
            decrypted_data
        };
        
        // 反序列化状态
        let workflow_state: WorkflowState = serde_json::from_slice(&decompressed_data)
            .map_err(|e| SnapshotError::DeserializationFailed(e.to_string()))?;
            
        // 恢复工作流状态
        self.state_storage
            .restore_workflow_state(workflow_id, workflow_state)
            .await?;
            
        // 记录快照恢复
        self.metrics.snapshot_restored(workflow_id, snapshot_id);
        
        log::info!("工作流 {} 已从快照 {} 成功恢复", workflow_id, snapshot_id);
        
        Ok(())
    }
    
    /// 创建定期快照
    pub async fn create_periodic_snapshots(&self) -> Result<Vec<SnapshotResult>, SnapshotError> {
        log::debug!("执行定期快照创建");
        
        // 获取活跃工作流
        let active_workflows = self.state_storage.get_active_workflow_ids().await?;
        
        let mut results = Vec::new();
        
        for workflow_id in active_workflows {
            // 获取快照策略
            let policy = self.snapshot_policy_provider
                .get_snapshot_policy(&workflow_id)
                .await?;
                
            // 检查是否应该创建快照
            if self.should_create_snapshot(&workflow_id, &policy).await? {
                match self.create_workflow_snapshot(&workflow_id).await {
                    Ok(snapshot_id) => {
                        results.push(SnapshotResult {
                            workflow_id: workflow_id.clone(),
                            snapshot_id,
                            success: true,
                            error: None,
                        });
                    },
                    Err(e) => {
                        log::error!("为工作流 {} 创建定期快照失败: {}", workflow_id, e);
                        
                        results.push(SnapshotResult {
                            workflow_id: workflow_id.clone(),
                            snapshot_id: String::new(),
                            success: false,
                            error: Some(e.to_string()),
                        });
                    }
                }
            }
        }
        
        log::info!(
            "定期快照创建完成，成功: {}, 失败: {}",
            results.iter().filter(|r| r.success).count(),
            results.iter().filter(|r
```

性能优化和指标收集

```rust
/// 工作流性能优化器
pub struct WorkflowPerformanceOptimizer {
    /// 性能指标收集器
    metrics_collector: Arc<MetricsCollector>,
    
    /// 性能分析器
    performance_analyzer: Box<dyn PerformanceAnalyzer>,
    
    /// 优化规则注册表
    optimization_rules: Vec<Box<dyn OptimizationRule>>,
    
    /// 工作流历史存储
    history_store: Arc<ExecutionHistoryStore>,
    
    /// 工作流引擎
    workflow_engine: Arc<WorkflowEngine>,
    
    /// 资源监控器
    resource_monitor: Arc<ResourceMonitor>,
    
    /// 优化配置
    config: OptimizationConfig,
    
    /// 优化工作器
    optimization_worker: Option<JoinHandle<()>>,
    
    /// 关闭信号
    shutdown: Arc<AtomicBool>,
    
    /// 优化历史记录
    optimization_history: RwLock<HashMap<String, Vec<OptimizationRecord>>>,
}

impl WorkflowPerformanceOptimizer {
    /// 创建新的工作流性能优化器
    pub fn new(
        metrics_collector: Arc<MetricsCollector>,
        performance_analyzer: Box<dyn PerformanceAnalyzer>,
        history_store: Arc<ExecutionHistoryStore>,
        workflow_engine: Arc<WorkflowEngine>,
        resource_monitor: Arc<ResourceMonitor>,
        config: OptimizationConfig,
    ) -> Self {
        Self {
            metrics_collector,
            performance_analyzer,
            optimization_rules: Vec::new(),
            history_store,
            workflow_engine,
            resource_monitor,
            config,
            optimization_worker: None,
            shutdown: Arc::new(AtomicBool::new(false)),
            optimization_history: RwLock::new(HashMap::new()),
        }
    }
    
    /// 启动性能优化器
    pub async fn start(&mut self) -> Result<(), OptimizationError> {
        if self.optimization_worker.is_some() {
            return Err(OptimizationError::AlreadyRunning("性能优化器已在运行".to_string()));
        }
        
        log::info!("启动工作流性能优化器");
        
        // 重置关闭信号
        self.shutdown.store(false, Ordering::SeqCst);
        
        // 注册默认优化规则
        self.register_default_rules();
        
        // 创建优化循环
        let shutdown = self.shutdown.clone();
        let metrics_collector = self.metrics_collector.clone();
        let performance_analyzer = self.performance_analyzer.clone_box();
        let rules = self.clone_rules();
        let history_store = self.history_store.clone();
        let workflow_engine = self.workflow_engine.clone();
        let resource_monitor = self.resource_monitor.clone();
        let config = self.config.clone();
        let optimization_history = self.optimization_history.clone();
        
        // 启动优化工作器
        let handle = tokio::spawn(async move {
            let mut optimization_interval = tokio::time::interval(config.optimization_interval);
            
            log::info!("工作流性能优化循环已启动");
            
            while !shutdown.load(Ordering::SeqCst) {
                optimization_interval.tick().await;
                
                // 执行优化周期
                if let Err(e) = Self::run_optimization_cycle(
                    metrics_collector.clone(),
                    performance_analyzer.clone_box(),
                    rules.clone(),
                    history_store.clone(),
                    workflow_engine.clone(),
                    resource_monitor.clone(),
                    &config,
                    optimization_history.clone(),
                ).await {
                    log::error!("性能优化循环执行失败: {}", e);
                }
            }
            
            log::info!("工作流性能优化循环已停止");
        });
        
        self.optimization_worker = Some(handle);
        
        log::info!("工作流性能优化器已启动");
        Ok(())
    }
    
    /// 停止性能优化器
    pub async fn stop(&mut self) -> Result<(), OptimizationError> {
        if self.optimization_worker.is_none() {
            return Ok(());
        }
        
        log::info!("停止工作流性能优化器");
        
        // 设置关闭信号
        self.shutdown.store(true, Ordering::SeqCst);
        
        // 等待工作器完成
        if let Some(worker) = self.optimization_worker.take() {
            match tokio::time::timeout(Duration::from_secs(10), worker).await {
                Ok(result) => {
                    if let Err(e) = result {
                        log::error!("优化工作器意外终止: {}", e);
                    }
                },
                Err(_) => {
                    log::warn!("优化工作器停止超时，强制中断");
                    // 任务将被废弃
                }
            }
        }
        
        log::info!("工作流性能优化器已停止");
        Ok(())
    }
    
    /// 注册默认优化规则
    fn register_default_rules(&mut self) {
        // 注册并行度优化规则
        self.register_rule(Box::new(ParallelismOptimizationRule::new(
            self.config.max_parallelism,
        )));
        
        // 注册数据局部性优化规则
        self.register_rule(Box::new(DataLocalityOptimizationRule::new(
            self.config.locality_threshold,
        )));
        
        // 注册资源分配优化规则
        self.register_rule(Box::new(ResourceAllocationOptimizationRule::new(
            self.config.resource_threshold,
        )));
        
        // 注册超时调整规则
        self.register_rule(Box::new(TimeoutAdjustmentRule::new(
            self.config.timeout_adjustment_factor,
        )));
        
        // 注册重试策略优化规则
        self.register_rule(Box::new(RetryStrategyOptimizationRule::new(
            self.config.max_retry_count,
        )));
        
        // 注册批处理优化规则
        self.register_rule(Box::new(BatchProcessingOptimizationRule::new(
            self.config.max_batch_size,
        )));
    }
    
    /// 注册优化规则
    pub fn register_rule(&mut self, rule: Box<dyn OptimizationRule>) {
        self.optimization_rules.push(rule);
    }
    
    /// 克隆优化规则
    fn clone_rules(&self) -> Vec<Box<dyn OptimizationRule>> {
        self.optimization_rules.iter().map(|r| r.clone_box()).collect()
    }
    
    /// 运行单次优化循环
    async fn run_optimization_cycle(
        metrics_collector: Arc<MetricsCollector>,
        performance_analyzer: Box<dyn PerformanceAnalyzer>,
        rules: Vec<Box<dyn OptimizationRule>>,
        history_store: Arc<ExecutionHistoryStore>,
        workflow_engine: Arc<WorkflowEngine>,
        resource_monitor: Arc<ResourceMonitor>,
        config: &OptimizationConfig,
        optimization_history: RwLock<HashMap<String, Vec<OptimizationRecord>>>,
    ) -> Result<(), OptimizationError> {
        // 获取需要优化的工作流列表
        let workflow_ids = Self::identify_workflows_for_optimization(
            &metrics_collector,
            config.min_execution_count,
        ).await?;
        
        if workflow_ids.is_empty() {
            log::debug!("未找到可优化的工作流");
            return Ok(());
        }
        
        log::info!("开始优化 {} 个工作流", workflow_ids.len());
        
        // 获取当前系统资源状态
        let system_resources = resource_monitor.get_system_resources().await?;
        
        // 处理每个需要优化的工作流
        for workflow_id in workflow_ids {
            // 获取工作流定义
            let workflow_definition = match workflow_engine.get_workflow_definition(&workflow_id).await {
                Ok(def) => def,
                Err(e) => {
                    log::error!("获取工作流 {} 定义失败: {}", workflow_id, e);
                    continue;
                }
            };
            
            // 获取工作流执行历史
            let execution_history = match history_store.get_workflow_execution_history(&workflow_id, 10).await {
                Ok(history) => history,
                Err(e) => {
                    log::error!("获取工作流 {} 执行历史失败: {}", workflow_id, e);
                    continue;
                }
            };
            
            // 获取工作流性能指标
            let performance_metrics = metrics_collector.get_workflow_metrics(&workflow_id).await;
            
            // 分析性能
            let performance_analysis = match performance_analyzer.analyze_workflow(
                &workflow_definition,
                &execution_history,
                &performance_metrics,
            ).await {
                Ok(analysis) => analysis,
                Err(e) => {
                    log::error!("分析工作流 {} 性能失败: {}", workflow_id, e);
                    continue;
                }
            };
            
            // 应用优化规则
            let mut applied_optimizations = Vec::new();
            let mut optimized_workflow = workflow_definition.clone();
            
            for rule in &rules {
                if rule.can_apply(&optimized_workflow, &performance_analysis) {
                    match rule.apply(&mut optimized_workflow, &performance_analysis, &system_resources).await {
                        Ok(optimizations) => {
                            if !optimizations.is_empty() {
                                log::info!(
                                    "对工作流 {} 应用优化规则 {}: {} 个优化",
                                    workflow_id,
                                    rule.name(),
                                    optimizations.len()
                                );
                                
                                applied_optimizations.extend(optimizations);
                            }
                        },
                        Err(e) => {
                            log::error!(
                                "对工作流 {} 应用优化规则 {} 失败: {}",
                                workflow_id,
                                rule.name(),
                                e
                            );
                        }
                    }
                }
            }
            
            // 如果有优化应用，更新工作流定义
            if !applied_optimizations.is_empty() {
                // 验证优化后的工作流
                match workflow_engine.validate_workflow(&optimized_workflow).await {
                    Ok(_) => {
                        // 更新工作流定义
                        match workflow_engine.update_workflow_definition(optimized_workflow).await {
                            Ok(_) => {
                                log::info!(
                                    "工作流 {} 已成功优化，应用了 {} 个优化",
                                    workflow_id,
                                    applied_optimizations.len()
                                );
                                
                                // 记录优化历史
                                let optimization_record = OptimizationRecord {
                                    timestamp: chrono::Utc::now(),
                                    workflow_id: workflow_id.clone(),
                                    applied_optimizations: applied_optimizations.clone(),
                                    performance_before: performance_analysis.clone(),
                                };
                                
                                // 更新优化历史
                                let mut history = optimization_history.write().await;
                                history
                                    .entry(workflow_id.clone())
                                    .or_insert_with(Vec::new)
                                    .push(optimization_record);
                            },
                            Err(e) => {
                                log::error!("更新工作流 {} 定义失败: {}", workflow_id, e);
                            }
                        }
                    },
                    Err(e) => {
                        log::error!("优化后的工作流 {} 验证失败: {}", workflow_id, e);
                    }
                }
            } else {
                log::debug!("工作流 {} 没有应用任何优化", workflow_id);
            }
        }
        
        Ok(())
    }
    
    /// 识别需要优化的工作流
    async fn identify_workflows_for_optimization(
        metrics_collector: &MetricsCollector,
        min_execution_count: u32,
    ) -> Result<Vec<String>, OptimizationError> {
        // 获取所有工作流指标
        let all_workflow_metrics = metrics_collector.get_all_workflow_metrics().await;
        
        // 筛选满足优化条件的工作流
        let mut candidates = Vec::new();
        
        for (workflow_id, metrics) in all_workflow_metrics {
            // 检查执行次数是否达到最小要求
            if metrics.execution_count >= min_execution_count {
                // 检查性能指标是否表明需要优化
                if Self::workflow_needs_optimization(&metrics) {
                    candidates.push(workflow_id);
                }
            }
        }
        
        Ok(candidates)
    }
    
    /// 确定工作流是否需要优化
    fn workflow_needs_optimization(metrics: &WorkflowMetrics) -> bool {
        // 检查平均执行时间
        if metrics.avg_execution_time.as_millis() > 5000 {
            return true;
        }
        
        // 检查失败率
        if metrics.failure_rate > 0.05 {
            return true;
        }
        
        // 检查资源使用率
        if metrics.avg_cpu_usage > 0.8 || metrics.avg_memory_usage > 0.8 {
            return true;
        }
        
        // 检查步骤执行时间异常
        for (_, step_metrics) in &metrics.step_metrics {
            if step_metrics.avg_execution_time.as_millis() > 2000 {
                return true;
            }
        }
        
        false
    }
    
    /// 获取工作流的优化历史
    pub async fn get_optimization_history(&self, workflow_id: &str) -> Vec<OptimizationRecord> {
        let history = self.optimization_history.read().await;
        
        match history.get(workflow_id) {
            Some(records) => records.clone(),
            None => Vec::new(),
        }
    }
}

/// 指标收集器
pub struct MetricsCollector {
    /// 活跃工作流指标
    workflow_metrics: RwLock<HashMap<String, WorkflowMetrics>>,
    
    /// 节点指标
    node_metrics: RwLock<HashMap<String, NodeMetrics>>,
    
    /// 系统指标
    system_metrics: RwLock<SystemMetrics>,
    
    /// 工作流引擎
    workflow_engine: Arc<WorkflowEngine>,
    
    /// 指标存储
    metrics_store: Arc<dyn MetricsStorage>,
    
    /// 指标收集配置
    collection_config: MetricsCollectionConfig,
    
    /// 指标收集工作器
    metrics_worker: Option<JoinHandle<()>>,
    
    /// 关闭信号
    shutdown: Arc<AtomicBool>,
}

impl MetricsCollector {
    /// 创建新的指标收集器
    pub fn new(
        workflow_engine: Arc<WorkflowEngine>,
        metrics_store: Arc<dyn MetricsStorage>,
        collection_config: MetricsCollectionConfig,
    ) -> Self {
        Self {
            workflow_metrics: RwLock::new(HashMap::new()),
            node_metrics: RwLock::new(HashMap::new()),
            system_metrics: RwLock::new(SystemMetrics::default()),
            workflow_engine,
            metrics_store,
            collection_config,
            metrics_worker: None,
            shutdown: Arc::new(AtomicBool::new(false)),
        }
    }
    
    /// 启动指标收集
    pub async fn start(&mut self) -> Result<(), MetricsError> {
        if self.metrics_worker.is_some() {
            return Err(MetricsError::AlreadyRunning("指标收集器已在运行".to_string()));
        }
        
        log::info!("启动工作流指标收集器");
        
        // 重置关闭信号
        self.shutdown.store(false, Ordering::SeqCst);
        
        // 创建指标收集循环
        let shutdown = self.shutdown.clone();
        let workflow_engine = self.workflow_engine.clone();
        let metrics_store = self.metrics_store.clone();
        let collection_interval = self.collection_config.collection_interval;
        let storage_interval = self.collection_config.storage_interval;
        let workflow_metrics = self.workflow_metrics.clone();
        let node_metrics = self.node_metrics.clone();
        let system_metrics = self.system_metrics.clone();
        
        // 启动指标收集工作器
        let handle = tokio::spawn(async move {
            let mut collection_interval_timer = tokio::time::interval(collection_interval);
            let mut storage_interval_timer = tokio::time::interval(storage_interval);
            
            log::info!("工作流指标收集循环已启动");
            
            while !shutdown.load(Ordering::SeqCst) {
                tokio::select! {
                    _ = collection_interval_timer.tick() => {
                        // 收集指标
                        if let Err(e) = Self::collect_metrics(
                            workflow_engine.clone(),
                            workflow_metrics.clone(),
                            node_metrics.clone(),
                            system_metrics.clone(),
                        ).await {
                            log::error!("收集指标失败: {}", e);
                        }
                    }
                    
                    _ = storage_interval_timer.tick() => {
                        // 存储指标
                        if let Err(e) = Self::store_metrics(
                            metrics_store.clone(),
                            workflow_metrics.clone(),
                            node_metrics.clone(),
                            system_metrics.clone(),
                        ).await {
                            log::error!("存储指标失败: {}", e);
                        }
                    }
                }
            }
            
            log::info!("工作流指标收集循环已停止");
        });
        
        self.metrics_worker = Some(handle);
        
        log::info!("工作流指标收集器已启动");
        Ok(())
    }
    
    /// 停止指标收集
    pub async fn stop(&mut self) -> Result<(), MetricsError> {
        if self.metrics_worker.is_none() {
            return Ok(());
        }
        
        log::info!("停止工作流指标收集器");
        
        // 设置关闭信号
        self.shutdown.store(true, Ordering::SeqCst);
        
        // 等待工作器完成
        if let Some(worker) = self.metrics_worker.take() {
            match tokio::time::timeout(Duration::from_secs(10), worker).await {
                Ok(result) => {
                    if let Err(e) = result {
                        log::error!("指标收集工作器意外终止: {}", e);
                    }
                },
                Err(_) => {
                    log::warn!("指标收集工作器停止超时，强制中断");
                    // 任务将被废弃
                }
            }
        }
        
        // 存储最终指标
        Self::store_metrics(
            self.metrics_store.clone(),
            self.workflow_metrics.clone(),
            self.node_metrics.clone(),
            self.system_metrics.clone(),
        ).await?;
        
        log::info!("工作流指标收集器已停止");
        Ok(())
    }
    
    /// 收集指标
    async fn collect_metrics(
        workflow_engine: Arc<WorkflowEngine>,
        workflow_metrics: RwLock<HashMap<String, WorkflowMetrics>>,
        node_metrics: RwLock<HashMap<String, NodeMetrics>>,
        system_metrics: RwLock<SystemMetrics>,
    ) -> Result<(), MetricsError> {
        // 1. 收集工作流指标
        Self::collect_workflow_metrics(workflow_engine.clone(), workflow_metrics.clone()).await?;
        
        // 2. 收集节点指标
        Self::collect_node_metrics(workflow_engine.clone(), node_metrics.clone()).await?;
        
        // 3. 收集系统指标
        Self::collect_system_metrics(system_metrics.clone()).await?;
        
        Ok(())
    }
    
    /// 收集工作流指标
    async fn collect_workflow_metrics(
        workflow_engine: Arc<WorkflowEngine>,
        workflow_metrics: RwLock<HashMap<String, WorkflowMetrics>>,
    ) -> Result<(), MetricsError> {
        // 获取活跃工作流
        let active_workflows = workflow_engine.get_active_workflows().await?;
        
        // 获取已完成工作流（自上次收集以来）
        let completed_workflows = workflow_engine.get_recently_completed_workflows().await?;
        
        // 更新工作流指标
        let mut metrics = workflow_metrics.write().await;
        
        // 处理活跃工作流
        for workflow in active_workflows {
            let workflow_id = workflow.id.clone();
            
            // 获取当前指标或创建新的
            let workflow_metric = metrics
                .entry(workflow_id.clone())
                .or_insert_with(|| WorkflowMetrics::new(&workflow_id));
                
            // 更新活跃工作流指标
            workflow_metric.update_from_active_workflow(&workflow);
        }
        
        // 处理已完成工作流
        for execution in completed_workflows {
            let workflow_id = execution.workflow_id.clone();
            
            // 获取当前指标或创建新的
            let workflow_metric = metrics
                .entry(workflow_id.clone())
                .or_insert_with(|| WorkflowMetrics::new(&workflow_id));
                
            // 更新已完成工作流指标
            workflow_metric.update_from_completed_execution(&execution);
        }
        
        Ok(())
    }
    
    /// 收集节点指标
    async fn collect_node_metrics(
        workflow_engine: Arc<WorkflowEngine>,
        node_metrics: RwLock<HashMap<String, NodeMetrics>>,
    ) -> Result<(), MetricsError> {
        // 获取所有节点状态
        let node_statuses = workflow_engine.get_all_node_statuses().await?;
        
        // 更新节点指标
        let mut metrics = node_metrics.write().await;
        
        for node_status in node_statuses {
            let node_id = node_status.node_id.clone();
            
            // 获取当前指标或创建新的
            let node_metric = metrics
                .entry(node_id.clone())
                .or_insert_with(|| NodeMetrics::new(&node_id));
                
            // 更新节点指标
            node_metric.update_from_node_status(&node_status);
        }
        
        Ok(())
    }
    
    /// 收集系统指标
    async fn collect_system_metrics(
        system_metrics: RwLock<SystemMetrics>,
    ) -> Result<(), MetricsError> {
        // 获取系统资源使用情况
        let cpu_usage = get_system_cpu_usage()?;
        let memory_usage = get_system_memory_usage()?;
        let disk_usage = get_system_disk_usage()?;
        let network_usage = get_system_network_usage()?;
        
        // 更新系统指标
        let mut metrics = system_metrics.write().await;
        
        metrics.update(
            cpu_usage,
            memory_usage,
            disk_usage,
            network_usage,
        );
        
        Ok(())
    }
    
    /// 存储指标
    async fn store_metrics(
        metrics_store: Arc<dyn MetricsStorage>,
        workflow_metrics: RwLock<HashMap<String, WorkflowMetrics>>,
        node_metrics: RwLock<HashMap<String, NodeMetrics>>,
        system_metrics: RwLock<SystemMetrics>,
    ) -> Result<(), MetricsError> {
        // 读取当前指标
        let workflows = workflow_metrics.read().await.clone();
        let nodes = node_metrics.read().await.clone();
        let system = system_metrics.read().await.clone();
        
        // 存储工作流指标
        for (id, metrics) in workflows {
            metrics_store.store_workflow_metrics(&id, &metrics).await?;
        }
        
        // 存储节点指标
        for (id, metrics) in nodes {
            metrics_store.store_node_metrics(&id, &metrics).await?;
        }
        
        // 存储系统指标
        metrics_store.store_system_metrics(&system).await?;
        
        Ok(())
    }
    
    /// 获取工作流指标
    pub async fn get_workflow_metrics(&self, workflow_id: &str) -> WorkflowMetrics {
        let metrics = self.workflow_metrics.read().await;
        
        metrics
            .get(workflow_id)
            .cloned()
            .unwrap_or_else(|| WorkflowMetrics::new(workflow_id))
    }
    
    /// 获取所有工作流指标
    pub async fn get_all_workflow_metrics(&self) -> HashMap<String, WorkflowMetrics> {
        self.workflow_metrics.read().await.clone()
    }
    
    /// 获取节点指标
    pub async fn get_node_metrics(&self, node_id: &str) -> Option<NodeMetrics> {
        let metrics = self.node_metrics.read().await;
        metrics.get(node_id).cloned()
    }
    
    /// 获取系统指标
    pub async fn get_system_metrics(&self) -> SystemMetrics {
        self.system_metrics.read().await.clone()
    }
    
    /// 记录工作流开始
    pub async fn record_workflow_started(&self, workflow_id: &str, workflow_type: &str) {
        let mut metrics = self.workflow_metrics.write().await;
        
        let workflow_metric = metrics
            .entry(workflow_id.to_string())
            .or_insert_with(|| WorkflowMetrics::new(workflow_id));
            
        workflow_metric.record_started(workflow_type);
    }
    
    /// 记录工作流完成
    pub async fn record_workflow_completed(
        &self,
        workflow_id: &str,
        execution_time: Duration,
        result: &WorkflowResult,
    ) {
        let mut metrics = self.workflow_metrics.write().await;
        
        if let Some(workflow_metric) = metrics.get_mut(workflow_id) {
            workflow_metric.record_completed(execution_time, result);
        }
    }
    
    /// 记录工作流步骤开始
    pub async fn record_step_started(&self, workflow_id: &str, step_id: &str, step_type: &str) {
        let mut metrics = self.workflow_metrics.write().await;
        
        if let Some(workflow_metric) = metrics.get_mut(workflow_id) {
            workflow_metric.record_step_started(step_id, step_type);
        }
    }
    
    /// 记录工作流步骤完成
    pub async fn record_step_completed(
        &self,
        workflow_id: &str,
        step_id: &str,
        execution_time: Duration,
        result: &StepResult,
    ) {
        let mut metrics = self.workflow_metrics.write().await;
        
        if let Some(workflow_metric) = metrics.get_mut(workflow_id) {
            workflow_metric.record_step_completed(step_id, execution_time, result);
        }
    }
}

/// 性能分析器
pub struct PerformanceAnalyzer {
    /// 运行时指标提供者
    runtime_metrics: Arc<MetricsCollector>,
    
    /// 性能模型注册表
    performance_models: PerformanceModelRegistry,
    
    /// 资源估算器
    resource_estimator: ResourceEstimator,
    
    /// 优化规则
    optimization_rules: Vec<Box<dyn OptimizationRule>>,
}

impl PerformanceAnalyzer {
    pub fn new(
        runtime_metrics: Arc<MetricsCollector>,
        performance_models: PerformanceModelRegistry,
        resource_estimator: ResourceEstimator,
    ) -> Self {
        Self {
            runtime_metrics,
            performance_models,
            optimization_rules: Vec::new(),
            resource_estimator,
        }
    }
    
    /// 分析工作流性能
    pub async fn analyze_workflow(
        &self,
        workflow: &WorkflowDefinition,
        execution_history: &[WorkflowExecution],
        metrics: &WorkflowMetrics,
    ) -> Result<PerformanceAnalysisResult, AnalysisError> {
        let mut result = PerformanceAnalysisResult {
            workflow_id: workflow.id.clone(),
            estimated_duration: Duration::from_secs(0),
            critical_path: Vec::new(),
            bottlenecks: Vec::new(),
            resource_usage: ResourceUsageEstimate::default(),
            optimizations: Vec::new(),
            metrics: metrics.clone(),
        };
```

工作流可观测性与追踪系统

```rust
/// 工作流追踪管理器
pub struct WorkflowTracer {
    /// OpenTelemetry 追踪器
    tracer: opentelemetry::sdk::trace::Tracer,
    
    /// 服务名称
    service_name: String,
    
    /// 是否启用
    enabled: AtomicBool,
    
    /// 采样率 (0.0-1.0)
    sampling_ratio: AtomicF64,
    
    /// 活跃追踪记录
    active_traces: RwLock<HashMap<String, WorkflowTrace>>,
    
    /// 追踪导出器
    exporter: Box<dyn SpanExporter>,
    
    /// 追踪过滤器
    filters: Vec<Box<dyn TraceFilter>>,
}

impl WorkflowTracer {
    /// 创建新的工作流追踪管理器
    pub fn new(
        service_name: String,
        exporter: Box<dyn SpanExporter>,
        sampling_ratio: f64,
    ) -> Result<Self, TracingError> {
        // 验证采样率
        if sampling_ratio < 0.0 || sampling_ratio > 1.0 {
            return Err(TracingError::InvalidSamplingRatio(sampling_ratio));
        }
        
        // 创建资源
        let resource = opentelemetry::sdk::Resource::new(vec![
            opentelemetry::KeyValue::new("service.name", service_name.clone()),
            opentelemetry::KeyValue::new("service.version", env!("CARGO_PKG_VERSION").to_string()),
        ]);
        
        // 创建采样器
        let sampler = if sampling_ratio >= 1.0 {
            Sampler::AlwaysOn
        } else if sampling_ratio <= 0.0 {
            Sampler::AlwaysOff
        } else {
            Sampler::TraceIdRatioBased(sampling_ratio)
        };
        
        // 创建批处理器
        let batch_processor = opentelemetry::sdk::trace::BatchSpanProcessor::builder(
            exporter.clone(),
            tokio::runtime::Handle::current(),
        )
        .build();
        
        // 创建追踪提供者
        let provider = opentelemetry::sdk::trace::TracerProvider::builder()
            .with_resource(resource)
            .with_sampler(sampler)
            .with_span_processor(batch_processor)
            .build();
        
        // 获取追踪器
        let tracer = provider.tracer("workflow_engine");
        
        Ok(Self {
            tracer,
            service_name,
            enabled: AtomicBool::new(true),
            sampling_ratio: AtomicF64::new(sampling_ratio),
            active_traces: RwLock::new(HashMap::new()),
            exporter,
            filters: Vec::new(),
        })
    }
    
    /// 启用或禁用追踪
    pub fn set_enabled(&self, enabled: bool) {
        self.enabled.store(enabled, Ordering::SeqCst);
    }
    
    /// 设置采样率
    pub fn set_sampling_ratio(&self, ratio: f64) -> Result<(), TracingError> {
        if ratio < 0.0 || ratio > 1.0 {
            return Err(TracingError::InvalidSamplingRatio(ratio));
        }
        
        self.sampling_ratio.store(ratio, Ordering::SeqCst);
        Ok(())
    }
    
    /// 添加追踪过滤器
    pub fn add_filter(&mut self, filter: Box<dyn TraceFilter>) {
        self.filters.push(filter);
    }
    
    /// 开始工作流追踪
    pub fn start_workflow_trace(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        workflow_version: &str,
        input_params: &serde_json::Value,
    ) -> WorkflowSpan {
        if !self.enabled.load(Ordering::SeqCst) {
            return WorkflowSpan::no_op();
        }
        
        // 检查是否应该追踪该工作流
        if !self.should_trace_workflow(workflow_id, workflow_type) {
            return WorkflowSpan::no_op();
        }
        
        // 创建追踪上下文
        let mut span_builder = self.tracer.span_builder(format!("workflow:{}", workflow_type))
            .with_kind(opentelemetry::trace::SpanKind::Internal)
            .with_attributes(vec![
                KeyValue::new("workflow.id", workflow_id.to_string()),
                KeyValue::new("workflow.type", workflow_type.to_string()),
                KeyValue::new("workflow.version", workflow_version.to_string()),
            ]);
            
        // 添加输入参数（过滤敏感信息）
        let filtered_input = self.filter_sensitive_data(input_params);
        span_builder = span_builder.with_attributes(vec![
            KeyValue::new("workflow.input", format!("{}", filtered_input)),
        ]);
        
        // 开始追踪
        let span = span_builder.start(&self.tracer);
        let context = Context::current_with_span(span);
        
        // 创建工作流追踪记录
        let trace = WorkflowTrace {
            workflow_id: workflow_id.to_string(),
            workflow_type: workflow_type.to_string(),
            start_time: Utc::now(),
            span_context: context.span().span_context().clone(),
            steps: RwLock::new(Vec::new()),
            end_time: None,
            status: WorkflowTraceStatus::Running,
        };
        
        // 保存活跃追踪
        let mut active_traces = self.active_traces.write().unwrap();
        active_traces.insert(workflow_id.to_string(), trace);
        
        // 返回追踪 span
        WorkflowSpan {
            context,
            tracer: self.tracer.clone(),
            workflow_id: workflow_id.to_string(),
            is_active: true,
        }
    }
    
    /// 记录工作流步骤
    pub fn trace_workflow_step(
        &self,
        workflow_id: &str,
        step_id: &str,
        step_type: &str,
        parent_span: &WorkflowSpan,
        f: impl FnOnce(&StepSpan) -> Result<serde_json::Value, WorkflowError>,
    ) -> Result<serde_json::Value, WorkflowError> {
        if !self.enabled.load(Ordering::SeqCst) || !parent_span.is_active {
            return f(&StepSpan::no_op());
        }
        
        // 创建步骤 span
        let parent_cx = parent_span.context.clone();
        let mut span_builder = self.tracer.span_builder(format!("step:{}", step_type))
            .with_parent_context(parent_cx)
            .with_kind(opentelemetry::trace::SpanKind::Internal)
            .with_attributes(vec![
                KeyValue::new("workflow.id", workflow_id.to_string()),
                KeyValue::new("step.id", step_id.to_string()),
                KeyValue::new("step.type", step_type.to_string()),
            ]);
            
        // 开始追踪
        let span = span_builder.start(&self.tracer);
        let context = Context::current_with_span(span);
        
        // 创建步骤追踪 span
        let step_span = StepSpan {
            context,
            tracer: self.tracer.clone(),
            workflow_id: workflow_id.to_string(),
            step_id: step_id.to_string(),
            is_active: true,
        };
        
        // 记录步骤开始时间
        let start_time = Utc::now();
        
        // 执行步骤函数
        let result = f(&step_span);
        
        // 记录步骤结束
        let end_time = Utc::now();
        let duration = end_time.signed_duration_since(start_time);
        
        // 更新 span 状态
        let span = step_span.context.span();
        
        match &result {
            Ok(output) => {
                // 设置成功状态
                span.set_status(opentelemetry::trace::Status::Ok);
                
                // 添加输出属性（过滤敏感信息）
                let filtered_output = self.filter_sensitive_data(output);
                span.set_attribute(KeyValue::new("step.output", format!("{}", filtered_output)));
                span.set_attribute(KeyValue::new("step.duration_ms", duration.num_milliseconds() as i64));
            },
            Err(e) => {
                // 设置错误状态
                span.set_status(opentelemetry::trace::Status::error(format!("{}", e)));
                span.record_exception(&[
                    KeyValue::new("exception.type", e.type_name()),
                    KeyValue::new("exception.message", format!("{}", e)),
                ]);
                span.set_attribute(KeyValue::new("step.error", format!("{}", e)));
                span.set_attribute(KeyValue::new("step.duration_ms", duration.num_milliseconds() as i64));
            }
        }
        
        // 结束步骤追踪
        drop(span);
        
        // 保存步骤记录
        if let Some(trace) = self.active_traces.write().unwrap().get_mut(workflow_id) {
            let step_record = WorkflowTraceStep {
                step_id: step_id.to_string(),
                step_type: step_type.to_string(),
                start_time,
                end_time: Some(end_time),
                duration: duration.to_std().unwrap_or_default(),
                status: match &result {
                    Ok(_) => StepStatus::Completed,
                    Err(_) => StepStatus::Failed,
                },
                error: result.as_ref().err().map(|e| format!("{}", e)),
            };
            
            trace.steps.write().unwrap().push(step_record);
        }
        
        result
    }
    
    /// 结束工作流追踪
    pub fn end_workflow_trace(
        &self,
        workflow_span: WorkflowSpan,
        result: &Result<serde_json::Value, WorkflowError>,
    ) {
        if !self.enabled.load(Ordering::SeqCst) || !workflow_span.is_active {
            return;
        }
        
        let workflow_id = workflow_span.workflow_id.clone();
        let span = workflow_span.context.span();
        
        // 获取工作流追踪记录
        let mut active_traces = self.active_traces.write().unwrap();
        if let Some(trace) = active_traces.get_mut(&workflow_id) {
            // 更新结束时间
            trace.end_time = Some(Utc::now());
            
            // 更新状态
            match result {
                Ok(_) => {
                    trace.status = WorkflowTraceStatus::Completed;
                    span.set_status(opentelemetry::trace::Status::Ok);
                },
                Err(e) => {
                    trace.status = WorkflowTraceStatus::Failed;
                    span.set_status(opentelemetry::trace::Status::error(format!("{}", e)));
                    span.record_exception(&[
                        KeyValue::new("exception.type", e.type_name()),
                        KeyValue::new("exception.message", format!("{}", e)),
                    ]);
                }
            }
            
            // 计算持续时间
            if let Some(end_time) = trace.end_time {
                let duration = end_time.signed_duration_since(trace.start_time);
                span.set_attribute(KeyValue::new("workflow.duration_ms", duration.num_milliseconds() as i64));
            }
            
            // 添加输出结果
            if let Ok(output) = result {
                let filtered_output = self.filter_sensitive_data(output);
                span.set_attribute(KeyValue::new("workflow.output", format!("{}", filtered_output)));
            }
        }
        
        // 结束追踪
        drop(span);
        
        // 存档完成的追踪
        if let Some(trace) = active_traces.remove(&workflow_id) {
            // 这里可以将完成的追踪存储到持久化存储
            // 例如：self.trace_storage.store_trace(trace).await;
        }
    }
    
    /// 确定是否应该追踪工作流
    fn should_trace_workflow(&self, workflow_id: &str, workflow_type: &str) -> bool {
        // 检查过滤器
        for filter in &self.filters {
            if !filter.should_trace(workflow_id, workflow_type) {
                return false;
            }
        }
        
        // 应用采样率
        let sampling_ratio = self.sampling_ratio.load(Ordering::SeqCst);
        if sampling_ratio >= 1.0 {
            return true;
        } else if sampling_ratio <= 0.0 {
            return false;
        }
        
        // 基于工作流ID进行确定性采样
        let hash = {
            let mut hasher = DefaultHasher::new();
            workflow_id.hash(&mut hasher);
            hasher.finish()
        };
        
        // 将哈希值转换为 0.0-1.0 范围
        let hash_float = (hash as f64) / (u64::MAX as f64);
        
        hash_float < sampling_ratio
    }
    
    /// 过滤敏感数据
    fn filter_sensitive_data(&self, data: &serde_json::Value) -> serde_json::Value {
        // 如果数据是对象，逐个字段处理
        if let serde_json::Value::Object(map) = data {
            let mut filtered_map = serde_json::Map::new();
            
            for (key, value) in map {
                if self.is_sensitive_field(key) {
                    // 敏感字段被替换为 "***"
                    filtered_map.insert(key.clone(), serde_json::Value::String("***".to_string()));
                } else if let serde_json::Value::Object(_) | serde_json::Value::Array(_) = value {
                    // 递归处理嵌套对象或数组
                    filtered_map.insert(key.clone(), self.filter_sensitive_data(value));
                } else {
                    // 非敏感字段保持不变
                    filtered_map.insert(key.clone(), value.clone());
                }
            }
            
            serde_json::Value::Object(filtered_map)
        } else if let serde_json::Value::Array(arr) = data {
            // 处理数组
            let filtered_arr: Vec<serde_json::Value> = arr
                .iter()
                .map(|item| self.filter_sensitive_data(item))
                .collect();
                
            serde_json::Value::Array(filtered_arr)
        } else {
            // 基本类型保持不变
            data.clone()
        }
    }
    
    /// 检查字段是否敏感
    fn is_sensitive_field(&self, field_name: &str) -> bool {
        let sensitive_patterns = [
            "password", "token", "secret", "key", "auth", "credentials",
            "credit", "card", "ssn", "social", "security", "private"
        ];
        
        for pattern in &sensitive_patterns {
            if field_name.to_lowercase().contains(pattern) {
                return true;
            }
        }
        
        false
    }
    
    /// 获取工作流追踪记录
    pub fn get_workflow_trace(&self, workflow_id: &str) -> Option<WorkflowTrace> {
        let active_traces = self.active_traces.read().unwrap();
        active_traces.get(workflow_id).cloned()
    }
    
    /// 获取所有活跃工作流追踪
    pub fn get_active_traces(&self) -> Vec<WorkflowTrace> {
        let active_traces = self.active_traces.read().unwrap();
        active_traces.values().cloned().collect()
    }
}

/// 工作流追踪记录
#[derive(Debug, Clone)]
pub struct WorkflowTrace {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 工作流类型
    pub workflow_type: String,
    
    /// 开始时间
    pub start_time: DateTime<Utc>,
    
    /// 追踪上下文
    pub span_context: opentelemetry::trace::SpanContext,
    
    /// 步骤记录
    pub steps: RwLock<Vec<WorkflowTraceStep>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 状态
    pub status: WorkflowTraceStatus,
}

/// 工作流步骤追踪记录
#[derive(Debug, Clone)]
pub struct WorkflowTraceStep {
    /// 步骤ID
    pub step_id: String,
    
    /// 步骤类型
    pub step_type: String,
    
    /// 开始时间
    pub start_time: DateTime<Utc>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 持续时间
    pub duration: Duration,
    
    /// 状态
    pub status: StepStatus,
    
    /// 错误信息
    pub error: Option<String>,
}

/// 工作流追踪状态
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum WorkflowTraceStatus {
    /// 运行中
    Running,
    
    /// 已完成
    Completed,
    
    /// 失败
    Failed,
    
    /// 已取消
    Cancelled,
}

/// 步骤状态
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum StepStatus {
    /// 等待执行
    Pending,
    
    /// 运行中
    Running,
    
    /// 已完成
    Completed,
    
    /// 失败
    Failed,
    
    /// 已跳过
    Skipped,
    
    /// 已取消
    Cancelled,
}

/// 工作流追踪 Span
pub struct WorkflowSpan {
    /// 追踪上下文
    pub context: Context,
    
    /// 追踪器
    pub tracer: opentelemetry::sdk::trace::Tracer,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 是否活跃
    pub is_active: bool,
}

impl WorkflowSpan {
    /// 创建空操作 Span
    pub fn no_op() -> Self {
        Self {
            context: Context::default(),
            tracer: opentelemetry::sdk::trace::TracerProvider::default().tracer("no_op"),
            workflow_id: String::new(),
            is_active: false,
        }
    }
    
    /// 记录属性
    pub fn record_attribute(&self, key: &str, value: impl Into<Value>) {
        if !self.is_active {
            return;
        }
        
        self.context.span().set_attribute(KeyValue::new(key, value.into()));
    }
    
    /// 记录事件
    pub fn record_event(&self, name: &str, attributes: Vec<KeyValue>) {
        if !self.is_active {
            return;
        }
        
        self.context.span().add_event(name.to_string(), attributes);
    }
}

/// 步骤追踪 Span
pub struct StepSpan {
    /// 追踪上下文
    pub context: Context,
    
    /// 追踪器
    pub tracer: opentelemetry::sdk::trace::Tracer,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 步骤ID
    pub step_id: String,
    
    /// 是否活跃
    pub is_active: bool,
}

impl StepSpan {
    /// 创建空操作 Span
    pub fn no_op() -> Self {
        Self {
            context: Context::default(),
            tracer: opentelemetry::sdk::trace::TracerProvider::default().tracer("no_op"),
            workflow_id: String::new(),
            step_id: String::new(),
            is_active: false,
        }
    }
    
    /// 记录属性
    pub fn record_attribute(&self, key: &str, value: impl Into<Value>) {
        if !self.is_active {
            return;
        }
        
        self.context.span().set_attribute(KeyValue::new(key, value.into()));
    }
    
    /// 记录事件
    pub fn record_event(&self, name: &str, attributes: Vec<KeyValue>) {
        if !self.is_active {
            return;
        }
        
        self.context.span().add_event(name.to_string(), attributes);
    }
    
    /// 记录检查点
    pub fn record_checkpoint(&self, name: &str, metadata: Option<serde_json::Value>) {
        if !self.is_active {
            return;
        }
        
        let mut attributes = vec![
            KeyValue::new("checkpoint.name", name.to_string()),
            KeyValue::new("checkpoint.timestamp", chrono::Utc::now().timestamp_millis() as i64),
        ];
        
        if let Some(data) = metadata {
            attributes.push(KeyValue::new("checkpoint.metadata", format!("{}", data)));
        }
        
        self.context.span().add_event("checkpoint".to_string(), attributes);
    }
}

/// 追踪过滤器
pub trait TraceFilter: Send + Sync {
    /// 确定是否应该追踪
    fn should_trace(&self, workflow_id: &str, workflow_type: &str) -> bool;
    
    /// 克隆过滤器
    fn clone_box(&self) -> Box<dyn TraceFilter>;
}

/// 工作流类型过滤器
#[derive(Clone)]
pub struct WorkflowTypeFilter {
    /// 包含的工作流类型列表
    included_types: HashSet<String>,
    
    /// 排除的工作流类型列表
    excluded_types: HashSet<String>,
}

impl WorkflowTypeFilter {
    /// 创建新的工作流类型过滤器
    pub fn new(included_types: HashSet<String>, excluded_types: HashSet<String>) -> Self {
        Self {
            included_types,
            excluded_types,
        }
    }
}

impl TraceFilter for WorkflowTypeFilter {
    fn should_trace(&self, _workflow_id: &str, workflow_type: &str) -> bool {
        // 如果在排除列表中，则不追踪
        if self.excluded_types.contains(workflow_type) {
            return false;
        }
        
        // 如果包含列表为空，则追踪所有非排除的类型
        if self.included_types.is_empty() {
            return true;
        }
        
        // 否则只追踪包含列表中的类型
        self.included_types.contains(workflow_type)
    }
    
    fn clone_box(&self) -> Box<dyn TraceFilter> {
        Box::new(self.clone())
    }
}

/// 工作流可观测性管理器
pub struct WorkflowObservability {
    /// 工作流追踪器
    pub tracer: WorkflowTracer,
    
    /// 指标收集器
    pub metrics: MetricsCollector,
    
    /// 结构化日志记录器
    pub logger: StructuredLogger,
    
    /// 可观测性配置
    pub config: ObservabilityConfig,
}

impl WorkflowObservability {
    /// 创建新的工作流可观测性管理器
    pub fn new(
        tracer: WorkflowTracer,
        metrics: MetricsCollector,
        logger: StructuredLogger,
        config: ObservabilityConfig,
    ) -> Self {
        Self {
            tracer,
            metrics,
            logger,
            config,
        }
    }
    
    /// 创建工作流执行上下文
    pub fn create_execution_context(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        workflow_version: &str,
        input_params: &serde_json::Value,
    ) -> WorkflowExecutionContext {
        // 创建日志上下文
        let log_context = LogContext {
            workflow_id: workflow_id.to_string(),
            workflow_type: workflow_type.to_string(),
            workflow_version: workflow_version.to_string(),
            execution_id: Uuid::new_v4().to_string(),
        };
        
        // 创建追踪 span
        let workflow_span = self.tracer.start_workflow_trace(
            workflow_id,
            workflow_type,
            workflow_version,
            input_params,
        );
        
        // 记录工作流开始指标
        self.metrics.record_workflow_started(workflow_id, workflow_type).unwrap_or_else(|e| {
            self.logger.warning(
                &log_context,
                &format!("无法记录工作流开始指标: {}", e),
                None,
            );
        });
        
        // 记录工作流开始日志
        self.logger.info(
            &log_context,
            &format!("工作流 [{}] 开始执行", workflow_type),
            Some(json!({
                "input": self.filter_sensitive_data(input_params),
            })),
        );
        
        WorkflowExecutionContext {
            workflow_id: workflow_id.to_string(),
            workflow_type: workflow_type.to_string(),
            workflow_version: workflow_version.to_string(),
            execution_id: log_context.execution_id.clone(),
            workflow_span,
            log_context,
            observability: self,
        }
    }
    
    /// 过滤敏感数据
    fn filter_sensitive_data(&self, data: &serde_json::Value) -> serde_json::Value {
        // 使用追踪器的敏感数据过滤方法
        self.tracer.filter_sensitive_data(data)
    }
}

/// 工作流执行上下文
pub struct WorkflowExecutionContext<'a> {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 工作流类型
    pub workflow_type: String,
    
    /// 工作流版本
    pub workflow_version: String,
    
    /// 执行ID
    pub execution_id: String,
    
    /// 工作流追踪 span
    pub workflow_span: WorkflowSpan,
    
    /// 日志上下文
    pub log_context: LogContext,
    
    /// 可观测性管理器引用
    pub observability: &'a WorkflowObservability,
}

impl<'a> WorkflowExecutionContext<'a> {
    /// 执行工作流步骤
    pub fn execute_step<F, R>(
        &self,
        step_id: &str,
        step_type: &str,
        step_fn: F,
    ) -> Result<R, WorkflowError>
    where
        F: FnOnce() -> Result<R, WorkflowError>,
        R: Serialize,
    {
        // 记录步骤开始
        self.observability.logger.info(
            &self.log_context,
            &format!("步骤 [{}] 开始执行", step_id),
            Some(json!({
                "step_type": step_type,
            })),
        );
        
        // 记录步骤开始指标
        self.observability.metrics.record_step_started(
            &self.workflow_id,
            step_id,
            step_type,
        ).unwrap_or_else(|e| {
            self.observability.logger.warning(
                &self.log_context,
                &format!("无法记录步骤开始指标: {}", e),
                None,
            );
        });
        
        // 执行步骤并追踪
        let result = self.observability.tracer.trace_workflow_step(
            &self.workflow_id,
            step_id,
            step_type,
            &self.workflow_span,
            |span| {
                // 执行步骤
                let start_time = Instant::now();
                let step_result = step_fn();
                let duration = start_time.elapsed();
                
                // 记录结果
                match &step_result {
                    Ok(output) => {
                        // 序列化输出
                        let output_json = match serde_json::to_value(output) {
                            Ok(json) => json,
                            Err(e) => {
                                span.record_attribute("serialization_error", e.to_string());
                                json!({"error": "无法序列化输出"})
                            }
                        };
                        
                        span.record_attribute("step.status", "completed");
                        span.record_attribute("step.duration_ms", duration.as_millis() as i64);
                        
                        Ok(output_json)
                    }
                    Err(e) => {
                        span.record_attribute("step.status", "failed");
                        span.record_attribute("step.error", e.to_string());
                        span.record_attribute("step.
```

工作流分布式执行协调
分布式工作流执行需要解决节点间协调、任务调度、状态一致性等问题。
以下是一个完整的分布式工作流协调框架实现:

```rust
/// 分布式工作流协调器
pub struct DistributedCoordinator {
    /// 节点标识符
    node_id: String,
    
    /// 集群管理器
    cluster: Arc<dyn ClusterManager>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 任务调度器
    scheduler: Arc<TaskScheduler>,
    
    /// 健康检查服务
    health_checker: Arc<HealthChecker>,
    
    /// 节点能力描述
    capabilities: NodeCapabilities,
    
    /// 心跳发送间隔
    heartbeat_interval: Duration,
    
    /// 运行状态
    running: AtomicBool,
    
    /// 活跃工作流实例
    active_instances: RwLock<HashMap<String, WorkflowInstanceInfo>>,
    
    /// 协调事件发送器
    event_sender: mpsc::Sender<CoordinationEvent>,
    
    /// 协调事件接收器
    event_receiver: Mutex<mpsc::Receiver<CoordinationEvent>>,
    
    /// 观测性管理器
    observability: Arc<WorkflowObservability>,
}

impl DistributedCoordinator {
    /// 创建新的分布式协调器
    pub fn new(
        node_id: String,
        cluster: Arc<dyn ClusterManager>,
        lock_service: Arc<dyn LockService>,
        state_store: Arc<dyn StateStore>,
        scheduler: Arc<TaskScheduler>,
        health_checker: Arc<HealthChecker>,
        capabilities: NodeCapabilities,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        let (event_sender, event_receiver) = mpsc::channel(1000);
        
        Self {
            node_id,
            cluster,
            lock_service,
            state_store,
            scheduler,
            health_checker,
            capabilities,
            heartbeat_interval: Duration::from_secs(10),
            running: AtomicBool::new(false),
            active_instances: RwLock::new(HashMap::new()),
            event_sender,
            event_receiver: Mutex::new(event_receiver),
            observability,
        }
    }
    
    /// 启动协调器
    pub async fn start(&self) -> Result<(), CoordinationError> {
        if self.running.swap(true, Ordering::SeqCst) {
            return Err(CoordinationError::AlreadyRunning);
        }
        
        // 注册节点到集群
        self.cluster.register_node(&self.node_id, self.capabilities.clone()).await?;
        
        // 启动心跳发送
        self.start_heartbeat().await?;
        
        // 启动事件处理循环
        self.start_event_loop().await?;
        
        // 加入工作流选举
        self.join_workflow_elections().await?;
        
        // 恢复未完成的工作流
        self.recover_workflows().await?;
        
        Ok(())
    }
    
    /// 停止协调器
    pub async fn stop(&self) -> Result<(), CoordinationError> {
        if !self.running.swap(false, Ordering::SeqCst) {
            return Ok(());
        }
        
        // 从集群注销节点
        self.cluster.deregister_node(&self.node_id).await?;
        
        // 释放所有持有的锁
        let active_instances = self.active_instances.read().unwrap();
        for (instance_id, _) in active_instances.iter() {
            let lock_key = format!("workflow:lock:{}", instance_id);
            let _ = self.lock_service.release_lock(&lock_key).await;
        }
        
        Ok(())
    }
    
    /// 启动心跳发送
    async fn start_heartbeat(&self) -> Result<(), CoordinationError> {
        let node_id = self.node_id.clone();
        let cluster = self.cluster.clone();
        let health_checker = self.health_checker.clone();
        let heartbeat_interval = self.heartbeat_interval;
        let running = self.running.clone();
        
        tokio::spawn(async move {
            while running.load(Ordering::SeqCst) {
                let health_status = health_checker.check_health().await;
                let _ = cluster.send_heartbeat(&node_id, health_status).await;
                tokio::time::sleep(heartbeat_interval).await;
            }
        });
        
        Ok(())
    }
    
    /// 启动事件处理循环
    async fn start_event_loop(&self) -> Result<(), CoordinationError> {
        let event_receiver = self.event_receiver.lock().unwrap();
        let event_receiver = event_receiver.clone();
        let coordinator = self.clone();
        let running = self.running.clone();
        
        tokio::spawn(async move {
            while running.load(Ordering::SeqCst) {
                if let Ok(event) = event_receiver.recv().await {
                    let _ = coordinator.handle_coordination_event(event).await;
                }
            }
        });
        
        Ok(())
    }
    
    /// 处理协调事件
    async fn handle_coordination_event(&self, event: CoordinationEvent) -> Result<(), CoordinationError> {
        match event {
            CoordinationEvent::WorkflowStarted(instance_id) => {
                self.on_workflow_started(instance_id).await
            },
            CoordinationEvent::WorkflowCompleted(instance_id, result) => {
                self.on_workflow_completed(instance_id, result).await
            },
            CoordinationEvent::WorkflowFailed(instance_id, error) => {
                self.on_workflow_failed(instance_id, error).await
            },
            CoordinationEvent::TaskCompleted(instance_id, task_id, result) => {
                self.on_task_completed(instance_id, task_id, result).await
            },
            CoordinationEvent::TaskFailed(instance_id, task_id, error) => {
                self.on_task_failed(instance_id, task_id, error).await
            },
            CoordinationEvent::NodeJoined(node_id, capabilities) => {
                self.on_node_joined(node_id, capabilities).await
            },
            CoordinationEvent::NodeLeft(node_id) => {
                self.on_node_left(node_id).await
            },
            CoordinationEvent::LeadershipAcquired(workflow_id) => {
                self.on_leadership_acquired(workflow_id).await
            },
            CoordinationEvent::LeadershipLost(workflow_id) => {
                self.on_leadership_lost(workflow_id).await
            },
        }
    }
    
    /// 加入工作流选举
    async fn join_workflow_elections(&self) -> Result<(), CoordinationError> {
        // 获取所有活跃的工作流
        let active_workflows = self.state_store.get_active_workflow_ids().await?;
        
        for workflow_id in active_workflows {
            self.join_workflow_election(&workflow_id).await?;
        }
        
        Ok(())
    }
    
    /// 加入特定工作流的选举
    async fn join_workflow_election(&self, workflow_id: &str) -> Result<(), CoordinationError> {
        let election_key = format!("workflow:election:{}", workflow_id);
        let node_id = self.node_id.clone();
        let event_sender = self.event_sender.clone();
        
        self.cluster.join_election(&election_key, node_id, move |is_leader| {
            let event = if is_leader {
                CoordinationEvent::LeadershipAcquired(workflow_id.to_string())
            } else {
                CoordinationEvent::LeadershipLost(workflow_id.to_string())
            };
            
            let _ = event_sender.try_send(event);
        }).await?;
        
        Ok(())
    }
    
    /// 当获得工作流领导权时
    async fn on_leadership_acquired(&self, workflow_id: String) -> Result<(), CoordinationError> {
        // 获取工作流定义和状态
        let workflow = self.state_store.get_workflow_definition(&workflow_id).await?;
        let state = self.state_store.get_workflow_state(&workflow_id).await?;
        
        // 如果工作流未完成，开始协调执行
        if !state.is_terminal() {
            self.coordinate_workflow_execution(workflow, state).await?;
        }
        
        Ok(())
    }
    
    /// 当失去工作流领导权时
    async fn on_leadership_lost(&self, workflow_id: String) -> Result<(), CoordinationError> {
        // 从活跃实例中移除
        let mut active_instances = self.active_instances.write().unwrap();
        active_instances.remove(&workflow_id);
        
        Ok(())
    }
    
    /// 协调工作流执行
    async fn coordinate_workflow_execution(
        &self,
        workflow: WorkflowDefinition,
        state: WorkflowState,
    ) -> Result<(), CoordinationError> {
        // 构建任务依赖图
        let task_graph = self.build_task_dependency_graph(&workflow);
        
        // 找出可以执行的任务
        let executable_tasks = self.find_executable_tasks(&task_graph, &state);
        
        // 将任务分配到合适的节点
        for task in executable_tasks {
            self.schedule_task(task, &workflow.id, &workflow).await?;
        }
        
        // 添加到活跃实例
        let instance_info = WorkflowInstanceInfo {
            workflow_id: workflow.id.clone(),
            definition: workflow,
            state,
            task_graph,
            start_time: Utc::now(),
        };
        
        let mut active_instances = self.active_instances.write().unwrap();
        active_instances.insert(workflow.id.clone(), instance_info);
        
        Ok(())
    }
    
    /// 构建任务依赖图
    fn build_task_dependency_graph(&self, workflow: &WorkflowDefinition) -> TaskGraph {
        let mut graph = TaskGraph::new();
        
        // 添加所有任务节点
        for task in &workflow.tasks {
            graph.add_node(task.id.clone(), task.clone());
        }
        
        // 添加依赖边
        for task in &workflow.tasks {
            for dep_id in &task.depends_on {
                graph.add_edge(dep_id.clone(), task.id.clone());
            }
        }
        
        graph
    }
    
    /// 查找可执行的任务
    fn find_executable_tasks(&self, graph: &TaskGraph, state: &WorkflowState) -> Vec<TaskDefinition> {
        let mut executable = Vec::new();
        
        for (task_id, task) in graph.nodes() {
            // 如果任务已经完成或正在执行，跳过
            if let Some(task_state) = state.task_states.get(task_id) {
                if task_state.is_terminal() || task_state.status == TaskStatus::Running {
                    continue;
                }
            }
            
            // 检查所有依赖是否已完成
            let mut dependencies_met = true;
            for dep_id in graph.get_dependencies(task_id) {
                if let Some(dep_state) = state.task_states.get(dep_id) {
                    if dep_state.status != TaskStatus::Completed {
                        dependencies_met = false;
                        break;
                    }
                } else {
                    dependencies_met = false;
                    break;
                }
            }
            
            if dependencies_met {
                executable.push(task.clone());
            }
        }
        
        executable
    }
    
    /// 调度任务执行
    async fn schedule_task(
        &self,
        task: TaskDefinition,
        workflow_id: &str,
        workflow: &WorkflowDefinition,
    ) -> Result<(), CoordinationError> {
        // 选择合适的执行节点
        let selected_node = self.select_execution_node(&task).await?;
        
        // 更新任务状态为调度中
        let task_state = TaskState {
            task_id: task.id.clone(),
            status: TaskStatus::Scheduled,
            scheduled_time: Some(Utc::now()),
            start_time: None,
            end_time: None,
            node_id: Some(selected_node.clone()),
            error: None,
            result: None,
        };
        
        self.state_store.update_task_state(workflow_id, &task_state).await?;
        
        // 创建任务执行请求
        let execution_request = TaskExecutionRequest {
            workflow_id: workflow_id.to_string(),
            workflow_definition: workflow.clone(),
            task: task.clone(),
            context: self.build_task_execution_context(workflow_id, &task).await?,
        };
        
        // 发送到选定节点执行
        self.cluster.send_execution_request(&selected_node, execution_request).await?;
        
        Ok(())
    }
    
    /// 选择执行节点
    async fn select_execution_node(&self, task: &TaskDefinition) -> Result<String, CoordinationError> {
        // 获取活跃节点列表
        let nodes = self.cluster.get_active_nodes().await?;
        
        // 根据任务要求过滤合适的节点
        let mut suitable_nodes = Vec::new();
        for (node_id, node_info) in nodes {
            if self.is_node_suitable_for_task(&node_info, task) {
                suitable_nodes.push((node_id, node_info));
            }
        }
        
        if suitable_nodes.is_empty() {
            return Err(CoordinationError::NoSuitableNodeFound);
        }
        
        // 根据负载选择最合适的节点
        suitable_nodes.sort_by(|(_, a), (_, b)| {
            a.load_factor.partial_cmp(&b.load_factor).unwrap_or(std::cmp::Ordering::Equal)
        });
        
        Ok(suitable_nodes[0].0.clone())
    }
    
    /// 检查节点是否适合执行任务
    fn is_node_suitable_for_task(&self, node_info: &NodeInfo, task: &TaskDefinition) -> bool {
        // 检查节点健康状态
        if node_info.health_status != HealthStatus::Healthy {
            return false;
        }
        
        // 检查节点是否支持任务类型
        if !node_info.capabilities.supported_task_types.contains(&task.task_type) {
            return false;
        }
        
        // 检查节点是否满足资源要求
        if let Some(resources) = &task.resource_requirements {
            if resources.cpu_cores > node_info.capabilities.available_resources.cpu_cores {
                return false;
            }
            
            if resources.memory_mb > node_info.capabilities.available_resources.memory_mb {
                return false;
            }
            
            if resources.disk_mb > node_info.capabilities.available_resources.disk_mb {
                return false;
            }
        }
        
        true
    }
    
    /// 构建任务执行上下文
    async fn build_task_execution_context(
        &self,
        workflow_id: &str,
        task: &TaskDefinition,
    ) -> Result<TaskExecutionContext, CoordinationError> {
        // 获取工作流状态
        let workflow_state = self.state_store.get_workflow_state(workflow_id).await?;
        
        // 收集所有依赖任务的输出
        let mut inputs = HashMap::new();
        for dep_id in &task.depends_on {
            if let Some(dep_state) = workflow_state.task_states.get(dep_id) {
                if let Some(result) = &dep_state.result {
                    inputs.insert(dep_id.clone(), result.clone());
                }
            }
        }
        
        Ok(TaskExecutionContext {
            workflow_id: workflow_id.to_string(),
            workflow_variables: workflow_state.variables.clone(),
            task_inputs: inputs,
            execution_params: task.parameters.clone(),
        })
    }
    
    /// 当工作流任务完成时
    async fn on_task_completed(
        &self,
        workflow_id: String,
        task_id: String,
        result: serde_json::Value,
    ) -> Result<(), CoordinationError> {
        // 获取工作流状态
        let mut workflow_state = self.state_store.get_workflow_state(&workflow_id).await?;
        
        // 更新任务状态
        let now = Utc::now();
        let task_state = workflow_state.task_states.entry(task_id.clone())
            .or_insert_with(|| TaskState {
                task_id: task_id.clone(),
                status: TaskStatus::Pending,
                scheduled_time: None,
                start_time: None,
                end_time: None,
                node_id: None,
                error: None,
                result: None,
            });
            
        task_state.status = TaskStatus::Completed;
        task_state.end_time = Some(now);
        task_state.result = Some(result);
        
        // 保存更新后的状态
        self.state_store.update_workflow_state(&workflow_id, &workflow_state).await?;
        
        // 获取工作流定义
        let workflow_def = self.state_store.get_workflow_definition(&workflow_id).await?;
        
        // 检查是否有新的可执行任务
        let task_graph = self.build_task_dependency_graph(&workflow_def);
        let executable_tasks = self.find_executable_tasks(&task_graph, &workflow_state);
        
        // 调度新的可执行任务
        for task in executable_tasks {
            self.schedule_task(task, &workflow_id, &workflow_def).await?;
        }
        
        // 检查工作流是否已经完成
        self.check_workflow_completion(&workflow_id, &workflow_def, &workflow_state).await?;
        
        Ok(())
    }
    
    /// 当工作流任务失败时
    async fn on_task_failed(
        &self,
        workflow_id: String,
        task_id: String,
        error: String,
    ) -> Result<(), CoordinationError> {
        // 获取工作流状态和定义
        let mut workflow_state = self.state_store.get_workflow_state(&workflow_id).await?;
        let workflow_def = self.state_store.get_workflow_definition(&workflow_id).await?;
        
        // 更新任务状态
        let now = Utc::now();
        let task_state = workflow_state.task_states.entry(task_id.clone())
            .or_insert_with(|| TaskState {
                task_id: task_id.clone(),
                status: TaskStatus::Pending,
                scheduled_time: None,
                start_time: None,
                end_time: None,
                node_id: None,
                error: None,
                result: None,
            });
            
        task_state.status = TaskStatus::Failed;
        task_state.end_time = Some(now);
        task_state.error = Some(error.clone());
        
        // 保存更新后的状态
        self.state_store.update_workflow_state(&workflow_id, &workflow_state).await?;
        
        // 找到对应的任务定义
        let task_def = workflow_def.tasks.iter()
            .find(|t| t.id == task_id)
            .ok_or(CoordinationError::TaskNotFound(task_id.clone()))?;
        
        // 检查是否需要重试
        if let Some(retry_policy) = &task_def.retry_policy {
            let retry_count = workflow_state.task_retry_counts.get(&task_id).unwrap_or(&0);
            
            if *retry_count < retry_policy.max_attempts {
                // 更新重试计数
                workflow_state.task_retry_counts.insert(task_id.clone(), retry_count + 1);
                self.state_store.update_workflow_state(&workflow_id, &workflow_state).await?;
                
                // 根据重试策略计算延迟
                let delay = self.calculate_retry_delay(retry_policy, *retry_count);
                
                // 安排任务重试
                let retry_task = task_def.clone();
                let coordinator = self.clone();
                let workflow_id_clone = workflow_id.clone();
                
                tokio::spawn(async move {
                    tokio::time::sleep(delay).await;
                    let _ = coordinator.schedule_task(retry_task, &workflow_id_clone, &workflow_def).await;
                });
                
                return Ok(());
            }
        }
        
        // 检查任务失败是否导致工作流失败
        if task_def.is_critical {
            // 更新工作流状态为失败
            workflow_state.status = WorkflowStatus::Failed;
            workflow_state.end_time = Some(now);
            workflow_state.error = Some(format!("关键任务 {} 失败: {}", task_id, error));
            
            self.state_store.update_workflow_state(&workflow_id, &workflow_state).await?;
            
            // 发送工作流失败事件
            self.event_sender.send(CoordinationEvent::WorkflowFailed(
                workflow_id.clone(),
                error.clone(),
            )).await.map_err(|_| CoordinationError::EventSendFailed)?;
        } else {
            // 检查是否有新的可执行任务
            let task_graph = self.build_task_dependency_graph(&workflow_def);
            let executable_tasks = self.find_executable_tasks(&task_graph, &workflow_state);
            
            // 调度新的可执行任务
            for task in executable_tasks {
                self.schedule_task(task, &workflow_id, &workflow_def).await?;
            }
            
            // 检查工作流是否已经完成
            self.check_workflow_completion(&workflow_id, &workflow_def, &workflow_state).await?;
        }
        
        Ok(())
    }
    
    /// 计算重试延迟
    fn calculate_retry_delay(&self, policy: &RetryPolicy, attempt: u32) -> Duration {
        match policy.backoff_strategy {
            BackoffStrategy::Fixed => policy.initial_delay,
            BackoffStrategy::Linear => policy.initial_delay.mul_f32(attempt as f32),
            BackoffStrategy::Exponential => {
                policy.initial_delay.mul_f32(policy.backoff_factor.powf(attempt as f32))
            }
        }
    }
    
    /// 检查工作流是否已完成
    async fn check_workflow_completion(
        &self,
        workflow_id: &str,
        workflow_def: &WorkflowDefinition,
        workflow_state: &WorkflowState,
    ) -> Result<(), CoordinationError> {
        // 构建任务依赖图
        let task_graph = self.build_task_dependency_graph(workflow_def);
        
        // 检查是否所有任务都已完成
        let mut all_completed = true;
        let mut any_failed = false;
        
        for task_def in &workflow_def.tasks {
            if let Some(state) = workflow_state.task_states.get(&task_def.id) {
                match state.status {
                    TaskStatus::Completed => continue,
                    TaskStatus::Failed => {
                        if task_def.is_critical {
                            any_failed = true;
                            break;
                        }
                    },
                    _ => {
                        all_completed = false;
                        break;
                    }
                }
            } else {
                all_completed = false;
                break;
            }
        }
        
        if all_completed || any_failed {
            let mut updated_state = workflow_state.clone();
            updated_state.end_time = Some(Utc::now());
            
            if any_failed {
                updated_state.status = WorkflowStatus::Failed;
                updated_state.error = Some("关键任务失败导致工作流失败".to_string());
                
                // 发送工作流失败事件
                self.event_sender.send(CoordinationEvent::WorkflowFailed(
                    workflow_id.to_string(),
                    updated_state.error.clone().unwrap_or_default(),
                )).await.map_err(|_| CoordinationError::EventSendFailed)?;
            } else {
                updated_state.status = WorkflowStatus::Completed;
                
                // 收集所有输出任务的结果
                let mut outputs = HashMap::new();
                for (task_id, task_state) in &updated_state.task_states {
                    if workflow_def.output_tasks.contains(task_id) {
                        if let Some(result) = &task_state.result {
                            outputs.insert(task_id.clone(), result.clone());
                        }
                    }
                }
                
                // 发送工作流完成事件
                self.event_sender.send(CoordinationEvent::WorkflowCompleted(
                    workflow_id.to_string(),
                    serde_json::to_value(outputs).unwrap_or(serde_json::Value::Null),
                )).await.map_err(|_| CoordinationError::EventSendFailed)?;
            }
            
            // 保存更新后的状态
            self.state_store.update_workflow_state(workflow_id, &updated_state).await?;
            
            // 从活跃实例中移除
            let mut active_instances = self.active_instances.write().unwrap();
            active_instances.remove(workflow_id);
        }
        
        Ok(())
    }
    
    /// 恢复未完成的工作流
    async fn recover_workflows(&self) -> Result<(), CoordinationError> {
        // 获取所有未完成的工作流
        let active_workflow_ids = self.state_store.get_active_workflow_ids().await?;
        
        for workflow_id in active_workflow_ids {
            // 尝试获取工作流锁
            let lock_key = format!("workflow:lock:{}", workflow_id);
            let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.node_id.clone(), Duration::from_secs(60)).await?;
            
            if lock_acquired {
                // 获取工作流定义和状态
                let workflow = self.state_store.get_workflow_definition(&workflow_id).await?;
                let mut state = self.state_store.get_workflow_state(&workflow_id).await?;
                
                // 重置所有正在运行的任务
                for task_state in state.task_states.values_mut() {
                    if task_state.status == TaskStatus::Running || task_state.status == TaskStatus::Scheduled {
                        task_state.status = TaskStatus::Pending;
                        task_state.node_id = None;
                    }
                }
                
                // 保存更新后的状态
                self.state_store.update_workflow_state(&workflow_id, &state).await?;
                
                // 重新协调工作流执行
                self.coordinate_workflow_execution(workflow, state).await?;
            }
        }
        
        Ok(())
    }
}

/// 任务图 - 表示任务之间的依赖关系
pub struct TaskGraph {
    /// 任务节点 - 任务ID到任务定义的映射
    nodes: HashMap<String, TaskDefinition>,
    
    /// 任务依赖 - 任务ID到其依赖任务ID的映射
    dependencies: HashMap<String, Vec<String>>,
    
    /// 任务依赖者 - 任务ID到依赖它的任务ID的映射
    dependents: HashMap<String, Vec<String>>,
}

impl TaskGraph {
    /// 创建新的任务图
    pub fn new() -> Self {
        Self {
            nodes: HashMap::new(),
            dependencies: HashMap::new(),
            dependents: HashMap::new(),
        }
    }
    
    /// 添加任务节点
    pub fn add_node(&mut self, task_id: String, task: TaskDefinition) {
        self.nodes.insert(task_id, task);
    }
    
    /// 添加依赖边
    pub fn add_edge(&mut self, from: String, to: String) {
        // 添加依赖
        self.dependencies.entry(to.clone())
            .or_insert_with(Vec::new)
            .push(from.clone());
        
        // 添加依赖者
        self.dependents.entry(from)
            .or_insert_with(Vec::new)
            .push(to);
    }
    
    /// 获取所有节点
    pub fn nodes(&self) -> impl Iterator<Item = (&String, &TaskDefinition)> {
        self.nodes.iter()
    }
    
    /// 获取任务的依赖
    pub fn get_dependencies(&self, task_id: &str) -> &[String] {
        if let Some
```

工作流容错与恢复机制
工作流容错恢复是确保工作流系统可靠性的关键组件，需要处理各种异常情况并恢复工作流执行。

```rust
/// 工作流容错管理器
pub struct FaultToleranceManager {
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 工作流引擎
    workflow_engine: Arc<WorkflowEngine>,
    
    /// 快照管理器
    snapshot_manager: Arc<SnapshotManager>,
    
    /// 节点管理器
    node_manager: Arc<NodeManager>,
    
    /// 故障处理器映射
    fault_handlers: RwLock<HashMap<WorkflowFaultType, Vec<Box<dyn FaultHandler>>>>,
    
    /// 配置
    config: FaultToleranceConfig,
    
    /// 观测性管理器
    observability: Arc<WorkflowObservability>,
}

/// 工作流故障类型
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum WorkflowFaultType {
    /// 节点崩溃
    NodeCrash,
    
    /// 任务执行失败
    TaskFailed,
    
    /// 工作流超时
    Timeout,
    
    /// 步骤失败
    StepFailed,
    
    /// 资源耗尽
    ResourceExhausted,
    
    /// 状态损坏
    StateCorruption,
    
    /// 网络分区
    NetworkPartition,
    
    /// 分布式一致性错误
    ConsistencyError,
    
    /// 外部系统故障
    ExternalSystemFailure,
}

/// 故障处理器接口
#[async_trait]
pub trait FaultHandler: Send + Sync {
    /// 处理故障
    async fn handle_fault(&self, context: &FaultContext) -> Result<RecoveryAction, RecoveryError>;
    
    /// 获取处理器类型
    fn get_type(&self) -> &'static str;
}

/// 故障上下文
pub struct FaultContext {
    /// 工作流实例ID
    pub workflow_id: String,
    
    /// 故障类型
    pub fault_type: WorkflowFaultType,
    
    /// 故障发生时间
    pub occurred_at: DateTime<Utc>,
    
    /// 故障详情
    pub details: serde_json::Value,
    
    /// 当前工作流状态
    pub workflow_state: Option<WorkflowState>,
    
    /// 故障任务信息
    pub task_info: Option<TaskInfo>,
    
    /// 故障节点信息
    pub node_info: Option<NodeInfo>,
}

/// 恢复行动
pub enum RecoveryAction {
    /// 重试任务
    RetryTask {
        /// 任务ID
        task_id: String,
        
        /// 延迟时间
        delay: Option<Duration>,
        
        /// 修改的任务参数
        modified_params: Option<serde_json::Value>,
    },
    
    /// 跳过任务
    SkipTask {
        /// 任务ID
        task_id: String,
        
        /// 模拟结果
        simulated_result: Option<serde_json::Value>,
    },
    
    /// 重新调度任务到不同节点
    RescheduleTask {
        /// 任务ID
        task_id: String,
        
        /// 指定节点ID
        target_node_id: Option<String>,
        
        /// 排除节点ID列表
        exclude_node_ids: Vec<String>,
    },
    
    /// 回滚到工作流快照
    RollbackToSnapshot {
        /// 快照ID
        snapshot_id: String,
    },
    
    /// 切换到备用流程
    SwitchToAlternativeFlow {
        /// 备用流程ID
        alternative_flow_id: String,
    },
    
    /// 启动补偿流程
    StartCompensation,
    
    /// 人工干预
    ManualIntervention {
        /// 消息
        message: String,
        
        /// 接收人
        recipients: Vec<String>,
    },
    
    /// 终止工作流
    TerminateWorkflow {
        /// 错误信息
        error_message: String,
    },
}

/// 恢复错误
#[derive(Debug, thiserror::Error)]
pub enum RecoveryError {
    #[error("状态存储错误: {0}")]
    StateStore(String),
    
    #[error("快照错误: {0}")]
    Snapshot(String),
    
    #[error("节点管理错误: {0}")]
    NodeManager(String),
    
    #[error("锁服务错误: {0}")]
    LockService(String),
    
    #[error("恢复策略错误: {0}")]
    Strategy(String),
    
    #[error("无法恢复: {0}")]
    Unrecoverable(String),
}

impl FaultToleranceManager {
    /// 创建新的故障容错管理器
    pub fn new(
        state_store: Arc<dyn StateStore>,
        lock_service: Arc<dyn LockService>,
        workflow_engine: Arc<WorkflowEngine>,
        snapshot_manager: Arc<SnapshotManager>,
        node_manager: Arc<NodeManager>,
        config: FaultToleranceConfig,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        let mut manager = Self {
            state_store,
            lock_service,
            workflow_engine,
            snapshot_manager,
            node_manager,
            fault_handlers: RwLock::new(HashMap::new()),
            config,
            observability,
        };
        
        // 注册默认故障处理器
        manager.register_default_handlers();
        
        manager
    }
    
    /// 注册默认故障处理器
    fn register_default_handlers(&self) {
        // 注册节点崩溃处理器
        self.register_fault_handler(
            WorkflowFaultType::NodeCrash,
            Box::new(NodeCrashHandler::new(
                self.workflow_engine.clone(),
                self.node_manager.clone(),
            )),
        );
        
        // 注册任务失败处理器
        self.register_fault_handler(
            WorkflowFaultType::TaskFailed,
            Box::new(TaskFailureHandler::new(
                self.workflow_engine.clone(),
                self.config.max_task_retries,
            )),
        );
        
        // 注册超时处理器
        self.register_fault_handler(
            WorkflowFaultType::Timeout,
            Box::new(TimeoutHandler::new(
                self.workflow_engine.clone(),
                self.config.max_workflow_retries,
            )),
        );
        
        // 注册步骤失败处理器
        self.register_fault_handler(
            WorkflowFaultType::StepFailed,
            Box::new(StepFailureHandler::new(
                self.workflow_engine.clone(),
                self.snapshot_manager.clone(),
                self.config.max_step_retries,
            )),
        );
        
        // 注册资源耗尽处理器
        self.register_fault_handler(
            WorkflowFaultType::ResourceExhausted,
            Box::new(ResourceExhaustionHandler::new(
                self.workflow_engine.clone(),
                self.node_manager.clone(),
            )),
        );
        
        // 注册状态损坏处理器
        self.register_fault_handler(
            WorkflowFaultType::StateCorruption,
            Box::new(StateCorruptionHandler::new(
                self.workflow_engine.clone(),
                self.snapshot_manager.clone(),
            )),
        );
    }
    
    /// 注册故障处理器
    pub fn register_fault_handler(
        &self,
        fault_type: WorkflowFaultType,
        handler: Box<dyn FaultHandler>,
    ) {
        let mut handlers = self.fault_handlers.write().unwrap();
        
        // 获取指定类型的处理器列表，如果不存在则创建
        let type_handlers = handlers.entry(fault_type).or_insert_with(Vec::new);
        
        // 添加处理器
        type_handlers.push(handler);
    }
    
    /// 处理工作流故障
    pub async fn handle_workflow_fault(
        &self,
        workflow_id: &str,
        fault_type: WorkflowFaultType,
        details: serde_json::Value,
    ) -> Result<RecoveryAction, RecoveryError> {
        // 创建追踪上下文
        let trace_ctx = self.observability
            .create_fault_handling_span(workflow_id, &fault_type, &details);
        let _trace_guard = trace_ctx.enter();
        
        // 获取工作流状态
        let workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        // 提取任务信息
        let task_info = if let Some(task_id) = details.get("task_id").and_then(|v| v.as_str()) {
            self.state_store.get_task_info(workflow_id, task_id).await
                .map_err(|e| RecoveryError::StateStore(e.to_string())).ok()
        } else {
            None
        };
        
        // 提取节点信息
        let node_info = if let Some(node_id) = details.get("node_id").and_then(|v| v.as_str()) {
            self.node_manager.get_node_info(node_id).await
                .map_err(|e| RecoveryError::NodeManager(e.to_string())).ok()
        } else {
            None
        };
        
        // 创建故障上下文
        let fault_context = FaultContext {
            workflow_id: workflow_id.to_string(),
            fault_type: fault_type.clone(),
            occurred_at: Utc::now(),
            details: details.clone(),
            workflow_state: Some(workflow_state),
            task_info,
            node_info,
        };
        
        // 记录故障信息
        self.observability.record_workflow_fault(
            workflow_id,
            &fault_type,
            &fault_context.occurred_at,
            &details,
        );
        
        // 尝试获取锁，确保只有一个节点处理故障
        let lock_key = format!("workflow:fault:lock:{}", workflow_id);
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, "fault-handler", Duration::from_secs(60)).await
            .map_err(|e| RecoveryError::LockService(e.to_string()))?;
        
        if !lock_acquired {
            return Err(RecoveryError::LockService(
                "无法获取故障处理锁，可能其他节点正在处理".to_string()
            ));
        }
        
        // 查找适用的故障处理器
        let handlers = self.fault_handlers.read().unwrap();
        let type_handlers = match handlers.get(&fault_type) {
            Some(h) => h,
            None => {
                // 没有找到处理器，使用默认策略
                self.lock_service.release_lock(&lock_key).await
                    .map_err(|e| RecoveryError::LockService(e.to_string()))?;
                
                return Err(RecoveryError::Strategy(
                    format!("没有找到处理 {:?} 类型故障的处理器", fault_type)
                ));
            }
        };
        
        // 依次尝试所有处理器
        let mut last_error = None;
        for handler in type_handlers {
            match handler.handle_fault(&fault_context).await {
                Ok(action) => {
                    // 释放锁
                    let _ = self.lock_service.release_lock(&lock_key).await;
                    
                    // 记录恢复行动
                    self.observability.record_recovery_action(
                        workflow_id,
                        &fault_type,
                        handler.get_type(),
                        &action,
                    );
                    
                    return Ok(action);
                },
                Err(e) => {
                    last_error = Some(e);
                    // 继续尝试下一个处理器
                }
            }
        }
        
        // 释放锁
        let _ = self.lock_service.release_lock(&lock_key).await;
        
        // 所有处理器都失败了
        Err(last_error.unwrap_or_else(|| RecoveryError::Unrecoverable(
            format!("所有 {:?} 故障处理器都失败了", fault_type)
        )))
    }
    
    /// 执行恢复行动
    pub async fn execute_recovery_action(
        &self,
        workflow_id: &str,
        action: &RecoveryAction,
    ) -> Result<(), RecoveryError> {
        match action {
            RecoveryAction::RetryTask { task_id, delay, modified_params } => {
                // 如果有延迟，等待指定时间
                if let Some(d) = delay {
                    tokio::time::sleep(d.clone()).await;
                }
                
                // 重置任务状态
                let mut task_update = TaskStateUpdate {
                    workflow_id: workflow_id.to_string(),
                    task_id: task_id.clone(),
                    status: TaskStatus::Pending,
                    node_id: None,
                    error: None,
                    result: None,
                };
                
                // 如果有修改的参数，更新任务参数
                if let Some(params) = modified_params {
                    task_update.parameters = Some(params.clone());
                }
                
                // 更新任务状态
                self.state_store.update_task_state(&task_update).await
                    .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
                
                // 重新调度任务
                self.workflow_engine.reschedule_task(workflow_id, task_id).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryAction::SkipTask { task_id, simulated_result } => {
                // 更新任务状态为已完成，但标记为已跳过
                let mut task_update = TaskStateUpdate {
                    workflow_id: workflow_id.to_string(),
                    task_id: task_id.clone(),
                    status: TaskStatus::Completed,
                    node_id: None,
                    error: None,
                    result: simulated_result.clone(),
                    metadata: Some(serde_json::json!({
                        "skipped": true,
                        "skipped_at": Utc::now().to_rfc3339(),
                    })),
                };
                
                // 更新任务状态
                self.state_store.update_task_state(&task_update).await
                    .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
                
                // 通知工作流引擎任务已完成，以继续执行
                self.workflow_engine.notify_task_completion(workflow_id, task_id, simulated_result.clone()).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryAction::RescheduleTask { task_id, target_node_id, exclude_node_ids } => {
                // 重置任务状态
                let task_update = TaskStateUpdate {
                    workflow_id: workflow_id.to_string(),
                    task_id: task_id.clone(),
                    status: TaskStatus::Pending,
                    node_id: None,
                    error: None,
                    result: None,
                    metadata: Some(serde_json::json!({
                        "rescheduled": true,
                        "rescheduled_at": Utc::now().to_rfc3339(),
                        "target_node_id": target_node_id,
                        "exclude_node_ids": exclude_node_ids,
                    })),
                };
                
                // 更新任务状态
                self.state_store.update_task_state(&task_update).await
                    .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
                
                // 重新调度任务到指定节点
                self.workflow_engine.reschedule_task_to_node(
                    workflow_id, 
                    task_id, 
                    target_node_id.clone(),
                    exclude_node_ids.clone(),
                ).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryAction::RollbackToSnapshot { snapshot_id } => {
                // 回滚到指定快照
                self.snapshot_manager.restore_snapshot(workflow_id, snapshot_id).await
                    .map_err(|e| RecoveryError::Snapshot(e.to_string()))?;
                
                // 重启工作流执行
                self.workflow_engine.restart_workflow_from_snapshot(workflow_id, snapshot_id).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryAction::SwitchToAlternativeFlow { alternative_flow_id } => {
                // 切换到备用流程
                self.workflow_engine.switch_to_alternative_flow(workflow_id, alternative_flow_id).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryAction::StartCompensation => {
                // 启动补偿流程
                self.workflow_engine.start_compensation_flow(workflow_id).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryAction::ManualIntervention { message, recipients } => {
                // 创建人工干预请求
                let intervention_request = ManualInterventionRequest {
                    workflow_id: workflow_id.to_string(),
                    message: message.clone(),
                    recipients: recipients.clone(),
                    created_at: Utc::now(),
                };
                
                // 保存干预请求
                self.state_store.create_intervention_request(&intervention_request).await
                    .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
                
                // 暂停工作流
                self.workflow_engine.pause_workflow(workflow_id).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
                
                // 发送通知（假设有通知服务）
                // self.notification_service.send_notification(...).await?;
            },
            RecoveryAction::TerminateWorkflow { error_message } => {
                // 终止工作流
                self.workflow_engine.terminate_workflow(workflow_id, error_message).await
                    .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
        }
        
        Ok(())
    }
    
    /// 恢复中断的工作流
    pub async fn recover_interrupted_workflows(&self) -> Result<Vec<String>, RecoveryError> {
        // 获取所有活跃但可能已中断的工作流
        let active_workflows = self.state_store.get_active_workflow_ids().await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        let mut recovered = Vec::new();
        
        for workflow_id in active_workflows {
            // 尝试获取锁
            let lock_key = format!("workflow:recovery:lock:{}", workflow_id);
            let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, "recovery-manager", Duration::from_secs(30)).await
                .map_err(|e| RecoveryError::LockService(e.to_string()))?;
            
            if !lock_acquired {
                // 其他节点可能已经在处理
                continue;
            }
            
            // 获取工作流状态
            let workflow_state = match self.state_store.get_workflow_state(&workflow_id).await {
                Ok(state) => state,
                Err(e) => {
                    let _ = self.lock_service.release_lock(&lock_key).await;
                    continue;
                }
            };
            
            // 检查工作流是否需要恢复
            let needs_recovery = match workflow_state.status {
                WorkflowStatus::Running => {
                    // 检查最后更新时间，如果超过阈值则认为需要恢复
                    let now = Utc::now();
                    let last_updated = workflow_state.last_updated_at.unwrap_or(workflow_state.start_time.unwrap_or(now));
                    
                    now.signed_duration_since(last_updated) > chrono::Duration::seconds(self.config.heartbeat_timeout_seconds as i64)
                },
                WorkflowStatus::Scheduled => true,
                _ => false,
            };
            
            if needs_recovery {
                // 恢复工作流
                match self.recover_workflow(&workflow_id).await {
                    Ok(_) => {
                        recovered.push(workflow_id.clone());
                    },
                    Err(e) => {
                        // 记录恢复失败
                        self.observability.record_recovery_failure(&workflow_id, &e);
                    }
                }
            }
            
            // 释放锁
            let _ = self.lock_service.release_lock(&lock_key).await;
        }
        
        Ok(recovered)
    }
    
    /// 恢复单个工作流
    async fn recover_workflow(&self, workflow_id: &str) -> Result<(), RecoveryError> {
        // 创建恢复追踪上下文
        let trace_ctx = self.observability.create_workflow_recovery_span(workflow_id);
        let _trace_guard = trace_ctx.enter();
        
        // 获取工作流状态
        let mut workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        // 获取工作流定义
        let workflow_def = self.state_store.get_workflow_definition(&workflow_state.workflow_definition_id).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        // 重置所有运行中和已调度的任务
        for (task_id, task_state) in workflow_state.task_states.iter_mut() {
            if task_state.status == TaskStatus::Running || task_state.status == TaskStatus::Scheduled {
                task_state.status = TaskStatus::Pending;
                task_state.node_id = None;
                task_state.start_time = None;
                
                // 创建任务状态更新
                let task_update = TaskStateUpdate {
                    workflow_id: workflow_id.to_string(),
                    task_id: task_id.clone(),
                    status: TaskStatus::Pending,
                    node_id: None,
                    error: None,
                    result: None,
                    metadata: Some(serde_json::json!({
                        "recovered": true,
                        "recovered_at": Utc::now().to_rfc3339(),
                    })),
                };
                
                // 更新任务状态
                self.state_store.update_task_state(&task_update).await
                    .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
            }
        }
        
        // 更新工作流状态
        workflow_state.last_updated_at = Some(Utc::now());
        self.state_store.update_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        // 记录恢复事件
        self.observability.record_workflow_recovery(
            workflow_id,
            "SYSTEM",
            "工作流自动恢复",
            &serde_json::json!({
                "recovery_time": Utc::now().to_rfc3339(),
                "workflow_status": format!("{:?}", workflow_state.status),
            }),
        );
        
        // 重新调度工作流
        self.workflow_engine.resume_workflow(workflow_id).await
            .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
        
        Ok(())
    }
}

/// 节点崩溃处理器
pub struct NodeCrashHandler {
    workflow_engine: Arc<WorkflowEngine>,
    node_manager: Arc<NodeManager>,
}

impl NodeCrashHandler {
    pub fn new(workflow_engine: Arc<WorkflowEngine>, node_manager: Arc<NodeManager>) -> Self {
        Self {
            workflow_engine,
            node_manager,
        }
    }
}

#[async_trait]
impl FaultHandler for NodeCrashHandler {
    async fn handle_fault(&self, context: &FaultContext) -> Result<RecoveryAction, RecoveryError> {
        // 获取崩溃节点ID
        let node_id = context.details.get("node_id")
            .and_then(|v| v.as_str())
            .ok_or_else(|| RecoveryError::Strategy("缺少节点ID".to_string()))?
            .to_string();
        
        // 标记节点为不可用
        self.node_manager.mark_node_unavailable(&node_id).await
            .map_err(|e| RecoveryError::NodeManager(e.to_string()))?;
        
        // 如果任务信息存在，重新调度任务
        if let Some(task_info) = &context.task_info {
            return Ok(RecoveryAction::RescheduleTask {
                task_id: task_info.id.clone(),
                target_node_id: None,
                exclude_node_ids: vec![node_id],
            });
        }
        
        // 如果没有任务信息，重新调度整个工作流
        Ok(RecoveryAction::SwitchToAlternativeFlow {
            alternative_flow_id: "auto_recovery".to_string(),
        })
    }
    
    fn get_type(&self) -> &'static str {
        "node_crash_handler"
    }
}

/// 任务失败处理器
pub struct TaskFailureHandler {
    workflow_engine: Arc<WorkflowEngine>,
    max_retries: u32,
}

impl TaskFailureHandler {
    pub fn new(workflow_engine: Arc<WorkflowEngine>, max_retries: u32) -> Self {
        Self {
            workflow_engine,
            max_retries,
        }
    }
}

#[async_trait]
impl FaultHandler for TaskFailureHandler {
    async fn handle_fault(&self, context: &FaultContext) -> Result<RecoveryAction, RecoveryError> {
        // 获取任务ID
        let task_id = context.details.get("task_id")
            .and_then(|v| v.as_str())
            .ok_or_else(|| RecoveryError::Strategy("缺少任务ID".to_string()))?
            .to_string();
        
        // 获取当前重试次数
        let retry_count = context.details.get("retry_count")
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as u32;
        
        // 检查是否超过最大重试次数
        if retry_count >= self.max_retries {
            // 如果任务是关键任务，终止工作流
            let is_critical = context.details.get("is_critical")
                .and_then(|v| v.as_bool())
                .unwrap_or(false);
            
            if is_critical {
                let error_message = context.details.get("error")
                    .and_then(|v| v.as_str())
                    .unwrap_or("关键任务执行失败")
                    .to_string();
                
                return Ok(RecoveryAction::TerminateWorkflow {
                    error_message,
                });
            } else {
                // 非关键任务，尝试跳过
                return Ok(RecoveryAction::SkipTask {
                    task_id,
                    simulated_result: None,
                });
            }
        }
        
        // 计算退避时间
        let delay = Duration::from_millis((1000.0 * 1.5f64.powi(retry_count as i32)) as u64);
        
        // 重试任务
        Ok(RecoveryAction::RetryTask {
            task_id,
            delay: Some(delay),
            modified_params: None,
        })
    }
    
    fn get_type(&self) -> &'static str {
        "task_failure_handler"
    }
}

/// 工作流引擎的容错扩展接口
impl
```

工作流状态恢复与数据一致性保障
分布式工作流执行中，数据一致性和状态恢复是确保系统可靠性的核心要素，以下是相关组件的实现：

```rust
/// 工作流一致性检查器
pub struct WorkflowConsistencyChecker {
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 事件存储
    event_store: Arc<dyn EventStore>,
    
    /// 一致性校验配置
    config: ConsistencyCheckConfig,
}

/// 一致性检查配置
pub struct ConsistencyCheckConfig {
    /// 是否验证事件序列与状态一致性
    pub verify_event_consistency: bool,
    
    /// 是否验证任务依赖完整性
    pub verify_task_dependencies: bool,
    
    /// 是否验证资源分配一致性
    pub verify_resource_allocations: bool,
    
    /// 一致性验证超时
    pub verification_timeout: Duration,
}

impl WorkflowConsistencyChecker {
    /// 创建新的一致性检查器
    pub fn new(
        state_store: Arc<dyn StateStore>, 
        event_store: Arc<dyn EventStore>,
        config: ConsistencyCheckConfig,
    ) -> Self {
        Self {
            state_store,
            event_store,
            config,
        }
    }
    
    /// 验证恢复点状态的一致性
    pub async fn verify_recovery_point_consistency(
        &self,
        workflow_id: &str,
        recovery_point: &RecoveryPoint,
    ) -> Result<bool, ConsistencyError> {
        // 提取工作流状态
        let workflow_state = match &recovery_point.data {
            RecoveryPointData::FullState(state) => state.clone(),
            RecoveryPointData::IncrementalState { .. } => {
                // 增量恢复点需要先合并生成完整状态
                return Err(ConsistencyError::InvalidRecoveryPoint(
                    "仅支持完整状态恢复点验证".to_string()
                ));
            }
            RecoveryPointData::EventLog(_) => {
                return Err(ConsistencyError::InvalidRecoveryPoint(
                    "事件日志恢复点不支持直接验证".to_string()
                ));
            }
        };
        
        // 基本验证：工作流ID匹配
        if workflow_state.id != workflow_id {
            return Ok(false);
        }
        
        // 验证工作流状态内部一致性
        let is_internally_consistent = self.verify_internal_consistency(&workflow_state).await?;
        if !is_internally_consistent {
            return Ok(false);
        }
        
        // 如果配置了验证事件一致性，则进行事件验证
        if self.config.verify_event_consistency {
            let is_event_consistent = self.verify_event_consistency(workflow_id, &workflow_state).await?;
            if !is_event_consistent {
                return Ok(false);
            }
        }
        
        // 如果配置了验证任务依赖，则进行任务依赖验证
        if self.config.verify_task_dependencies {
            let is_dependencies_consistent = self.verify_task_dependencies(&workflow_state).await?;
            if !is_dependencies_consistent {
                return Ok(false);
            }
        }
        
        // 如果配置了验证资源分配，则进行资源分配验证
        if self.config.verify_resource_allocations {
            let is_resources_consistent = self.verify_resource_allocations(&workflow_state).await?;
            if !is_resources_consistent {
                return Ok(false);
            }
        }
        
        Ok(true)
    }
    
    /// 验证工作流状态内部一致性
    async fn verify_internal_consistency(&self, state: &WorkflowState) -> Result<bool, ConsistencyError> {
        // 检查关键字段是否有效
        if state.id.is_empty() || state.workflow_definition_id.is_empty() {
            return Ok(false);
        }
        
        // 检查状态类型是否合理
        match &state.status {
            WorkflowStatus::Created | WorkflowStatus::Running | WorkflowStatus::Paused |
            WorkflowStatus::Completed | WorkflowStatus::Failed | WorkflowStatus::Cancelled => {
                // 有效状态
            },
            _ => {
                return Ok(false);
            }
        }
        
        // 检查任务状态与工作流状态一致性
        for (task_id, task_state) in &state.task_states {
            if task_id.is_empty() {
                return Ok(false);
            }
            
            // 检查任务状态是否与工作流状态兼容
            match state.status {
                WorkflowStatus::Completed => {
                    // 工作流完成时，所有任务应该是完成状态
                    if task_state.status != TaskStatus::Completed && 
                       task_state.status != TaskStatus::Skipped {
                        return Ok(false);
                    }
                },
                WorkflowStatus::Failed => {
                    // 工作流失败时，至少有一个任务应该是失败状态
                    // 或者所有任务都完成但工作流逻辑判断失败
                },
                _ => {
                    // 其他工作流状态下，任务状态可以多样
                }
            }
        }
        
        // 验证时间顺序
        if let (Some(start_time), Some(end_time)) = (state.start_time, state.end_time) {
            if end_time < start_time {
                return Ok(false);
            }
        }
        
        Ok(true)
    }
    
    /// 验证事件序列与工作流状态一致性
    async fn verify_event_consistency(
        &self, 
        workflow_id: &str, 
        state: &WorkflowState
    ) -> Result<bool, ConsistencyError> {
        // 获取工作流事件
        let events = self.event_store.get_workflow_events(workflow_id).await
            .map_err(|e| ConsistencyError::EventRetrievalFailed(e.to_string()))?;
        
        if events.is_empty() {
            // 如果没有事件但有状态，这可能是有效的（初始状态）
            return Ok(true);
        }
        
        // 构建事件状态机来验证状态
        let mut event_states = HashMap::new();
        
        // 追踪最后已知的工作流状态
        let mut last_workflow_status = WorkflowStatus::Created;
        
        // 追踪任务状态转换
        let mut task_state_transitions = HashMap::<String, Vec<TaskStatus>>::new();
        
        // 检查事件时间顺序并构建状态转换图
        let mut last_event_time = events[0].timestamp;
        
        for event in &events {
            // 验证事件时间顺序
            if event.timestamp < last_event_time {
                return Ok(false);
            }
            last_event_time = event.timestamp;
            
            // 基于事件类型更新状态
            match event.event_type {
                EventType::WorkflowCreated => {
                    last_workflow_status = WorkflowStatus::Created;
                },
                EventType::WorkflowStarted => {
                    // 检查状态转换有效性
                    if last_workflow_status != WorkflowStatus::Created && 
                       last_workflow_status != WorkflowStatus::Paused {
                        return Ok(false);
                    }
                    last_workflow_status = WorkflowStatus::Running;
                },
                EventType::WorkflowCompleted => {
                    if last_workflow_status != WorkflowStatus::Running {
                        return Ok(false);
                    }
                    last_workflow_status = WorkflowStatus::Completed;
                },
                EventType::WorkflowFailed => {
                    if last_workflow_status != WorkflowStatus::Running {
                        return Ok(false);
                    }
                    last_workflow_status = WorkflowStatus::Failed;
                },
                EventType::WorkflowPaused => {
                    if last_workflow_status != WorkflowStatus::Running {
                        return Ok(false);
                    }
                    last_workflow_status = WorkflowStatus::Paused;
                },
                EventType::WorkflowResumed => {
                    if last_workflow_status != WorkflowStatus::Paused {
                        return Ok(false);
                    }
                    last_workflow_status = WorkflowStatus::Running;
                },
                EventType::WorkflowCancelled => {
                    last_workflow_status = WorkflowStatus::Cancelled;
                },
                EventType::TaskScheduled => {
                    // 从事件数据提取任务ID
                    if let Some(task_id) = extract_task_id_from_event(event) {
                        let transitions = task_state_transitions
                            .entry(task_id.clone())
                            .or_insert_with(Vec::new);
                        transitions.push(TaskStatus::Scheduled);
                    }
                },
                EventType::TaskStarted => {
                    if let Some(task_id) = extract_task_id_from_event(event) {
                        let transitions = task_state_transitions
                            .entry(task_id.clone())
                            .or_insert_with(Vec::new);
                        
                        // 检查任务状态转换有效性
                        if let Some(last_status) = transitions.last() {
                            if *last_status != TaskStatus::Scheduled && 
                               *last_status != TaskStatus::Pending {
                                return Ok(false);
                            }
                        }
                        
                        transitions.push(TaskStatus::Running);
                    }
                },
                EventType::TaskCompleted => {
                    if let Some(task_id) = extract_task_id_from_event(event) {
                        let transitions = task_state_transitions
                            .entry(task_id.clone())
                            .or_insert_with(Vec::new);
                        
                        // 检查任务状态转换有效性
                        if let Some(last_status) = transitions.last() {
                            if *last_status != TaskStatus::Running {
                                return Ok(false);
                            }
                        }
                        
                        transitions.push(TaskStatus::Completed);
                    }
                },
                EventType::TaskFailed => {
                    if let Some(task_id) = extract_task_id_from_event(event) {
                        let transitions = task_state_transitions
                            .entry(task_id.clone())
                            .or_insert_with(Vec::new);
                        
                        // 检查任务状态转换有效性
                        if let Some(last_status) = transitions.last() {
                            if *last_status != TaskStatus::Running {
                                return Ok(false);
                            }
                        }
                        
                        transitions.push(TaskStatus::Failed);
                    }
                },
                // 处理其他事件类型...
                _ => {}
            }
        }
        
        // 验证最终状态是否与事件构建的状态一致
        if state.status != last_workflow_status {
            return Ok(false);
        }
        
        // 验证任务状态是否与事件状态一致
        for (task_id, transitions) in task_state_transitions {
            if let Some(task_state) = state.task_states.get(&task_id) {
                if let Some(last_status) = transitions.last() {
                    if *last_status != task_state.status {
                        return Ok(false);
                    }
                }
            } else {
                // 事件中有任务但状态中没有
                return Ok(false);
            }
        }
        
        Ok(true)
    }
    
    /// 验证任务依赖关系一致性
    async fn verify_task_dependencies(&self, state: &WorkflowState) -> Result<bool, ConsistencyError> {
        // 获取工作流定义
        let workflow_def = self.state_store.get_workflow_definition(&state.workflow_definition_id).await
            .map_err(|e| ConsistencyError::DefinitionRetrievalFailed(e.to_string()))?;
        
        // 构建任务依赖图
        let mut dependencies = HashMap::new();
        
        // 从工作流定义提取任务依赖
        for (task_id, task_def) in &workflow_def.tasks {
            dependencies.insert(task_id.clone(), task_def.depends_on.clone());
        }
        
        // 检查已完成任务的依赖是否都已完成
        for (task_id, task_state) in &state.task_states {
            if task_state.status == TaskStatus::Completed || 
               task_state.status == TaskStatus::Running {
                
                // 获取此任务的依赖
                if let Some(deps) = dependencies.get(task_id) {
                    for dep_id in deps {
                        // 检查依赖任务是否存在
                        if let Some(dep_state) = state.task_states.get(dep_id) {
                            // 如果任务正在运行或已完成，其依赖必须是已完成状态
                            if dep_state.status != TaskStatus::Completed &&
                               dep_state.status != TaskStatus::Skipped {
                                return Ok(false);
                            }
                        } else {
                            // 依赖任务不存在
                            return Ok(false);
                        }
                    }
                }
            }
        }
        
        Ok(true)
    }
    
    /// 验证资源分配一致性
    async fn verify_resource_allocations(&self, state: &WorkflowState) -> Result<bool, ConsistencyError> {
        // 获取所有正在运行任务的资源分配
        let mut resource_allocations = HashMap::new();
        
        for (task_id, task_state) in &state.task_states {
            if task_state.status == TaskStatus::Running {
                if let Some(node_id) = &task_state.node_id {
                    // 检查节点是否已有资源分配记录
                    let node_allocations = resource_allocations
                        .entry(node_id.clone())
                        .or_insert_with(Vec::new);
                    
                    node_allocations.push(task_id.clone());
                }
            }
        }
        
        // 检查每个节点的资源分配是否过载
        for (node_id, task_ids) in resource_allocations {
            // 获取节点容量
            let node_info = self.state_store.get_node_info(&node_id).await
                .map_err(|e| ConsistencyError::NodeInfoRetrievalFailed(e.to_string()))?;
            
            // 计算已分配资源总和
            let mut total_cpu = 0.0;
            let mut total_memory = 0;
            
            for task_id in &task_ids {
                if let Some(task_state) = state.task_states.get(task_id) {
                    if let Some(resource_req) = &task_state.resource_requirements {
                        total_cpu += resource_req.cpu;
                        total_memory += resource_req.memory;
                    }
                }
            }
            
            // 检查是否超过节点容量
            if total_cpu > node_info.capacity.cpu || 
               total_memory > node_info.capacity.memory {
                return Ok(false);
            }
        }
        
        Ok(true)
    }
}

/// 从事件中提取任务ID的辅助函数
fn extract_task_id_from_event(event: &WorkflowEvent) -> Option<String> {
    if let Some(data) = event.data.as_object() {
        if let Some(task_id) = data.get("task_id") {
            if let Some(id_str) = task_id.as_str() {
                return Some(id_str.to_string());
            }
        }
    }
    None
}

/// 一致性检查错误
#[derive(Debug, thiserror::Error)]
pub enum ConsistencyError {
    #[error("无效的恢复点: {0}")]
    InvalidRecoveryPoint(String),
    
    #[error("获取事件失败: {0}")]
    EventRetrievalFailed(String),
    
    #[error("获取工作流定义失败: {0}")]
    DefinitionRetrievalFailed(String),
    
    #[error("获取节点信息失败: {0}")]
    NodeInfoRetrievalFailed(String),
    
    #[error("验证超时")]
    VerificationTimeout,
    
    #[error("其他错误: {0}")]
    Other(String),
}

/// 工作流快照管理器
pub struct SnapshotManager {
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 事件存储
    event_store: Arc<dyn EventStore>,
    
    /// 一致性检查器
    consistency_checker: WorkflowConsistencyChecker,
    
    /// 数据保护器（加密/解密）
    data_protector: Arc<dyn DataProtector>,
    
    /// 快照配置
    config: SnapshotConfig,
    
    /// 观测性管理器
    observability: Arc<WorkflowObservability>,
}

/// 快照配置
pub struct SnapshotConfig {
    /// 自动快照间隔（秒）
    pub auto_snapshot_interval_seconds: u64,
    
    /// 保留快照数量
    pub max_snapshots_to_keep: u32,
    
    /// 是否启用增量快照
    pub enable_incremental_snapshots: bool,
    
    /// 是否加密快照
    pub encrypt_snapshots: bool,
    
    /// 是否压缩快照
    pub compress_snapshots: bool,
}

/// 恢复点类型
pub enum RecoveryPointType {
    /// 自动创建的快照
    AutoSnapshot,
    
    /// 手动创建的快照
    ManualSnapshot,
    
    /// 恢复前备份
    RecoveryBackup,
    
    /// 检查点（步骤间）
    Checkpoint,
}

/// 恢复点数据
pub enum RecoveryPointData {
    /// 完整工作流状态
    FullState(WorkflowState),
    
    /// 增量状态（基于基础快照ID）
    IncrementalState {
        base_snapshot_id: String,
        changes: serde_json::Value,
    },
    
    /// 事件日志
    EventLog(Vec<WorkflowEvent>),
}

/// 恢复点
pub struct RecoveryPoint {
    /// 唯一ID
    pub id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 恢复点类型
    pub point_type: RecoveryPointType,
    
    /// 创建时间
    pub created_at: DateTime<Utc>,
    
    /// 恢复点数据
    pub data: RecoveryPointData,
    
    /// 元数据
    pub metadata: HashMap<String, String>,
    
    /// 校验和
    pub checksum: String,
}

impl SnapshotManager {
    /// 创建新的快照管理器
    pub fn new(
        state_store: Arc<dyn StateStore>,
        event_store: Arc<dyn EventStore>,
        data_protector: Arc<dyn DataProtector>,
        config: SnapshotConfig,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        let consistency_checker = WorkflowConsistencyChecker::new(
            state_store.clone(),
            event_store.clone(),
            ConsistencyCheckConfig {
                verify_event_consistency: true,
                verify_task_dependencies: true,
                verify_resource_allocations: true,
                verification_timeout: Duration::from_secs(30),
            },
        );
        
        Self {
            state_store,
            event_store,
            consistency_checker,
            data_protector,
            config,
            observability,
        }
    }
    
    /// 创建工作流快照
    pub async fn create_snapshot(
        &self,
        workflow_id: &str,
        point_type: RecoveryPointType,
        metadata: Option<HashMap<String, String>>,
    ) -> Result<String, SnapshotError> {
        // 创建追踪上下文
        let trace_ctx = self.observability.create_snapshot_operation_span(
            workflow_id,
            "create_snapshot",
        );
        let _guard = trace_ctx.enter();
        
        // 获取当前工作流状态
        let workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| SnapshotError::StateRetrievalFailed(e.to_string()))?;
        
        // 序列化状态
        let state_json = serde_json::to_vec(&workflow_state)
            .map_err(|e| SnapshotError::SerializationFailed(e.to_string()))?;
        
        // 计算校验和
        let checksum = compute_checksum(&state_json);
        
        // 可选：压缩数据
        let processed_data = if self.config.compress_snapshots {
            compress_data(&state_json)
                .map_err(|e| SnapshotError::CompressionFailed(e.to_string()))?
        } else {
            state_json
        };
        
        // 可选：加密数据
        let protected_data = if self.config.encrypt_snapshots {
            self.data_protector.encrypt_data(&processed_data, "workflow-snapshot-key").await
                .map_err(|e| SnapshotError::EncryptionFailed(e.to_string()))?
        } else {
            processed_data
        };
        
        // 准备元数据
        let mut snapshot_metadata = metadata.unwrap_or_default();
        snapshot_metadata.insert("workflow_definition_id".to_string(), workflow_state.workflow_definition_id.clone());
        snapshot_metadata.insert("workflow_status".to_string(), format!("{:?}", workflow_state.status));
        snapshot_metadata.insert("compressed".to_string(), self.config.compress_snapshots.to_string());
        snapshot_metadata.insert("encrypted".to_string(), self.config.encrypt_snapshots.to_string());
        snapshot_metadata.insert("created_at".to_string(), Utc::now().to_rfc3339());
        
        // 生成快照ID
        let snapshot_id = generate_snapshot_id(workflow_id);
        
        // 创建恢复点
        let recovery_point = RecoveryPoint {
            id: snapshot_id.clone(),
            workflow_id: workflow_id.to_string(),
            point_type,
            created_at: Utc::now(),
            data: RecoveryPointData::FullState(workflow_state),
            metadata: snapshot_metadata,
            checksum,
        };
        
        // 保存恢复点
        self.state_store.save_recovery_point(&recovery_point).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
        
        // 清理旧快照
        if let Err(e) = self.cleanup_old_snapshots(workflow_id).await {
            // 仅记录错误，不终止操作
            self.observability.record_warning(
                workflow_id,
                "snapshot_cleanup_failed",
                &format!("清理旧快照失败: {}", e),
            );
        }
        
        // 记录快照创建事件
        self.observability.record_snapshot_created(
            workflow_id,
            &snapshot_id,
            format!("{:?}", point_type).as_str(),
        );
        
        Ok(snapshot_id)
    }
    
    /// 恢复工作流到指定快照
    pub async fn restore_snapshot(
        &self,
        workflow_id: &str,
        snapshot_id: &str,
    ) -> Result<(), SnapshotError> {
        // 创建追踪上下文
        let trace_ctx = self.observability.create_snapshot_operation_span(
            workflow_id,
            "restore_snapshot",
        );
        let _guard = trace_ctx.enter();
        
        // 获取恢复点
        let recovery_point = self.state_store.get_recovery_point(workflow_id, snapshot_id).await
            .map_err(|e| SnapshotError::SnapshotNotFound(format!("快照不存在: {}", e)))?;
        
        // 在恢复前创建当前状态的备份
        if let Err(e) = self.create_backup_before_restore(workflow_id).await {
            // 记录错误但继续
            self.observability.record_warning(
                workflow_id,
                "backup_before_restore_failed",
                &format!("恢复前创建备份失败: {}", e),
            );
        }
        
        // 验证快照一致性
        let is_consistent = self.consistency_checker
            .verify_recovery_point_consistency(workflow_id, &recovery_point).await
            .map_err(|e| SnapshotError::ConsistencyCheckFailed(e.to_string()))?;
        
        if !is_consistent {
            return Err(SnapshotError::InconsistentSnapshot(
                "快照一致性验证失败".to_string()
            ));
        }
        
        // 获取工作流状态
        let workflow_state = match &recovery_point.data {
            RecoveryPointData::FullState(state) => state.clone(),
            RecoveryPointData::IncrementalState { .. } => {
                // 增量恢复需要先应用基础状态，然后应用变更
                return Err(SnapshotError::UnsupportedRecoveryPoint(
                    "暂不支持从增量快照恢复".to_string()
                ));
            }
            RecoveryPointData::EventLog(_) => {
                return Err(SnapshotError::UnsupportedRecoveryPoint(
                    "暂不支持从事件日志恢复".to_string()
                ));
            }
        };
        
        // 更新工作流状态
        match self.state_store.restore_workflow_state(workflow_id, &workflow_state).await {
            Ok(_) => {
                // 记录恢复成功事件
                self.observability.record_snapshot_restored(
                    workflow_id,
                    snapshot_id,
                    &format!("{:?}", workflow_state.status),
                );
                
                Ok(())
            },
            Err(e) => {
                // 记录恢复失败
                self.observability.record_error(
                    workflow_id,
                    "snapshot_restore_failed",
                    &format!("恢复快照失败: {}", e),
                );
                
                Err(SnapshotError::RestoreFailed(e.to_string()))
            }
        }
    }
    
    /// 在恢复前创建备份
    async fn create_backup_before_restore(&self, workflow_id: &str) -> Result<String, SnapshotError> {
        let metadata = {
            let mut map = HashMap::new();
            map.insert("purpose".to_string(), "pre_restore_backup".to_string());
            map.insert("auto_generated".to_string(), "true".to_string());
            Some(map)
        };
        
        self.create_snapshot(workflow_id, RecoveryPointType::RecoveryBackup, metadata).await
    }
    
    /// 清理旧快照
    async fn cleanup_old_snapshots(&self, workflow_id: &str) -> Result<(), SnapshotError> {
        if self.config.max_snapshots_to_keep == 0 {
            // 不限制快照数量
            return Ok(());
        }
        
        // 获取所有快照，按创建时间排序
        let mut snapshots = self.state_store.list_recovery_points(workflow_id).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
        
        // 按创建时间排序
        snapshots.sort_by(|a, b| a.created_at.cmp(&b.created_at));
        
        // 保留最新的N个快照
        if snapshots.len() > self.config.max_snapshots_to_keep as usize {
            let to_delete = snapshots.len() - self.config.max_snapshots_to_keep as usize;
            
            for snapshot in snapshots.iter().take(to_delete) {
                // 不删除手动创建的快照
                if let RecoveryPointType::ManualSnapshot = snapshot.point_type {
                    continue;
                }
                
                if let Err(e) = self.state_store.delete_recovery_point(workflow_id, &snapshot.id).await {
                    // 记录错误但继续
                    self.observability.record_warning(
                        workflow_id,
                        "snapshot_delete_failed",
                        &format!("删除快照失败: {}", e),
```

工作流状态存储与事件溯源设计
工作流引擎的可靠性核心在于状态存储的设计。以下是工作流状态存储及事件溯源的关键组件实现：

```rust
/// 工作流状态存储抽象
pub trait StateStore: Send + Sync + 'static {
    /// 保存工作流状态
    async fn save_workflow_state(&self, state: &WorkflowState) -> Result<(), StorageError>;
    
    /// 获取工作流状态
    async fn get_workflow_state(&self, workflow_id: &str) -> Result<WorkflowState, StorageError>;
    
    /// 更新工作流状态
    async fn update_workflow_state(&self, workflow_id: &str, state: &WorkflowState) -> Result<(), StorageError>;
    
    /// 删除工作流状态
    async fn delete_workflow_state(&self, workflow_id: &str) -> Result<(), StorageError>;
    
    /// 保存恢复点
    async fn save_recovery_point(&self, recovery_point: &RecoveryPoint) -> Result<(), StorageError>;
    
    /// 获取恢复点
    async fn get_recovery_point(&self, workflow_id: &str, recovery_point_id: &str) -> Result<RecoveryPoint, StorageError>;
    
    /// 列出工作流的所有恢复点
    async fn list_recovery_points(&self, workflow_id: &str) -> Result<Vec<RecoveryPoint>, StorageError>;
    
    /// 删除恢复点
    async fn delete_recovery_point(&self, workflow_id: &str, recovery_point_id: &str) -> Result<(), StorageError>;
    
    /// 获取节点信息
    async fn get_node_info(&self, node_id: &str) -> Result<NodeInfo, StorageError>;
    
    /// 获取工作流定义
    async fn get_workflow_definition(&self, definition_id: &str) -> Result<WorkflowDefinition, StorageError>;
    
    /// 更新任务状态
    async fn update_task_state(&self, update: &TaskStateUpdate) -> Result<(), StorageError>;
}

/// 事件存储抽象
pub trait EventStore: Send + Sync + 'static {
    /// 记录工作流事件
    async fn record_event(&self, event: &WorkflowEvent) -> Result<(), StorageError>;
    
    /// 获取工作流事件
    async fn get_workflow_events(&self, workflow_id: &str) -> Result<Vec<WorkflowEvent>, StorageError>;
    
    /// 按事件类型获取工作流事件
    async fn get_workflow_events_by_type(&self, workflow_id: &str, event_type: &EventType) -> Result<Vec<WorkflowEvent>, StorageError>;
    
    /// 获取指定时间范围内的事件
    async fn get_workflow_events_in_timerange(
        &self, 
        workflow_id: &str, 
        start_time: &DateTime<Utc>, 
        end_time: &DateTime<Utc>
    ) -> Result<Vec<WorkflowEvent>, StorageError>;
    
    /// 按批次获取事件
    async fn get_events_batch(&self, batch_size: usize, cursor: Option<&str>) -> Result<(Vec<WorkflowEvent>, Option<String>), StorageError>;
}

/// 内存状态存储实现
pub struct InMemoryStateStore {
    /// 工作流状态
    workflow_states: Arc<RwLock<HashMap<String, WorkflowState>>>,
    
    /// 恢复点
    recovery_points: Arc<RwLock<HashMap<String, HashMap<String, RecoveryPoint>>>>,
    
    /// 节点信息
    node_infos: Arc<RwLock<HashMap<String, NodeInfo>>>,
    
    /// 工作流定义
    workflow_definitions: Arc<RwLock<HashMap<String, WorkflowDefinition>>>,
}

impl InMemoryStateStore {
    /// 创建新的内存状态存储
    pub fn new() -> Self {
        Self {
            workflow_states: Arc::new(RwLock::new(HashMap::new())),
            recovery_points: Arc::new(RwLock::new(HashMap::new())),
            node_infos: Arc::new(RwLock::new(HashMap::new())),
            workflow_definitions: Arc::new(RwLock::new(HashMap::new())),
        }
    }
}

#[async_trait]
impl StateStore for InMemoryStateStore {
    async fn save_workflow_state(&self, state: &WorkflowState) -> Result<(), StorageError> {
        let mut states = self.workflow_states.write().await;
        states.insert(state.id.clone(), state.clone());
        Ok(())
    }
    
    async fn get_workflow_state(&self, workflow_id: &str) -> Result<WorkflowState, StorageError> {
        let states = self.workflow_states.read().await;
        states.get(workflow_id)
            .cloned()
            .ok_or_else(|| StorageError::NotFound(format!("工作流状态不存在: {}", workflow_id)))
    }
    
    async fn update_workflow_state(&self, workflow_id: &str, state: &WorkflowState) -> Result<(), StorageError> {
        let mut states = self.workflow_states.write().await;
        if !states.contains_key(workflow_id) {
            return Err(StorageError::NotFound(format!("工作流状态不存在: {}", workflow_id)));
        }
        states.insert(workflow_id.to_string(), state.clone());
        Ok(())
    }
    
    async fn delete_workflow_state(&self, workflow_id: &str) -> Result<(), StorageError> {
        let mut states = self.workflow_states.write().await;
        if states.remove(workflow_id).is_none() {
            return Err(StorageError::NotFound(format!("工作流状态不存在: {}", workflow_id)));
        }
        Ok(())
    }
    
    async fn save_recovery_point(&self, recovery_point: &RecoveryPoint) -> Result<(), StorageError> {
        let mut points = self.recovery_points.write().await;
        let workflow_points = points
            .entry(recovery_point.workflow_id.clone())
            .or_insert_with(HashMap::new);
            
        workflow_points.insert(recovery_point.id.clone(), recovery_point.clone());
        Ok(())
    }
    
    async fn get_recovery_point(&self, workflow_id: &str, recovery_point_id: &str) -> Result<RecoveryPoint, StorageError> {
        let points = self.recovery_points.read().await;
        let workflow_points = points.get(workflow_id)
            .ok_or_else(|| StorageError::NotFound(format!("工作流恢复点不存在: {}", workflow_id)))?;
            
        workflow_points.get(recovery_point_id)
            .cloned()
            .ok_or_else(|| StorageError::NotFound(format!("恢复点不存在: {}", recovery_point_id)))
    }
    
    async fn list_recovery_points(&self, workflow_id: &str) -> Result<Vec<RecoveryPoint>, StorageError> {
        let points = self.recovery_points.read().await;
        let workflow_points = points.get(workflow_id)
            .map(|points| points.values().cloned().collect())
            .unwrap_or_else(Vec::new);
            
        Ok(workflow_points)
    }
    
    async fn delete_recovery_point(&self, workflow_id: &str, recovery_point_id: &str) -> Result<(), StorageError> {
        let mut points = self.recovery_points.write().await;
        
        if let Some(workflow_points) = points.get_mut(workflow_id) {
            if workflow_points.remove(recovery_point_id).is_none() {
                return Err(StorageError::NotFound(format!("恢复点不存在: {}", recovery_point_id)));
            }
        } else {
            return Err(StorageError::NotFound(format!("工作流恢复点不存在: {}", workflow_id)));
        }
        
        Ok(())
    }
    
    async fn get_node_info(&self, node_id: &str) -> Result<NodeInfo, StorageError> {
        let infos = self.node_infos.read().await;
        infos.get(node_id)
            .cloned()
            .ok_or_else(|| StorageError::NotFound(format!("节点信息不存在: {}", node_id)))
    }
    
    async fn get_workflow_definition(&self, definition_id: &str) -> Result<WorkflowDefinition, StorageError> {
        let definitions = self.workflow_definitions.read().await;
        definitions.get(definition_id)
            .cloned()
            .ok_or_else(|| StorageError::NotFound(format!("工作流定义不存在: {}", definition_id)))
    }
    
    async fn update_task_state(&self, update: &TaskStateUpdate) -> Result<(), StorageError> {
        let mut states = self.workflow_states.write().await;
        let state = states.get_mut(&update.workflow_id)
            .ok_or_else(|| StorageError::NotFound(format!("工作流状态不存在: {}", update.workflow_id)))?;
            
        let task_state = state.task_states.get_mut(&update.task_id)
            .ok_or_else(|| StorageError::NotFound(format!("任务状态不存在: {}", update.task_id)))?;
            
        task_state.status = update.status.clone();
        
        if let Some(node_id) = &update.node_id {
            task_state.node_id = Some(node_id.clone());
        } else {
            task_state.node_id = None;
        }
        
        if let Some(error) = &update.error {
            task_state.error = Some(error.clone());
        }
        
        if let Some(result) = &update.result {
            task_state.result = Some(result.clone());
        }
        
        if let Some(metadata) = &update.metadata {
            for (key, value) in metadata.as_object().unwrap() {
                task_state.metadata.insert(key.clone(), value.clone());
            }
        }
        
        task_state.last_updated = Utc::now();
        
        Ok(())
    }
}

/// 持久化状态存储实现
pub struct PersistentStateStore {
    /// 存储引擎
    storage_engine: Arc<dyn StorageEngine>,
    
    /// 缓存
    cache: Option<Arc<WorkflowStateCache>>,
    
    /// 观测性管理器
    observability: Arc<WorkflowObservability>,
}

/// 存储引擎抽象
pub trait StorageEngine: Send + Sync + 'static {
    /// 存储数据
    async fn put(&self, key: &str, value: &[u8]) -> Result<(), StorageError>;
    
    /// 获取数据
    async fn get(&self, key: &str) -> Result<Vec<u8>, StorageError>;
    
    /// 删除数据
    async fn delete(&self, key: &str) -> Result<(), StorageError>;
    
    /// 列出键前缀
    async fn list_prefix(&self, prefix: &str) -> Result<Vec<String>, StorageError>;
    
    /// 测试键是否存在
    async fn exists(&self, key: &str) -> Result<bool, StorageError>;
    
    /// 批量获取
    async fn batch_get(&self, keys: &[String]) -> Result<HashMap<String, Vec<u8>>, StorageError>;
    
    /// 批量存储
    async fn batch_put(&self, kvs: &HashMap<String, Vec<u8>>) -> Result<(), StorageError>;
}

impl PersistentStateStore {
    /// 创建新的持久化状态存储
    pub fn new(
        storage_engine: Arc<dyn StorageEngine>,
        cache: Option<Arc<WorkflowStateCache>>,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        Self {
            storage_engine,
            cache,
            observability,
        }
    }
    
    /// 生成工作流状态键
    fn workflow_state_key(workflow_id: &str) -> String {
        format!("workflow:state:{}", workflow_id)
    }
    
    /// 生成恢复点键
    fn recovery_point_key(workflow_id: &str, recovery_point_id: &str) -> String {
        format!("workflow:recovery:{}:{}", workflow_id, recovery_point_id)
    }
    
    /// 生成恢复点列表键前缀
    fn recovery_points_prefix(workflow_id: &str) -> String {
        format!("workflow:recovery:{}:", workflow_id)
    }
    
    /// 生成节点信息键
    fn node_info_key(node_id: &str) -> String {
        format!("node:info:{}", node_id)
    }
    
    /// 生成工作流定义键
    fn workflow_definition_key(definition_id: &str) -> String {
        format!("workflow:definition:{}", definition_id)
    }
}

#[async_trait]
impl StateStore for PersistentStateStore {
    async fn save_workflow_state(&self, state: &WorkflowState) -> Result<(), StorageError> {
        let state_bytes = serde_json::to_vec(state)
            .map_err(|e| StorageError::SerializationError(e.to_string()))?;
            
        // 保存到存储引擎
        let key = Self::workflow_state_key(&state.id);
        self.storage_engine.put(&key, &state_bytes).await?;
        
        // 更新缓存
        if let Some(cache) = &self.cache {
            cache.put_workflow_state(&state.id, state.clone()).await;
        }
        
        // 记录指标
        self.observability.record_metric(
            "workflow_state_save",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), state.id.clone()),
                ("status".to_string(), format!("{:?}", state.status)),
            ])),
        );
        
        Ok(())
    }
    
    async fn get_workflow_state(&self, workflow_id: &str) -> Result<WorkflowState, StorageError> {
        // 尝试从缓存获取
        if let Some(cache) = &self.cache {
            if let Some(state) = cache.get_workflow_state(workflow_id).await {
                // 记录缓存命中指标
                self.observability.record_metric(
                    "workflow_state_cache_hit",
                    MetricValue::Counter(1),
                    Some(HashMap::from([
                        ("workflow_id".to_string(), workflow_id.to_string()),
                    ])),
                );
                
                return Ok(state);
            }
        }
        
        // 从存储引擎获取
        let key = Self::workflow_state_key(workflow_id);
        let state_bytes = self.storage_engine.get(&key).await?;
        
        // 反序列化
        let state: WorkflowState = serde_json::from_slice(&state_bytes)
            .map_err(|e| StorageError::DeserializationError(e.to_string()))?;
            
        // 更新缓存
        if let Some(cache) = &self.cache {
            cache.put_workflow_state(workflow_id, state.clone()).await;
        }
        
        // 记录指标
        self.observability.record_metric(
            "workflow_state_get",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
            ])),
        );
        
        Ok(state)
    }
    
    async fn update_workflow_state(&self, workflow_id: &str, state: &WorkflowState) -> Result<(), StorageError> {
        // 检查状态是否存在
        let key = Self::workflow_state_key(workflow_id);
        let exists = self.storage_engine.exists(&key).await?;
        
        if !exists {
            return Err(StorageError::NotFound(format!("工作流状态不存在: {}", workflow_id)));
        }
        
        // 序列化并保存
        let state_bytes = serde_json::to_vec(state)
            .map_err(|e| StorageError::SerializationError(e.to_string()))?;
            
        self.storage_engine.put(&key, &state_bytes).await?;
        
        // 更新缓存
        if let Some(cache) = &self.cache {
            cache.put_workflow_state(workflow_id, state.clone()).await;
        }
        
        // 记录指标
        self.observability.record_metric(
            "workflow_state_update",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("status".to_string(), format!("{:?}", state.status)),
            ])),
        );
        
        Ok(())
    }
    
    async fn delete_workflow_state(&self, workflow_id: &str) -> Result<(), StorageError> {
        let key = Self::workflow_state_key(workflow_id);
        
        // 检查状态是否存在
        let exists = self.storage_engine.exists(&key).await?;
        
        if !exists {
            return Err(StorageError::NotFound(format!("工作流状态不存在: {}", workflow_id)));
        }
        
        // 从存储引擎删除
        self.storage_engine.delete(&key).await?;
        
        // 从缓存删除
        if let Some(cache) = &self.cache {
            cache.remove_workflow_state(workflow_id).await;
        }
        
        // 记录指标
        self.observability.record_metric(
            "workflow_state_delete",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
            ])),
        );
        
        Ok(())
    }
    
    async fn save_recovery_point(&self, recovery_point: &RecoveryPoint) -> Result<(), StorageError> {
        // 序列化恢复点
        let point_bytes = serde_json::to_vec(recovery_point)
            .map_err(|e| StorageError::SerializationError(e.to_string()))?;
            
        // 保存到存储引擎
        let key = Self::recovery_point_key(&recovery_point.workflow_id, &recovery_point.id);
        self.storage_engine.put(&key, &point_bytes).await?;
        
        // 记录指标
        self.observability.record_metric(
            "recovery_point_save",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), recovery_point.workflow_id.clone()),
                ("recovery_point_id".to_string(), recovery_point.id.clone()),
                ("recovery_point_type".to_string(), format!("{:?}", recovery_point.point_type)),
            ])),
        );
        
        Ok(())
    }
    
    async fn get_recovery_point(&self, workflow_id: &str, recovery_point_id: &str) -> Result<RecoveryPoint, StorageError> {
        // 从存储引擎获取
        let key = Self::recovery_point_key(workflow_id, recovery_point_id);
        let point_bytes = self.storage_engine.get(&key).await?;
        
        // 反序列化
        let recovery_point: RecoveryPoint = serde_json::from_slice(&point_bytes)
            .map_err(|e| StorageError::DeserializationError(e.to_string()))?;
            
        // 记录指标
        self.observability.record_metric(
            "recovery_point_get",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("recovery_point_id".to_string(), recovery_point_id.to_string()),
            ])),
        );
        
        Ok(recovery_point)
    }
    
    async fn list_recovery_points(&self, workflow_id: &str) -> Result<Vec<RecoveryPoint>, StorageError> {
        // 获取前缀键列表
        let prefix = Self::recovery_points_prefix(workflow_id);
        let keys = self.storage_engine.list_prefix(&prefix).await?;
        
        if keys.is_empty() {
            return Ok(Vec::new());
        }
        
        // 批量获取所有恢复点
        let values = self.storage_engine.batch_get(&keys).await?;
        
        // 反序列化
        let mut recovery_points = Vec::with_capacity(values.len());
        
        for value in values.values() {
            let recovery_point: RecoveryPoint = serde_json::from_slice(value)
                .map_err(|e| StorageError::DeserializationError(e.to_string()))?;
                
            recovery_points.push(recovery_point);
        }
        
        // 记录指标
        self.observability.record_metric(
            "recovery_points_list",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("count".to_string(), recovery_points.len().to_string()),
            ])),
        );
        
        Ok(recovery_points)
    }
    
    async fn delete_recovery_point(&self, workflow_id: &str, recovery_point_id: &str) -> Result<(), StorageError> {
        let key = Self::recovery_point_key(workflow_id, recovery_point_id);
        
        // 检查恢复点是否存在
        let exists = self.storage_engine.exists(&key).await?;
        
        if !exists {
            return Err(StorageError::NotFound(format!("恢复点不存在: {}", recovery_point_id)));
        }
        
        // 从存储引擎删除
        self.storage_engine.delete(&key).await?;
        
        // 记录指标
        self.observability.record_metric(
            "recovery_point_delete",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("recovery_point_id".to_string(), recovery_point_id.to_string()),
            ])),
        );
        
        Ok(())
    }
    
    async fn get_node_info(&self, node_id: &str) -> Result<NodeInfo, StorageError> {
        // 从存储引擎获取
        let key = Self::node_info_key(node_id);
        let info_bytes = self.storage_engine.get(&key).await?;
        
        // 反序列化
        let node_info: NodeInfo = serde_json::from_slice(&info_bytes)
            .map_err(|e| StorageError::DeserializationError(e.to_string()))?;
            
        Ok(node_info)
    }
    
    async fn get_workflow_definition(&self, definition_id: &str) -> Result<WorkflowDefinition, StorageError> {
        // 从存储引擎获取
        let key = Self::workflow_definition_key(definition_id);
        let def_bytes = self.storage_engine.get(&key).await?;
        
        // 反序列化
        let definition: WorkflowDefinition = serde_json::from_slice(&def_bytes)
            .map_err(|e| StorageError::DeserializationError(e.to_string()))?;
            
        Ok(definition)
    }
    
    async fn update_task_state(&self, update: &TaskStateUpdate) -> Result<(), StorageError> {
        // 获取当前工作流状态
        let mut state = self.get_workflow_state(&update.workflow_id).await?;
        
        // 更新任务状态
        let task_state = state.task_states.get_mut(&update.task_id)
            .ok_or_else(|| StorageError::NotFound(format!("任务状态不存在: {}", update.task_id)))?;
            
        task_state.status = update.status.clone();
        
        if let Some(node_id) = &update.node_id {
            task_state.node_id = Some(node_id.clone());
        } else {
            task_state.node_id = None;
        }
        
        if let Some(error) = &update.error {
            task_state.error = Some(error.clone());
        }
        
        if let Some(result) = &update.result {
            task_state.result = Some(result.clone());
        }
        
        if let Some(metadata) = &update.metadata {
            for (key, value) in metadata.as_object().unwrap() {
                task_state.metadata.insert(key.clone(), value.clone());
            }
        }
        
        task_state.last_updated = Utc::now();
        
        // 保存更新后的工作流状态
        self.update_workflow_state(&update.workflow_id, &state).await?;
        
        // 记录指标
        self.observability.record_metric(
            "task_state_update",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), update.workflow_id.clone()),
                ("task_id".to_string(), update.task_id.clone()),
                ("status".to_string(), format!("{:?}", update.status)),
            ])),
        );
        
        Ok(())
    }
}

/// 事件溯源存储实现
pub struct EventSourcedStateStore {
    /// 事件存储
    event_store: Arc<dyn EventStore>,
    
    /// 状态缓存
    state_cache: Arc<WorkflowStateCache>,
    
    /// 观测性管理器
    observability: Arc<WorkflowObservability>,
}

impl EventSourcedStateStore {
    /// 创建新的事件溯源状态存储
    pub fn new(
        event_store: Arc<dyn EventStore>,
        state_cache: Arc<WorkflowStateCache>,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        Self {
            event_store,
            state_cache,
            observability,
        }
    }
    
    /// 从事件重建工作流状态
    async fn rebuild_state_from_events(&self, workflow_id: &str) -> Result<WorkflowState, StorageError> {
        // 获取所有工作流事件
        let events = self.event_store.get_workflow_events(workflow_id).await?;
        
        if events.is_empty() {
            return Err(StorageError::NotFound(format!("工作流没有事件: {}", workflow_id)));
        }
        
        // 提取工作流定义ID
        let definition_id = extract_definition_id_from_events(&events)
            .ok_or_else(|| StorageError::CorruptedState("无法从事件中提取工作流定义ID".to_string()))?;
        
        // 初始化空状态
        let mut state = WorkflowState {
            id: workflow_id.to_string(),
            workflow_definition_id: definition_id,
            status: WorkflowStatus::Created,
            task_states: HashMap::new(),
            variables: HashMap::new(),
            created_at: events[0].timestamp,
            start_time: None,
            end_time: None,
            last_updated_at: Some(events.last().unwrap().timestamp),
            metadata: HashMap::new(),
        };
        
        // 应用所有事件到状态
        for event in &events {
            apply_event_to_state(&mut state, event)?;
        }
        
        // 缓存重建的状态
        self.state_cache.put_workflow_state(workflow_id, state.clone()).await;
        
        // 记录指标
        self.observability.record_metric(
            "workflow_state_rebuilt",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("event_count".to_string(), events.len().to_string()),
            ])),
        );
        
        Ok(state)
    }
}

#[async_trait]
impl StateStore for EventSourcedStateStore {
    async fn save_workflow_state(&self, state: &WorkflowState) -> Result<(), StorageError> {
        // 事件溯源方式不直接保存状态，而是记录状态变更事件
        let event = create_state_snapshot_event(state)?;
        
        // 记录事件
        self.event_store.record_event(&event).await?;
        
        // 更新缓存
        self.state_cache.put_workflow_state(&state.id, state.clone()).await;
        
        Ok(())
    }
    
    async fn get_workflow_state(&self, workflow_id: &str) -> Result<WorkflowState, StorageError> {
        // 尝试从缓存获取
        if let Some(state) = self.state_cache.get_workflow_state(workflow_id).await {
            return Ok(state);
        }
        
        // 从事件重建状态
        self.rebuild_state_from_events(workflow_id).await
    }
    
    async fn update_workflow_state(&self,

/// 继续实现 EventSourcedStateStore
#[async_trait]
impl StateStore for EventSourcedStateStore {
    // ... [上一部分代码接续]
    
    async fn update_workflow_state(&self, workflow_id: &str, state: &WorkflowState) -> Result<(), StorageError> {
        // 生成状态变更事件
        let event = create_state_change_event(workflow_id, state)?;
        
        // 记录事件
        self.event_store.record_event(&event).await?;
        
        // 更新缓存
        self.state_cache.put_workflow_state(workflow_id, state.clone()).await;
        
        Ok(())
    }
    
    async fn delete_workflow_state(&self, workflow_id: &str) -> Result<(), StorageError> {
        // 创建状态删除事件
        let event = WorkflowEvent {
            id: Uuid::new_v4().to_string(),
            workflow_id: workflow_id.to_string(),
            event_type: EventType::WorkflowDeleted,
            timestamp: Utc::now(),
            data: json!({}),
        };
        
        // 记录事件
        self.event_store.record_event(&event).await?;
        
        // 从缓存中移除
        self.state_cache.remove_workflow_state(workflow_id).await;
        
        Ok(())
    }
    
    // 其他方法的实现...
}

/// 工作流恢复管理器
pub struct WorkflowRecoveryManager {
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 工作流引擎
    workflow_engine: Arc<WorkflowEngine>,
    
    /// 恢复策略提供者
    recovery_strategy: Arc<dyn RecoveryStrategy>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
}

impl WorkflowRecoveryManager {
    /// 创建新的工作流恢复管理器
    pub fn new(
        state_store: Arc<dyn StateStore>,
        workflow_engine: Arc<WorkflowEngine>,
        recovery_strategy: Arc<dyn RecoveryStrategy>,
        observability: Arc<WorkflowObservability>,
        lock_service: Arc<dyn LockService>,
    ) -> Self {
        Self {
            state_store,
            workflow_engine,
            recovery_strategy,
            observability,
            lock_service,
        }
    }
    
    /// 自动恢复中断的工作流
    pub async fn recover_interrupted_workflows(&self) -> Result<Vec<String>, RecoveryError> {
        // 获取需要恢复的工作流ID列表
        let workflows_to_recover = self.recovery_strategy.identify_workflows_to_recover().await
            .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            
        if workflows_to_recover.is_empty() {
            return Ok(Vec::new());
        }
        
        let mut recovered = Vec::new();
        
        for workflow_id in workflows_to_recover {
            // 为每个工作流恢复获取锁，避免并发恢复
            let lock_key = format!("workflow:recovery:{}", workflow_id);
            let lock_acquired = self.lock_service.acquire_lock(&lock_key, Duration::from_secs(60)).await
                .map_err(|e| RecoveryError::LockAcquisition(e.to_string()))?;
                
            if !lock_acquired {
                // 未获取到锁，跳过该工作流
                continue;
            }
            
            // 检查是否需要恢复
            let needs_recovery = self.recovery_strategy.should_recover_workflow(&workflow_id).await
                .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
                
            if needs_recovery {
                // 恢复工作流
                match self.recover_workflow(&workflow_id).await {
                    Ok(_) => {
                        recovered.push(workflow_id.clone());
                    },
                    Err(e) => {
                        // 记录恢复失败
                        self.observability.record_recovery_failure(&workflow_id, &e);
                    }
                }
            }
            
            // 释放锁
            let _ = self.lock_service.release_lock(&lock_key).await;
        }
        
        Ok(recovered)
    }
    
    /// 恢复单个工作流
    async fn recover_workflow(&self, workflow_id: &str) -> Result<(), RecoveryError> {
        // 创建恢复追踪上下文
        let trace_ctx = self.observability.create_workflow_recovery_span(workflow_id);
        let _trace_guard = trace_ctx.enter();
        
        // 获取工作流状态
        let mut workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        // 获取工作流定义
        let workflow_def = self.state_store.get_workflow_definition(&workflow_state.workflow_definition_id).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        // 重置所有运行中和已调度的任务
        for (task_id, task_state) in workflow_state.task_states.iter_mut() {
            if task_state.status == TaskStatus::Running || task_state.status == TaskStatus::Scheduled {
                task_state.status = TaskStatus::Pending;
                task_state.node_id = None;
                task_state.start_time = None;
                
                // 创建任务状态更新
                let task_update = TaskStateUpdate {
                    workflow_id: workflow_id.to_string(),
                    task_id: task_id.clone(),
                    status: TaskStatus::Pending,
                    node_id: None,
                    error: None,
                    result: None,
                    metadata: Some(serde_json::json!({
                        "recovered": true,
                        "recovered_at": Utc::now().to_rfc3339(),
                    })),
                };
                
                // 更新任务状态
                self.state_store.update_task_state(&task_update).await
                    .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
            }
        }
        
        // 更新工作流状态
        workflow_state.last_updated_at = Some(Utc::now());
        self.state_store.update_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
        
        // 记录恢复事件
        self.observability.record_workflow_recovery(
            workflow_id,
            "SYSTEM",
            "工作流自动恢复",
            &serde_json::json!({
                "recovery_time": Utc::now().to_rfc3339(),
                "workflow_status": format!("{:?}", workflow_state.status),
            }),
        );
        
        // 重新调度工作流
        self.workflow_engine.resume_workflow(workflow_id).await
            .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
        
        Ok(())
    }
    
    /// 从指定的恢复点恢复工作流
    pub async fn recover_from_point(&self, workflow_id: &str, recovery_point_id: &str) -> Result<(), RecoveryError> {
        // 创建恢复追踪上下文
        let trace_ctx = self.observability.create_workflow_recovery_span(workflow_id);
        let _trace_guard = trace_ctx.enter();
        
        // 为工作流恢复获取锁
        let lock_key = format!("workflow:recovery:{}", workflow_id);
        let lock_acquired = self.lock_service.acquire_lock(&lock_key, Duration::from_secs(60)).await
            .map_err(|e| RecoveryError::LockAcquisition(e.to_string()))?;
            
        if !lock_acquired {
            return Err(RecoveryError::LockAcquisition(format!("无法获取工作流锁: {}", workflow_id)));
        }
        
        // 确保锁在函数退出时释放
        let _lock_guard = scopeguard::guard((), |_| {
            let lock_key = format!("workflow:recovery:{}", workflow_id);
            let release_fut = self.lock_service.release_lock(&lock_key);
            tokio::spawn(async move {
                let _ = release_fut.await;
            });
        });
        
        // 获取恢复点
        let recovery_point = self.state_store.get_recovery_point(workflow_id, recovery_point_id).await
            .map_err(|e| RecoveryError::StateStore(e.to_string()))?;
            
        // 执行恢复操作
        match recovery_point.point_type {
            RecoveryPointType::Checkpoint => {
                // 从检查点恢复
                self.recovery_strategy.apply_recovery_action(
                    workflow_id,
                    RecoveryAction::RollbackToSnapshot { snapshot_id: recovery_point_id.to_string() }
                ).await
                .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryPointType::EventBased => {
                // 基于事件重建到特定点
                self.recovery_strategy.apply_recovery_action(
                    workflow_id,
                    RecoveryAction::RebuildToEvent { event_id: recovery_point.metadata.get("event_id").unwrap().as_str().unwrap().to_string() }
                ).await
                .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
            RecoveryPointType::TaskBased => {
                // 重置到特定任务
                let task_id = recovery_point.metadata.get("task_id").unwrap().as_str().unwrap().to_string();
                self.recovery_strategy.apply_recovery_action(
                    workflow_id,
                    RecoveryAction::ResetToTask { task_id }
                ).await
                .map_err(|e| RecoveryError::Strategy(e.to_string()))?;
            },
        }
        
        // 记录恢复事件
        self.observability.record_workflow_recovery(
            workflow_id,
            "USER",
            "从恢复点恢复工作流",
            &serde_json::json!({
                "recovery_time": Utc::now().to_rfc3339(),
                "recovery_point_id": recovery_point_id,
                "recovery_point_type": format!("{:?}", recovery_point.point_type),
            }),
        );
        
        Ok(())
    }
}

/// 快照管理器
pub struct SnapshotManager {
    /// 状态存储
    state_storage: Arc<dyn StateStore>,
    
    /// 压缩器
    compressor: Option<Arc<dyn DataCompressor>>,
    
    /// 加密器
    encryptor: Option<Arc<dyn DataEncryptor>>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
}

impl SnapshotManager {
    /// 创建新的快照管理器
    pub fn new(
        state_storage: Arc<dyn StateStore>,
        compressor: Option<Arc<dyn DataCompressor>>,
        encryptor: Option<Arc<dyn DataEncryptor>>,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        Self {
            state_storage,
            compressor,
            encryptor,
            observability,
        }
    }
    
    /// 为工作流创建快照
    pub async fn create_snapshot(
        &self,
        workflow_id: &str,
        execution_id: &str,
        snapshot_type: SnapshotType,
    ) -> Result<String, SnapshotError> {
        // 创建快照追踪上下文
        let trace_ctx = self.observability.create_snapshot_span(workflow_id);
        let _trace_guard = trace_ctx.enter();
        
        // 生成快照ID
        let snapshot_id = format!("snapshot-{}-{}", workflow_id, Uuid::new_v4());
        
        // 获取工作流状态
        let workflow_state = self.state_storage.get_workflow_state(workflow_id).await
            .map_err(|e| SnapshotError::StateFetchFailed(e.to_string()))?;
            
        // 序列化状态
        let state_json = serde_json::to_vec(&workflow_state)
            .map_err(|e| SnapshotError::SerializationFailed(e.to_string()))?;
            
        // 压缩数据（如果配置了压缩器）
        let compressed_state = if let Some(compressor) = &self.compressor {
            compressor.compress(&state_json)
                .map_err(|e| SnapshotError::CompressionFailed(e.to_string()))?
        } else {
            state_json
        };
        
        // 加密数据（如果配置了加密器）
        let protected_state = if let Some(encryptor) = &self.encryptor {
            encryptor.encrypt(&compressed_state)
                .map_err(|e| SnapshotError::EncryptionFailed(e.to_string()))?
        } else {
            compressed_state
        };
        
        // 创建快照元数据
        let snapshot = WorkflowSnapshot {
            id: snapshot_id.clone(),
            workflow_id: workflow_id.to_string(),
            execution_id: execution_id.to_string(),
            created_at: Utc::now(),
            size_bytes: protected_state.len() as u64,
            checksum: calculate_checksum(&protected_state),
            is_compressed: self.compressor.is_some(),
            is_encrypted: self.encryptor.is_some(),
            metadata: HashMap::new(),
        };
        
        // 创建恢复点
        let recovery_point = RecoveryPoint {
            id: snapshot_id.clone(),
            workflow_id: workflow_id.to_string(),
            point_type: RecoveryPointType::Checkpoint,
            created_at: Utc::now(),
            data_size: protected_state.len() as u64,
            metadata: snapshot.metadata.clone(),
        };
        
        // 存储恢复点
        self.state_storage.save_recovery_point(&recovery_point).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
        
        // 存储快照数据
        self.save_snapshot_data(&snapshot_id, &protected_state).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
        
        // 记录创建快照事件
        self.observability.record_metric(
            "snapshot_created",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("snapshot_id".to_string(), snapshot_id.clone()),
                ("snapshot_type".to_string(), format!("{:?}", snapshot_type)),
                ("size_bytes".to_string(), protected_state.len().to_string()),
            ])),
        );
        
        log::info!("为工作流创建了快照: workflow_id={}, execution_id={}, snapshot_id={}", 
                  workflow_id, execution_id, snapshot_id);
        
        Ok(snapshot_id)
    }
    
    /// 存储快照数据
    async fn save_snapshot_data(&self, snapshot_id: &str, data: &[u8]) -> Result<(), StorageError> {
        // 创建存储键
        let storage_key = format!("workflow:snapshot:data:{}", snapshot_id);
        
        // 存储数据
        let storage = match self.state_storage.as_any().downcast_ref::<PersistentStateStore>() {
            Some(persistent_store) => persistent_store.get_storage_engine(),
            None => {
                // 如果不是 PersistentStateStore，尝试其他实现
                return Err(StorageError::Unsupported("存储引擎不支持保存快照数据".to_string()));
            }
        };
        
        storage.put(&storage_key, data).await
    }
    
    /// 从快照恢复工作流状态
    pub async fn restore_from_snapshot(
        &self,
        snapshot_id: &str,
    ) -> Result<WorkflowState, SnapshotError> {
        // 创建恢复追踪上下文
        let trace_ctx = self.observability.create_snapshot_restore_span(snapshot_id);
        let _trace_guard = trace_ctx.enter();
        
        // 获取快照数据
        let protected_state = self.get_snapshot_data(snapshot_id).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
            
        // 解密数据（如果需要）
        let compressed_state = if let Some(encryptor) = &self.encryptor {
            encryptor.decrypt(&protected_state)
                .map_err(|e| SnapshotError::DecryptionFailed(e.to_string()))?
        } else {
            protected_state
        };
        
        // 解压数据（如果需要）
        let state_json = if let Some(compressor) = &self.compressor {
            compressor.decompress(&compressed_state)
                .map_err(|e| SnapshotError::DecompressionFailed(e.to_string()))?
        } else {
            compressed_state
        };
        
        // 反序列化工作流状态
        let state: WorkflowState = serde_json::from_slice(&state_json)
            .map_err(|e| SnapshotError::DeserializationFailed(e.to_string()))?;
            
        // 记录从快照恢复事件
        self.observability.record_metric(
            "snapshot_restored",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), state.id.clone()),
                ("snapshot_id".to_string(), snapshot_id.to_string()),
                ("state_size".to_string(), state_json.len().to_string()),
            ])),
        );
        
        log::info!("从快照恢复了工作流状态: workflow_id={}, snapshot_id={}", 
                  state.id, snapshot_id);
        
        Ok(state)
    }
    
    /// 获取快照数据
    async fn get_snapshot_data(&self, snapshot_id: &str) -> Result<Vec<u8>, StorageError> {
        // 创建存储键
        let storage_key = format!("workflow:snapshot:data:{}", snapshot_id);
        
        // 获取数据
        let storage = match self.state_storage.as_any().downcast_ref::<PersistentStateStore>() {
            Some(persistent_store) => persistent_store.get_storage_engine(),
            None => {
                // 如果不是 PersistentStateStore，尝试其他实现
                return Err(StorageError::Unsupported("存储引擎不支持获取快照数据".to_string()));
            }
        };
        
        storage.get(&storage_key).await
    }
    
    /// 列出工作流的所有快照
    pub async fn list_snapshots(&self, workflow_id: &str) -> Result<Vec<WorkflowSnapshot>, SnapshotError> {
        // 获取所有恢复点
        let recovery_points = self.state_storage.list_recovery_points(workflow_id).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
            
        // 过滤出检查点类型的恢复点
        let checkpoint_recovery_points: Vec<_> = recovery_points.into_iter()
            .filter(|point| point.point_type == RecoveryPointType::Checkpoint)
            .collect();
            
        if checkpoint_recovery_points.is_empty() {
            return Ok(Vec::new());
        }
        
        // 转换为快照
        let snapshots = checkpoint_recovery_points.into_iter()
            .map(|point| WorkflowSnapshot {
                id: point.id,
                workflow_id: point.workflow_id,
                execution_id: point.metadata.get("execution_id")
                    .map(|v| v.as_str().unwrap_or("unknown").to_string())
                    .unwrap_or_else(|| "unknown".to_string()),
                created_at: point.created_at,
                size_bytes: point.data_size,
                checksum: point.metadata.get("checksum")
                    .map(|v| v.as_str().unwrap_or("").to_string())
                    .unwrap_or_default(),
                is_compressed: point.metadata.get("is_compressed")
                    .map(|v| v.as_bool().unwrap_or(false))
                    .unwrap_or(false),
                is_encrypted: point.metadata.get("is_encrypted")
                    .map(|v| v.as_bool().unwrap_or(false))
                    .unwrap_or(false),
                metadata: point.metadata,
            })
            .collect();
            
        Ok(snapshots)
    }
    
    /// 删除快照
    pub async fn delete_snapshot(&self, workflow_id: &str, snapshot_id: &str) -> Result<(), SnapshotError> {
        // 删除恢复点
        self.state_storage.delete_recovery_point(workflow_id, snapshot_id).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
            
        // 删除快照数据
        let storage_key = format!("workflow:snapshot:data:{}", snapshot_id);
        let storage = match self.state_storage.as_any().downcast_ref::<PersistentStateStore>() {
            Some(persistent_store) => persistent_store.get_storage_engine(),
            None => {
                // 如果不是 PersistentStateStore，尝试其他实现
                return Err(SnapshotError::StorageFailed("存储引擎不支持删除快照数据".to_string()));
            }
        };
        
        storage.delete(&storage_key).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
            
        // 记录删除快照事件
        self.observability.record_metric(
            "snapshot_deleted",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("snapshot_id".to_string(), snapshot_id.to_string()),
            ])),
        );
        
        log::info!("删除了工作流快照: workflow_id={}, snapshot_id={}", 
                  workflow_id, snapshot_id);
        
        Ok(())
    }
    
    /// 清理过期快照
    pub async fn cleanup_expired_snapshots(&self, max_age: Duration) -> Result<usize, SnapshotError> {
        // 获取所有工作流ID
        let workflow_ids = self.get_all_workflow_ids().await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
            
        let mut total_deleted = 0;
        let now = Utc::now();
        
        for workflow_id in workflow_ids {
            // 获取工作流的所有快照
            let snapshots = self.list_snapshots(&workflow_id).await?;
            
            // 过滤出过期的快照
            let expired_snapshots: Vec<_> = snapshots.into_iter()
                .filter(|snapshot| {
                    now.signed_duration_since(snapshot.created_at) > max_age
                })
                .collect();
                
            // 删除过期快照
            for snapshot in expired_snapshots {
                if let Err(e) = self.delete_snapshot(&workflow_id, &snapshot.id).await {
                    log::warn!("删除过期快照失败: workflow_id={}, snapshot_id={}, error={:?}",
                             workflow_id, snapshot.id, e);
                } else {
                    total_deleted += 1;
                }
            }
        }
        
        log::info!("清理了 {} 个过期快照", total_deleted);
        
        Ok(total_deleted)
    }
    
    /// 获取所有工作流ID
    async fn get_all_workflow_ids(&self) -> Result<Vec<String>, StorageError> {
        // 实现依赖于具体存储引擎
        // 这里是一个示例实现
        let workflow_keys_prefix = "workflow:state:";
        let storage = match self.state_storage.as_any().downcast_ref::<PersistentStateStore>() {
            Some(persistent_store) => persistent_store.get_storage_engine(),
            None => {
                return Err(StorageError::Unsupported("存储引擎不支持列出所有工作流".to_string()));
            }
        };
        
        let keys = storage.list_prefix(workflow_keys_prefix).await?;
        
        // 从键中提取工作流ID
        let workflow_ids = keys.into_iter()
            .map(|key| key[workflow_keys_prefix.len()..].to_string())
            .collect();
            
        Ok(workflow_ids)
    }
}

/// 状态转换器
pub struct StateTransitioner {
    /// 事件总线
    event_bus: Arc<EventBus>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
}

impl StateTransitioner {
    /// 创建新的状态转换器
    pub fn new(
        event_bus: Arc<EventBus>,
        state_store: Arc<dyn StateStore>,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        Self {
            event_bus,
            state_store,
            observability,
        }
    }
    
    /// 从事件中转换状态
    pub async fn transition_state_from_event(&self, event: &WorkflowEvent) -> Result<(), StateTransitionError> {
        // 获取当前工作流状态
        let workflow_id = &event.workflow_id;
        let current_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| StateTransitionError::StateFetchError(e.to_string()))?;
            
        // 根据事件类型和当前状态执行转换
        let new_state = match (&current_state.status, &event.event_type) {
            // 创建 -> 运行
            (WorkflowStatus::Created, EventType::WorkflowStarted) => {
                let mut new_state = current_state.clone();
                new_state.status = WorkflowStatus::Running;
                new_state.start_time = Some(event.timestamp);
                new_state.last_updated_at = Some(event.timestamp);
                
                // 从事件数据中提取启动参数
                if let Some(inputs) = event.data.get("inputs") {
                    if let Some(inputs_obj) = inputs.as_object() {
                        for (key, value) in inputs_obj {
                            new_state.variables.insert(key.clone(), value.clone());
                        }
                    }
                }
                
                new_state
            },
            
            // 运行 -> 完成
            (WorkflowStatus::Running, EventType::WorkflowCompleted) => {
                let mut new_state = current_state.clone();
                new_state.status = WorkflowStatus::Completed;
                new_state.end_time = Some(event.timestamp);
                new_state.last_updated_at = Some(event.timestamp);
                
                // 从事件数据中提取输出结果
                if let Some(outputs) = event.data.get("outputs") {
                    new_state.variables.insert("workflow_result".to_string(), outputs.clone());
                }
                
                new_state
            },
            
            // 运行 -> 失败
            (WorkflowStatus::Running, EventType::WorkflowFailed) => {
                let mut new_state = current_state.clone();
                new_state.status = WorkflowStatus::Failed;
                new_state.end_time = Some(event.timestamp);
                new_state.last_updated_at = Some(event.timestamp);
                
                // 从事件数据中提取错误信息
                if let Some(error) = event.data.get("error") {
                    new_state.variables.insert("workflow_error".to_string(), error.clone());
                }
                
                new_state
            },
            
            // 运行 -> 取消
            (WorkflowStatus::Running, EventType::WorkflowCancelled) => {
                let mut new_state = current_state.clone();
                new_state.status = WorkflowStatus::Cancelled;
                new_state.end_time = Some(event.timestamp);
                new_state.last_updated_at = Some(event.timestamp);
                
                // 从事件数据中提取取
/// 继续实现 StateTransitioner
impl StateTransitioner {
    // ... [上一部分代码接续]
    
    // 运行 -> 取消
    (WorkflowStatus::Running, EventType::WorkflowCancelled) => {
        let mut new_state = current_state.clone();
        new_state.status = WorkflowStatus::Cancelled;
        new_state.end_time = Some(event.timestamp);
        new_state.last_updated_at = Some(event.timestamp);
        
        // 从事件数据中提取取消原因
        if let Some(reason) = event.data.get("reason") {
            new_state.variables.insert("cancel_reason".to_string(), reason.clone());
        }
        
        new_state
    },
    
    // 运行 -> 暂停
    (WorkflowStatus::Running, EventType::WorkflowSuspended) => {
        let mut new_state = current_state.clone();
        new_state.status = WorkflowStatus::Suspended;
        new_state.last_updated_at = Some(event.timestamp);
        
        // 从事件数据中提取暂停原因
        if let Some(reason) = event.data.get("reason") {
            new_state.variables.insert("suspend_reason".to_string(), reason.clone());
        }
        
        // 从事件数据中提取暂停点
        if let Some(suspend_point) = event.data.get("suspend_point") {
            new_state.variables.insert("suspend_point".to_string(), suspend_point.clone());
        }
        
        new_state
    },
    
    // 暂停 -> 运行
    (WorkflowStatus::Suspended, EventType::WorkflowResumed) => {
        let mut new_state = current_state.clone();
        new_state.status = WorkflowStatus::Running;
        new_state.last_updated_at = Some(event.timestamp);
        
        // 从事件数据中提取恢复输入
        if let Some(inputs) = event.data.get("inputs") {
            if let Some(inputs_obj) = inputs.as_object() {
                for (key, value) in inputs_obj {
                    new_state.variables.insert(key.clone(), value.clone());
                }
            }
        }
        
        new_state
    },
    
    // 其他状态转换...
    _ => {
        // 无效的状态转换
        return Err(StateTransitionError::InvalidTransition(
            format!("Invalid transition from {:?} with event {:?}", 
                   current_state.status, event.event_type)
        ));
    },
};

// 保存更新后的状态
self.state_store.update_workflow_state(workflow_id, &new_state).await
    .map_err(|e| StateTransitionError::StateUpdateError(e.to_string()))?;
    
// 发布状态变更事件
let state_changed_event = WorkflowEvent {
    id: Uuid::new_v4().to_string(),
    workflow_id: workflow_id.clone(),
    event_type: EventType::WorkflowStateChanged,
    timestamp: Utc::now(),
    data: json!({
        "previous_status": format!("{:?}", current_state.status),
        "new_status": format!("{:?}", new_state.status),
        "source_event": event.id,
    }),
};

if let Err(e) = self.event_bus.publish_event(&state_changed_event).await {
    log::warn!("Failed to publish workflow state changed event: {:?}", e);
}

// 记录状态变更指标
self.observability.record_metric(
    "workflow_state_transition",
    MetricValue::Counter(1),
    Some(HashMap::from([
        ("workflow_id".to_string(), workflow_id.clone()),
        ("previous_state".to_string(), format!("{:?}", current_state.status)),
        ("new_state".to_string(), format!("{:?}", new_state.status)),
    ])),
);

Ok(())
}
}

/// 错误处理组件
pub struct ErrorHandler {
    /// 错误分类器
    error_classifier: Arc<dyn ErrorClassifier>,
    
    /// 补偿操作注册表
    compensation_registry: Arc<CompensationRegistry>,
    
    /// 降级服务提供者
    fallback_provider: Arc<dyn FallbackProvider>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
}

impl ErrorHandler {
    /// 创建新的错误处理器
    pub fn new(
        error_classifier: Arc<dyn ErrorClassifier>,
        compensation_registry: Arc<CompensationRegistry>,
        fallback_provider: Arc<dyn FallbackProvider>,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        Self {
            error_classifier,
            compensation_registry,
            fallback_provider,
            observability,
        }
    }
    
    /// 处理任务错误
    pub async fn handle_task_error(
        &self,
        task: &TaskDefinition,
        error: WorkflowError,
        attempt: u32,
        first_failure_time: Option<DateTime<Utc>>,
        context: &TaskContext,
    ) -> Result<ErrorHandlingAction, HandlingError> {
        // 创建错误处理追踪上下文
        let trace_ctx = self.observability.create_error_handling_span(
            &context.workflow_id, 
            &task.id, 
            &format!("{:?}", error)
        );
        let _trace_guard = trace_ctx.enter();
        
        // 1. 分类错误
        let error_class = self.error_classifier.classify(&error);
        log::info!("Classified error for task {}: {:?}", task.id, error_class);
        
        // 记录错误指标
        self.observability.record_metric(
            "task_error",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), context.workflow_id.clone()),
                ("task_id".to_string(), task.id.clone()),
                ("error_class".to_string(), format!("{:?}", error_class)),
                ("attempt".to_string(), attempt.to_string()),
            ])),
        );
        
        // 2. 检查是否应该重试
        if let Some(retry) = &task.retry_strategy {
            if retry.should_retry(&error, attempt, first_failure_time) {
                let delay = retry.next_delay(attempt);
                log::info!("Scheduling retry #{} for task {} after {:?}", 
                         attempt + 1, task.id, delay);
                
                // 记录重试指标
                self.observability.record_metric(
                    "task_retry_scheduled",
                    MetricValue::Counter(1),
                    Some(HashMap::from([
                        ("workflow_id".to_string(), context.workflow_id.clone()),
                        ("task_id".to_string(), task.id.clone()),
                        ("attempt".to_string(), (attempt + 1).to_string()),
                        ("delay_ms".to_string(), delay.as_millis().to_string()),
                    ])),
                );
                
                return Ok(ErrorHandlingAction::Retry { 
                    delay, 
                    attempt: attempt + 1,
                    error: error.clone(),
                });
            }
        }
        
        // 3. 检查是否有补偿操作
        if let Some(compensation) = self.compensation_registry.get_compensation(task) {
            log::info!("Executing compensation for failed task {}", task.id);
            
            // 记录补偿指标
            self.observability.record_metric(
                "task_compensation_started",
                MetricValue::Counter(1),
                Some(HashMap::from([
                    ("workflow_id".to_string(), context.workflow_id.clone()),
                    ("task_id".to_string(), task.id.clone()),
                    ("compensation_id".to_string(), compensation.id.clone()),
                ])),
            );
            
            return Ok(ErrorHandlingAction::Compensate(compensation));
        }
        
        // 4. 如果没有补偿，检查是否有错误处理步骤
        if let Some(handler_id) = &task.error_handler {
            log::info!("Using error handler {} for task {}", handler_id, task.id);
            
            // 记录错误处理指标
            self.observability.record_metric(
                "task_error_handler_invoked",
                MetricValue::Counter(1),
                Some(HashMap::from([
                    ("workflow_id".to_string(), context.workflow_id.clone()),
                    ("task_id".to_string(), task.id.clone()),
                    ("handler_id".to_string(), handler_id.clone()),
                ])),
            );
            
            return Ok(ErrorHandlingAction::ExecuteHandler(handler_id.clone()));
        }
        
        // 5. 检查是否可以降级
        if let Some(fallback) = self.fallback_provider.get_fallback_for_task(task, &error) {
            log::info!("Using fallback for task {}: {}", task.id, fallback.description);
            
            // 记录降级指标
            self.observability.record_metric(
                "task_fallback_used",
                MetricValue::Counter(1),
                Some(HashMap::from([
                    ("workflow_id".to_string(), context.workflow_id.clone()),
                    ("task_id".to_string(), task.id.clone()),
                    ("fallback_id".to_string(), fallback.id.clone()),
                ])),
            );
            
            return Ok(ErrorHandlingAction::UseFallback(fallback));
        }
        
        // 6. 如果以上策略都不适用，检查任务的错误策略
        match task.error_policy {
            ErrorPolicy::FailWorkflow => {
                log::info!("Task {} failure will cause workflow to fail", task.id);
                
                return Ok(ErrorHandlingAction::FailWorkflow {
                    reason: error.to_string(),
                });
            },
            ErrorPolicy::ContinueWorkflow => {
                log::info!("Ignoring task {} failure and continuing workflow", task.id);
                
                return Ok(ErrorHandlingAction::ContinueWorkflow {
                    skip_result: json!({
                        "error": error.to_string(),
                        "skipped": true,
                        "timestamp": Utc::now().to_rfc3339(),
                    }),
                });
            },
            _ => {
                // 默认行为是失败工作流
                return Ok(ErrorHandlingAction::FailWorkflow {
                    reason: error.to_string(),
                });
            }
        }
    }
}

/// 补偿操作注册表
pub struct CompensationRegistry {
    /// 任务ID到补偿操作的映射
    compensations: RwLock<HashMap<String, CompensationAction>>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
}

impl CompensationRegistry {
    /// 创建新的补偿操作注册表
    pub fn new(observability: Arc<WorkflowObservability>) -> Self {
        Self {
            compensations: RwLock::new(HashMap::new()),
            observability,
        }
    }
    
    /// 注册补偿操作
    pub fn register_compensation(&self, task_id: &str, compensation: CompensationAction) {
        let mut compensations = self.compensations.write().unwrap();
        compensations.insert(task_id.to_string(), compensation);
        
        // 记录注册指标
        self.observability.record_metric(
            "compensation_registered",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("task_id".to_string(), task_id.to_string()),
                ("compensation_id".to_string(), compensation.id.clone()),
            ])),
        );
    }
    
    /// 获取任务的补偿操作
    pub fn get_compensation(&self, task: &TaskDefinition) -> Option<CompensationAction> {
        let compensations = self.compensations.read().unwrap();
        
        // 首先检查精确匹配
        if let Some(compensation) = compensations.get(&task.id) {
            return Some(compensation.clone());
        }
        
        // 然后检查任务类型匹配
        if let Some(compensation) = compensations.get(&format!("type:{}", task.task_type)) {
            return Some(compensation.clone());
        }
        
        None
    }
    
    /// 批量注册补偿操作
    pub fn register_compensations(&self, compensations: Vec<(String, CompensationAction)>) {
        let mut comps = self.compensations.write().unwrap();
        
        for (task_id, compensation) in compensations {
            comps.insert(task_id, compensation);
            
            // 记录注册指标
            self.observability.record_metric(
                "compensation_registered",
                MetricValue::Counter(1),
                Some(HashMap::from([
                    ("task_id".to_string(), task_id),
                    ("compensation_id".to_string(), compensation.id.clone()),
                ])),
            );
        }
    }
    
    /// 移除补偿操作
    pub fn remove_compensation(&self, task_id: &str) -> Option<CompensationAction> {
        let mut compensations = self.compensations.write().unwrap();
        let removed = compensations.remove(task_id);
        
        if removed.is_some() {
            // 记录移除指标
            self.observability.record_metric(
                "compensation_removed",
                MetricValue::Counter(1),
                Some(HashMap::from([
                    ("task_id".to_string(), task_id.to_string()),
                ])),
            );
        }
        
        removed
    }
    
    /// 清除所有补偿操作
    pub fn clear_compensations(&self) {
        let mut compensations = self.compensations.write().unwrap();
        let count = compensations.len();
        compensations.clear();
        
        // 记录清除指标
        self.observability.record_metric(
            "compensations_cleared",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("count".to_string(), count.to_string()),
            ])),
        );
    }
}

/// 补偿操作
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CompensationAction {
    /// 补偿操作ID
    pub id: String,
    
    /// 补偿操作名称
    pub name: String,
    
    /// 补偿操作描述
    pub description: Option<String>,
    
    /// 补偿操作类型
    pub action_type: CompensationActionType,
    
    /// 补偿操作参数
    pub parameters: HashMap<String, Value>,
    
    /// 创建时间
    pub created_at: DateTime<Utc>,
}

/// 补偿操作类型
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub enum CompensationActionType {
    /// 执行特定的补偿任务
    Task { task_id: String },
    
    /// 执行服务调用
    ServiceCall { service: String, operation: String },
    
    /// 执行脚本
    Script { language: String, code: String },
    
    /// 发送通知
    Notification { channel: String, template: String },
    
    /// 人工介入
    ManualIntervention { instructions: String },
}

/// 补偿引擎
pub struct CompensationEngine {
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 补偿操作执行器
    executor: Arc<dyn CompensationExecutor>,
    
    /// 事件总线
    event_bus: Arc<EventBus>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
}

impl CompensationEngine {
    /// 创建新的补偿引擎
    pub fn new(
        state_store: Arc<dyn StateStore>,
        executor: Arc<dyn CompensationExecutor>,
        event_bus: Arc<EventBus>,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        Self {
            state_store,
            executor,
            event_bus,
            observability,
        }
    }
    
    /// 启动针对特定工作流的补偿流程
    pub async fn start_compensation(
        &self,
        workflow_id: &str,
        reason: &str,
    ) -> Result<(), CompensationError> {
        // 创建补偿追踪上下文
        let trace_ctx = self.observability.create_compensation_span(workflow_id);
        let _trace_guard = trace_ctx.enter();
        
        log::info!("Starting compensation for workflow {}: {}", workflow_id, reason);
        
        // 获取工作流状态
        let mut workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| CompensationError::StateFetchError(e.to_string()))?;
            
        // 检查工作流是否已经在补偿中
        if workflow_state.status == WorkflowStatus::Compensating {
            return Err(CompensationError::AlreadyCompensating(workflow_id.to_string()));
        }
        
        // 更新工作流状态为补偿中
        workflow_state.status = WorkflowStatus::Compensating;
        workflow_state.last_updated_at = Some(Utc::now());
        workflow_state.variables.insert("compensation_reason".to_string(), json!(reason));
        workflow_state.variables.insert("compensation_started_at".to_string(), json!(Utc::now().to_rfc3339()));
        
        // 保存更新后的状态
        self.state_store.update_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| CompensationError::StateUpdateError(e.to_string()))?;
            
        // 发布补偿开始事件
        let compensation_started_event = WorkflowEvent {
            id: Uuid::new_v4().to_string(),
            workflow_id: workflow_id.to_string(),
            event_type: EventType::CompensationStarted,
            timestamp: Utc::now(),
            data: json!({
                "reason": reason,
            }),
        };
        
        if let Err(e) = self.event_bus.publish_event(&compensation_started_event).await {
            log::warn!("Failed to publish compensation started event: {:?}", e);
        }
        
        // 记录补偿开始指标
        self.observability.record_metric(
            "compensation_started",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("reason".to_string(), reason.to_string()),
            ])),
        );
        
        // 根据已执行步骤的顺序构建补偿计划（倒序执行补偿）
        let compensation_plan = self.build_compensation_plan(workflow_id).await?;
        
        // 开始执行补偿计划
        self.execute_compensation_plan(workflow_id, compensation_plan).await?;
        
        Ok(())
    }
    
    /// 构建补偿计划
    async fn build_compensation_plan(&self, workflow_id: &str) -> Result<Vec<CompensationStep>, CompensationError> {
        // 获取工作流状态
        let workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| CompensationError::StateFetchError(e.to_string()))?;
            
        // 获取工作流定义
        let workflow_def = self.state_store.get_workflow_definition(&workflow_state.workflow_definition_id).await
            .map_err(|e| CompensationError::DefinitionFetchError(e.to_string()))?;
            
        // 获取已完成的任务
        let completed_tasks: Vec<_> = workflow_state.task_states.iter()
            .filter(|(_, state)| state.status == TaskStatus::Completed)
            .map(|(id, _)| id.clone())
            .collect();
            
        // 倒序处理已完成的任务
        let mut compensation_steps = Vec::new();
        
        for task_id in completed_tasks.iter().rev() {
            // 获取任务定义
            if let Some(task_def) = workflow_def.tasks.get(task_id) {
                // 查找任务的补偿操作
                if let Some(compensation_id) = &task_def.compensation_task {
                    if let Some(compensation_task) = workflow_def.tasks.get(compensation_id) {
                        compensation_steps.push(CompensationStep {
                            original_task_id: task_id.clone(),
                            compensation_task_id: compensation_id.clone(),
                            compensation_task: compensation_task.clone(),
                            status: CompensationStepStatus::Pending,
                            attempt: 0,
                            error: None,
                            start_time: None,
                            end_time: None,
                        });
                    }
                }
            }
        }
        
        Ok(compensation_steps)
    }
    
    /// 执行补偿计划
    async fn execute_compensation_plan(
        &self,
        workflow_id: &str,
        mut compensation_plan: Vec<CompensationStep>,
    ) -> Result<(), CompensationError> {
        // 获取工作流状态
        let mut workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| CompensationError::StateFetchError(e.to_string()))?;
            
        // 更新补偿计划到工作流状态
        workflow_state.variables.insert("compensation_plan".to_string(), json!(compensation_plan));
        self.state_store.update_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| CompensationError::StateUpdateError(e.to_string()))?;
            
        let mut compensation_succeeded = true;
        
        // 执行每个补偿步骤
        for step in &mut compensation_plan {
            // 更新步骤状态
            step.status = CompensationStepStatus::Running;
            step.start_time = Some(Utc::now());
            
            // 更新工作流状态中的补偿计划
            workflow_state.variables.insert("compensation_plan".to_string(), json!(compensation_plan));
            self.state_store.update_workflow_state(workflow_id, &workflow_state).await
                .map_err(|e| CompensationError::StateUpdateError(e.to_string()))?;
                
            // 发布补偿步骤开始事件
            let step_started_event = WorkflowEvent {
                id: Uuid::new_v4().to_string(),
                workflow_id: workflow_id.to_string(),
                event_type: EventType::CompensationStepStarted,
                timestamp: Utc::now(),
                data: json!({
                    "original_task_id": step.original_task_id,
                    "compensation_task_id": step.compensation_task_id,
                }),
            };
            
            if let Err(e) = self.event_bus.publish_event(&step_started_event).await {
                log::warn!("Failed to publish compensation step started event: {:?}", e);
            }
            
            // 执行补偿步骤
            let result = self.executor.execute_compensation_task(
                workflow_id,
                &step.original_task_id,
                &step.compensation_task,
                &workflow_state,
            ).await;
            
            // 更新步骤状态
            step.end_time = Some(Utc::now());
            
            match result {
                Ok(_) => {
                    // 补偿成功
                    step.status = CompensationStepStatus::Completed;
                    
                    // 发布补偿步骤完成事件
                    let step_completed_event = WorkflowEvent {
                        id: Uuid::new_v4().to_string(),
                        workflow_id: workflow_id.to_string(),
                        event_type: EventType::CompensationStepCompleted,
                        timestamp: Utc::now(),
                        data: json!({
                            "original_task_id": step.original_task_id,
                            "compensation_task_id": step.compensation_task_id,
                        }),
                    };
                    
                    if let Err(e) = self.event_bus.publish_event(&step_completed_event).await {
                        log::warn!("Failed to publish compensation step completed event: {:?}", e);
                    }
                },
                Err(e) => {
                    // 补偿失败
                    compensation_succeeded = false;
                    step.status = CompensationStepStatus::Failed;
                    step.error = Some(e.to_string());
                    
                    // 发布补偿步骤失败事件
                    let step_failed_event = WorkflowEvent {
                        id: Uuid::new_v4().to_string(),
                        workflow_id: workflow_id.to_string(),
                        event_type: EventType::CompensationStepFailed,
                        timestamp: Utc::now(),
                        data: json!({
                            "original_task_id": step.original_task_id,
                            "compensation_task_id": step.compensation_task_id,
                            "error": e.to_string(),
                        }),
                    };
                    
                    if let Err(e) = self.event_bus.publish_event(&step_failed_event).await {
                        log::warn!("Failed to publish compensation step failed event: {:?}", e);
                    }
                    
                    // 记录补偿步骤失败指标
                    self.observability.record_metric(
                        "compensation_step_failed",
                        MetricValue::Counter(1),
                        Some(HashMap::from([
                            ("workflow_id".to_string(), workflow_id.to_string()),
                            ("original_task_id".to_string(), step.original_task_id.clone()),
                            ("compensation_task_id".to_string(), step.compensation_task_id.clone()),
                        ])),
                    );
                }
            }
            
            // 更新工作流状态中的补偿计划
            workflow_state.variables.insert("compensation_plan".to_string(), json!(compensation_plan));
            self.state_store.update_workflow_state(workflow_id, &workflow_state).await
                .map_err(|e| CompensationError::StateUpdateError(e.to_string()))?;
        }
        
        // 更新工作流状态
        workflow_state.status = if compensation_succeeded {
            WorkflowStatus::Compensated
        } else {
            WorkflowStatus::CompensationFailed
        };
        
        workflow_state.end_time = Some(Utc::now());
        workflow_state.last_updated_at = Some(Utc::now());
        workflow_state.variables.insert("compensation_completed_at".to_string(), json!(Utc::now().to_rfc3339()));
        workflow_state.variables.insert("compensation_succeeded".to_string(), json!(compensation_succeeded));
        
        // 保存更新后的状态
        self.state_store.update_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| CompensationError::StateUpdateError(e.to_string()))?;
        
        // 发布补偿完成事件
        let event_type = if compensation_succeeded {
            EventType::CompensationCompleted
        } else {
            EventType::CompensationFailed
        };
        
        let compensation_completed_event = WorkflowEvent {
            id: Uuid::new_v4().to_string(),
            workflow_id: workflow_id.to_string(),
            event_type,
            timestamp: Utc::now(),
            data: json!({
                "succeeded": compensation_succeeded,
                "steps_count": compensation_plan.len(),
                "failed_steps": compensation_plan.iter()
                    .filter(|s| s.status == CompensationStepStatus::Failed)
                    .map(|s| s.compensation_task_id.clone())
                    .collect::<Vec<_>>(),
            }),
        };
        
        if let Err(e) = self.event_bus.publish_event(&compensation_completed_event).await {
            log::warn!("Failed to publish compensation completed event: {:?}", e);
        }
        
        // 记录补偿完成指标
        self.observability.record_metric(
            if compensation_succeeded { "compensation_completed" } else { "compensation_failed" },
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("steps_count".to_string(), compensation_plan.len().to_string()),
                ("failed_steps".to_string(), compensation_plan.iter()
                    .filter(|s| s.status == CompensationStepStatus::Failed)
                    .count().to_string()),
            ])),
        );
        
        log::info!("Compensation for workflow {} {}", 
                 workflow_id, 
                 if compensation_succeeded { "completed successfully" } else { "failed" });
        
        Ok(())
    }
}

/// 补偿步骤
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CompensationStep {
    /// 原始任务ID
    pub original_task_id: String,
    
    /// 补偿任务ID
    pub compensation_task_id: String,
    
    /// 补偿任务定义
    pub                

/// 补偿任务定义
pub compensation_task: TaskDefinition,
    
    /// 补偿步骤状态
    pub status: CompensationStepStatus,
    
    /// 补偿尝试次数
    pub attempt: u32,
    
    /// 错误信息（如果有）
    pub error: Option<String>,
    
    /// 开始时间
    pub start_time: Option<DateTime<Utc>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
}

/// 补偿步骤状态
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub enum CompensationStepStatus {
    /// 等待执行
    Pending,
    
    /// 正在执行
    Running,
    
    /// 已完成
    Completed,
    
    /// 失败
    Failed,
    
    /// 跳过
    Skipped,
}

/// 补偿错误
#[derive(Debug, thiserror::Error)]
pub enum CompensationError {
    #[error("Failed to fetch state: {0}")]
    StateFetchError(String),
    
    #[error("Failed to update state: {0}")]
    StateUpdateError(String),
    
    #[error("Failed to fetch workflow definition: {0}")]
    DefinitionFetchError(String),
    
    #[error("Failed to execute compensation task: {0}")]
    ExecutionError(String),
    
    #[error("Workflow {0} is already being compensated")]
    AlreadyCompensating(String),
    
    #[error("No compensation steps found for workflow")]
    NoCompensationSteps,
    
    #[error("Not all steps were compensated: {0}")]
    IncompleteCompensation(String),
}

/// 工作流事务管理器
pub struct WorkflowTransactionManager {
    /// 事务存储
    transaction_store: Arc<dyn TransactionStore>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 事件总线
    event_bus: Arc<EventBus>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
    
    /// 事务超时配置
    transaction_timeout: Duration,
    
    /// 是否启用两阶段提交
    enable_two_phase_commit: bool,
}

impl WorkflowTransactionManager {
    /// 创建新的工作流事务管理器
    pub fn new(
        transaction_store: Arc<dyn TransactionStore>,
        state_store: Arc<dyn StateStore>,
        event_bus: Arc<EventBus>,
        observability: Arc<WorkflowObservability>,
        transaction_timeout: Duration,
        enable_two_phase_commit: bool,
    ) -> Self {
        Self {
            transaction_store,
            state_store,
            event_bus,
            observability,
            transaction_timeout,
            enable_two_phase_commit,
        }
    }
    
    /// 开始工作流事务
    pub async fn begin_transaction(&self, workflow_id: &str) -> Result<TransactionId, TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(workflow_id, "begin_transaction");
        let _trace_guard = trace_ctx.enter();
        
        log::info!("Beginning transaction for workflow {}", workflow_id);
        
        // 检查是否已存在活跃事务
        let existing_txs = self.transaction_store.get_active_transactions(workflow_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        if !existing_txs.is_empty() {
            return Err(TransactionError::TransactionAlreadyExists(
                format!("Workflow {} already has active transactions", workflow_id)
            ));
        }
        
        // 创建新事务
        let tx_id = TransactionId::new();
        let transaction = WorkflowTransaction {
            id: tx_id.clone(),
            workflow_id: workflow_id.to_string(),
            status: TransactionStatus::Active,
            resources: Vec::new(),
            created_at: Utc::now(),
            expires_at: Utc::now() + self.transaction_timeout,
            last_updated_at: Utc::now(),
            commit_status: None,
        };
        
        // 保存事务
        self.transaction_store.save_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 发布事务开始事件
        let transaction_started_event = WorkflowEvent {
            id: Uuid::new_v4().to_string(),
            workflow_id: workflow_id.to_string(),
            event_type: EventType::TransactionStarted,
            timestamp: Utc::now(),
            data: json!({
                "transaction_id": tx_id.to_string(),
                "expires_at": transaction.expires_at.to_rfc3339(),
            }),
        };
        
        if let Err(e) = self.event_bus.publish_event(&transaction_started_event).await {
            log::warn!("Failed to publish transaction started event: {:?}", e);
        }
        
        // 记录事务开始指标
        self.observability.record_metric(
            "transaction_started",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("transaction_id".to_string(), tx_id.to_string()),
            ])),
        );
        
        Ok(tx_id)
    }
    
    /// 提交工作流事务
    pub async fn commit_transaction(&self, tx_id: &TransactionId) -> Result<(), TransactionError> {
        // 获取事务
        let mut transaction = self.transaction_store.get_transaction(tx_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(&transaction.workflow_id, "commit_transaction");
        let _trace_guard = trace_ctx.enter();
        
        log::info!("Committing transaction {} for workflow {}", tx_id, transaction.workflow_id);
        
        // 检查事务状态
        if transaction.status != TransactionStatus::Active && 
           transaction.status != TransactionStatus::Prepared {
            return Err(TransactionError::InvalidTransactionStatus(
                format!("Cannot commit transaction in {:?} state", transaction.status)
            ));
        }
        
        // 检查事务是否过期
        if Utc::now() > transaction.expires_at {
            transaction.status = TransactionStatus::TimedOut;
            
            // 保存事务状态
            self.transaction_store.save_transaction(&transaction).await
                .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                
            return Err(TransactionError::TransactionTimedOut(
                format!("Transaction {} has timed out", tx_id)
            ));
        }
        
        // 处理两阶段提交
        if self.enable_two_phase_commit && transaction.status != TransactionStatus::Prepared {
            // 准备阶段
            if let Err(prepare_error) = self.prepare_transaction(tx_id).await {
                // 准备失败，回滚事务
                if let Err(rollback_error) = self.rollback_transaction(tx_id).await {
                    log::error!("Failed to rollback transaction after prepare failure: {:?}", rollback_error);
                }
                
                return Err(prepare_error);
            }
            
            // 重新获取事务（状态已更新）
            transaction = self.transaction_store.get_transaction(tx_id).await
                .map_err(|e| TransactionError::StorageError(e.to_string()))?;
        }
        
        // 更新事务状态为已提交
        transaction.status = TransactionStatus::Committed;
        transaction.last_updated_at = Utc::now();
        transaction.commit_status = Some(CommitStatus {
            committed_at: Utc::now(),
            commit_log: "Transaction committed successfully".to_string(),
        });
        
        // 保存事务状态
        self.transaction_store.save_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 提交所有资源变更
        for resource in &transaction.resources {
            if let Err(commit_error) = self.commit_resource_changes(tx_id, resource).await {
                log::error!("Failed to commit changes for resource {}: {:?}", resource.resource_id, commit_error);
                
                // 这里我们可以选择两种策略：
                // 1. 继续提交其他资源，忽略错误（尽力而为）
                // 2. 返回错误，但保持事务状态为已提交（需要人工干预）
                // 我们选择第1种策略，但记录错误
                self.observability.record_metric(
                    "transaction_resource_commit_failed",
                    MetricValue::Counter(1),
                    Some(HashMap::from([
                        ("workflow_id".to_string(), transaction.workflow_id.clone()),
                        ("transaction_id".to_string(), tx_id.to_string()),
                        ("resource_id".to_string(), resource.resource_id.clone()),
                        ("resource_type".to_string(), resource.resource_type.clone()),
                    ])),
                );
            }
        }
        
        // 发布事务提交事件
        let transaction_committed_event = WorkflowEvent {
            id: Uuid::new_v4().to_string(),
            workflow_id: transaction.workflow_id.clone(),
            event_type: EventType::TransactionCommitted,
            timestamp: Utc::now(),
            data: json!({
                "transaction_id": tx_id.to_string(),
                "resources_count": transaction.resources.len(),
            }),
        };
        
        if let Err(e) = self.event_bus.publish_event(&transaction_committed_event).await {
            log::warn!("Failed to publish transaction committed event: {:?}", e);
        }
        
        // 记录事务提交指标
        self.observability.record_metric(
            "transaction_committed",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), transaction.workflow_id.clone()),
                ("transaction_id".to_string(), tx_id.to_string()),
                ("resources_count".to_string(), transaction.resources.len().to_string()),
            ])),
        );
        
        log::info!("Transaction {} committed successfully", tx_id);
        
        Ok(())
    }
    
    /// 回滚工作流事务
    pub async fn rollback_transaction(&self, tx_id: &TransactionId) -> Result<(), TransactionError> {
        // 获取事务
        let mut transaction = self.transaction_store.get_transaction(tx_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(&transaction.workflow_id, "rollback_transaction");
        let _trace_guard = trace_ctx.enter();
        
        log::info!("Rolling back transaction {} for workflow {}", tx_id, transaction.workflow_id);
        
        // 检查事务状态
        if transaction.status == TransactionStatus::Committed {
            return Err(TransactionError::InvalidTransactionStatus(
                format!("Cannot rollback committed transaction {}", tx_id)
            ));
        }
        
        // 更新事务状态为已回滚
        transaction.status = TransactionStatus::RolledBack;
        transaction.last_updated_at = Utc::now();
        
        // 保存事务状态
        self.transaction_store.save_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 回滚所有资源变更（倒序执行）
        for resource in transaction.resources.iter().rev() {
            if let Err(rollback_error) = self.rollback_resource_changes(tx_id, resource).await {
                log::error!("Failed to rollback changes for resource {}: {:?}", resource.resource_id, rollback_error);
                
                // 记录回滚失败指标
                self.observability.record_metric(
                    "transaction_resource_rollback_failed",
                    MetricValue::Counter(1),
                    Some(HashMap::from([
                        ("workflow_id".to_string(), transaction.workflow_id.clone()),
                        ("transaction_id".to_string(), tx_id.to_string()),
                        ("resource_id".to_string(), resource.resource_id.clone()),
                        ("resource_type".to_string(), resource.resource_type.clone()),
                    ])),
                );
            }
        }
        
        // 发布事务回滚事件
        let transaction_rolled_back_event = WorkflowEvent {
            id: Uuid::new_v4().to_string(),
            workflow_id: transaction.workflow_id.clone(),
            event_type: EventType::TransactionRolledBack,
            timestamp: Utc::now(),
            data: json!({
                "transaction_id": tx_id.to_string(),
                "resources_count": transaction.resources.len(),
            }),
        };
        
        if let Err(e) = self.event_bus.publish_event(&transaction_rolled_back_event).await {
            log::warn!("Failed to publish transaction rolled back event: {:?}", e);
        }
        
        // 记录事务回滚指标
        self.observability.record_metric(
            "transaction_rolled_back",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), transaction.workflow_id.clone()),
                ("transaction_id".to_string(), tx_id.to_string()),
                ("resources_count".to_string(), transaction.resources.len().to_string()),
            ])),
        );
        
        log::info!("Transaction {} rolled back successfully", tx_id);
        
        Ok(())
    }
    
    /// 准备事务（两阶段提交的第一阶段）
    async fn prepare_transaction(&self, tx_id: &TransactionId) -> Result<(), TransactionError> {
        // 获取事务
        let mut transaction = self.transaction_store.get_transaction(tx_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        log::info!("Preparing transaction {} for workflow {}", tx_id, transaction.workflow_id);
        
        // 检查事务状态
        if transaction.status != TransactionStatus::Active {
            return Err(TransactionError::InvalidTransactionStatus(
                format!("Cannot prepare transaction in {:?} state", transaction.status)
            ));
        }
        
        // 检查事务是否过期
        if Utc::now() > transaction.expires_at {
            transaction.status = TransactionStatus::TimedOut;
            
            // 保存事务状态
            self.transaction_store.save_transaction(&transaction).await
                .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                
            return Err(TransactionError::TransactionTimedOut(
                format!("Transaction {} has timed out", tx_id)
            ));
        }
        
        // 准备所有资源变更
        for resource in &transaction.resources {
            if let Err(prepare_error) = self.prepare_resource_changes(tx_id, resource).await {
                log::error!("Failed to prepare changes for resource {}: {:?}", resource.resource_id, prepare_error);
                
                // 准备失败，直接返回错误（调用者将回滚事务）
                return Err(prepare_error);
            }
        }
        
        // 更新事务状态为已准备
        transaction.status = TransactionStatus::Prepared;
        transaction.last_updated_at = Utc::now();
        
        // 保存事务状态
        self.transaction_store.save_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 发布事务准备事件
        let transaction_prepared_event = WorkflowEvent {
            id: Uuid::new_v4().to_string(),
            workflow_id: transaction.workflow_id.clone(),
            event_type: EventType::TransactionPrepared,
            timestamp: Utc::now(),
            data: json!({
                "transaction_id": tx_id.to_string(),
                "resources_count": transaction.resources.len(),
            }),
        };
        
        if let Err(e) = self.event_bus.publish_event(&transaction_prepared_event).await {
            log::warn!("Failed to publish transaction prepared event: {:?}", e);
        }
        
        // 记录事务准备指标
        self.observability.record_metric(
            "transaction_prepared",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), transaction.workflow_id.clone()),
                ("transaction_id".to_string(), tx_id.to_string()),
                ("resources_count".to_string(), transaction.resources.len().to_string()),
            ])),
        );
        
        log::info!("Transaction {} prepared successfully", tx_id);
        
        Ok(())
    }
    
    /// 添加资源到事务
    pub async fn add_resource_to_transaction(
        &self,
        tx_id: &TransactionId,
        resource_type: &str,
        resource_id: &str,
        operation: ResourceOperation,
        before_state: Value,
        after_state: Value,
    ) -> Result<(), TransactionError> {
        // 获取事务
        let mut transaction = self.transaction_store.get_transaction(tx_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        log::info!("Adding resource {} of type {} to transaction {}", 
                 resource_id, resource_type, tx_id);
        
        // 检查事务状态
        if transaction.status != TransactionStatus::Active {
            return Err(TransactionError::InvalidTransactionStatus(
                format!("Cannot add resource to transaction in {:?} state", transaction.status)
            ));
        }
        
        // 检查事务是否过期
        if Utc::now() > transaction.expires_at {
            transaction.status = TransactionStatus::TimedOut;
            
            // 保存事务状态
            self.transaction_store.save_transaction(&transaction).await
                .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                
            return Err(TransactionError::TransactionTimedOut(
                format!("Transaction {} has timed out", tx_id)
            ));
        }
        
        // 创建资源变更
        let resource_change = ResourceChange {
            resource_type: resource_type.to_string(),
            resource_id: resource_id.to_string(),
            operation,
            before_state,
            after_state,
            created_at: Utc::now(),
        };
        
        // 添加资源变更到事务
        transaction.resources.push(resource_change);
        transaction.last_updated_at = Utc::now();
        
        // 保存事务状态
        self.transaction_store.save_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 记录资源添加指标
        self.observability.record_metric(
            "transaction_resource_added",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), transaction.workflow_id.clone()),
                ("transaction_id".to_string(), tx_id.to_string()),
                ("resource_type".to_string(), resource_type.to_string()),
                ("resource_id".to_string(), resource_id.to_string()),
                ("operation".to_string(), format!("{:?}", operation)),
            ])),
        );
        
        log::info!("Resource {} added to transaction {} successfully", resource_id, tx_id);
        
        Ok(())
    }
    
    /// 准备资源变更
    async fn prepare_resource_changes(
        &self,
        tx_id: &TransactionId,
        resource: &ResourceChange,
    ) -> Result<(), TransactionError> {
        // 根据资源类型获取相应的资源管理器
        let resource_manager = self.get_resource_manager(&resource.resource_type)?;
        
        // 调用资源管理器的准备方法
        resource_manager.prepare_change(tx_id, resource).await
            .map_err(|e| TransactionError::ResourceOperationFailed(
                format!("Failed to prepare changes for resource {}: {}", 
                       resource.resource_id, e)
            ))
    }
    
    /// 提交资源变更
    async fn commit_resource_changes(
        &self,
        tx_id: &TransactionId,
        resource: &ResourceChange,
    ) -> Result<(), TransactionError> {
        // 根据资源类型获取相应的资源管理器
        let resource_manager = self.get_resource_manager(&resource.resource_type)?;
        
        // 调用资源管理器的提交方法
        resource_manager.commit_change(tx_id, resource).await
            .map_err(|e| TransactionError::ResourceOperationFailed(
                format!("Failed to commit changes for resource {}: {}", 
                       resource.resource_id, e)
            ))
    }
    
    /// 回滚资源变更
    async fn rollback_resource_changes(
        &self,
        tx_id: &TransactionId,
        resource: &ResourceChange,
    ) -> Result<(), TransactionError> {
        // 根据资源类型获取相应的资源管理器
        let resource_manager = self.get_resource_manager(&resource.resource_type)?;
        
        // 调用资源管理器的回滚方法
        resource_manager.rollback_change(tx_id, resource).await
            .map_err(|e| TransactionError::ResourceOperationFailed(
                format!("Failed to rollback changes for resource {}: {}", 
                       resource.resource_id, e)
            ))
    }
    
    /// 获取资源管理器
    fn get_resource_manager(&self, resource_type: &str) -> Result<Arc<dyn ResourceManager>, TransactionError> {
        // 实际实现中，这里会有一个注册表来查找对应的资源管理器
        // 简化起见，我们直接返回错误
        Err(TransactionError::UnsupportedResourceType(
            format!("Resource type {} is not supported", resource_type)
        ))
    }
}

/// 工作流事务
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct WorkflowTransaction {
    /// 事务ID
    pub id: TransactionId,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 事务状态
    pub status: TransactionStatus,
    
    /// 资源变更列表
    pub resources: Vec<ResourceChange>,
    
    /// 创建时间
    pub created_at: DateTime<Utc>,
    
    /// 过期时间
    pub expires_at: DateTime<Utc>,
    
    /// 最后更新时间
    pub last_updated_at: DateTime<Utc>,
    
    /// 提交状态
    pub commit_status: Option<CommitStatus>,
}

/// 提交状态
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CommitStatus {
    /// 提交时间
    pub committed_at: DateTime<Utc>,
    
    /// 提交日志
    pub commit_log: String,
}

/// 资源变更
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ResourceChange {
    /// 资源类型
    pub resource_type: String,
    
    /// 资源ID
    pub resource_id: String,
    
    /// 操作类型
    pub operation: ResourceOperation,
    
    /// 变更前状态
    pub before_state: Value,
    
    /// 变更后状态
    pub after_state: Value,
    
    /// 创建时间
    pub created_at: DateTime<Utc>,
}

/// 资源操作类型
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub enum ResourceOperation {
    /// 创建资源
    Create,
    
    /// 更新资源
    Update,
    
    /// 删除资源
    Delete,
    
    /// 锁定资源
    Lock,
    
    /// 解锁资源
    Unlock,
}

/// 事务错误
#[derive(Debug, thiserror::Error)]
pub enum TransactionError {
    #[error("Storage error: {0}")]
    StorageError(String),
    
    #[error("Invalid transaction status: {0}")]
    InvalidTransactionStatus(String),
    
    #[error("Transaction timed out: {0}")]
    TransactionTimedOut(String),
    
    #[error("Transaction already exists: {0}")]
    TransactionAlreadyExists(String),
    
    #[error("Resource operation failed: {0}")]
    ResourceOperationFailed(String),
    
    #[error("Unsupported resource type: {0}")]
    UnsupportedResourceType(String),
    
    #[error("Transaction not found: {0}")]
    TransactionNotFound(String),
}

/// 资源管理器特质
#[async_trait]
pub trait ResourceManager: Send + Sync + 'static {
    /// 准备资源变更
    async fn prepare_change(&self, tx_id: &TransactionId, change: &ResourceChange) -> Result<(), String>;
    
    /// 提交资源变更
    async fn commit_change(&self, tx_id: &TransactionId, change: &ResourceChange) -> Result<(), String>;
    
    /// 回滚资源变更
    async fn rollback_change(&self, tx_id: &TransactionId, change: &ResourceChange) -> Result<(), String>;
}

```

工作流状态一致性校验

```rust
/// 状态一致性验证器
pub struct StateConsistencyValidator {
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 事件存储
    event_store: Arc<dyn EventStore>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
    
    /// 验证配置
    config: ConsistencyValidationConfig,
}

impl StateConsistencyValidator {
    /// 创建新的状态一致性验证器
    pub fn new(
        state_store: Arc<dyn StateStore>,
        event_store: Arc<dyn EventStore>,
        observability: Arc<WorkflowObservability>,
        config: ConsistencyValidationConfig,
    ) -> Self {
        Self {
            state_store,
            event_store,
            observability,
            config,
        }
    }
    
    /// 验证工作流状态一致性
    pub async fn validate_workflow_state(&self, workflow_id: &str) -> Result<ValidationResult, ConsistencyError> {
        // 创建验证追踪上下文
        let trace_ctx = self.observability.create_consistency_validation_span(workflow_id);
        let _trace_guard = trace_ctx.enter();
        
        log::info!("Validating state consistency for workflow {}", workflow_id);
        
        // 获取工作流状态
        let workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| ConsistencyError::StateFetchError(e.to_string()))?;
            
        // 验证内部一致性
        let internal_consistency = self.verify_internal_consistency(&workflow_state).await?;
        
        // 验证事件一致性
        let event_consistency = if self.config.verify_event_consistency {
            self.verify_event_consistency(workflow_id, &workflow_state).await?
        } else {
            true
        };
        
        // 验证任务依赖一致性
        let dependency_consistency = if self.config.verify_task_dependencies {
            self.verify_task_dependencies(&workflow_state).await?
        } else {
            true
        };
        
        // 验证资源分配一致性
        let resource_consistency = if self.config.verify_resource_allocations {
            self.verify_resource_allocations(&workflow_state).await?
        } else {
            true
        };
        
        // 统计结果
        let is_consistent = internal_consistency && event_consistency && 
                          dependency_consistency && resource_consistency;
                          
        let details = ValidationDetails {
            internal_consistency,
            event_consistency,
            dependency_consistency,
            resource_consistency,
            validation_time: Utc::now(),
        };
        
        // 记录验证指标
        self.observability.record_metric(
            "workflow_consistency_validation",
            MetricValue::Counter(1),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("is_consistent".to_string(), is_consistent.to_string()),
                ("internal_consistency".to_string(), internal_consistency.to_string()),
                ("event_consistency".to_string(), event_consistency.to_string()),
                ("dependency_consistency".to_string(), dependency_consistency.to_string()),
                ("resource_consistency".to_string(), resource_consistency.to_string()),
            ])),
        );
        
        let result = ValidationResult {
            is_consistent,
            details,
            workflow_id: workflow_id.to_string(),
            timestamp: Utc::now(),
        };
        
        log::info!("Workflow {} consistency validation result: {}", workflow_id, is_consistent);
        
        Ok(result)
    }
    
    /// 验证资源分配一致性
    async fn verify_resource_allocations(&self, state: &WorkflowState) -> Result<bool, ConsistencyError> {
        // 获取所有已分配资源
        let resource_allocations = state.resource_allocations.clone();
        
        // 检查所有资源是否有效
        for (resource_id, allocation) in &resource_allocations {
            // 验证分配的资源数量不超过任务需要
            if let Some(task_state) = state.task_states.get(&allocation.task_id) {
                if let Some(requirements) = &task_state.resource_requirements {
                    // 检查CPU资源
                    if allocation.resources.cpu > requirements.cpu {
                        log::warn!("Resource inconsistency: Task {} allocated more CPU ({}) than required ({})",
                                 allocation.task_id, allocation.resources.cpu, requirements.cpu);
                        return Ok(false);
                    }
                    
                    // 检查内存资源
                    if allocation.resources.memory > requirements.memory {
                        log::warn!("Resource inconsistency: Task {} allocated more memory ({}) than required ({})",
                                 allocation.task_id, allocation.resources.memory, requirements.memory);
                        return Ok(false);
                    }
                    
                    // 检查GPU资源
                    if allocation.resources.gpu > requirements.gpu {
                        log::warn!("Resource inconsistency: Task {} allocated more GPU ({}) than required ({})",
                                 allocation.task_id, allocation.resources.gpu, requirements.gpu);
                        return Ok(false);
                    }
                }
            } else {
                // 资源被分配给不存在的任务
                log::warn!("Resource inconsistency: Resource {} allocated to non-existent task {}",
                         resource_id, allocation.task_id);
                return Ok(false);
            }
            
            // 检查资源分配时间一致性
            if let (Some(task_state), Some(start_time), Some(end_time)) = (
                state.task_states.get(&allocation.task_id),
                allocation.allocated_at,
                allocation.released_at,
            ) {
                // 检查资源分配时间与任务执行时间一致
                if task_state.status == TaskStatus::Completed || task_state.status == TaskStatus::Failed {
                    if task_state.start_time.is_none() || task_state.end_time.is_none() {
                        log::warn!("Task time inconsistency: Completed task {} has no start/end time",
                                 allocation.task_id);
                        return Ok(false);
                    }
                    
                    let task_start = task_state.start_time.unwrap();
                    let task_end = task_state.end_time.unwrap();
                    
                    // 检查资源分配时间是否在任务执行时间之前
                    if start_time > task_start {
                        log::warn!("Resource timing inconsistency: Resource {} allocated after task {} started",
                                 resource_id, allocation.task_id);
                        return Ok(false);
                    }
                    
                    // 检查资源释放时间是否在任务执行时间之后
                    if end_time < task_end {
                        log::warn!("Resource timing inconsistency: Resource {} released before task {} ended",
                                 resource_id, allocation.task_id);
                        return Ok(false);
                    }
                }
            }
        }
        
        Ok(true)
    }
}

/// 验证结果
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ValidationResult {
    /// 是否一致
    pub is_consistent: bool,
    
    /// 详细信息
    pub details: ValidationDetails,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 验证时间
    pub timestamp: DateTime<Utc>,
}

/// 验证详细信息
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ValidationDetails {
    /// 内部一致性
    pub internal_consistency: bool,
    
    /// 事件一致性
    pub event_consistency: bool,
    
    /// 依赖一致性
    pub dependency_consistency: bool,
    
    /// 资源分配一致性
    pub resource_consistency: bool,
    
    /// 验证时间
    pub validation_time: DateTime<Utc>,
}

/// 一致性错误
#[derive(Debug, thiserror::Error)]
pub enum ConsistencyError {
    #[error("Failed to fetch state: {0}")]
    StateFetchError(String),
    
    #[error("Failed to fetch events: {0}")]
    EventRetrievalFailed(String),
    
    #[error("Failed to fetch workflow definition: {0}")]
    DefinitionRetrievalFailed(String),
    
    #[error("Invalid recovery point: {0}")]
    InvalidRecoveryPoint(String),
    
    #[error("Internal validation error: {0}")]
    InternalValidationError(String),
}

/// 一致性验证配置
#[derive(Clone, Debug)]
pub struct ConsistencyValidationConfig {
    /// 是否验证事件一致性
    pub verify_event_consistency: bool,
    
    /// 是否验证任务依赖
    pub verify_task_dependencies: bool,
    
    /// 是否验证资源分配
    pub verify_resource_allocations: bool,
    
    /// 忽略的不一致类型
    pub ignored_inconsistencies: Vec<InconsistencyType>,
}

/// 不一致类型
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum InconsistencyType {
    /// 时间顺序不一致
    TimeOrdering,
    
    /// 状态转换不一致
    StateTransition,
    
    /// 任务依赖不一致
    TaskDependency,
    
    /// 资源分配不一致
    ResourceAllocation,
    
    /// 事件序列不一致
    EventSequence,
}
```

工作流分布式追踪实现

```rust
/// 分布式追踪管理器
pub struct DistributedTracingManager {
    /// OpenTelemetry 追踪器
    tracer: opentelemetry::trace::Tracer,
    
    /// 是否启用
    enabled: AtomicBool,
    
    /// 追踪配置
    config: TracingConfig,
    
    /// 活跃工作流追踪
    active_traces: RwLock<HashMap<String, WorkflowTrace>>,
    
    /// 追踪存储
    trace_store: Arc<dyn TraceStore>,
    
    /// 敏感字段过滤器
    sensitive_filter: SensitiveDataFilter,
    
    /// 采样决策器
    sampler: Box<dyn Sampler>,
}

impl DistributedTracingManager {
    /// 创建新的分布式追踪管理器
    pub fn new(
        tracer: opentelemetry::trace::Tracer,
        config: TracingConfig,
        trace_store: Arc<dyn TraceStore>,
        sampler: Box<dyn Sampler>,
    ) -> Self {
        Self {
            tracer,
            enabled: AtomicBool::new(config.enabled),
            config,
            active_traces: RwLock::new(HashMap::new()),
            trace_store,
            sensitive_filter: SensitiveDataFilter::new(config.sensitive_fields.clone()),
            sampler,
        }
    }
    
    /// 启用/禁用追踪
    pub fn set_enabled(&self, enabled: bool) {
        self.enabled.store(enabled, Ordering::SeqCst);
    }
    
    /// 开始工作流追踪
    pub fn start_workflow_trace(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        workflow_version: &str,
        input_params: &Value,
    ) -> WorkflowSpan {
        if !self.enabled.load(Ordering::SeqCst) {
            return WorkflowSpan::no_op();
        }
        
        // 检查是否应该追踪该工作流
        if !self.should_trace_workflow(workflow_id, workflow_type) {
            return WorkflowSpan::no_op();
        }
        
        // 创建追踪上下文
        let mut span_builder = self.tracer.span_builder(format!("workflow:{}", workflow_type))
            .with_kind(opentelemetry::trace::SpanKind::Internal)
            .with_attributes(vec![
                KeyValue::new("workflow.id", workflow_id.to_string()),
                KeyValue::new("workflow.type", workflow_type.to_string()),
                KeyValue::new("workflow.version", workflow_version.to_string()),
            ]);
            
        // 添加输入参数（过滤敏感信息）
        let filtered_input = self.sensitive_filter.filter_data(input_params);
        span_builder = span_builder.with_attributes(vec![
            KeyValue::new("workflow.input", format!("{}", filtered_input)),
        ]);
        
        // 开始追踪
        let span = span_builder.start(&self.tracer);
        let context = Context::current_with_span(span);
        
        // 创建工作流追踪记录
        let trace = WorkflowTrace {
            workflow_id: workflow_id.to_string(),
            workflow_type: workflow_type.to_string(),
            start_time: Utc::now(),
            span_context: context.span().span_context().clone(),
            steps: RwLock::new(Vec::new()),
            end_time: None,
            status: WorkflowTraceStatus::Running,
        };
        
        // 保存活跃追踪
        let mut active_traces = self.active_traces.write().unwrap();
        active_traces.insert(workflow_id.to_string(), trace);
        
        // 返回追踪 span
        WorkflowSpan {
            span: context.span(),
            context,
            _is_no_op: false,
            trace_id: context.span().span_context().trace_id().to_string(),
        }
    }
    
    /// 开始任务追踪
    pub fn start_task_trace(
        &self,
        workflow_id: &str,
        task_id: &str,
        task_type: &str,
        input_params: &Value,
    ) -> TaskSpan {
        if !self.enabled.load(Ordering::SeqCst) {
            return TaskSpan::no_op();
        }
        
        // 获取工作流追踪上下文
        let workflow_trace = {
            let active_traces = self.active_traces.read().unwrap();
            match active_traces.get(workflow_id) {
                Some(trace) => trace.clone(),
                None => {
                    // 没有工作流追踪上下文，创建无操作span
                    return TaskSpan::no_op();
                }
            }
        };
        
        // 创建父追踪上下文
        let parent_context = opentelemetry::Context::new().with_remote_span_context(workflow_trace.span_context);
        
        // 创建任务追踪
        let mut span_builder = self.tracer.span_builder(format!("task:{}", task_type))
            .with_kind(opentelemetry::trace::SpanKind::Internal)
            .with_parent_context(parent_context.clone())
            .with_attributes(vec![
                KeyValue::new("workflow.id", workflow_id.to_string()),
                KeyValue::new("task.id", task_id.to_string()),
                KeyValue::new("task.type", task_type.to_string()),
            ]);
            
        // 添加输入参数（过滤敏感信息）
        let filtered_input = self.sensitive_filter.filter_data(input_params);
        span_builder = span_builder.with_attributes(vec![
            KeyValue::new("task.input", format!("{}", filtered_input)),
        ]);
        
        // 开始追踪
        let span = span_builder.start(&self.tracer);
        let context = Context::current_with_span(span);
        
        // 创建步骤记录
        let step = WorkflowTraceStep {
            step_id: task_id.to_string(),
            step_type: task_type.to_string(),
            start_time: Utc::now(),
            end_time: None,
            duration: Duration::default(),
            status: StepStatus::Running,
            error: None,
        };
        
        // 添加到工作流追踪记录
        {
            let mut active_traces = self.active_traces.write().unwrap();
            if let Some(trace) = active_traces.get_mut(workflow_id) {
                let mut steps = trace.steps.write().unwrap();
                steps.push(step);
            }
        }
        
        // 返回任务追踪span
        TaskSpan {
            span: context.span(),
            context,
            task_id: task_id.to_string(),
            workflow_id: workflow_id.to_string(),
            _is_no_op: false,
            trace_id: context.span().span_context().trace_id().to_string(),
        }
    }
    
    /// 结束工作流追踪
    pub fn end_workflow_trace(
        &self,
        workflow_id: &str,
        status: WorkflowTraceStatus,
        output: Option<&Value>,
        error: Option<&str>,
    ) {
        if !self.enabled.load(Ordering::SeqCst) {
            return;
        }
        
        // 获取工作流追踪记录
        let trace = {
            let mut active_traces = self.active_traces.write().unwrap();
            match active_traces.remove(workflow_id) {
                Some(mut trace) => {
                    // 更新追踪记录
                    trace.end_time = Some(Utc::now());
                    trace.status = status.clone();
                    trace
                }
                None => {
                    // 没有找到工作流追踪记录
                    return;
                }
            }
        };
        
        // 获取追踪上下文
        let context = opentelemetry::Context::new().with_remote_span_context(trace.span_context);
        let span = context.span();
        
        // 设置追踪属性
        if let Some(output_value) = output {
            // 过滤敏感数据
            let filtered_output = self.sensitive_filter.filter_data(output_value);
            span.set_attribute(KeyValue::new("workflow.output", format!("{}", filtered_output)));
        }
        
        // 设置错误信息
        if let Some(err) = error {
            span.set_attribute(KeyValue::new("workflow.error", err.to_string()));
            span.record_error(&opentelemetry::trace::Status::Error { description: err.to_string() });
        }
        
        // 设置状态
        match status {
            WorkflowTraceStatus::Completed => {
                span.set_attribute(KeyValue::new("workflow.status", "completed"));
                span.set_status(opentelemetry::trace::Status::Ok);
            }
            WorkflowTraceStatus::Failed => {
                span.set_attribute(KeyValue::new("workflow.status", "failed"));
                if error.is_none() {
                    span.record_error(&opentelemetry::trace::Status::Error { 
                        description: "Workflow failed".to_string() 
                    });
                }
            }
            WorkflowTraceStatus::Cancelled => {
                span.set_attribute(KeyValue::new("workflow.status", "cancelled"));
                span.set_status(opentelemetry::trace::Status::Cancelled);
            }
            _ => {
                span.set_attribute(KeyValue::new("workflow.status", format!("{:?}", status)));
            }
        }
        
        // 计算持续时间
        if let Some(end_time) = trace.end_time {
            let duration = end_time.signed_duration_since(trace.start_time);
            span.set_attribute(KeyValue::new("workflow.duration_ms", duration.num_milliseconds() as i64));
        }
        
        // 结束追踪
        span.end();
        
        // 存储追踪记录
        if let Err(e) = self.trace_store.store_workflow_trace(&trace) {
            log::error!("Failed to store workflow trace: {:?}", e);
        }
    }
    
    /// 结束任务追踪
    pub fn end_task_trace(
        &self,
        workflow_id: &str,
        task_id: &str,
        status: StepStatus,
        output: Option<&Value>,
        error: Option<&str>,
    ) {
        if !self.enabled.load(Ordering::SeqCst) {
            return;
        }
        
        // 更新工作流追踪记录中的任务状态
        {
            let active_traces = self.active_traces.read().unwrap();
            if let Some(trace) = active_traces.get(workflow_id) {
                let mut steps = trace.steps.write().unwrap();
                for step in steps.iter_mut() {
                    if step.step_id == task_id {
                        step.end_time = Some(Utc::now());
                        if let Some(start_time) = step.start_time.checked_sub_signed(Duration::seconds(0)) {
                            step.duration = Utc::now().signed_duration_since(start_time);
                        }
                        step.status = status.clone();
                        step.error = error.map(String::from);
                        break;
                    }
                }
            }
        }
        
        // 获取当前活跃任务的追踪上下文
        // 注：实际应用中，这里应该通过存储的TaskSpan或者追踪上下文查找
        // 但为简化示例，我们直接创建一个新的span并结束它
        
        let parent_trace = {
            let active_traces = self.active_traces.read().unwrap();
            match active_traces.get(workflow_id) {
                Some(trace) => trace.clone(),
                None => {
                    // 没有找到工作流追踪记录
                    return;
                }
            }
        };
        
        // 创建父追踪上下文
        let parent_context = opentelemetry::Context::new().with_remote_span_context(parent_trace.span_context);
        
        // 创建任务追踪
        let span = self.tracer.span_builder(format!("task_end:{}", task_id))
            .with_kind(opentelemetry::trace::SpanKind::Internal)
            .with_parent_context(parent_context)
            .with_attributes(vec![
                KeyValue::new("workflow.id", workflow_id.to_string()),
                KeyValue::new("task.id", task_id.to_string()),
                KeyValue::new("task.status", format!("{:?}", status)),
            ])
            .start(&self.tracer);
            
        // 设置输出数据
        if let Some(output_value) = output {
            // 过滤敏感数据
            let filtered_output = self.sensitive_filter.filter_data(output_value);
            span.set_attribute(KeyValue::new("task.output", format!("{}", filtered_output)));
        }
        
        // 设置错误信息
        if let Some(err) = error {
            span.set_attribute(KeyValue::new("task.error", err.to_string()));
            span.record_error(&opentelemetry::trace::Status::Error { description: err.to_string() });
        }
        
        // 设置状态
        match status {
            StepStatus::Completed => {
                span.set_status(opentelemetry::trace::Status::Ok);
            }
            StepStatus::Failed => {
                if error.is_none() {
                    span.record_error(&opentelemetry::trace::Status::Error { 
                        description: "Task failed".to_string() 
                    });
                }
            }
            StepStatus::Skipped => {
                span.set_attribute(KeyValue::new("task.skipped", true));
            }
            _ => {}
        }
        
        // 结束追踪
        span.end();
    }
    
    /// 判断是否应该追踪工作流
    fn should_trace_workflow(&self, workflow_id: &str, workflow_type: &str) -> bool {
        // 调用采样器决定是否需要追踪
        self.sampler.should_sample(
            SamplingParameters {
                workflow_id: workflow_id.to_string(),
                workflow_type: workflow_type.to_string(),
                timestamp: Utc::now(),
            }
        )
    }
}

/// 工作流追踪 Span
#[derive(Debug)]
pub struct WorkflowSpan {
    /// 追踪 span
    span: opentelemetry::trace::Span,
    
    /// 追踪上下文
    context: Context,
    
    /// 是否无操作
    _is_no_op: bool,
    
    /// 追踪 ID
    trace_id: String,
}

impl WorkflowSpan {
    /// 创建无操作 span
    pub fn no_op() -> Self {
        Self {
            span: opentelemetry::trace::Span::new(SpanContext::empty_context()),
            context: Context::new(),
            _is_no_op: true,
            trace_id: "no-op".to_string(),
        }
    }
    
    /// 添加事件
    pub fn add_event(&self, name: &str, attributes: Vec<KeyValue>) {
        if self._is_no_op {
            return;
        }
        
        self.span.add_event(name.to_string(), attributes);
    }
    
    /// 添加属性
    pub fn add_attribute(&self, key: &str, value: impl Into<Value>) {
        if self._is_no_op {
            return;
        }
        
        self.span.set_attribute(KeyValue::new(key, value));
    }
    
    /// 获取追踪 ID
    pub fn trace_id(&self) -> &str {
        &self.trace_id
    }
}

/// 任务追踪 Span
#[derive(Debug)]
pub struct TaskSpan {
    /// 追踪 span
    span: opentelemetry::trace::Span,
    
    /// 追踪上下文
    context: Context,
    
    /// 任务 ID
    task_id: String,
    
    /// 工作流 ID
    workflow_id: String,
    
    /// 是否无操作
    _is_no_op: bool,
    
    /// 追踪 ID
    trace_id: String,
}

impl TaskSpan {
    /// 创建无操作 span
    pub fn no_op() -> Self {
        Self {
            span: opentelemetry::trace::Span::new(SpanContext::empty_context()),
            context: Context::new(),
            task_id: "no-op".to_string(),
            workflow_id: "no-op".to_string(),
            _is_no_op: true,
            trace_id: "no-op".to_string(),
        }
    }
    
    /// 添加事件
    pub fn add_event(&self, name: &str, attributes: Vec<KeyValue>) {
        if self._is_no_op {
            return;
        }
        
        self.span.add_event(name.to_string(), attributes);
    }
    
    /// 添加属性
    pub fn add_attribute(&self, key: &str, value: impl Into<Value>) {
        if self._is_no_op {
            return;
        }
        
        self.span.set_attribute(KeyValue::new(key, value));
    }
    
    /// 获取追踪 ID
    pub fn trace_id(&self) -> &str {
        &self.trace_id
    }
}

/// 追踪存储接口
#[async_trait]
pub trait TraceStore: Send + Sync + 'static {
    /// 存储工作流追踪
    fn store_workflow_trace(&self, trace: &WorkflowTrace) -> Result<(), TracingError>;
    
    /// 获取工作流追踪
    async fn get_workflow_trace(&self, workflow_id: &str) -> Result<Option<WorkflowTrace>, TracingError>;
    
    /// 获取时间范围内的工作流追踪
    async fn get_workflow_traces_in_timerange(
        &self,
        start_time: DateTime<Utc>,
        end_time: DateTime<Utc>,
        limit: u32,
        offset: u32,
    ) -> Result<Vec<WorkflowTrace>, TracingError>;
    
    /// 通过追踪 ID 获取工作流追踪
    async fn get_workflow_trace_by_trace_id(&self, trace_id: &str) -> Result<Option<WorkflowTrace>, TracingError>;
}

/// 追踪错误
#[derive(Debug, thiserror::Error)]
pub enum TracingError {
    #[error("Failed to initialize tracer: {0}")]
    InitializationError(String),
    
    #[error("Failed to store trace: {0}")]
    StorageError(String),
    
    #[error("Failed to retrieve trace: {0}")]
    RetrievalError(String),
    
    #[error("Trace not found: {0}")]
    NotFound(String),
}

/// 追踪配置
#[derive(Clone, Debug)]
pub struct TracingConfig {
    /// 是否启用
    pub enabled: bool,
    
    /// 采样率
    pub sampling_ratio: f64,
    
    /// OpenTelemetry 导出器类型
    pub exporter_type: ExporterType,
    
    /// Jaeger 端点
    pub jaeger_endpoint: String,
    
    /// 服务名称
    pub service_name: String,
    
    /// 敏感字段列表
    pub sensitive_fields: Vec<String>,
    
    /// 最大队列大小
    pub max_queue_size: usize,
    
    /// 调度延迟（毫秒）
    pub scheduled_delay_ms: u64,
    
    /// 最大导出批量大小
    pub max_export_batch_size: usize,
}

/// 导出器类型
#[derive(Clone, Debug)]
pub enum ExporterType {
    /// Jaeger 导出器
    Jaeger,
    
    /// Zipkin 导出器
    Zipkin,
    
    /// OTLP 导出器
    OTLP,
    
    /// 控制台导出器
    Console,
}

/// 敏感数据过滤器
#[derive(Clone, Debug)]
pub struct SensitiveDataFilter {
    /// 敏感字段列表
    sensitive_fields: Vec<String>,
}

impl SensitiveDataFilter {
    /// 创建新的敏感数据过滤器
    pub fn new(sensitive_fields: Vec<String>) -> Self {
        Self { sensitive_fields }
    }
    
    /// 过滤数据
    pub fn filter_data(&self, data: &Value) -> Value {
        self.filter_value(data)
    }
    
    /// 过滤值
    fn filter_value(&self, value: &Value) -> Value {
        match value {
            Value::Object(map) => {
                let mut filtered_map = serde_json::Map::new();
                for (key, val) in map {
                    if self.sensitive_fields.contains(key) {
                        filtered_map.insert(key.clone(), Value::String("***REDACTED***".to_string()));
                    } else {
                        filtered_map.insert(key.clone(), self.filter_value(val));
                    }
                }
                Value::Object(filtered_map)
            }
            Value::Array(arr) => {
                let filtered_arr = arr.iter().map(|v| self.filter_value(v)).collect();
                Value::Array(filtered_arr)
            }
            _ => value.clone(),
        }
    }
}

/// 采样器接口
pub trait Sampler: Send + Sync + 'static {
    /// 决定是否采样
    fn should_sample(&self, params: SamplingParameters) -> bool;
}

/// 采样参数
#[derive(Clone, Debug)]
pub struct SamplingParameters {
    /// 工作流 ID
    pub workflow_id: String,
    
    /// 工作流类型
    pub workflow_type: String,
    
    /// 时间戳
    pub timestamp: DateTime<Utc>,
}

/// 概率采样器
#[derive(Clone, Debug)]
pub struct ProbabilitySampler {
    /// 采样率
    pub sampling_ratio: f64,
}

impl Sampler for ProbabilitySampler {
    fn should_sample(&self, _params: SamplingParameters) -> bool {
        let random_value: f64 = rand::random();
        random_value < self.sampling_ratio
    }
}

/// 类型过滤采样器
/// 类型过滤采样器
#[derive(Clone, Debug)]
pub struct TypeFilterSampler {
    /// 包含的工作流类型
    pub included_types: HashSet<String>,
    
    /// 采样率
    pub sampling_ratio: f64,
}

impl Sampler for TypeFilterSampler {
    fn should_sample(&self, params: SamplingParameters) -> bool {
        // 检查工作流类型是否在包含列表中
        if self.included_types.contains(&params.workflow_type) {
            // 应用采样率
            let random_value: f64 = rand::random();
            return random_value < self.sampling_ratio;
        }
        
        // 不在包含列表中的类型不采样
        false
    }
}

/// 基于向量时钟的分布式一致性协议
pub struct VectorClockConsistencyProtocol {
    /// 节点ID
    node_id: String,
    
    /// 向量时钟
    vector_clocks: RwLock<HashMap<String, HashMap<String, u64>>>,
    
    /// 数据存储
    data_store: Arc<dyn DataStore>,
    
    /// 冲突解决策略
    conflict_resolver: Arc<dyn ConflictResolver>,
    
    /// 一致性配置
    config: ConsistencyConfig,
}

impl VectorClockConsistencyProtocol {
    /// 创建新的向量时钟一致性协议
    pub fn new(
        node_id: String,
        data_store: Arc<dyn DataStore>,
        conflict_resolver: Arc<dyn ConflictResolver>,
        config: ConsistencyConfig,
    ) -> Self {
        Self {
            node_id,
            vector_clocks: RwLock::new(HashMap::new()),
            data_store,
            conflict_resolver,
            config,
        }
    }
    
    /// 获取向量时钟
    pub fn get_vector_clock(&self, object_id: &str) -> HashMap<String, u64> {
        let vector_clocks = self.vector_clocks.read().unwrap();
        
        vector_clocks.get(object_id)
            .cloned()
            .unwrap_or_default()
    }
    
    /// 更新向量时钟
    pub fn update_vector_clock(&self, object_id: &str, mut new_clock: HashMap<String, u64>) {
        let mut vector_clocks = self.vector_clocks.write().unwrap();
        
        let current_clock = vector_clocks.entry(object_id.to_string())
            .or_insert_with(HashMap::new);
        
        // 合并时钟，取每个节点的最大值
        for (node, &version) in &new_clock {
            let current_version = current_clock.entry(node.clone()).or_insert(0);
            *current_version = (*current_version).max(version);
        }
    }
    
    /// 递增向量时钟
    pub fn increment_vector_clock(&self, object_id: &str) -> HashMap<String, u64> {
        let mut vector_clocks = self.vector_clocks.write().unwrap();
        
        let clock = vector_clocks.entry(object_id.to_string())
            .or_insert_with(HashMap::new);
        
        // 递增当前节点的时钟
        let version = clock.entry(self.node_id.clone()).or_insert(0);
        *version += 1;
        
        clock.clone()
    }
    
    /// 检查向量时钟是否存在因果关系
    pub fn check_causality(
        &self,
        clock1: &HashMap<String, u64>,
        clock2: &HashMap<String, u64>,
    ) -> CausalityResult {
        let mut clock1_dominates = true;
        let mut clock2_dominates = true;
        
        // 检查 clock1 是否支配 clock2
        for (node, &version1) in clock1 {
            let version2 = clock2.get(node).copied().unwrap_or(0);
            
            if version1 < version2 {
                clock1_dominates = false;
            }
            
            if version1 > version2 {
                clock2_dominates = false;
            }
        }
        
        // 检查 clock2 中的其他节点
        for (node, &version2) in clock2 {
            if !clock1.contains_key(node) && version2 > 0 {
                clock1_dominates = false;
            }
        }
        
        if clock1_dominates && clock2_dominates {
            CausalityResult::Concurrent
        } else if clock1_dominates {
            CausalityResult::Before
        } else if clock2_dominates {
            CausalityResult::After
        } else {
            CausalityResult::Concurrent
        }
    }
    
    /// 写入数据
    pub async fn write_data(
        &self,
        object_id: &str,
        object_type: &str,
        data: Value,
    ) -> Result<(), ConsistencyError> {
        // 增加向量时钟
        let clock = self.increment_vector_clock(object_id);
        
        // 创建数据操作记录
        let op = DataOperation {
            object_id: object_id.to_string(),
            object_type: object_type.to_string(),
            data: data.clone(),
            vector_clock: clock.clone(),
            timestamp: Utc::now(),
            node_id: self.node_id.clone(),
            operation_type: OperationType::Write,
        };
        
        // 保存数据
        self.data_store.store_data(&op).await?;
        
        // 根据一致性级别决定同步策略
        match self.config.consistency_level {
            ConsistencyLevel::Strong => {
                // 强一致性：同步复制到所有节点
                self.sync_to_all_nodes(&op).await?;
            }
            ConsistencyLevel::Causal => {
                // 因果一致性：异步复制，但读取时需确保因果一致性
                tokio::spawn(self.clone().sync_to_all_nodes(op.clone()));
            }
            ConsistencyLevel::Eventual => {
                // 最终一致性：异步复制
                tokio::spawn(self.clone().sync_to_all_nodes(op.clone()));
            }
        }
        
        Ok(())
    }
    
    /// 读取数据
    pub async fn read_data(
        &self,
        object_id: &str,
        consistency_level: Option<ConsistencyLevel>,
    ) -> Result<Value, ConsistencyError> {
        // 获取当前向量时钟
        let clock = self.get_vector_clock(object_id);
        
        // 使用提供的一致性级别或默认配置
        let level = consistency_level.unwrap_or(self.config.consistency_level);
        
        match level {
            ConsistencyLevel::Strong => {
                // 强一致性：从所有节点获取最新数据
                let remote_ops = self.fetch_from_all_nodes(object_id).await?;
                
                // 解决可能的冲突
                if remote_ops.is_empty() {
                    return Err(ConsistencyError::DataNotFound(object_id.to_string()));
                }
                
                let resolved_data = self.resolve_conflicts(remote_ops).await?;
                return Ok(resolved_data);
            }
            ConsistencyLevel::Causal => {
                // 因果一致性：确保所有因果相关的更新都已应用
                let local_op = self.data_store.get_data(object_id).await?;
                
                if let Some(op) = local_op {
                    // 检查是否需要同步远程数据
                    let remote_ops = self.fetch_from_all_nodes(object_id).await?;
                    
                    for remote_op in &remote_ops {
                        // 检查是否有因果关系
                        let causality = self.check_causality(&op.vector_clock, &remote_op.vector_clock);
                        
                        if causality == CausalityResult::After {
                            // 存在因果依赖，需要先应用远程更新
                            self.apply_remote_operation(remote_op).await?;
                        }
                    }
                    
                    // 获取最新的本地数据
                    let updated_op = self.data_store.get_data(object_id).await?
                        .ok_or_else(|| ConsistencyError::DataNotFound(object_id.to_string()))?;
                    
                    return Ok(updated_op.data);
                } else {
                    // 本地没有数据，从远程获取
                    let remote_ops = self.fetch_from_all_nodes(object_id).await?;
                    
                    if remote_ops.is_empty() {
                        return Err(ConsistencyError::DataNotFound(object_id.to_string()));
                    }
                    
                    let resolved_data = self.resolve_conflicts(remote_ops).await?;
                    return Ok(resolved_data);
                }
            }
            ConsistencyLevel::Eventual => {
                // 最终一致性：直接返回本地数据
                let local_op = self.data_store.get_data(object_id).await?;
                
                if let Some(op) = local_op {
                    return Ok(op.data);
                } else {
                    // 本地没有数据，从远程获取
                    let remote_ops = self.fetch_from_all_nodes(object_id).await?;
                    
                    if remote_ops.is_empty() {
                        return Err(ConsistencyError::DataNotFound(object_id.to_string()));
                    }
                    
                    let resolved_data = self.resolve_conflicts(remote_ops).await?;
                    return Ok(resolved_data);
                }
            }
        }
    }
    
    /// 同步数据到所有节点
    async fn sync_to_all_nodes(&self, op: &DataOperation) -> Result<(), ConsistencyError> {
        // 在实际环境中，这里会调用网络API将操作发送到其他节点
        // 为简化示例，这里只是模拟同步过程
        
        let all_nodes = self.get_all_nodes().await?;
        
        let mut tasks = Vec::new();
        
        for node in all_nodes {
            if node != self.node_id {
                let op_clone = op.clone();
                let task = tokio::spawn(async move {
                    // 向节点发送操作
                    // 实际实现中，这里会使用网络调用
                    // 如: self.network_client.send_operation(node, op_clone).await
                    
                    // 模拟网络延迟
                    tokio::time::sleep(Duration::from_millis(100)).await;
                    
                    Ok::<_, ConsistencyError>(())
                });
                
                tasks.push(task);
            }
        }
        
        // 等待所有同步任务完成
        for task in tasks {
            task.await.map_err(|e| ConsistencyError::SyncError(e.to_string()))??;
        }
        
        Ok(())
    }
    
    /// 从所有节点获取数据
    async fn fetch_from_all_nodes(&self, object_id: &str) -> Result<Vec<DataOperation>, ConsistencyError> {
        // 在实际环境中，这里会调用网络API从其他节点获取数据
        // 为简化示例，这里只是模拟获取过程
        
        let all_nodes = self.get_all_nodes().await?;
        
        let mut operations = Vec::new();
        
        // 添加本地数据
        if let Some(local_op) = self.data_store.get_data(object_id).await? {
            operations.push(local_op);
        }
        
        let mut tasks = Vec::new();
        
        for node in all_nodes {
            if node != self.node_id {
                let object_id = object_id.to_string();
                let task = tokio::spawn(async move {
                    // 从节点获取数据
                    // 实际实现中，这里会使用网络调用
                    // 如: self.network_client.get_data(node, object_id).await
                    
                    // 模拟网络延迟
                    tokio::time::sleep(Duration::from_millis(100)).await;
                    
                    // 模拟返回空数据
                    Ok::<Option<DataOperation>, ConsistencyError>(None)
                });
                
                tasks.push(task);
            }
        }
        
        // 等待所有获取任务完成
        for task in tasks {
            if let Some(op) = task.await.map_err(|e| ConsistencyError::FetchError(e.to_string()))?? {
                operations.push(op);
            }
        }
        
        Ok(operations)
    }
    
    /// 解决冲突
    async fn resolve_conflicts(&self, operations: Vec<DataOperation>) -> Result<Value, ConsistencyError> {
        if operations.is_empty() {
            return Err(ConsistencyError::NoDataAvailable);
        }
        
        if operations.len() == 1 {
            return Ok(operations[0].data.clone());
        }
        
        // 查找具有最新向量时钟的操作
        let mut latest_ops = Vec::new();
        
        for op in &operations {
            if latest_ops.is_empty() {
                latest_ops.push(op);
                continue;
            }
            
            let causality = self.check_causality(&latest_ops[0].vector_clock, &op.vector_clock);
            
            match causality {
                CausalityResult::Before => {
                    // 当前操作晚于最新操作
                    latest_ops.clear();
                    latest_ops.push(op);
                }
                CausalityResult::Concurrent => {
                    // 当前操作与最新操作并发
                    latest_ops.push(op);
                }
                _ => {
                    // 当前操作早于最新操作，忽略
                }
            }
        }
        
        if latest_ops.len() == 1 {
            return Ok(latest_ops[0].data.clone());
        }
        
        // 多个并发操作，需要解决冲突
        let object_type = latest_ops[0].object_type.clone();
        
        let mut values = Vec::new();
        for op in latest_ops {
            values.push(op.data.clone());
        }
        
        // 使用冲突解决器解决冲突
        let resolved_data = self.conflict_resolver.resolve(&object_type, values).await?;
        
        Ok(resolved_data)
    }
    
    /// 应用远程操作
    async fn apply_remote_operation(&self, op: &DataOperation) -> Result<(), ConsistencyError> {
        // 更新向量时钟
        self.update_vector_clock(&op.object_id, op.vector_clock.clone());
        
        // 将操作应用到本地存储
        self.data_store.store_data(op).await?;
        
        Ok(())
    }
    
    /// 获取所有节点
    async fn get_all_nodes(&self) -> Result<Vec<String>, ConsistencyError> {
        // 在实际实现中，这里会查询服务发现系统
        // 为简化示例，这里返回固定的节点列表
        
        Ok(vec![
            "node1".to_string(),
            "node2".to_string(),
            "node3".to_string(),
        ])
    }
}

impl Clone for VectorClockConsistencyProtocol {
    fn clone(&self) -> Self {
        Self {
            node_id: self.node_id.clone(),
            vector_clocks: RwLock::new(self.vector_clocks.read().unwrap().clone()),
            data_store: self.data_store.clone(),
            conflict_resolver: self.conflict_resolver.clone(),
            config: self.config.clone(),
        }
    }
}

/// 数据操作
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct DataOperation {
    /// 对象ID
    pub object_id: String,
    
    /// 对象类型
    pub object_type: String,
    
    /// 数据
    pub data: Value,
    
    /// 向量时钟
    pub vector_clock: HashMap<String, u64>,
    
    /// 时间戳
    pub timestamp: DateTime<Utc>,
    
    /// 节点ID
    pub node_id: String,
    
    /// 操作类型
    pub operation_type: OperationType,
}

/// 操作类型
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub enum OperationType {
    /// 读取
    Read,
    
    /// 写入
    Write,
    
    /// 删除
    Delete,
}

/// 因果关系结果
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum CausalityResult {
    /// 在之前（因果关系：第一个操作在第二个操作之前）
    Before,
    
    /// 在之后（因果关系：第一个操作在第二个操作之后）
    After,
    
    /// 并发（无因果关系）
    Concurrent,
}

/// 数据存储接口
#[async_trait]
pub trait DataStore: Send + Sync + 'static {
    /// 存储数据
    async fn store_data(&self, operation: &DataOperation) -> Result<(), ConsistencyError>;
    
    /// 获取数据
    async fn get_data(&self, object_id: &str) -> Result<Option<DataOperation>, ConsistencyError>;
    
    /// 获取对象的所有操作历史
    async fn get_operation_history(&self, object_id: &str) -> Result<Vec<DataOperation>, ConsistencyError>;
}

/// 冲突解决器接口
#[async_trait]
pub trait ConflictResolver: Send + Sync + 'static {
    /// 解决冲突
    async fn resolve(&self, object_type: &str, values: Vec<Value>) -> Result<Value, ConsistencyError>;
}

/// 一致性错误
#[derive(Debug, thiserror::Error)]
pub enum ConsistencyError {
    #[error("Storage error: {0}")]
    StorageError(String),
    
    #[error("Sync error: {0}")]
    SyncError(String),
    
    #[error("Fetch error: {0}")]
    FetchError(String),
    
    #[error("Data not found: {0}")]
    DataNotFound(String),
    
    #[error("No data available")]
    NoDataAvailable,
    
    #[error("Conflict resolution failed: {0}")]
    ConflictResolutionFailed(String),
    
    #[error("Invalid vector clock: {0}")]
    InvalidVectorClock(String),
}

/// 一致性级别
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum ConsistencyLevel {
    /// 强一致性：同步复制，保证一致，但可能影响性能
    Strong,
    
    /// 因果一致性：保证因果关系的操作顺序
    Causal,
    
    /// 最终一致性：异步复制，可能有短暂不一致
    Eventual,
}

/// 一致性配置
#[derive(Clone, Debug)]
pub struct ConsistencyConfig {
    /// 一致性级别
    pub consistency_level: ConsistencyLevel,
    
    /// 同步超时时间
    pub sync_timeout: Duration,
    
    /// 最大重试次数
    pub max_retries: u32,
    
    /// 重试退避时间
    pub retry_backoff: Duration,
}

/// 默认的冲突解决器实现
pub struct DefaultConflictResolver;

#[async_trait]
impl ConflictResolver for DefaultConflictResolver {
    async fn resolve(&self, object_type: &str, values: Vec<Value>) -> Result<Value, ConsistencyError> {
        if values.is_empty() {
            return Err(ConsistencyError::NoDataAvailable);
        }
        
        if values.len() == 1 {
            return Ok(values[0].clone());
        }
        
        match object_type {
            "workflow_definition" => {
                // 对于工作流定义，选择最新版本
                let mut latest_value = values[0].clone();
                let mut latest_version = 0;
                
                for value in values {
                    if let Some(version) = value.get("version").and_then(|v| v.as_u64()) {
                        if version > latest_version {
                            latest_version = version;
                            latest_value = value;
                        }
                    }
                }
                
                Ok(latest_value)
            }
            "workflow_instance" => {
                // 对于工作流实例，合并状态，选择最新的状态
                let mut merged_value = json!({});
                
                for value in values {
                    if let Some(obj) = value.as_object() {
                        for (key, val) in obj {
                            // 合并非工作流状态字段
                            if key != "status" && key != "task_states" {
                                merged_value[key] = val.clone();
                            }
                            
                            // 对于状态字段，选择优先级最高的状态
                            if key == "status" {
                                let current_status = merged_value.get("status")
                                    .and_then(|s| s.as_str())
                                    .unwrap_or("");
                                
                                let new_status = val.as_str().unwrap_or("");
                                
                                let priority_status = self.get_status_priority(current_status, new_status);
                                merged_value["status"] = json!(priority_status);
                            }
                            
                            // 对于任务状态，合并各个任务的最新状态
                            if key == "task_states" && val.is_object() {
                                if !merged_value.get("task_states").is_some() {
                                    merged_value["task_states"] = json!({});
                                }
                                
                                let task_states = val.as_object().unwrap();
                                
                                for (task_id, task_state) in task_states {
                                    if !merged_value["task_states"].get(task_id).is_some() {
                                        merged_value["task_states"][task_id] = task_state.clone();
                                    } else {
                                        // 合并任务状态
                                        let current_status = merged_value["task_states"][task_id].get("status")
                                            .and_then(|s| s.as_str())
                                            .unwrap_or("");
                                        
                                        let new_status = task_state.get("status")
                                            .and_then(|s| s.as_str())
                                            .unwrap_or("");
                                        
                                        let priority_status = self.get_status_priority(current_status, new_status);
                                        merged_value["task_states"][task_id]["status"] = json!(priority_status);
                                    }
                                }
                            }
                        }
                    }
                }
                
                Ok(merged_value)
            }
            _ => {
                // 对于其他类型，选择最后一个值
                Ok(values.last().unwrap().clone())
            }
        }
    }
}

impl DefaultConflictResolver {
    /// 获取状态优先级
    fn get_status_priority(&self, status1: &str, status2: &str) -> &str {
        // 状态优先级: Completed > Failed > Cancelled > Running > Paused > Created
        let priority = |status: &str| -> u8 {
            match status {
                "Completed" => 6,
                "Failed" => 5,
                "Cancelled" => 4,
                "Running" => 3,
                "Paused" => 2,
                "Created" => 1,
                _ => 0,
            }
        };
        
        if priority(status1) >= priority(status2) {
            status1
        } else {
            status2
        }
    }
}

/// 实现一个简单的内存数据存储
pub struct InMemoryDataStore {
    /// 数据存储
    data: RwLock<HashMap<String, Vec<DataOperation>>>,
}

impl InMemoryDataStore {
    /// 创建新的内存数据存储
    pub fn new() -> Self {
        Self {
            data: RwLock::new(HashMap::new()),
        }
    }
}

#[async_trait]
impl DataStore for InMemoryDataStore {
    async fn store_data(&self, operation: &DataOperation) -> Result<(), ConsistencyError> {
        let mut data = self.data.write().unwrap();
        
        let operations = data.entry(operation.object_id.clone())
            .or_insert_with(Vec::new);
        
        operations.push(operation.clone());
        
        Ok(())
    }
    
    async fn get_data(&self, object_id: &str) -> Result<Option<DataOperation>, ConsistencyError> {
        let data = self.data.read().unwrap();
        
        if let Some(operations) = data.get(object_id) {
            if operations.is_empty() {
                return Ok(None);
            }
            
            // 返回最新的操作
            return Ok(Some(operations.last().unwrap().clone()));
        }
        
        Ok(None)
    }
    
    async fn get_operation_history(&self, object_id: &str) -> Result<Vec<DataOperation>, ConsistencyError> {
        let data = self.data.read().unwrap();
        
        if let Some(operations) = data.get(object_id) {
            return Ok(operations.clone());
        }
        
        Ok(Vec::new())
    }
}
```

以上代码实现了基于向量时钟的分布式一致性协议，支持三种一致性级别：
强一致性、因果一致性和最终一致性。
该协议使用向量时钟来追踪分布式系统中操作的因果关系，并能够检测并发修改并解决冲突。
此外，还实现了几个关键组件：
数据存储接口和内存存储实现
冲突解决器接口和默认实现
类型过滤采样器，用于追踪系统
完整的向量时钟一致性协议实现，包括向量时钟管理、数据同步和冲突解决等

该实现保证了在分布式环境中工作流状态的一致性，
允许根据不同的需求选择合适的一致性级别，
并能够自动解决多节点并发修改导致的数据冲突

现在，我们将实现分布式工作流事务协调器和状态快照机制：

```rust
/// 分布式工作流事务协调器
pub struct WorkflowTransactionCoordinator {
    /// 协调器ID
    coordinator_id: String,
    
    /// 节点ID
    node_id: String,
    
    /// 事务存储
    transaction_store: Arc<dyn TransactionStore>,
    
    /// 资源管理器注册表
    resource_managers: RwLock<HashMap<String, Arc<dyn ResourceManager>>>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
    
    /// 事务超时
    transaction_timeout: Duration,
    
    /// 状态检查间隔
    status_check_interval: Duration,
    
    /// 是否启用两阶段提交
    enable_two_phase_commit: bool,
}

impl WorkflowTransactionCoordinator {
    /// 创建新的事务协调器
    pub fn new(
        coordinator_id: String,
        node_id: String,
        transaction_store: Arc<dyn TransactionStore>,
        lock_service: Arc<dyn LockService>,
        state_store: Arc<dyn StateStore>,
        observability: Arc<WorkflowObservability>,
        config: TransactionCoordinatorConfig,
    ) -> Self {
        Self {
            coordinator_id,
            node_id,
            transaction_store,
            resource_managers: RwLock::new(HashMap::new()),
            lock_service,
            state_store,
            observability,
            transaction_timeout: config.transaction_timeout,
            status_check_interval: config.status_check_interval,
            enable_two_phase_commit: config.enable_two_phase_commit,
        }
    }
    
    /// 注册资源管理器
    pub fn register_resource_manager(
        &self,
        resource_type: String,
        manager: Arc<dyn ResourceManager>,
    ) {
        let mut managers = self.resource_managers.write().unwrap();
        managers.insert(resource_type, manager);
    }
    
    /// 开始新事务
    pub async fn begin_transaction(&self) -> Result<TransactionId, TransactionError> {
        let tx_id = TransactionId::new();
        
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(&tx_id.to_string(), "begin_transaction");
        let _trace_guard = trace_ctx.enter();
        
        // 创建事务记录
        let transaction = Transaction {
            id: tx_id.clone(),
            status: TransactionStatus::Active,
            coordinator_id: self.coordinator_id.clone(),
            start_time: Utc::now(),
            last_update_time: Utc::now(),
            participants: Vec::new(),
            changes: Vec::new(),
            metadata: HashMap::new(),
        };
        
        // 存储事务
        self.transaction_store.create_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
        
        // 记录指标
        self.observability.record_transaction_started(&tx_id.to_string());
        
        Ok(tx_id)
    }
    
    /// 为事务注册资源变更
    pub async fn register_resource_change(
        &self,
        tx_id: &TransactionId,
        resource_type: String,
        change: ResourceChange,
    ) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(&tx_id.to_string(), "register_resource_change");
        let _trace_guard = trace_ctx.enter();
        
        // 获取事务
        let mut transaction = self.transaction_store.get_transaction(tx_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?
            .ok_or_else(|| TransactionError::TransactionNotFound(tx_id.to_string()))?;
        
        // 验证事务状态
        if transaction.status != TransactionStatus::Active {
            return Err(TransactionError::InvalidTransactionStatus(
                format!("事务状态必须为Active，当前为: {:?}", transaction.status)
            ));
        }
        
        // 确保资源类型存在
        if !self.resource_managers.read().unwrap().contains_key(&resource_type) {
            return Err(TransactionError::UnsupportedResourceType(resource_type));
        }
        
        // 添加资源变更
        let change_record = ResourceChangeRecord {
            id: Uuid::new_v4().to_string(),
            transaction_id: tx_id.clone(),
            resource_type: resource_type.clone(),
            change: change.clone(),
            status: ResourceChangeStatus::Registered,
            created_at: Utc::now(),
        };
        
        transaction.changes.push(change_record.clone());
        
        // 如果是新参与者，添加到参与者列表
        if !transaction.participants.contains(&resource_type) {
            transaction.participants.push(resource_type.clone());
        }
        
        // 更新事务
        transaction.last_update_time = Utc::now();
        self.transaction_store.update_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
        
        Ok(())
    }
    
    /// 提交事务
    pub async fn commit_transaction(&self, tx_id: &TransactionId) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(&tx_id.to_string(), "commit_transaction");
        let _trace_guard = trace_ctx.enter();
        
        // 获取事务锁
        let lock_key = format!("transaction:lock:{}", tx_id);
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.node_id.clone(), Duration::from_secs(60)).await
            .map_err(|e| TransactionError::LockServiceError(e.to_string()))?;
            
        if !lock_acquired {
            return Err(TransactionError::LockServiceError(
                format!("无法获取事务锁: {}", tx_id)
            ));
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone).await;
            });
        });
        
        // 获取事务
        let mut transaction = self.transaction_store.get_transaction(tx_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?
            .ok_or_else(|| TransactionError::TransactionNotFound(tx_id.to_string()))?;
        
        // 验证事务状态
        if transaction.status != TransactionStatus::Active {
            return Err(TransactionError::InvalidTransactionStatus(
                format!("事务状态必须为Active，当前为: {:?}", transaction.status)
            ));
        }
        
        // 检查事务是否超时
        let now = Utc::now();
        if now - transaction.start_time > self.transaction_timeout {
            // 将事务标记为超时
            transaction.status = TransactionStatus::TimedOut;
            self.transaction_store.update_transaction(&transaction).await
                .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                
            return Err(TransactionError::TransactionTimedOut(tx_id.to_string()));
        }
        
        // 处理两阶段提交或单阶段提交
        if self.enable_two_phase_commit {
            // 两阶段提交
            // 阶段1：准备
            if let Err(e) = self.prepare_transaction(&transaction).await {
                // 准备失败，回滚所有已准备的资源
                self.rollback_prepared_resources(&transaction).await?;
                
                // 更新事务状态为失败
                transaction.status = TransactionStatus::Failed;
                self.transaction_store.update_transaction(&transaction).await
                    .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                    
                return Err(e);
            }
            
            // 更新事务状态为准备完成
            transaction.status = TransactionStatus::Prepared;
            self.transaction_store.update_transaction(&transaction).await
                .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
            // 阶段2：提交
            if let Err(e) = self.commit_prepared_transaction(&transaction).await {
                // 提交失败，回滚所有已准备的资源
                self.rollback_prepared_resources(&transaction).await?;
                
                // 更新事务状态为失败
                transaction.status = TransactionStatus::Failed;
                self.transaction_store.update_transaction(&transaction).await
                    .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                    
                return Err(e);
            }
        } else {
            // 单阶段提交：直接提交所有变更
            if let Err(e) = self.commit_resources(&transaction).await {
                // 提交失败，尝试回滚
                if let Err(rollback_err) = self.rollback_resources(&transaction).await {
                    // 回滚也失败，记录错误
                    self.observability.record_transaction_error(
                        &tx_id.to_string(),
                        "commit_and_rollback_failed",
                        &format!("提交失败: {}，回滚也失败: {}", e, rollback_err),
                    );
                }
                
                // 更新事务状态为失败
                transaction.status = TransactionStatus::Failed;
                self.transaction_store.update_transaction(&transaction).await
                    .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                    
                return Err(e);
            }
        }
        
        // 更新事务状态为已提交
        transaction.status = TransactionStatus::Committed;
        transaction.last_update_time = Utc::now();
        self.transaction_store.update_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 记录指标
        self.observability.record_transaction_committed(&tx_id.to_string());
        
        Ok(())
    }
    
    /// 回滚事务
    pub async fn rollback_transaction(&self, tx_id: &TransactionId) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(&tx_id.to_string(), "rollback_transaction");
        let _trace_guard = trace_ctx.enter();
        
        // 获取事务锁
        let lock_key = format!("transaction:lock:{}", tx_id);
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.node_id.clone(), Duration::from_secs(60)).await
            .map_err(|e| TransactionError::LockServiceError(e.to_string()))?;
            
        if !lock_acquired {
            return Err(TransactionError::LockServiceError(
                format!("无法获取事务锁: {}", tx_id)
            ));
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone).await;
            });
        });
        
        // 获取事务
        let mut transaction = self.transaction_store.get_transaction(tx_id).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?
            .ok_or_else(|| TransactionError::TransactionNotFound(tx_id.to_string()))?;
        
        // 验证事务状态
        if transaction.status == TransactionStatus::Committed {
            return Err(TransactionError::InvalidTransactionStatus(
                "已提交的事务不能回滚".to_string()
            ));
        }
        
        if transaction.status == TransactionStatus::RolledBack {
            // 已经回滚，直接返回
            return Ok(());
        }
        
        // 回滚资源变更
        if let Err(e) = self.rollback_resources(&transaction).await {
            // 回滚失败
            self.observability.record_transaction_error(
                &tx_id.to_string(),
                "rollback_failed",
                &format!("回滚失败: {}", e),
            );
            
            // 更新事务状态为失败
            transaction.status = TransactionStatus::Failed;
            self.transaction_store.update_transaction(&transaction).await
                .map_err(|e| TransactionError::StorageError(e.to_string()))?;
                
            return Err(e);
        }
        
        // 更新事务状态为已回滚
        transaction.status = TransactionStatus::RolledBack;
        transaction.last_update_time = Utc::now();
        self.transaction_store.update_transaction(&transaction).await
            .map_err(|e| TransactionError::StorageError(e.to_string()))?;
            
        // 记录指标
        self.observability.record_transaction_rolledback(&tx_id.to_string());
        
        Ok(())
    }
    
    /// 准备事务（两阶段提交第一阶段）
    async fn prepare_transaction(&self, transaction: &Transaction) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(
            &transaction.id.to_string(),
            "prepare_transaction",
        );
        let _trace_guard = trace_ctx.enter();
        
        let resource_managers = self.resource_managers.read().unwrap();
        
        for change in &transaction.changes {
            // 获取资源管理器
            let manager = resource_managers.get(&change.resource_type)
                .ok_or_else(|| TransactionError::UnsupportedResourceType(change.resource_type.clone()))?;
                
            // 准备变更
            manager.prepare_change(&transaction.id, &change.change).await
                .map_err(|e| TransactionError::ResourceOperationFailed(
                    format!("准备资源变更失败: {}", e)
                ))?;
        }
        
        Ok(())
    }
    
    /// 提交准备好的事务（两阶段提交第二阶段）
    async fn commit_prepared_transaction(&self, transaction: &Transaction) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(
            &transaction.id.to_string(),
            "commit_prepared_transaction",
        );
        let _trace_guard = trace_ctx.enter();
        
        let resource_managers = self.resource_managers.read().unwrap();
        
        for change in &transaction.changes {
            // 获取资源管理器
            let manager = resource_managers.get(&change.resource_type)
                .ok_or_else(|| TransactionError::UnsupportedResourceType(change.resource_type.clone()))?;
                
            // 提交变更
            manager.commit_change(&transaction.id, &change.change).await
                .map_err(|e| TransactionError::ResourceOperationFailed(
                    format!("提交资源变更失败: {}", e)
                ))?;
        }
        
        Ok(())
    }
    
    /// 回滚已准备的资源
    async fn rollback_prepared_resources(&self, transaction: &Transaction) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(
            &transaction.id.to_string(),
            "rollback_prepared_resources",
        );
        let _trace_guard = trace_ctx.enter();
        
        let resource_managers = self.resource_managers.read().unwrap();
        
        for change in &transaction.changes {
            // 获取资源管理器
            if let Some(manager) = resource_managers.get(&change.resource_type) {
                // 回滚变更
                if let Err(e) = manager.rollback_change(&transaction.id, &change.change).await {
                    // 记录错误但继续回滚其他资源
                    self.observability.record_transaction_error(
                        &transaction.id.to_string(),
                        "rollback_prepared_resource_failed",
                        &format!("回滚准备好的资源失败: 资源类型={}, 错误={}", change.resource_type, e),
                    );
                }
            }
        }
        
        Ok(())
    }
    
    /// 直接提交资源（单阶段提交）
    async fn commit_resources(&self, transaction: &Transaction) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(
            &transaction.id.to_string(),
            "commit_resources",
        );
        let _trace_guard = trace_ctx.enter();
        
        let resource_managers = self.resource_managers.read().unwrap();
        
        // 记录已成功提交的变更，用于部分失败时回滚
        let mut committed_changes = Vec::new();
        
        for change in &transaction.changes {
            // 获取资源管理器
            let manager = resource_managers.get(&change.resource_type)
                .ok_or_else(|| TransactionError::UnsupportedResourceType(change.resource_type.clone()))?;
                
            // 提交变更
            match manager.commit_change(&transaction.id, &change.change).await {
                Ok(_) => {
                    committed_changes.push(change);
                },
                Err(e) => {
                    // 提交失败，回滚已提交的变更
                    for committed in committed_changes {
                        if let Some(manager) = resource_managers.get(&committed.resource_type) {
                            if let Err(rollback_err) = manager.rollback_change(&transaction.id, &committed.change).await {
                                // 记录回滚错误
                                self.observability.record_transaction_error(
                                    &transaction.id.to_string(),
                                    "rollback_after_partial_commit_failed",
                                    &format!("部分提交后回滚失败: 资源类型={}, 错误={}", committed.resource_type, rollback_err),
                                );
                            }
                        }
                    }
                    
                    return Err(TransactionError::ResourceOperationFailed(
                        format!("提交资源变更失败: 资源类型={}, 错误={}", change.resource_type, e)
                    ));
                }
            }
        }
        
        Ok(())
    }
    
    /// 回滚资源
    async fn rollback_resources(&self, transaction: &Transaction) -> Result<(), TransactionError> {
        // 创建事务追踪上下文
        let trace_ctx = self.observability.create_transaction_span(
            &transaction.id.to_string(),
            "rollback_resources",
        );
        let _trace_guard = trace_ctx.enter();
        
        let resource_managers = self.resource_managers.read().unwrap();
        let mut errors = Vec::new();
        
        for change in &transaction.changes {
            // 获取资源管理器
            if let Some(manager) = resource_managers.get(&change.resource_type) {
                // 回滚变更
                if let Err(e) = manager.rollback_change(&transaction.id, &change.change).await {
                    // 记录错误但继续回滚其他资源
                    let error_msg = format!("回滚资源失败: 资源类型={}, 错误={}", change.resource_type, e);
                    self.observability.record_transaction_error(
                        &transaction.id.to_string(),
                        "rollback_resource_failed",
                        &error_msg,
                    );
                    errors.push(error_msg);
                }
            }
        }
        
        if errors.is_empty() {
            Ok(())
        } else {
            Err(TransactionError::ResourceOperationFailed(
                format!("部分资源回滚失败: {}", errors.join("; "))
            ))
        }
    }
    
    /// 启动超时事务清理任务
    pub fn start_timeout_cleaner(&self) -> JoinHandle<()> {
        let coordinator_id = self.coordinator_id.clone();
        let transaction_store = self.transaction_store.clone();
        let status_check_interval = self.status_check_interval;
        let transaction_timeout = self.transaction_timeout;
        let observer = self.observability.clone();
        
        tokio::spawn(async move {
            loop {
                // 等待下一个检查间隔
                tokio::time::sleep(status_check_interval).await;
                
                // 获取活跃事务
                match transaction_store.get_active_transactions_by_coordinator(&coordinator_id).await {
                    Ok(transactions) => {
                        let now = Utc::now();
                        
                        for transaction in transactions {
                            // 检查是否超时
                            if now - transaction.start_time > transaction_timeout {
                                // 更新事务状态为超时
                                let mut updated = transaction.clone();
                                updated.status = TransactionStatus::TimedOut;
                                
                                if let Err(e) = transaction_store.update_transaction(&updated).await {
                                    observer.record_transaction_error(
                                        &transaction.id.to_string(),
                                        "timeout_update_failed",
                                        &format!("更新超时事务状态失败: {}", e),
                                    );
                                } else {
                                    observer.record_transaction_timeout(&transaction.id.to_string());
                                }
                            }
                        }
                    },
                    Err(e) => {
                        // 记录获取事务失败
                        observer.record_error(
                            "system",
                            "get_active_transactions_failed",
                            &format!("获取活跃事务失败: {}", e),
                        );
                    }
                }
            }
        })
    }
}

/// 工作流快照管理器
pub struct WorkflowSnapshotManager {
    /// 快照管理器ID
    id: String,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 事件存储
    event_store: Arc<dyn EventStore>,
    
    /// 数据保护器（加密和压缩）
    data_protector: Arc<dyn DataProtector>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
    
    /// 快照配置
    config: SnapshotConfig,
    
    /// 一致性检查器
    consistency_checker: WorkflowConsistencyChecker,
}

impl WorkflowSnapshotManager {
    /// 创建新的快照管理器
    pub fn new(
        id: String,
        state_store: Arc<dyn StateStore>,
        event_store: Arc<dyn EventStore>,
        data_protector: Arc<dyn DataProtector>,
        lock_service: Arc<dyn LockService>,
        observability: Arc<WorkflowObservability>,
        config: SnapshotConfig,
    ) -> Self {
        let consistency_checker = WorkflowConsistencyChecker::new(
            state_store.clone(),
            event_store.clone(),
            ConsistencyCheckConfig {
                verify_event_consistency: true,
                verify_task_dependencies: true,
                verify_resource_allocations: true,
                verification_timeout: Duration::from_secs(30),
            },
        );
        
        Self {
            id,
            state_store,
            event_store,
            data_protector,
            lock_service,
            observability,
            config,
            consistency_checker,
        }
    }
    
    /// 创建工作流快照
    pub async fn create_snapshot(
        &self,
        workflow_id: &str,
        snapshot_type: SnapshotType,
        metadata: Option<HashMap<String, String>>,
    ) -> Result<String, SnapshotError> {
        // 创建追踪上下文
        let trace_ctx = self.observability.create_snapshot_operation_span(
            workflow_id,
            "create_snapshot",
        );
        let _trace_guard = trace_ctx.enter();
        
        // 获取工作流锁，防止并发操作
        let lock_key = format!("workflow:snapshot:lock:{}", workflow_id);
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.id.clone(), Duration::from_secs(60)).await
            .map_err(|e| SnapshotError::LockAcquisitionFailed(e.to_string()))?;
            
        if !lock_acquired {
            return Err(SnapshotError::LockAcquisitionFailed(
                format!("无法获取工作流快照锁: {}", workflow_id)
            ));
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone).await;
            });
        });
        
        // 获取工作流状态
        let workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| SnapshotError::WorkflowNotFound(format!("无法获取工作流状态: {}", e)))?;
            
        // 生成快照ID
        let snapshot_id = format!("snapshot-{}-{}", workflow_id, Uuid::new_v4());
        
        // 准备元数据
        let snapshot_metadata = if let Some(meta) = metadata {
            meta
        } else {
            HashMap::new()
        };
        
        // 开始计时
        let start_time = Instant::now();
        
        // 序列化状态
        let state_json = serde_json::to_string(&workflow_state)
            .map_err(|e| SnapshotError::SerializationFailed(e.to_string()))?;
            
        // 保护数据（压缩和加密）
        let protected_data = self.data_protector.protect(state_json.as_bytes())
            .map_err(|e| SnapshotError::DataProtectionFailed(e.to_string()))?;
            
        // 计算校验和
        let checksum = calculate_checksum(&protected_data)
            .map_err(|e| SnapshotError::ChecksumFailed(e.to_string()))?;
            
        // 创建恢复点
        let recovery_point = RecoveryPoint {
            id: snapshot_id.clone(),
            workflow_id: workflow_id.to_string(),
            point_type: match snapshot_type {
                SnapshotType::AutoSnapshot => RecoveryPointType::AutoSnapshot,
                SnapshotType::ManualSnapshot => RecoveryPointType::ManualSnapshot,
                SnapshotType::Checkpoint => RecoveryPointType::Checkpoint,
                SnapshotType::RecoveryBackup => RecoveryPointType::RecoveryBackup,
            },
            created_at: Utc::now(),
            data: RecoveryPointData::FullState(workflow_state),
            metadata: snapshot_metadata,
            checksum,
        };
        
        // 保存恢复点
        self.state_store.save_recovery_point(&recovery_point).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
            
        // 清理旧快照（根据配置）
        if self.config.enable_auto_cleanup {
            tokio::spawn(self.clone().cleanup_old_snapshots(workflow_id.to_string()));
        }
        
        // 计算耗时
        let elapsed = start_time.elapsed();
        
        // 记录快照创建事件
        self.observability.record_snapshot_created(
            workflow_id,
            &snapshot_id,
            &format!("{:?}", snapshot_type),
        );
        
        // 记录性能指标
        self.observability.record_metric(
            "snapshot_creation_time",
            MetricValue::Histogram(elapsed.as_millis() as f64),
            Some(HashMap::from([
                ("workflow_id".to_string(), workflow_id.to_string()),
                ("snapshot_type".to_string(), format!("{:?}", snapshot_type)),
                ("size_bytes".to_string(), state_json.len().to_string()),
                ("duration_ms".to_string(), elapsed.as_millis().to_string()),
            ])),
        );
        
        log::info!("成功创建工作流快照: workflow_id={}, snapshot_id={}, type={:?}, size={}bytes, time={}ms", 
                  workflow_id, snapshot_id, snapshot_type, state_json.len(), elapsed.as_millis());
        
        Ok(snapshot_id)
    }
    
    /// 从快照恢复工作流
    pub async fn restore_from_snapshot(
        &self,
        workflow_id: &str,
        snapshot_id: &str,
    ) -> Result<(), SnapshotError> {
        // 创建追踪上下文
        let trace_ctx = self.observability.create_snapshot_operation_span(
            workflow_id,
            "restore_from_snapshot",
        );
        let _trace_guard = trace_ctx.enter();
        
        // 获取工作流锁
        let lock_key = format!("workflow:snapshot:lock:{}", workflow_id);
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.id.clone(), Duration::from_secs(60)).await
            .map_err(|e| SnapshotError::LockAcquisitionFailed(e.to_string()))?;
            
        if !lock_acquired {
            return Err(SnapshotError::LockAcquisitionFailed(
                format!("无法获取工作流快照锁: {}", workflow_id)
            ));
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone).await;
            });
        });
        
        // 获取恢复点
        let recovery_point = self.state_store.get_recovery_point(workflow_id, snapshot_id).await
            .map_err(|e| SnapshotError::SnapshotNotFound(format!("无法找到快照: {}", e)))?;
            
        // 创建恢复前备份
        self.create_recovery_backup(workflow_id).await?;
        
        // 验证快照一致性
        self.consistency_checker.verify_recovery_point_consistency(workflow_id, &recovery_point).await
            .map_err(|e| SnapshotError::ConsistencyCheckFailed(e.to_string()))?;
            
        // 获取状态数据
        let workflow_state = match &recovery_point.data {
            RecoveryPointData::FullState(state) => state.clone(),
            RecoveryPointData::IncrementalState { .. } => {
                return Err(SnapshotError::UnsupportedRecoveryType(
                    "暂不支持增量快照恢复".to_string()
                ));
            },
            RecoveryPointData::EventLog(_) => {
                return Err(SnapshotError::UnsupportedRecoveryType(
                    "暂不支持事件日志恢复".to_string()
                ));
            }
        };
        
        // 恢复工作流状态
        self.state_store.update_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| SnapshotError::RestoreFailed(e.to_string()))?;
            
        // 记录快照恢复事件
        self.observability.record_snapshot_restored(
            workflow_id,
            snapshot_id,
            &format!("{:?}", workflow_state.status),
        );
        
        log::info!("成功从快照恢复工作流: workflow_id={}, snapshot_id={}", workflow_id, snapshot_id);
        
        Ok(())
    }
    
    /// 创建恢复前备份
    async fn create_recovery_backup(&self, workflow_id: &str) -> Result<String, SnapshotError> {
        // 创建追踪上下文
        let trace_ctx = self.observability.create_snapshot_operation_span(
            workflow_id,
            "create_recovery_backup",
        );
        let _trace_guard = trace_ctx.enter();
        
        // 获取当前工作流状态
        let workflow_state = self.state_store.get_workflow_state(workflow_id).await
            .map_err(|e| SnapshotError::WorkflowNotFound(format!("无法获取工作流状态: {}", e)))?;
            
        // 创建恢复前备份快照
        let backup_metadata = HashMap::from([
            ("backup_type".to_string(), "recovery_backup".to_string()),
            ("backup_time".to_string(), Utc::now().to_rfc3339()),
        ]);
        
        self.create_snapshot(workflow_id, SnapshotType::RecoveryBackup, Some(backup_metadata)).await
    }
    
    /// 清理旧快照
    async fn cleanup_old_snapshots(self, workflow_id: String) -> Result<(), SnapshotError> {
        // 获取所有快照
        let snapshots = self.state_store.list_recovery_points(&workflow_id).await
            .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
            
        // 按类型分组
        let mut auto_snapshots = Vec::new();
        let mut manual_snapshots = Vec::new();
        let mut recovery_backups = Vec::new();
        let mut checkpoints = Vec::new();
        
        for snapshot in snapshots {
            match snapshot.point_type {
                RecoveryPointType::AutoSnapshot => auto_snapshots.push(snapshot),
                RecoveryPointType::ManualSnapshot => manual_snapshots.push(snapshot),
                RecoveryPointType::RecoveryBackup => recovery_backups.push(snapshot),
                RecoveryPointType::Checkpoint => checkpoints.push(snapshot),
            }
        }
        
        // 按创建时间排序（降序）
        auto_snapshots.sort_by(|a, b| b.created_at.cmp(&a.created_at));
        manual_snapshots.sort_by(|a, b| b.created_at.cmp(&a.created_at));
        recovery_backups.sort_by(|a, b| b.created_at.cmp(&a.created_at));
        checkpoints.sort_by(|a, b| b.created_at.cmp(&a.created_at));
        
        // 清理自动快照
        if auto_snapshots.len() > self.config.max_auto_snapshots {
            for snapshot in &auto_snapshots[self.config.max_auto_snapshots..] {
                self.state_store.delete_recovery_point(&workflow_id, &snapshot.id).await
                    .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
                    
                log::debug!("清理旧的自动快照: workflow_id={}, snapshot_id={}", workflow_id, snapshot.id);
            }
        }
        
        // 清理恢复备份
        if recovery_backups.len() > self.config.max_recovery_backups {
            for snapshot in &recovery_backups[self.config.max_recovery_backups..] {
                self.state_store.delete_recovery_point(&workflow_id, &snapshot.id).await
                    .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
                    
                log::debug!("清理旧的恢复备份: workflow_id={}, snapshot_id={}", workflow_id, snapshot.id);
            }
        }
        
        // 清理检查点
        if checkpoints.len() > self.config.max_checkpoints {
            for snapshot in &checkpoints[self.config.max_checkpoints..] {
                self.state_store.delete_recovery_point(&workflow_id, &snapshot.id).await
                    .map_err(|e| SnapshotError::StorageFailed(e.to_string()))?;
                    
                log::debug!("清理旧的检查点: workflow_id={}, snapshot_id={}", workflow_id, snapshot.id);
            }
        }
        
        Ok(())
    }
}

/// 工作流状态机
pub struct WorkflowStateMachine {
    /// 工作流ID
    workflow_id: String,
    
    /// 工作流执行ID
    execution_id: String,
    
    /// 当前状态
    current_state: WorkflowState,
    
    /// 当前事件ID
    next_event_id: u64,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 事件存储
    event_store: Arc<dyn EventStore>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
    
    /// 事件处理器
    event_handlers: HashMap<EventType, Vec<Arc<dyn EventHandler>>>,
}

impl WorkflowStateMachine {
    /// 创建新的工作流状态机
    pub fn new(
        workflow_id: String,
        execution_id: String,
        state_store: Arc<dyn StateStore>,
        event_store: Arc<dyn EventStore>,
        lock_service: Arc<dyn LockService>,
        observability: Arc<WorkflowObservability>,
    ) -> Result<Self, WorkflowError> {
        let workflow_state = state_store.get_workflow_state(&workflow_id).sync()?;
        
        let next_event_id = event_store.get_latest_event_id(&workflow_id, &execution_id).sync()
            .map(|id| id + 1)
            .unwrap_or(1);
            
        Ok(Self {
            workflow_id,
            execution_id,
            current_state: workflow_state,
            next_event_id,
            lock_service,
            state_store,
            event_store,
            observability,
            event_handlers: HashMap::new(),
        })
    }
    
    /// 注册事件处理器
    pub fn register_event_handler(&mut self, event_type: EventType, handler: Arc<dyn EventHandler>) {
        self.event_handlers.entry(event_type).or_insert_with(Vec::new).push(handler);
    }
    
    /// 处理事件
    pub async fn process_event(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 创建追踪上下文
        let trace_ctx = self.observability.create_event_processing_span(
            &self.workflow_id,
            &event.event_type.to_string(),
        );
        let _trace_guard = trace_ctx.enter();
        
        // 验证事件ID
        if event.event_id != self.next_event_id {
            return Err(WorkflowError::InvalidEventSequence(format!(
                "无效的事件ID，期望 {}，实际 {}", 
                self.next_event_id, 
                event.event_id
            )));
        }
        
        // 获取工作流锁
        let lock_key = format!("workflow:lock:{}", self.workflow_id);
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.execution_id.clone(), Duration::from_secs(30)).await?;
        
        if !lock_acquired {
            return Err(WorkflowError::LockAcquisitionFailed(
                format!("无法获取工作流锁: {}", self.workflow_id)
            ));
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let execution_id = self.execution_id.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone, &execution_id).await;
            });
        });
        
        // 存储事件
        self.event_store.append_event(&self.workflow_id, &self.execution_id, event).await?;
        
        // 处理事件
        match event.event_type {
            EventType::WorkflowExecutionStarted => self.handle_workflow_execution_started(event).await?,
            EventType::WorkflowExecutionCompleted => self.handle_workflow_execution_completed(event).await?,
            EventType::WorkflowExecutionFailed => self.handle_workflow_execution_failed(event).await?,
            EventType::WorkflowExecutionCancelled => self.handle_workflow_execution_cancelled(event).await?,
            EventType::WorkflowExecutionTimedOut => self.handle_workflow_execution_timed_out(event).await?,
            EventType::TaskScheduled => self.handle_task_scheduled(event).await?,
            EventType::TaskStarted => self.handle_task_started(event).await?,
            EventType::TaskCompleted => self.handle_task_completed(event).await?,
            EventType::TaskFailed => self.handle_task_failed(event).await?,
            EventType::TaskTimedOut => self.handle_task_timed_out(event).await?,
            // 处理其他事件类型...
        }
        
        // 更新事件ID
        self.next_event_id += 1;
        
        // 调用自定义事件处理器
        if let Some(handlers) = self.event_handlers.get(&event.event_type) {
            for handler in handlers {
                handler.handle_event(event, &mut self.current_state).await?;
            }
        }
        
        // 更新工作流状态
        self.state_store.update_workflow_state(&self.workflow_id, &self.current_state).await?;
        
        // 记录事件处理
        self.observability.record_event_processed(
            &self.workflow_id,
            &self.execution_id,
            &event.event_type.to_string(),
            event.event_id,
        );
        
        Ok(())
    }
    
    /// 处理工作流执行开始事件
    async fn handle_workflow_execution_started(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 更新工作流执行信息
        self.current_state.status = WorkflowStatus::Running;
        self.current_state.start_time = event.timestamp;
        self.current_state.current_execution_id = Some(self.execution_id.clone());
        
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(input) = attrs.get("input") {
                self.current_state.input = Some(input.clone());
            }
            
            if let Some(timeout) = attrs.get("execution_timeout").and_then(|v| v.as_u64()) {
                self.current_state.execution_timeout = Some(Duration::from_secs(timeout));
            }
        }
        
        Ok(())
    }
    
    /// 处理工作流执行完成事件
    async fn handle_workflow_execution_completed(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 更新工作流执行信息
        self.current_state.status = WorkflowStatus::Completed;
        self.current_state.end_time = Some(event.timestamp);
        
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(result) = attrs.get("result") {
                self.current_state.result = Some(result.clone());
            }
        }
        
        Ok(())
    }
    
    /// 处理工作流执行失败事件
    async fn handle_workflow_execution_failed(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 更新工作流执行信息
        self.current_state.status = WorkflowStatus::Failed;
        self.current_state.end_time = Some(event.timestamp);
        
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(error) = attrs.get("error") {
                self.current_state.error = Some(error.clone());
            }
            
            if let Some(failure_reason) = attrs.get("reason").and_then(|v| v.as_str()) {
                self.current_state.failure_reason = Some(failure_reason.to_string());
            }
        }
        
        Ok(())
    }
    
    /// 处理工作流执行取消事件
    async fn handle_workflow_execution_cancelled(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 更新工作流执行信息
        self.current_state.status = WorkflowStatus::Cancelled;
        self.current_state.end_time = Some(event.timestamp);
        
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(reason) = attrs.get("reason").and_then(|v| v.as_str()) {
                self.current_state.cancellation_reason = Some(reason.to_string());
            }
        }
        
        Ok(())
    }
    
    /// 处理工作流执行超时事件
    async fn handle_workflow_execution_timed_out(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 更新工作流执行信息
        self.current_state.status = WorkflowStatus::TimedOut;
        self.current_state.end_time = Some(event.timestamp);
        
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(timeout_type) = attrs.get("timeout_type").and_then(|v| v.as_str()) {
                self.current_state.timeout_type = Some(timeout_type.to_string());
            }
        }
        
        Ok(())
    }
    
    /// 处理任务调度事件
    async fn handle_task_scheduled(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(task_id) = attrs.get("task_id").and_then(|v| v.as_str()) {
                let task_state = TaskState {
                    task_id: task_id.to_string(),
                    status: TaskStatus::Scheduled,
                    scheduled_at: event.timestamp,
                    start_time: None,
                    end_time: None,
                    result: None,
                    error: None,
                    attempt: 0,
                    node_id: None,
                    last_heartbeat: None,
                };
                
                // 更新任务状态
                self.current_state.task_states.insert(task_id.to_string(), task_state);
            }
        }
        
        Ok(())
    }
    
    /// 处理任务开始事件
    async fn handle_task_started(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(task_id) = attrs.get("task_id").and_then(|v| v.as_str()) {
                if let Some(task_state) = self.current_state.task_states.get_mut(task_id) {
                    // 更新任务状态
                    task_state.status = TaskStatus::Running;
                    task_state.start_time = Some(event.timestamp);
                    
                    // 获取节点ID
                    if let Some(node_id) = attrs.get("node_id").and_then(|v| v.as_str()) {
                        task_state.node_id = Some(node_id.to_string());
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// 处理任务完成事件
    async fn handle_task_completed(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(task_id) = attrs.get("task_id").and_then(|v| v.as_str()) {
                if let Some(task_state) = self.current_state.task_states.get_mut(task_id) {
                    // 更新任务状态
                    task_state.status = TaskStatus::Completed;
                    task_state.end_time = Some(event.timestamp);
                    
                    // 获取任务结果
                    if let Some(result) = attrs.get("result") {
                        task_state.result = Some(result.clone());
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// 处理任务失败事件
    async fn handle_task_failed(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(task_id) = attrs.get("task_id").and_then(|v| v.as_str()) {
                if let Some(task_state) = self.current_state.task_states.get_mut(task_id) {
                    // 更新任务状态
                    task_state.status = TaskStatus::Failed;
                    task_state.end_time = Some(event.timestamp);
                    task_state.attempt += 1;
                    
                    // 获取错误信息
                    if let Some(error) = attrs.get("error") {
                        task_state.error = Some(error.clone());
                    }
                    
                    // 检查是否需要重试
                    if let Some(retry_policy) = attrs.get("retry_policy") {
                        if let Some(max_attempts) = retry_policy.get("max_attempts").and_then(|v| v.as_u64()) {
                            if task_state.attempt < max_attempts as u32 {
                                // 重置为待调度状态，准备重试
                                task_state.status = TaskStatus::Scheduled;
                                task_state.start_time = None;
                                task_state.end_time = None;
                                task_state.error = None;
                            }
                        }
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// 处理任务超时事件
    async fn handle_task_timed_out(&mut self, event: &Event) -> Result<(), WorkflowError> {
        // 获取事件属性
        if let Some(attrs) = event.attributes.as_object() {
            if let Some(task_id) = attrs.get("task_id").and_then(|v| v.as_str()) {
                if let Some(task_state) = self.current_state.task_states.get_mut(task_id) {
                    // 更新任务状态
                    task_state.status = TaskStatus::TimedOut;
                    task_state.end_time = Some(event.timestamp);
                    task_state.attempt += 1;
                    
                    // 添加超时错误
                    task_state.error = Some(serde_json::json!({
                        "type": "TaskTimeout",
                        "message": "任务执行超时"
                    }));
                    
                    // 检查是否需要重试
                    if let Some(retry_policy) = attrs.get("retry_policy") {
                        if let Some(max_attempts) = retry_policy.get("max_attempts").and_then(|v| v.as_u64()) {
                            if task_state.attempt < max_attempts as u32 {
                                // 重置为待调度状态，准备重试
                                task_state.status = TaskStatus::Scheduled;
                                task_state.start_time = None;
                                task_state.end_time = None;
                                task_state.error = None;
                            }
                        }
                    }
                }
            }
        }
        
        Ok(())
    }
}

/// 工作流容错处理器
pub struct WorkflowFaultHandler {
    /// 节点管理器
    node_manager: Arc<NodeManager>,
    
    /// 工作流引擎
    workflow_engine: Arc<WorkflowEngine>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 事件存储
    event_store: Arc<dyn EventStore>,
    
    /// 观测性组件
    observability: Arc<WorkflowObservability>,
    
    /// 故障处理策略
    fault_handlers: RwLock<HashMap<FaultType, Vec<Box<dyn FaultHandlingStrategy>>>>,
    
    /// 恢复策略
    recovery_strategies: RwLock<HashMap<RecoveryStrategyType, Box<dyn RecoveryStrategy>>>,
}

impl WorkflowFaultHandler {
    /// 创建新的工作流容错处理器
    pub fn new(
        node_manager: Arc<NodeManager>,
        workflow_engine: Arc<WorkflowEngine>,
        lock_service: Arc<dyn LockService>,
        state_store: Arc<dyn StateStore>,
        event_store: Arc<dyn EventStore>,
        observability: Arc<WorkflowObservability>,
    ) -> Self {
        Self {
            node_manager,
            workflow_engine,
            lock_service,
            state_store,
            event_store,
            observability,
            fault_handlers: RwLock::new(HashMap::new()),
            recovery_strategies: RwLock::new(HashMap::new()),
        }
    }
    
    /// 注册故障处理策略
    pub fn register_fault_handling_strategy(
        &self,
        fault_type: FaultType,
        strategy: Box<dyn FaultHandlingStrategy>,
    ) {
        let mut handlers = self.fault_handlers.write().unwrap();
        handlers.entry(fault_type).or_insert_with(Vec::new).push(strategy);
    }
    
    /// 注册恢复策略
    pub fn register_recovery_strategy(
        &self,
        strategy_type: RecoveryStrategyType,
        strategy: Box<dyn RecoveryStrategy>,
    ) {
        let mut strategies = self.recovery_strategies.write().unwrap();
        strategies.insert(strategy_type, strategy);
    }
    
    /// 处理节点故障
    pub async fn handle_node_failure(&self, node_id: &str) -> Result<Vec<String>, FaultHandlingError> {
        // 创建故障处理追踪上下文
        let trace_ctx = self.observability.create_fault_handling_span("node_failure", node_id);
        let _trace_guard = trace_ctx.enter();
        
        log::info!("处理节点故障: node_id={}", node_id);
        
        // 获取节点锁
        let lock_key = format!("node:fault:lock:{}", node_id);
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, "fault_handler", Duration::from_secs(60)).await
            .map_err(|e| FaultHandlingError::LockAcquisitionFailed(e.to_string()))?;
            
        if !lock_acquired {
            return Err(FaultHandlingError::LockAcquisitionFailed(
                format!("无法获取节点故障锁: {}", node_id)
            ));
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone).await;
            });
        });
        
        // 获取节点上的活跃工作流
        let active_workflows = self.state_store.get_workflows_by_node(node_id).await
            .map_err(|e| FaultHandlingError::StateStoreFailed(e.to_string()))?;
            
        // 处理每个受影响的工作流
        let mut recovered_workflows = Vec::new();
        
        for workflow_id in active_workflows {
            // 尝试恢复工作流
            match self.recover_workflow_from_node_failure(&workflow_id, node_id).await {
                Ok(_) => {
                    recovered_workflows.push(workflow_id);
                    
                    self.observability.record_workflow_recovered(
                        &workflow_id,
                        "node_failure",
                        &serde_json::json!({
                            "failed_node": node_id,
                            "recovery_time": Utc::now().to_rfc3339(),
                        }),
                    );
                },
                Err(e) => {
                    log::error!("恢复工作流失败: workflow_id={}, node_id={}, error={}", 
                               workflow_id, node_id, e);
                               
                    self.observability.record_workflow_recovery_failed(
                        &workflow_id,
                        "node_failure",
                        &format!("恢复失败: {}", e),
                    );
                }
            }
        }
        
        // 更新节点
    // 更新节点状态
    self.node_manager.update_node_status(node_id, NodeStatus::Faulty).await
        .map_err(|e| FaultHandlingError::NodeManagerFailed(e.to_string()))?;
        
    log::info!("节点故障处理完成: node_id={}, 已恢复{}个工作流", 
               node_id, recovered_workflows.len());
               
    Ok(recovered_workflows)
}

/// 从节点故障中恢复工作流
async fn recover_workflow_from_node_failure(
    &self,
    workflow_id: &str,
    failed_node_id: &str,
) -> Result<(), FaultHandlingError> {
    // 创建故障处理追踪上下文
    let trace_ctx = self.observability.create_fault_handling_span(
        "recover_workflow",
        workflow_id,
    );
    let _trace_guard = trace_ctx.enter();
    
    log::info!("从节点故障恢复工作流: workflow_id={}, failed_node_id={}", 
              workflow_id, failed_node_id);
              
    // 获取工作流锁
    let lock_key = format!("workflow:fault:lock:{}", workflow_id);
    let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, "fault_handler", Duration::from_secs(60)).await
        .map_err(|e| FaultHandlingError::LockAcquisitionFailed(e.to_string()))?;
        
    if !lock_acquired {
        return Err(FaultHandlingError::LockAcquisitionFailed(
            format!("无法获取工作流故障锁: {}", workflow_id)
        ));
    }
    
    // 确保锁在函数退出时释放
    let lock_key_clone = lock_key.clone();
    let lock_service = self.lock_service.clone();
    let _lock_guard = scopeguard::guard((), |_| {
        tokio::spawn(async move {
            let _ = lock_service.release_lock(&lock_key_clone).await;
        });
    });
    
    // 获取工作流状态
    let workflow_state = self.state_store.get_workflow_state(workflow_id).await
        .map_err(|e| FaultHandlingError::StateStoreFailed(e.to_string()))?;
        
    // 选择恢复策略
    let strategy_type = self.determine_recovery_strategy(&workflow_state, failed_node_id);
    
    // 获取对应的恢复策略
    let recovery_strategies = self.recovery_strategies.read().unwrap();
    let strategy = recovery_strategies.get(&strategy_type).ok_or_else(|| {
        FaultHandlingError::UnsupportedRecoveryStrategy(
            format!("不支持的恢复策略: {:?}", strategy_type)
        )
    })?;
    
    // 执行恢复策略
    let recovery_context = RecoveryContext {
        workflow_id: workflow_id.to_string(),
        failed_node_id: failed_node_id.to_string(),
        workflow_state: workflow_state.clone(),
        fault_time: Utc::now(),
    };
    
    strategy.execute(&recovery_context).await
        .map_err(|e| FaultHandlingError::RecoveryFailed(e.to_string()))?;
        
    // 更新工作流状态为恢复中
    let mut updated_state = workflow_state.clone();
    updated_state.status = WorkflowStatus::Recovering;
    updated_state.recovery_info = Some(RecoveryInfo {
        recovery_start_time: Utc::now(),
        recovery_strategy: strategy_type.to_string(),
        failed_node_id: failed_node_id.to_string(),
        affected_tasks: workflow_state.task_states.iter()
            .filter(|(_, task)| task.node_id.as_deref() == Some(failed_node_id))
            .map(|(id, _)| id.clone())
            .collect(),
    });
    
    self.state_store.update_workflow_state(workflow_id, &updated_state).await
        .map_err(|e| FaultHandlingError::StateStoreFailed(e.to_string()))?;
        
    // 记录恢复事件
    let event = Event {
        event_id: 0, // 将由事件存储分配
        event_type: EventType::WorkflowRecovering,
        workflow_id: workflow_id.to_string(),
        execution_id: updated_state.current_execution_id.clone().unwrap_or_default(),
        timestamp: Utc::now(),
        attributes: serde_json::json!({
            "recovery_strategy": strategy_type.to_string(),
            "failed_node_id": failed_node_id,
            "affected_tasks": updated_state.recovery_info.as_ref().unwrap().affected_tasks,
        }),
    };
    
    self.event_store.append_event(workflow_id, &updated_state.current_execution_id.clone().unwrap_or_default(), &event).await
        .map_err(|e| FaultHandlingError::EventStoreFailed(e.to_string()))?;
        
    // 通知工作流引擎重新调度工作流
    self.workflow_engine.reschedule_workflow(workflow_id).await
        .map_err(|e| FaultHandlingError::RescheduleFailed(e.to_string()))?;
        
    log::info!("工作流恢复流程已启动: workflow_id={}, strategy={:?}", 
              workflow_id, strategy_type);
              
    Ok(())
}

/// 确定恢复策略
fn determine_recovery_strategy(
    &self,
    workflow_state: &WorkflowState,
    failed_node_id: &str,
) -> RecoveryStrategyType {
    // 获取故障任务
    let failed_tasks: Vec<_> = workflow_state.task_states.iter()
        .filter(|(_, task)| {
            task.node_id.as_deref() == Some(failed_node_id) && 
            matches!(task.status, TaskStatus::Running | TaskStatus::Scheduled)
        })
        .collect();
        
    // 如果没有正在运行的故障任务，则使用简单重新调度
    if failed_tasks.is_empty() {
        return RecoveryStrategyType::Reschedule;
    }
    
    // 检查是否有检查点
    let has_checkpoint = workflow_state.recovery_points.iter()
        .any(|point| point.point_type == RecoveryPointType::Checkpoint);
        
    // 如果有检查点，优先使用检查点恢复
    if has_checkpoint {
        return RecoveryStrategyType::CheckpointRestore;
    }
    
    // 如果工作流支持补偿，使用补偿策略
    let workflow_definition = self.workflow_engine.get_workflow_definition(&workflow_state.workflow_type).unwrap();
    if workflow_definition.supports_compensation {
        return RecoveryStrategyType::Compensation;
    }
    
    // 默认使用重试策略
    RecoveryStrategyType::Retry
}
}

/// 分布式工作流调度器
pub struct DistributedWorkflowScheduler {
    /// 调度器ID
    id: String,
    
    /// 集群管理器
    cluster_manager: Arc<ClusterManager>,
    
    /// 事件总线
    event_bus: Arc<EventBus>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 工作流执行器
    workflow_executor: Arc<WorkflowExecutor>,
    
    /// 观测性
    observability: Arc<WorkflowObservability>,
    
    /// 调度策略
    scheduling_strategy: SchedulingStrategy,
    
    /// 工作流优先级队列
    priority_queues: Arc<RwLock<PriorityQueues>>,
    
    /// 活跃工作流实例
    active_workflows: Arc<RwLock<HashMap<String, WorkflowExecutionInfo>>>,
    
    /// 调度配置
    config: SchedulerConfig,
    
    /// 是否运行中
    running: AtomicBool,
    
    /// 关闭通道
    shutdown_tx: watch::Sender<bool>,
    
    /// 关闭通道接收器
    shutdown_rx: watch::Receiver<bool>,
}

impl DistributedWorkflowScheduler {
    /// 创建新的分布式工作流调度器
    pub fn new(
        id: String,
        cluster_manager: Arc<ClusterManager>,
        event_bus: Arc<EventBus>,
        state_store: Arc<dyn StateStore>,
        lock_service: Arc<dyn LockService>,
        workflow_executor: Arc<WorkflowExecutor>,
        observability: Arc<WorkflowObservability>,
        config: SchedulerConfig,
    ) -> Self {
        let (shutdown_tx, shutdown_rx) = watch::channel(false);
        
        Self {
            id,
            cluster_manager,
            event_bus,
            state_store,
            lock_service,
            workflow_executor,
            observability,
            scheduling_strategy: config.scheduling_strategy.clone(),
            priority_queues: Arc::new(RwLock::new(PriorityQueues::new())),
            active_workflows: Arc::new(RwLock::new(HashMap::new())),
            config,
            running: AtomicBool::new(false),
            shutdown_tx,
            shutdown_rx,
        }
    }
    
    /// 启动调度器
    pub async fn start(&self) -> Result<(), SchedulerError> {
        // 检查是否已运行
        if self.running.load(Ordering::Acquire) {
            return Err(SchedulerError::AlreadyRunning);
        }
        
        // 设置运行状态
        self.running.store(true, Ordering::Release);
        
        // 启动工作流执行器
        self.workflow_executor.start().await
            .map_err(|e| SchedulerError::ExecutorStartFailed(e.to_string()))?;
            
        // 注册集群事件监听器
        self.register_cluster_event_listeners();
        
        // 注册工作流事件监听器
        self.register_workflow_event_listeners();
        
        // 启动调度循环
        self.start_scheduling_loop();
        
        // 恢复中断的工作流
        self.recover_interrupted_workflows().await
            .map_err(|e| SchedulerError::WorkflowRecoveryFailed(e.to_string()))?;
            
        log::info!("分布式工作流调度器已启动: {}", self.id);
            
        Ok(())
    }
    
    /// 停止调度器
    pub async fn stop(&self) -> Result<(), SchedulerError> {
        // 检查是否已停止
        if !self.running.load(Ordering::Acquire) {
            return Ok(());
        }
        
        // 设置停止状态
        self.running.store(false, Ordering::Release);
        
        // 发送关闭信号
        self.shutdown_tx.send(true)
            .map_err(|_| SchedulerError::ShutdownFailed("无法发送关闭信号".to_string()))?;
            
        // 停止工作流执行器
        self.workflow_executor.stop().await
            .map_err(|e| SchedulerError::ExecutorStopFailed(e.to_string()))?;
            
        // 等待所有活跃工作流完成或超时
        self.wait_for_active_workflows_completion(Duration::from_secs(30)).await;
        
        log::info!("分布式工作流调度器已停止: {}", self.id);
        
        Ok(())
    }
    
    /// 调度工作流
    pub async fn schedule_workflow(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        input: Option<serde_json::Value>,
        options: WorkflowScheduleOptions,
    ) -> Result<String, SchedulerError> {
        // 检查是否运行
        if !self.running.load(Ordering::Acquire) {
            return Err(SchedulerError::NotRunning);
        }
        
        // 生成执行ID
        let execution_id = format!("exec-{}", Uuid::new_v4().to_string());
        
        // 构建工作流状态
        let workflow_state = WorkflowState {
            workflow_id: workflow_id.to_string(),
            workflow_type: workflow_type.to_string(),
            status: WorkflowStatus::Pending,
            start_time: None,
            end_time: None,
            input: input.clone(),
            result: None,
            error: None,
            failure_reason: None,
            cancellation_reason: None,
            timeout_type: None,
            current_execution_id: Some(execution_id.clone()),
            task_states: HashMap::new(),
            recovery_points: Vec::new(),
            recovery_info: None,
            metrics: WorkflowMetrics::new(),
            options,
        };
        
        // 保存工作流状态
        self.state_store.create_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| SchedulerError::StatePersistenceFailed(e.to_string()))?;
            
        // 创建工作流开始事件
        let start_event = Event {
            event_id: 1, // 初始事件
            event_type: EventType::WorkflowExecutionStarted,
            workflow_id: workflow_id.to_string(),
            execution_id: execution_id.clone(),
            timestamp: Utc::now(),
            attributes: serde_json::json!({
                "workflow_type": workflow_type,
                "input": input,
                "execution_timeout": options.execution_timeout.map(|d| d.as_secs()),
            }),
        };
        
        // 保存工作流事件
        self.event_store.append_event(workflow_id, &execution_id, &start_event).await
            .map_err(|e| SchedulerError::EventPersistenceFailed(e.to_string()))?;
            
        // 添加到调度队列
        let priority = options.priority.unwrap_or(WorkflowPriority::Normal);
        self.enqueue_workflow(workflow_id, workflow_type, priority).await?;
        
        // 记录工作流已调度
        self.observability.record_workflow_scheduled(
            workflow_id,
            &execution_id,
            workflow_type,
            &priority.to_string(),
        );
        
        log::info!("工作流已调度: workflow_id={}, execution_id={}, type={}, priority={:?}", 
                  workflow_id, execution_id, workflow_type, priority);
                  
        Ok(execution_id)
    }
    
    /// 取消工作流
    pub async fn cancel_workflow(
        &self,
        workflow_id: &str,
        reason: Option<String>,
    ) -> Result<(), SchedulerError> {
        // 检查是否运行
        if !self.running.load(Ordering::Acquire) {
            return Err(SchedulerError::NotRunning);
        }
        
        // 获取工作流状态
        let workflow_state = match self.state_store.get_workflow_state(workflow_id).await {
            Ok(state) => state,
            Err(e) => return Err(SchedulerError::WorkflowNotFound(e.to_string())),
        };
        
        // 检查工作流是否可取消
        if matches!(workflow_state.status, 
            WorkflowStatus::Completed | 
            WorkflowStatus::Failed | 
            WorkflowStatus::Cancelled | 
            WorkflowStatus::TimedOut) {
            return Err(SchedulerError::InvalidWorkflowState(
                format!("工作流已处于终态: {:?}", workflow_state.status)
            ));
        }
        
        // 获取当前执行ID
        let execution_id = workflow_state.current_execution_id.clone()
            .ok_or_else(|| SchedulerError::InvalidWorkflowState("工作流没有活跃的执行ID".to_string()))?;
            
        // 尝试从队列中移除
        let removed = self.dequeue_workflow(workflow_id).await;
        
        // 如果正在执行中，则发送取消信号
        if !removed {
            // 通知执行器取消工作流
            self.workflow_executor.cancel_workflow(workflow_id).await
                .map_err(|e| SchedulerError::CancellationFailed(e.to_string()))?;
        }
        
        // 创建取消事件
        let cancel_event = Event {
            event_id: 0, // 将由事件存储分配
            event_type: EventType::WorkflowExecutionCancelled,
            workflow_id: workflow_id.to_string(),
            execution_id,
            timestamp: Utc::now(),
            attributes: serde_json::json!({
                "reason": reason.clone().unwrap_or_else(|| "用户请求取消".to_string()),
            }),
        };
        
        // 保存取消事件
        self.event_store.append_event(workflow_id, &workflow_state.current_execution_id.unwrap(), &cancel_event).await
            .map_err(|e| SchedulerError::EventPersistenceFailed(e.to_string()))?;
            
        // 更新工作流状态
        let mut updated_state = workflow_state.clone();
        updated_state.status = WorkflowStatus::Cancelled;
        updated_state.end_time = Some(Utc::now());
        updated_state.cancellation_reason = reason;
        
        self.state_store.update_workflow_state(workflow_id, &updated_state).await
            .map_err(|e| SchedulerError::StatePersistenceFailed(e.to_string()))?;
            
        // 从活跃工作流中移除
        {
            let mut active_workflows = self.active_workflows.write().await;
            active_workflows.remove(workflow_id);
        }
        
        // 记录工作流取消
        self.observability.record_workflow_cancelled(
            workflow_id,
            &updated_state.current_execution_id.unwrap(),
            &updated_state.cancellation_reason.unwrap_or_default(),
        );
        
        log::info!("工作流已取消: workflow_id={}, reason={}", 
                  workflow_id, updated_state.cancellation_reason.unwrap_or_default());
                  
        Ok(())
    }
    
    /// 启动调度循环
    fn start_scheduling_loop(&self) {
        let scheduler = self.clone();
        tokio::spawn(async move {
            let mut interval = time::interval(Duration::from_millis(scheduler.config.scheduling_interval_ms));
            let mut shutdown_rx = scheduler.shutdown_rx.clone();
            
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        if let Err(e) = scheduler.schedule_next_batch().await {
                            log::error!("调度下一批工作流失败: {}", e);
                        }
                    }
                    _ = shutdown_rx.changed() => {
                        if *shutdown_rx.borrow() {
                            log::info!("调度循环收到关闭信号");
                            break;
                        }
                    }
                }
            }
            
            log::info!("调度循环已停止");
        });
    }
    
    /// 调度下一批工作流
    async fn schedule_next_batch(&self) -> Result<usize, SchedulerError> {
        // 创建分布式锁
        let lock_key = format!("scheduler:lock:{}", self.cluster_manager.get_partition_id());
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.id.clone(), Duration::from_secs(5)).await
            .map_err(|e| SchedulerError::LockAcquisitionFailed(e.to_string()))?;
            
        if !lock_acquired {
            // 其他调度器已获取锁，跳过本次调度
            return Ok(0);
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let scheduler_id = self.id.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone, &scheduler_id).await;
            });
        });
        
        // 获取集群资源状态
        let cluster_resources = self.cluster_manager.get_cluster_resources().await
            .map_err(|e| SchedulerError::ClusterResourcesFailed(e.to_string()))?;
            
        // 获取可执行的工作流
        let workflows_to_execute = self.select_workflows_to_execute(&cluster_resources).await?;
        
        if workflows_to_execute.is_empty() {
            return Ok(0);
        }
        
        // 执行选定的工作流
        let mut executed_count = 0;
        
        for scheduled_workflow in workflows_to_execute {
            // 分配执行节点
            let assigned_node = self.assign_execution_node(&scheduled_workflow, &cluster_resources).await?;
            
            // 提交工作流到执行器
            let execution_info = WorkflowExecutionInfo {
                workflow_id: scheduled_workflow.workflow_id.clone(),
                execution_id: scheduled_workflow.execution_id.clone(),
                node_id: assigned_node.node_id.clone(),
                scheduled_time: Utc::now(),
                status: WorkflowExecutionStatus::Scheduled,
            };
            
            self.workflow_executor.execute_workflow(
                &scheduled_workflow.workflow_id,
                &scheduled_workflow.workflow_type,
                &scheduled_workflow.execution_id,
                &assigned_node.node_id,
            ).await.map_err(|e| SchedulerError::ExecutionFailed(e.to_string()))?;
            
            // 记录活跃工作流
            {
                let mut active_workflows = self.active_workflows.write().await;
                active_workflows.insert(scheduled_workflow.workflow_id.clone(), execution_info);
            }
            
            // 更新工作流状态
            let mut workflow_state = self.state_store.get_workflow_state(&scheduled_workflow.workflow_id).await
                .map_err(|e| SchedulerError::StateRetrievalFailed(e.to_string()))?;
                
            workflow_state.status = WorkflowStatus::Running;
            workflow_state.start_time = Some(Utc::now());
            
            self.state_store.update_workflow_state(&scheduled_workflow.workflow_id, &workflow_state).await
                .map_err(|e| SchedulerError::StatePersistenceFailed(e.to_string()))?;
                
            // 创建工作流开始执行事件
            let started_event = Event {
                event_id: 0, // 将由事件存储分配
                event_type: EventType::WorkflowExecutionStarted,
                workflow_id: scheduled_workflow.workflow_id.clone(),
                execution_id: scheduled_workflow.execution_id.clone(),
                timestamp: Utc::now(),
                attributes: serde_json::json!({
                    "node_id": assigned_node.node_id,
                    "workflow_type": scheduled_workflow.workflow_type,
                }),
            };
            
            self.event_store.append_event(
                &scheduled_workflow.workflow_id, 
                &scheduled_workflow.execution_id, 
                &started_event
            ).await.map_err(|e| SchedulerError::EventPersistenceFailed(e.to_string()))?;
            
            // 记录工作流开始执行
            self.observability.record_workflow_execution_started(
                &scheduled_workflow.workflow_id,
                &scheduled_workflow.execution_id,
                &scheduled_workflow.workflow_type,
                &assigned_node.node_id,
            );
            
            log::info!("工作流开始执行: workflow_id={}, execution_id={}, node_id={}", 
                      scheduled_workflow.workflow_id, scheduled_workflow.execution_id, assigned_node.node_id);
                      
            executed_count += 1;
            
            // 检查是否达到批处理限制
            if executed_count >= self.config.max_batch_size {
                break;
            }
        }
        
        Ok(executed_count)
    }
    
    /// 选择要执行的工作流
    async fn select_workflows_to_execute(
        &self,
        cluster_resources: &ClusterResources,
    ) -> Result<Vec<ScheduledWorkflowInfo>, SchedulerError> {
        // 根据调度策略选择工作流
        match self.scheduling_strategy {
            SchedulingStrategy::StrictPriority => {
                self.select_workflows_by_strict_priority(cluster_resources).await
            },
            SchedulingStrategy::WeightedFair => {
                self.select_workflows_by_weighted_fair(cluster_resources).await
            },
            SchedulingStrategy::Resource => {
                self.select_workflows_by_resource(cluster_resources).await
            },
            SchedulingStrategy::Deadline => {
                self.select_workflows_by_deadline(cluster_resources).await
            },
            SchedulingStrategy::DynamicAdaptive => {
                self.select_workflows_dynamically(cluster_resources).await
            },
        }
    }
    
    /// 按严格优先级选择工作流
    async fn select_workflows_by_strict_priority(
        &self,
        cluster_resources: &ClusterResources,
    ) -> Result<Vec<ScheduledWorkflowInfo>, SchedulerError> {
        let mut selected_workflows = Vec::new();
        let mut remaining_resources = cluster_resources.clone();
        
        // 按优先级从高到低处理队列
        let priority_queues = self.priority_queues.read().await;
        
        for priority in [
            WorkflowPriority::Critical,
            WorkflowPriority::High,
            WorkflowPriority::Normal,
            WorkflowPriority::Low,
            WorkflowPriority::Background,
        ] {
            if let Some(queue) = priority_queues.get_queue(&priority) {
                for workflow_id in queue.iter() {
                    // 检查是否有足够资源
                    let workflow_state = match self.state_store.get_workflow_state(workflow_id).await {
                        Ok(state) => state,
                        Err(e) => {
                            log::warn!("无法获取工作流状态，跳过调度: workflow_id={}, error={}", workflow_id, e);
                            continue;
                        }
                    };
                    
                    // 计算工作流资源需求
                    let resource_requirements = self.calculate_workflow_resources(&workflow_state);
                    
                    // 检查资源是否满足
                    if !remaining_resources.can_accommodate(&resource_requirements) {
                        continue;
                    }
                    
                    // 从资源中减去已分配部分
                    remaining_resources.allocate(&resource_requirements);
                    
                    // 添加到选中的工作流列表
                    selected_workflows.push(ScheduledWorkflowInfo {
                        workflow_id: workflow_id.clone(),
                        workflow_type: workflow_state.workflow_type.clone(),
                        execution_id: workflow_state.current_execution_id.clone().unwrap_or_default(),
                        priority,
                        resource_requirements,
                        scheduled_at: Utc::now(),
                    });
                    
                    // 检查是否达到批处理限制
                    if selected_workflows.len() >= self.config.max_batch_size {
                        return Ok(selected_workflows);
                    }
                }
            }
        }
        
        Ok(selected_workflows)
    }
    
    /// 分配执行节点
    async fn assign_execution_node(
        &self,
        workflow: &ScheduledWorkflowInfo,
        cluster_resources: &ClusterResources,
    ) -> Result<NodeInfo, SchedulerError> {
        // 获取所有活跃节点
        let active_nodes = self.cluster_manager.get_active_nodes().await
            .map_err(|e| SchedulerError::NodeSelectionFailed(e.to_string()))?;
            
        if active_nodes.is_empty() {
            return Err(SchedulerError::NoAvailableNodes("没有可用的执行节点".to_string()));
        }
        
        // 筛选满足资源要求的节点
        let candidate_nodes: Vec<_> = active_nodes.iter()
            .filter(|node| {
                let node_resources = cluster_resources.get_node_resources(&node.node_id);
                match node_resources {
                    Some(resources) => resources.can_accommodate(&workflow.resource_requirements),
                    None => false,
                }
            })
            .collect();
            
        if candidate_nodes.is_empty() {
            return Err(SchedulerError::NoAvailableNodes(
                format!("没有节点满足工作流资源需求: workflow_id={}", workflow.workflow_id)

    // 更新节点状态
    self.node_manager.update_node_status(node_id, NodeStatus::Faulty).await
        .map_err(|e| FaultHandlingError::NodeManagerFailed(e.to_string()))?;
        
    log::info!("节点故障处理完成: node_id={}, 已恢复{}个工作流", 
               node_id, recovered_workflows.len());
               
    Ok(recovered_workflows)
}

/// 从节点故障中恢复工作流
async fn recover_workflow_from_node_failure(
    &self,
    workflow_id: &str,
    failed_node_id: &str,
) -> Result<(), FaultHandlingError> {
    // 创建故障处理追踪上下文
    let trace_ctx = self.observability.create_fault_handling_span(
        "recover_workflow",
        workflow_id,
    );
    let _trace_guard = trace_ctx.enter();
    
    log::info!("从节点故障恢复工作流: workflow_id={}, failed_node_id={}", 
              workflow_id, failed_node_id);
              
    // 获取工作流锁
    let lock_key = format!("workflow:fault:lock:{}", workflow_id);
    let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, "fault_handler", Duration::from_secs(60)).await
        .map_err(|e| FaultHandlingError::LockAcquisitionFailed(e.to_string()))?;
        
    if !lock_acquired {
        return Err(FaultHandlingError::LockAcquisitionFailed(
            format!("无法获取工作流故障锁: {}", workflow_id)
        ));
    }
    
    // 确保锁在函数退出时释放
    let lock_key_clone = lock_key.clone();
    let lock_service = self.lock_service.clone();
    let _lock_guard = scopeguard::guard((), |_| {
        tokio::spawn(async move {
            let _ = lock_service.release_lock(&lock_key_clone).await;
        });
    });
    
    // 获取工作流状态
    let workflow_state = self.state_store.get_workflow_state(workflow_id).await
        .map_err(|e| FaultHandlingError::StateStoreFailed(e.to_string()))?;
        
    // 选择恢复策略
    let strategy_type = self.determine_recovery_strategy(&workflow_state, failed_node_id);
    
    // 获取对应的恢复策略
    let recovery_strategies = self.recovery_strategies.read().unwrap();
    let strategy = recovery_strategies.get(&strategy_type).ok_or_else(|| {
        FaultHandlingError::UnsupportedRecoveryStrategy(
            format!("不支持的恢复策略: {:?}", strategy_type)
        )
    })?;
    
    // 执行恢复策略
    let recovery_context = RecoveryContext {
        workflow_id: workflow_id.to_string(),
        failed_node_id: failed_node_id.to_string(),
        workflow_state: workflow_state.clone(),
        fault_time: Utc::now(),
    };
    
    strategy.execute(&recovery_context).await
        .map_err(|e| FaultHandlingError::RecoveryFailed(e.to_string()))?;
        
    // 更新工作流状态为恢复中
    let mut updated_state = workflow_state.clone();
    updated_state.status = WorkflowStatus::Recovering;
    updated_state.recovery_info = Some(RecoveryInfo {
        recovery_start_time: Utc::now(),
        recovery_strategy: strategy_type.to_string(),
        failed_node_id: failed_node_id.to_string(),
        affected_tasks: workflow_state.task_states.iter()
            .filter(|(_, task)| task.node_id.as_deref() == Some(failed_node_id))
            .map(|(id, _)| id.clone())
            .collect(),
    });
    
    self.state_store.update_workflow_state(workflow_id, &updated_state).await
        .map_err(|e| FaultHandlingError::StateStoreFailed(e.to_string()))?;
        
    // 记录恢复事件
    let event = Event {
        event_id: 0, // 将由事件存储分配
        event_type: EventType::WorkflowRecovering,
        workflow_id: workflow_id.to_string(),
        execution_id: updated_state.current_execution_id.clone().unwrap_or_default(),
        timestamp: Utc::now(),
        attributes: serde_json::json!({
            "recovery_strategy": strategy_type.to_string(),
            "failed_node_id": failed_node_id,
            "affected_tasks": updated_state.recovery_info.as_ref().unwrap().affected_tasks,
        }),
    };
    
    self.event_store.append_event(workflow_id, &updated_state.current_execution_id.clone().unwrap_or_default(), &event).await
        .map_err(|e| FaultHandlingError::EventStoreFailed(e.to_string()))?;
        
    // 通知工作流引擎重新调度工作流
    self.workflow_engine.reschedule_workflow(workflow_id).await
        .map_err(|e| FaultHandlingError::RescheduleFailed(e.to_string()))?;
        
    log::info!("工作流恢复流程已启动: workflow_id={}, strategy={:?}", 
              workflow_id, strategy_type);
              
    Ok(())
}

/// 确定恢复策略
fn determine_recovery_strategy(
    &self,
    workflow_state: &WorkflowState,
    failed_node_id: &str,
) -> RecoveryStrategyType {
    // 获取故障任务
    let failed_tasks: Vec<_> = workflow_state.task_states.iter()
        .filter(|(_, task)| {
            task.node_id.as_deref() == Some(failed_node_id) && 
            matches!(task.status, TaskStatus::Running | TaskStatus::Scheduled)
        })
        .collect();
        
    // 如果没有正在运行的故障任务，则使用简单重新调度
    if failed_tasks.is_empty() {
        return RecoveryStrategyType::Reschedule;
    }
    
    // 检查是否有检查点
    let has_checkpoint = workflow_state.recovery_points.iter()
        .any(|point| point.point_type == RecoveryPointType::Checkpoint);
        
    // 如果有检查点，优先使用检查点恢复
    if has_checkpoint {
        return RecoveryStrategyType::CheckpointRestore;
    }
    
    // 如果工作流支持补偿，使用补偿策略
    let workflow_definition = self.workflow_engine.get_workflow_definition(&workflow_state.workflow_type).unwrap();
    if workflow_definition.supports_compensation {
        return RecoveryStrategyType::Compensation;
    }
    
    // 默认使用重试策略
    RecoveryStrategyType::Retry
}
}

/// 分布式工作流调度器
pub struct DistributedWorkflowScheduler {
    /// 调度器ID
    id: String,
    
    /// 集群管理器
    cluster_manager: Arc<ClusterManager>,
    
    /// 事件总线
    event_bus: Arc<EventBus>,
    
    /// 状态存储
    state_store: Arc<dyn StateStore>,
    
    /// 锁服务
    lock_service: Arc<dyn LockService>,
    
    /// 工作流执行器
    workflow_executor: Arc<WorkflowExecutor>,
    
    /// 观测性
    observability: Arc<WorkflowObservability>,
    
    /// 调度策略
    scheduling_strategy: SchedulingStrategy,
    
    /// 工作流优先级队列
    priority_queues: Arc<RwLock<PriorityQueues>>,
    
    /// 活跃工作流实例
    active_workflows: Arc<RwLock<HashMap<String, WorkflowExecutionInfo>>>,
    
    /// 调度配置
    config: SchedulerConfig,
    
    /// 是否运行中
    running: AtomicBool,
    
    /// 关闭通道
    shutdown_tx: watch::Sender<bool>,
    
    /// 关闭通道接收器
    shutdown_rx: watch::Receiver<bool>,
}

impl DistributedWorkflowScheduler {
    /// 创建新的分布式工作流调度器
    pub fn new(
        id: String,
        cluster_manager: Arc<ClusterManager>,
        event_bus: Arc<EventBus>,
        state_store: Arc<dyn StateStore>,
        lock_service: Arc<dyn LockService>,
        workflow_executor: Arc<WorkflowExecutor>,
        observability: Arc<WorkflowObservability>,
        config: SchedulerConfig,
    ) -> Self {
        let (shutdown_tx, shutdown_rx) = watch::channel(false);
        
        Self {
            id,
            cluster_manager,
            event_bus,
            state_store,
            lock_service,
            workflow_executor,
            observability,
            scheduling_strategy: config.scheduling_strategy.clone(),
            priority_queues: Arc::new(RwLock::new(PriorityQueues::new())),
            active_workflows: Arc::new(RwLock::new(HashMap::new())),
            config,
            running: AtomicBool::new(false),
            shutdown_tx,
            shutdown_rx,
        }
    }
    
    /// 启动调度器
    pub async fn start(&self) -> Result<(), SchedulerError> {
        // 检查是否已运行
        if self.running.load(Ordering::Acquire) {
            return Err(SchedulerError::AlreadyRunning);
        }
        
        // 设置运行状态
        self.running.store(true, Ordering::Release);
        
        // 启动工作流执行器
        self.workflow_executor.start().await
            .map_err(|e| SchedulerError::ExecutorStartFailed(e.to_string()))?;
            
        // 注册集群事件监听器
        self.register_cluster_event_listeners();
        
        // 注册工作流事件监听器
        self.register_workflow_event_listeners();
        
        // 启动调度循环
        self.start_scheduling_loop();
        
        // 恢复中断的工作流
        self.recover_interrupted_workflows().await
            .map_err(|e| SchedulerError::WorkflowRecoveryFailed(e.to_string()))?;
            
        log::info!("分布式工作流调度器已启动: {}", self.id);
            
        Ok(())
    }
    
    /// 停止调度器
    pub async fn stop(&self) -> Result<(), SchedulerError> {
        // 检查是否已停止
        if !self.running.load(Ordering::Acquire) {
            return Ok(());
        }
        
        // 设置停止状态
        self.running.store(false, Ordering::Release);
        
        // 发送关闭信号
        self.shutdown_tx.send(true)
            .map_err(|_| SchedulerError::ShutdownFailed("无法发送关闭信号".to_string()))?;
            
        // 停止工作流执行器
        self.workflow_executor.stop().await
            .map_err(|e| SchedulerError::ExecutorStopFailed(e.to_string()))?;
            
        // 等待所有活跃工作流完成或超时
        self.wait_for_active_workflows_completion(Duration::from_secs(30)).await;
        
        log::info!("分布式工作流调度器已停止: {}", self.id);
        
        Ok(())
    }
    
    /// 调度工作流
    pub async fn schedule_workflow(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        input: Option<serde_json::Value>,
        options: WorkflowScheduleOptions,
    ) -> Result<String, SchedulerError> {
        // 检查是否运行
        if !self.running.load(Ordering::Acquire) {
            return Err(SchedulerError::NotRunning);
        }
        
        // 生成执行ID
        let execution_id = format!("exec-{}", Uuid::new_v4().to_string());
        
        // 构建工作流状态
        let workflow_state = WorkflowState {
            workflow_id: workflow_id.to_string(),
            workflow_type: workflow_type.to_string(),
            status: WorkflowStatus::Pending,
            start_time: None,
            end_time: None,
            input: input.clone(),
            result: None,
            error: None,
            failure_reason: None,
            cancellation_reason: None,
            timeout_type: None,
            current_execution_id: Some(execution_id.clone()),
            task_states: HashMap::new(),
            recovery_points: Vec::new(),
            recovery_info: None,
            metrics: WorkflowMetrics::new(),
            options,
        };
        
        // 保存工作流状态
        self.state_store.create_workflow_state(workflow_id, &workflow_state).await
            .map_err(|e| SchedulerError::StatePersistenceFailed(e.to_string()))?;
            
        // 创建工作流开始事件
        let start_event = Event {
            event_id: 1, // 初始事件
            event_type: EventType::WorkflowExecutionStarted,
            workflow_id: workflow_id.to_string(),
            execution_id: execution_id.clone(),
            timestamp: Utc::now(),
            attributes: serde_json::json!({
                "workflow_type": workflow_type,
                "input": input,
                "execution_timeout": options.execution_timeout.map(|d| d.as_secs()),
            }),
        };
        
        // 保存工作流事件
        self.event_store.append_event(workflow_id, &execution_id, &start_event).await
            .map_err(|e| SchedulerError::EventPersistenceFailed(e.to_string()))?;
            
        // 添加到调度队列
        let priority = options.priority.unwrap_or(WorkflowPriority::Normal);
        self.enqueue_workflow(workflow_id, workflow_type, priority).await?;
        
        // 记录工作流已调度
        self.observability.record_workflow_scheduled(
            workflow_id,
            &execution_id,
            workflow_type,
            &priority.to_string(),
        );
        
        log::info!("工作流已调度: workflow_id={}, execution_id={}, type={}, priority={:?}", 
                  workflow_id, execution_id, workflow_type, priority);
                  
        Ok(execution_id)
    }
    
    /// 取消工作流
    pub async fn cancel_workflow(
        &self,
        workflow_id: &str,
        reason: Option<String>,
    ) -> Result<(), SchedulerError> {
        // 检查是否运行
        if !self.running.load(Ordering::Acquire) {
            return Err(SchedulerError::NotRunning);
        }
        
        // 获取工作流状态
        let workflow_state = match self.state_store.get_workflow_state(workflow_id).await {
            Ok(state) => state,
            Err(e) => return Err(SchedulerError::WorkflowNotFound(e.to_string())),
        };
        
        // 检查工作流是否可取消
        if matches!(workflow_state.status, 
            WorkflowStatus::Completed | 
            WorkflowStatus::Failed | 
            WorkflowStatus::Cancelled | 
            WorkflowStatus::TimedOut) {
            return Err(SchedulerError::InvalidWorkflowState(
                format!("工作流已处于终态: {:?}", workflow_state.status)
            ));
        }
        
        // 获取当前执行ID
        let execution_id = workflow_state.current_execution_id.clone()
            .ok_or_else(|| SchedulerError::InvalidWorkflowState("工作流没有活跃的执行ID".to_string()))?;
            
        // 尝试从队列中移除
        let removed = self.dequeue_workflow(workflow_id).await;
        
        // 如果正在执行中，则发送取消信号
        if !removed {
            // 通知执行器取消工作流
            self.workflow_executor.cancel_workflow(workflow_id).await
                .map_err(|e| SchedulerError::CancellationFailed(e.to_string()))?;
        }
        
        // 创建取消事件
        let cancel_event = Event {
            event_id: 0, // 将由事件存储分配
            event_type: EventType::WorkflowExecutionCancelled,
            workflow_id: workflow_id.to_string(),
            execution_id,
            timestamp: Utc::now(),
            attributes: serde_json::json!({
                "reason": reason.clone().unwrap_or_else(|| "用户请求取消".to_string()),
            }),
        };
        
        // 保存取消事件
        self.event_store.append_event(workflow_id, &workflow_state.current_execution_id.unwrap(), &cancel_event).await
            .map_err(|e| SchedulerError::EventPersistenceFailed(e.to_string()))?;
            
        // 更新工作流状态
        let mut updated_state = workflow_state.clone();
        updated_state.status = WorkflowStatus::Cancelled;
        updated_state.end_time = Some(Utc::now());
        updated_state.cancellation_reason = reason;
        
        self.state_store.update_workflow_state(workflow_id, &updated_state).await
            .map_err(|e| SchedulerError::StatePersistenceFailed(e.to_string()))?;
            
        // 从活跃工作流中移除
        {
            let mut active_workflows = self.active_workflows.write().await;
            active_workflows.remove(workflow_id);
        }
        
        // 记录工作流取消
        self.observability.record_workflow_cancelled(
            workflow_id,
            &updated_state.current_execution_id.unwrap(),
            &updated_state.cancellation_reason.unwrap_or_default(),
        );
        
        log::info!("工作流已取消: workflow_id={}, reason={}", 
                  workflow_id, updated_state.cancellation_reason.unwrap_or_default());
                  
        Ok(())
    }
    
    /// 启动调度循环
    fn start_scheduling_loop(&self) {
        let scheduler = self.clone();
        tokio::spawn(async move {
            let mut interval = time::interval(Duration::from_millis(scheduler.config.scheduling_interval_ms));
            let mut shutdown_rx = scheduler.shutdown_rx.clone();
            
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        if let Err(e) = scheduler.schedule_next_batch().await {
                            log::error!("调度下一批工作流失败: {}", e);
                        }
                    }
                    _ = shutdown_rx.changed() => {
                        if *shutdown_rx.borrow() {
                            log::info!("调度循环收到关闭信号");
                            break;
                        }
                    }
                }
            }
            
            log::info!("调度循环已停止");
        });
    }
    
    /// 调度下一批工作流
    async fn schedule_next_batch(&self) -> Result<usize, SchedulerError> {
        // 创建分布式锁
        let lock_key = format!("scheduler:lock:{}", self.cluster_manager.get_partition_id());
        let lock_acquired = self.lock_service.try_acquire_lock(&lock_key, self.id.clone(), Duration::from_secs(5)).await
            .map_err(|e| SchedulerError::LockAcquisitionFailed(e.to_string()))?;
            
        if !lock_acquired {
            // 其他调度器已获取锁，跳过本次调度
            return Ok(0);
        }
        
        // 确保锁在函数退出时释放
        let lock_key_clone = lock_key.clone();
        let lock_service = self.lock_service.clone();
        let scheduler_id = self.id.clone();
        let _lock_guard = scopeguard::guard((), |_| {
            tokio::spawn(async move {
                let _ = lock_service.release_lock(&lock_key_clone, &scheduler_id).await;
            });
        });
        
        // 获取集群资源状态
        let cluster_resources = self.cluster_manager.get_cluster_resources().await
            .map_err(|e| SchedulerError::ClusterResourcesFailed(e.to_string()))?;
            
        // 获取可执行的工作流
        let workflows_to_execute = self.select_workflows_to_execute(&cluster_resources).await?;
        
        if workflows_to_execute.is_empty() {
            return Ok(0);
        }
        
        // 执行选定的工作流
        let mut executed_count = 0;
        
        for scheduled_workflow in workflows_to_execute {
            // 分配执行节点
            let assigned_node = self.assign_execution_node(&scheduled_workflow, &cluster_resources).await?;
            
            // 提交工作流到执行器
            let execution_info = WorkflowExecutionInfo {
                workflow_id: scheduled_workflow.workflow_id.clone(),
                execution_id: scheduled_workflow.execution_id.clone(),
                node_id: assigned_node.node_id.clone(),
                scheduled_time: Utc::now(),
                status: WorkflowExecutionStatus::Scheduled,
            };
            
            self.workflow_executor.execute_workflow(
                &scheduled_workflow.workflow_id,
                &scheduled_workflow.workflow_type,
                &scheduled_workflow.execution_id,
                &assigned_node.node_id,
            ).await.map_err(|e| SchedulerError::ExecutionFailed(e.to_string()))?;
            
            // 记录活跃工作流
            {
                let mut active_workflows = self.active_workflows.write().await;
                active_workflows.insert(scheduled_workflow.workflow_id.clone(), execution_info);
            }
            
            // 更新工作流状态
            let mut workflow_state = self.state_store.get_workflow_state(&scheduled_workflow.workflow_id).await
                .map_err(|e| SchedulerError::StateRetrievalFailed(e.to_string()))?;
                
            workflow_state.status = WorkflowStatus::Running;
            workflow_state.start_time = Some(Utc::now());
            
            self.state_store.update_workflow_state(&scheduled_workflow.workflow_id, &workflow_state).await
                .map_err(|e| SchedulerError::StatePersistenceFailed(e.to_string()))?;
                
            // 创建工作流开始执行事件
            let started_event = Event {
                event_id: 0, // 将由事件存储分配
                event_type: EventType::WorkflowExecutionStarted,
                workflow_id: scheduled_workflow.workflow_id.clone(),
                execution_id: scheduled_workflow.execution_id.clone(),
                timestamp: Utc::now(),
                attributes: serde_json::json!({
                    "node_id": assigned_node.node_id,
                    "workflow_type": scheduled_workflow.workflow_type,
                }),
            };
            
            self.event_store.append_event(
                &scheduled_workflow.workflow_id, 
                &scheduled_workflow.execution_id, 
                &started_event
            ).await.map_err(|e| SchedulerError::EventPersistenceFailed(e.to_string()))?;
            
            // 记录工作流开始执行
            self.observability.record_workflow_execution_started(
                &scheduled_workflow.workflow_id,
                &scheduled_workflow.execution_id,
                &scheduled_workflow.workflow_type,
                &assigned_node.node_id,
            );
            
            log::info!("工作流开始执行: workflow_id={}, execution_id={}, node_id={}", 
                      scheduled_workflow.workflow_id, scheduled_workflow.execution_id, assigned_node.node_id);
                      
            executed_count += 1;
            
            // 检查是否达到批处理限制
            if executed_count >= self.config.max_batch_size {
                break;
            }
        }
        
        Ok(executed_count)
    }
    
    /// 选择要执行的工作流
    async fn select_workflows_to_execute(
        &self,
        cluster_resources: &ClusterResources,
    ) -> Result<Vec<ScheduledWorkflowInfo>, SchedulerError> {
        // 根据调度策略选择工作流
        match self.scheduling_strategy {
            SchedulingStrategy::StrictPriority => {
                self.select_workflows_by_strict_priority(cluster_resources).await
            },
            SchedulingStrategy::WeightedFair => {
                self.select_workflows_by_weighted_fair(cluster_resources).await
            },
            SchedulingStrategy::Resource => {
                self.select_workflows_by_resource(cluster_resources).await
            },
            SchedulingStrategy::Deadline => {
                self.select_workflows_by_deadline(cluster_resources).await
            },
            SchedulingStrategy::DynamicAdaptive => {
                self.select_workflows_dynamically(cluster_resources).await
            },
        }
    }
    
    /// 按严格优先级选择工作流
    async fn select_workflows_by_strict_priority(
        &self,
        cluster_resources: &ClusterResources,
    ) -> Result<Vec<ScheduledWorkflowInfo>, SchedulerError> {
        let mut selected_workflows = Vec::new();
        let mut remaining_resources = cluster_resources.clone();
        
        // 按优先级从高到低处理队列
        let priority_queues = self.priority_queues.read().await;
        
        for priority in [
            WorkflowPriority::Critical,
            WorkflowPriority::High,
            WorkflowPriority::Normal,
            WorkflowPriority::Low,
            WorkflowPriority::Background,
        ] {
            if let Some(queue) = priority_queues.get_queue(&priority) {
                for workflow_id in queue.iter() {
                    // 检查是否有足够资源
                    let workflow_state = match self.state_store.get_workflow_state(workflow_id).await {
                        Ok(state) => state,
                        Err(e) => {
                            log::warn!("无法获取工作流状态，跳过调度: workflow_id={}, error={}", workflow_id, e);
                            continue;
                        }
                    };
                    
                    // 计算工作流资源需求
                    let resource_requirements = self.calculate_workflow_resources(&workflow_state);
                    
                    // 检查资源是否满足
                    if !remaining_resources.can_accommodate(&resource_requirements) {
                        continue;
                    }
                    
                    // 从资源中减去已分配部分
                    remaining_resources.allocate(&resource_requirements);
                    
                    // 添加到选中的工作流列表
                    selected_workflows.push(ScheduledWorkflowInfo {
                        workflow_id: workflow_id.clone(),
                        workflow_type: workflow_state.workflow_type.clone(),
                        execution_id: workflow_state.current_execution_id.clone().unwrap_or_default(),
                        priority,
                        resource_requirements,
                        scheduled_at: Utc::now(),
                    });
                    
                    // 检查是否达到批处理限制
                    if selected_workflows.len() >= self.config.max_batch_size {
                        return Ok(selected_workflows);
                    }
                }
            }
        }
        
        Ok(selected_workflows)
    }
    
    /// 分配执行节点
    async fn assign_execution_node(
        &self,
        workflow: &ScheduledWorkflowInfo,
        cluster_resources: &ClusterResources,
    ) -> Result<NodeInfo, SchedulerError> {
        // 获取所有活跃节点
        let active_nodes = self.cluster_manager.get_active_nodes().await
            .map_err(|e| SchedulerError::NodeSelectionFailed(e.to_string()))?;
            
        if active_nodes.is_empty() {
            return Err(SchedulerError::NoAvailableNodes("没有可用的执行节点".to_string()));
        }
        
        // 筛选满足资源要求的节点
        let candidate_nodes: Vec<_> = active_nodes.iter()
            .filter(|node| {
                let node_resources = cluster_resources.get_node_resources(&node.node_id);
                match node_resources {
                    Some(resources) => resources.can_accommodate(&workflow.resource_requirements),
                    None => false,
                }
            })
            .collect();
            
        if candidate_nodes.is_empty() {
            return Err(SchedulerError::NoAvailableNodes(
                format!("没有节点满足工作流资源需求: workflow_id={}", workflow.workflow_id)

Search files...
继续实现分布式工作流执行系统的关键组件：

```rust
            ))
        }
        
        // 使用基于负载的节点选择算法选择最优节点
        let selected_node = self.select_best_node(&candidate_nodes, &workflow.resource_requirements)
            .ok_or_else(|| SchedulerError::NodeSelectionFailed("无法选择最佳执行节点".to_string()))?;
            
        Ok(selected_node.clone())
    }
    
    /// 选择最佳执行节点
    fn select_best_node(
        &self,
        candidates: &[&NodeInfo],
        resource_requirements: &ResourceRequirements,
    ) -> Option<&NodeInfo> {
        // 如果只有一个候选节点，直接选择
        if candidates.len() == 1 {
            return Some(candidates[0]);
        }
        
        // 计算每个节点的负载分数
        let mut node_scores: Vec<(f64, &NodeInfo)> = Vec::with_capacity(candidates.len());
        
        for node in candidates {
            // 获取节点最近的负载统计
            let load_stats = match self.cluster_manager.get_node_load_stats(&node.node_id) {
                Ok(stats) => stats,
                Err(_) => continue, // 跳过无法获取负载信息的节点
            };
            
            // 计算资源利用率
            let cpu_utilization = load_stats.cpu_utilization;
            let memory_utilization = load_stats.memory_utilization;
            let gpu_utilization = load_stats.gpu_utilization.unwrap_or(0.0);
            
            // 计算节点负载分数（越低越好）
            let mut score = 0.0;
            
            // 根据资源需求类型赋予不同权重
            if resource_requirements.cpu_cores > 0.0 {
                score += cpu_utilization * 0.5;
            }
            
            if resource_requirements.memory_mb > 0 {
                score += memory_utilization * 0.3;
            }
            
            if resource_requirements.gpu_memory_mb.unwrap_or(0) > 0 {
                score += gpu_utilization * 0.8;
            }
            
            // 考虑节点最近任务完成率
            score -= load_stats.task_success_rate * 0.2;
            
            // 加入近期错误率（越高分数越高）
            score += load_stats.recent_error_rate * 0.3;
            
            node_scores.push((score, *node));
        }
        
        // 按分数排序（升序，最低分最优）
        node_scores.sort_by(|a, b| a.0.partial_cmp(&b.0).unwrap_or(std::cmp::Ordering::Equal));
        
        // 返回最佳节点
        node_scores.first().map(|(_, node)| node)
    }
    
    /// 计算工作流资源需求
    fn calculate_workflow_resources(&self, workflow_state: &WorkflowState) -> ResourceRequirements {
        // 获取工作流定义
        let workflow_definition = match self.workflow_engine.get_workflow_definition(&workflow_state.workflow_type) {
            Some(def) => def,
            None => return ResourceRequirements::default(), // 返回默认资源需求
        };
        
        // 基础资源需求
        let mut requirements = ResourceRequirements {
            cpu_cores: 1.0,                // 默认需要1个CPU核心
            memory_mb: 512,                // 默认需要512MB内存
            disk_mb: 1024,                 // 默认需要1GB磁盘
            network_bandwidth_mbps: 10,    // 默认需要10Mbps网络带宽
            gpu_memory_mb: None,           // 默认不需要GPU
            special_hardware: Vec::new(),  // 默认不需要特殊硬件
        };
        
        // 根据工作流类型调整资源需求
        match workflow_state.workflow_type.as_str() {
            "DATA_PROCESSING" => {
                requirements.cpu_cores = 2.0;
                requirements.memory_mb = 2048;
                requirements.disk_mb = 4096;
            },
            "ML_TRAINING" => {
                requirements.cpu_cores = 4.0;
                requirements.memory_mb = 8192;
                requirements.gpu_memory_mb = Some(4096);
            },
            "AI_INFERENCE" => {
                requirements.cpu_cores = 2.0;
                requirements.memory_mb = 4096;
                requirements.gpu_memory_mb = Some(2048);
            },
            "VIDEO_PROCESSING" => {
                requirements.cpu_cores = 4.0;
                requirements.memory_mb = 4096;
                requirements.gpu_memory_mb = Some(2048);
            },
            _ => {
                // 使用工作流定义中的资源需求
                if let Some(resources) = &workflow_definition.resource_requirements {
                    requirements.cpu_cores = resources.cpu_cores.unwrap_or(requirements.cpu_cores);
                    requirements.memory_mb = resources.memory_mb.unwrap_or(requirements.memory_mb);
                    requirements.disk_mb = resources.disk_mb.unwrap_or(requirements.disk_mb);
                    requirements.network_bandwidth_mbps = resources.network_bandwidth_mbps.unwrap_or(requirements.network_bandwidth_mbps);
                    requirements.gpu_memory_mb = resources.gpu_memory_mb;
                    requirements.special_hardware = resources.special_hardware.clone().unwrap_or_default();
                }
            }
        }
        
        // 考虑工作流选项中的资源限制
        if let Some(resource_limits) = &workflow_state.options.resource_limits {
            requirements.cpu_cores = resource_limits.cpu_cores.unwrap_or(requirements.cpu_cores);
            requirements.memory_mb = resource_limits.memory_mb.unwrap_or(requirements.memory_mb);
            requirements.disk_mb = resource_limits.disk_mb.unwrap_or(requirements.disk_mb);
            requirements.network_bandwidth_mbps = resource_limits.network_bandwidth_mbps.unwrap_or(requirements.network_bandwidth_mbps);
            requirements.gpu_memory_mb = resource_limits.gpu_memory_mb.or(requirements.gpu_memory_mb);
            
            if let Some(hw) = &resource_limits.special_hardware {
                requirements.special_hardware = hw.clone();
            }
        }
        
        requirements
    }
    
    /// 将工作流添加到调度队列
    async fn enqueue_workflow(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        priority: WorkflowPriority,
    ) -> Result<(), SchedulerError> {
        let mut priority_queues = self.priority_queues.write().await;
        priority_queues.enqueue(workflow_id, priority)
            .map_err(|e| SchedulerError::EnqueueFailed(e.to_string()))
    }
    
    /// 从调度队列中移除工作流
    async fn dequeue_workflow(&self, workflow_id: &str) -> bool {
        let mut priority_queues = self.priority_queues.write().await;
        priority_queues.remove(workflow_id)
    }
    
    /// 等待活跃工作流完成
    async fn wait_for_active_workflows_completion(&self, timeout: Duration) {
        let start_time = Instant::now();
        let mut interval = time::interval(Duration::from_millis(100));
        
        loop {
            let active_count = {
                let active_workflows = self.active_workflows.read().await;
                active_workflows.len()
            };
            
            if active_count == 0 {
                break;
            }
            
            if start_time.elapsed() > timeout {
                log::warn!("超时等待活跃工作流完成，仍有{}个工作流运行中", active_count);
                break;
            }
            
            interval.tick().await;
        }
    }
    
    /// 恢复中断的工作流
    async fn recover_interrupted_workflows(&self) -> Result<(), SchedulerError> {
        // 获取处于运行状态的工作流
        let running_workflows = self.state_store.get_workflows_by_status(WorkflowStatus::Running).await
            .map_err(|e| SchedulerError::StateRetrievalFailed(e.to_string()))?;
            
        log::info!("发现{}个中断的工作流需要恢复", running_workflows.len());
        
        for workflow_state in running_workflows {
            // 检查工作流是否真的在执行
            let is_actually_running = {
                let active_workflows = self.active_workflows.read().await;
                active_workflows.contains_key(&workflow_state.workflow_id)
            };
            
            if is_actually_running {
                continue; // 工作流已在运行，跳过
            }
            
            // 重新入队等待调度
            let priority = workflow_state.options.priority.unwrap_or(WorkflowPriority::Normal);
            self.enqueue_workflow(&workflow_state.workflow_id, &workflow_state.workflow_type, priority).await?;
            
            // 记录工作流已恢复
            log::info!("工作流已重新入队等待恢复: workflow_id={}", workflow_state.workflow_id);
        }
        
        Ok(())
    }
    
    /// 注册集群事件监听器
    fn register_cluster_event_listeners(&self) {
        let scheduler = self.clone();
        
        // 节点故障处理
        self.event_bus.subscribe(EventType::NodeFailed, move |event| {
            let scheduler = scheduler.clone();
            tokio::spawn(async move {
                if let Ok(payload) = serde_json::from_value::<NodeFailedEvent>(event.attributes.clone()) {
                    if let Err(err) = scheduler.handle_node_failure(&payload.node_id).await {
                        log::error!("处理节点故障失败: node_id={}, error={}", payload.node_id, err);
                    }
                }
            });
        });
        
        let scheduler = self.clone();
        
        // 节点恢复处理
        self.event_bus.subscribe(EventType::NodeRecovered, move |event| {
            let scheduler = scheduler.clone();
            tokio::spawn(async move {
                if let Ok(payload) = serde_json::from_value::<NodeRecoveredEvent>(event.attributes.clone()) {
                    if let Err(err) = scheduler.handle_node_recovery(&payload.node_id).await {
                        log::error!("处理节点恢复失败: node_id={}, error={}", payload.node_id, err);
                    }
                }
            });
        });
    }
    
    /// 注册工作流事件监听器
    fn register_workflow_event_listeners(&self) {
        let scheduler = self.clone();
        
        // 工作流完成处理
        self.event_bus.subscribe(EventType::WorkflowExecutionCompleted, move |event| {
            let scheduler = scheduler.clone();
            tokio::spawn(async move {
                let workflow_id = event.workflow_id.clone();
                
                // 从活跃工作流中移除
                {
                    let mut active_workflows = scheduler.active_workflows.write().await;
                    active_workflows.remove(&workflow_id);
                }
                
                log::info!("工作流已完成: workflow_id={}", workflow_id);
            });
        });
        
        let scheduler = self.clone();
        
        // 工作流失败处理
        self.event_bus.subscribe(EventType::WorkflowExecutionFailed, move |event| {
            let scheduler = scheduler.clone();
            tokio::spawn(async move {
                let workflow_id = event.workflow_id.clone();
                
                // 从活跃工作流中移除
                {
                    let mut active_workflows = scheduler.active_workflows.write().await;
                    active_workflows.remove(&workflow_id);
                }
                
                log::info!("工作流已失败: workflow_id={}", workflow_id);
            });
        });
    }
    
    /// 处理节点故障
    async fn handle_node_failure(&self, node_id: &str) -> Result<(), SchedulerError> {
        log::info!("处理节点故障: node_id={}", node_id);
        
        // 获取受影响的工作流
        let affected_workflows = {
            let active_workflows = self.active_workflows.read().await;
            active_workflows.iter()
                .filter(|(_, info)| info.node_id == node_id)
                .map(|(id, _)| id.clone())
                .collect::<Vec<_>>()
        };
        
        if affected_workflows.is_empty() {
            log::info!("节点故障不影响任何工作流: node_id={}", node_id);
            return Ok(());
        }
        
        log::info!("节点故障影响{}个工作流: node_id={}", affected_workflows.len(), node_id);
        
        // 为每个受影响的工作流创建恢复任务
        for workflow_id in affected_workflows {
            // 从活跃工作流中移除
            {
                let mut active_workflows = self.active_workflows.write().await;
                active_workflows.remove(&workflow_id);
            }
            
            // 获取工作流状态
            let mut workflow_state = match self.state_store.get_workflow_state(&workflow_id).await {
                Ok(state) => state,
                Err(e) => {
                    log::error!("获取工作流状态失败: workflow_id={}, error={}", workflow_id, e);
                    continue;
                }
            };
            
            // 更新工作流状态为恢复中
            workflow_state.status = WorkflowStatus::Recovering;
            workflow_state.recovery_info = Some(RecoveryInfo {
                recovery_start_time: Utc::now(),
                recovery_strategy: RecoveryStrategyType::Reschedule.to_string(),
                failed_node_id: node_id.to_string(),
                affected_tasks: Vec::new(), // 具体任务将在恢复过程中确定
            });
            
            // 保存工作流状态
            if let Err(e) = self.state_store.update_workflow_state(&workflow_id, &workflow_state).await {
                log::error!("更新工作流状态失败: workflow_id={}, error={}", workflow_id, e);
                continue;
            }
            
            // 创建节点故障事件
            let node_failed_event = Event {
                event_id: 0, // 将由事件存储分配
                event_type: EventType::WorkflowNodeFailed,
                workflow_id: workflow_id.clone(),
                execution_id: workflow_state.current_execution_id.clone().unwrap_or_default(),
                timestamp: Utc::now(),
                attributes: serde_json::json!({
                    "node_id": node_id,
                    "reason": "节点故障",
                }),
            };
            
            // 记录事件
            if let Err(e) = self.event_store.append_event(
                &workflow_id, 
                &workflow_state.current_execution_id.clone().unwrap_or_default(), 
                &node_failed_event
            ).await {
                log::error!("记录节点故障事件失败: workflow_id={}, error={}", workflow_id, e);
            }
            
            // 重新入队等待调度
            let priority = workflow_state.options.priority.unwrap_or(WorkflowPriority::Normal);
            if let Err(e) = self.enqueue_workflow(&workflow_id, &workflow_state.workflow_type, priority).await {
                log::error!("重新入队工作流失败: workflow_id={}, error={}", workflow_id, e);
                continue;
            }
            
            log::info!("工作流已标记为恢复状态，等待重新调度: workflow_id={}", workflow_id);
        }
        
        Ok(())
    }
    
    /// 处理节点恢复
    async fn handle_node_recovery(&self, node_id: &str) -> Result<(), SchedulerError> {
        log::info!("处理节点恢复: node_id={}", node_id);
        
        // 更新集群资源状态
        if let Err(e) = self.cluster_manager.update_node_status(node_id, NodeStatus::Active).await {
            log::error!("更新节点状态失败: node_id={}, error={}", node_id, e);
        }
        
        // 触发下一轮调度
        if let Err(e) = self.schedule_next_batch().await {
            log::error!("触发下一轮调度失败: error={}", e);
        }
        
        Ok(())
    }
}

/// 工作流执行引擎
pub struct WorkflowExecutor {
    /// 执行器ID
    id: String,
    
    /// 任务执行器
    task_executor: Arc<TaskExecutor>,
    
    /// 工作流执行中间件
    execution_middleware: Vec<Box<dyn WorkflowExecutionMiddleware>>,
    
    /// 工作流存储
    workflow_storage: Arc<dyn WorkflowStorage>,
    
    /// 工作流指标收集器
    metrics: Arc<WorkflowMetrics>,
    
    /// 观测性
    observability: Arc<WorkflowObservability>,
    
    /// 任务队列
    task_queue: Arc<TaskQueue>,
    
    /// 执行配置
    config: ExecutorConfig,
    
    /// 是否运行中
    running: AtomicBool,
    
    /// 关闭通道
    shutdown_tx: watch::Sender<bool>,
    
    /// 关闭通道接收器
    shutdown_rx: watch::Receiver<bool>,
}

impl WorkflowExecutor {
    /// 创建工作流执行器
    pub fn new(
        id: String,
        task_executor: Arc<TaskExecutor>,
        workflow_storage: Arc<dyn WorkflowStorage>,
        metrics: Arc<WorkflowMetrics>,
        observability: Arc<WorkflowObservability>,
        config: ExecutorConfig,
    ) -> Self {
        let (shutdown_tx, shutdown_rx) = watch::channel(false);
        
        Self {
            id,
            task_executor,
            execution_middleware: Vec::new(),
            workflow_storage,
            metrics,
            observability,
            task_queue: Arc::new(TaskQueue::new(config.queue_capacity)),
            config,
            running: AtomicBool::new(false),
            shutdown_tx,
            shutdown_rx,
        }
    }
    
    /// 添加执行中间件
    pub fn add_middleware<T: WorkflowExecutionMiddleware + 'static>(&mut self, middleware: T) {
        self.execution_middleware.push(Box::new(middleware));
    }
    
    /// 启动执行器
    pub async fn start(&self) -> Result<(), ExecutorError> {
        // 检查是否已运行
        if self.running.load(Ordering::Acquire) {
            return Err(ExecutorError::AlreadyRunning);
        }
        
        // 设置运行状态
        self.running.store(true, Ordering::Release);
        
        // 启动工作线程
        self.start_worker_threads();
        
        log::info!("工作流执行器已启动: {}", self.id);
        
        Ok(())
    }
    
    /// 停止执行器
    pub async fn stop(&self) -> Result<(), ExecutorError> {
        // 检查是否已停止
        if !self.running.load(Ordering::Acquire) {
            return Ok(());
        }
        
        // 设置停止状态
        self.running.store(false, Ordering::Release);
        
        // 发送关闭信号
        self.shutdown_tx.send(true)
            .map_err(|_| ExecutorError::ShutdownFailed("无法发送关闭信号".to_string()))?;
            
        // 等待任务队列清空或超时
        self.wait_for_queue_empty(Duration::from_secs(30)).await;
        
        log::info!("工作流执行器已停止: {}", self.id);
        
        Ok(())
    }
    
    /// 执行工作流
    pub async fn execute_workflow(
        &self,
        workflow_id: &str,
        workflow_type: &str,
        execution_id: &str,
        node_id: &str,
    ) -> Result<(), ExecutorError> {
        // 检查是否运行
        if !self.running.load(Ordering::Acquire) {
            return Err(ExecutorError::NotRunning);
        }
        
        // 创建工作流执行任务
        let execution_task = WorkflowExecutionTask {
            workflow_id: workflow_id.to_string(),
            workflow_type: workflow_type.to_string(),
            execution_id: execution_id.to_string(),
            node_id: node_id.to_string(),
            created_at: Utc::now(),
        };
        
        // 将任务添加到队列
        self.task_queue.push(execution_task).await
            .map_err(|e| ExecutorError::QueueFailed(e.to_string()))?;
            
        log::debug!("工作流执行任务已入队: workflow_id={}, execution_id={}", workflow_id, execution_id);
        
        Ok(())
    }
    
    /// 取消工作流
    pub async fn cancel_workflow(&self, workflow_id: &str) -> Result<(), ExecutorError> {
        // 检查是否运行
        if !self.running.load(Ordering::Acquire) {
            return Err(ExecutorError::NotRunning);
        }
        
        // 获取工作流状态
        let workflow_state = match self.workflow_storage.get_workflow_state(workflow_id).await {
            Ok(state) => state,
            Err(e) => return Err(ExecutorError::WorkflowNotFound(e.to_string())),
        };
        
        // 检查工作流是否在执行中
        if workflow_state.status != WorkflowStatus::Running {
            return Err(ExecutorError::InvalidWorkflowState(
                format!("工作流状态不是运行中: {:?}", workflow_state.status)
            ));
        }
        
        // 发送取消信号
        let cancel_signal = WorkflowCancelSignal {
            workflow_id: workflow_id.to_string(),
            execution_id: workflow_state.current_execution_id.clone().unwrap_or_default(),
            reason: "用户请求取消".to_string(),
            timestamp: Utc::now(),
        };
        
        self.task_executor.cancel_tasks(workflow_id).await
            .map_err(|e| ExecutorError::CancellationFailed(e.to_string()))?;
            
        log::info!("已发送工作流取消信号: workflow_id={}", workflow_id);
        
        Ok(())
    }
    
    /// 启动工作线程
    fn start_worker_threads(&self) {
        for i in 0..self.config.worker_threads {
            let executor = self.clone();
            let worker_id = format!("{}-worker-{}", self.id, i);
            
            tokio::spawn(async move {
                executor.worker_loop(worker_id).await;
            });
        }
    }
    
    /// 工作线程循环
    async fn worker_loop(&self, worker_id: String) {
        log::info!("工作流执行线程已启动: {}", worker_id);
        
        let mut shutdown_rx = self.shutdown_rx.clone();
        
        loop {
            tokio::select! {
                // 等待关闭信号
                _ = shutdown_rx.changed() => {
                    if *shutdown_rx.borrow() {
                        log::info!("工作流执行线程收到关闭信号: {}", worker_id);
                        break;
                    }
                }
                
                // 获取下一个任务
                task_result = self.task_queue.pop() => {
                    match task_result {
                        Ok(task) => {
                            let result = self.process_execution_task(task).await;
                            
                            if let Err(err) = result {
                                log::error!("执行工作流任务失败: worker={}, error={}", worker_id, err);
                            }
                        }
                        Err(err) => {
                            if !self.running.load(Ordering::Acquire) {
                                break;
                            }
                            
                            log::warn!("从任务队列获取任务失败: worker={}, error={}", worker_id, err);
                            
                            // 短暂延迟后重试
                            tokio::time::sleep(Duration::from_millis(100)).await;
                        }
                    }
                }
            }
        }
        
        log::info!("工作流执行线程已停止: {}", worker_id);
    }
    
    /// 处理工作流执行任务
    async fn process_execution_task(&self, task: WorkflowExecutionTask) -> Result<(), ExecutorError> {
        let workflow_id = task.workflow_id.clone();
        let execution_id = task.execution_id.clone();
        let workflow_type = task.workflow_type.clone();
        let node_id = task.node_id.clone();
        
        log::info!("开始执行工作流: workflow_id={}, execution_id={}, type={}", 
                  workflow_id, execution_id, workflow_type);
        
        // 创建执行追踪上下文
        let trace_ctx = self.observability.create_workflow_execution_span(
            &workflow_id,
            &execution_id,
            &workflow_type,
        );
        let _trace_guard = trace_ctx.enter();
        
        // 记录执行开始
        self.metrics.record_workflow_execution_started(&workflow_id, &workflow_type);
        
        // 获取工作流定义
        let workflow_definition = match self.workflow_storage.get_workflow_definition(&workflow_type).await {
            Ok(def) => def,
            Err(e) => {
                let error = format!("获取工作流定义失败: {}", e);
                self.handle_execution_failure(&workflow_id, &execution_id, &error).await?;
                return Err(ExecutorError::WorkflowDefinitionNotFound(error));
            }
        };
        
        // 获取工作流状态
        let mut workflow_state = match self.workflow_storage.get_workflow_state(&workflow_id).await {
            Ok(state) => state,
            Err(e) => {
                let error = format!("获取工作流状态失败: {}", e);
                self.handle_execution_failure(&workflow_id, &execution_id, &error).await?;
                return Err(ExecutorError::WorkflowStateNotFound(error));
            }
        };
        
        // 检查工作流状态
        if workflow_state.status != WorkflowStatus::Running && workflow_state.status != WorkflowStatus::Recovering {
            let error = format!("工作流状态不是运行中或恢复中: {:?}", workflow_state.status);
            self.handle_execution_failure(&workflow_id, &execution_id, &error).await?;
            return Err(ExecutorError::InvalidWorkflowState(error));
        }
        
        // 执行前中间件
        for middleware in &self.execution_middleware {
            if let Err(e) = middleware.before_execution(&workflow_id, &execution_id, &workflow_definition, &workflow_state).await {
                let error = format!("执行前中间件失败: {}", e);
                self.handle_execution_failure(&workflow_id, &execution_id, &error).await?;
                return Err(ExecutorError::MiddlewareFailed(error));
            }
        }
        
        // 构建任务调度计划
        let task_schedule = match self.build_task_schedule(&workflow_definition, &workflow_state).await {
            Ok(schedule) => schedule,
            Err(e) => {
                let error = format!("构建任务调度计划失败: {}", e);
                self.handle_execution_failure(&workflow_id, &execution_id, &error).await?;
                return Err(ExecutorError::ScheduleBuildFailed(error));
            }
        };
        
        // 执行工作流任务
        let execution_result = self.execute_workflow_tasks(
            &workflow_id,
            &execution_id,
            &task_schedule,
            &workflow_definition,
            &mut workflow_state,
        ).await;
        
        // 处理执行结果
        match execution_result {
            Ok(result) => {
                // 更新工作流状态
                workflow_state.status = WorkflowStatus::Completed;
                workflow_state.end_time = Some(Utc::now());
                workflow_state.result = Some(result);
                
                if let Err(e) = self.workflow_storage.update_workflow_state(&workflow_id, &workflow_state).await {
                    log::error!("更新工作流状态失败: workflow_id={}, error={}", workflow_id, e);
                }
                
                // 创建工作流完成事件
                let completed_event = Event {
                    event_id: 0, // 将
    event_id: 0, // 将由事件存储分配
    event_type: EventType::WorkflowExecutionCompleted,
    workflow_id: workflow_id.clone(),
    execution_id: execution_id.clone(),
    timestamp: Utc::now(),
    attributes: serde_json::json!({
        "result": result,
    }),
};

// 记录工作流完成事件
if let Err(e) = self.workflow_storage.add_event(&workflow_id, &execution_id, &completed_event).await {
    log::error!("记录工作流完成事件失败: workflow_id={}, error={}", workflow_id, e);
}

// 执行后中间件
for middleware in &self.execution_middleware {
    if let Err(e) = middleware.after_execution(&workflow_id, &execution_id, &workflow_definition, &workflow_state).await {
        log::warn!("执行后中间件失败: {}", e);
    }
}

// 记录执行指标
self.metrics.record_workflow_execution_completed(
    &workflow_id,
    &workflow_type,
    workflow_state.start_time.unwrap_or_else(Utc::now),
    Utc::now(),
);

log::info!("工作流执行完成: workflow_id={}, execution_id={}", workflow_id, execution_id);

Ok(())
            },
            Err(e) => {
                let error = format!("工作流执行失败: {}", e);
                self.handle_execution_failure(&workflow_id, &execution_id, &error).await?;
                return Err(ExecutorError::ExecutionFailed(error));
            }
        }
    }
    
    /// 执行工作流任务
    async fn execute_workflow_tasks(
        &self,
        workflow_id: &str,
        execution_id: &str,
        task_schedule: &TaskSchedule,
        workflow_definition: &WorkflowDefinition,
        workflow_state: &mut WorkflowState,
    ) -> Result<serde_json::Value, ExecutorError> {
        let mut task_results = HashMap::new();
        let mut task_executions = HashMap::new();
        
        // 追踪依赖完成状态
        let mut completed_tasks = HashSet::new();
        
        // 创建多阶段执行器
        let mut pending_tasks = task_schedule.get_initial_tasks();
        
        log::info!("开始执行工作流任务: workflow_id={}, 初始任务数={}", workflow_id, pending_tasks.len());
        
        // 循环执行任务，直到所有任务完成
        while !pending_tasks.is_empty() {
            log::debug!("当前待执行任务数: {}", pending_tasks.len());
            
            // 批量执行当前阶段的任务
            let mut futures = Vec::new();
            
            for task_id in &pending_tasks {
                let task_def = task_schedule.get_task(task_id)
                    .ok_or_else(|| ExecutorError::TaskNotFound(format!("任务不存在: {}", task_id)))?;
                
                // 收集任务输入
                let task_input = self.prepare_task_input(task_id, &task_def, &task_results, workflow_state).await?;
                
                // 创建任务执行上下文
                let task_context = TaskExecutionContext {
                    workflow_id: workflow_id.to_string(),
                    execution_id: execution_id.to_string(),
                    task_id: task_id.clone(),
                    task_type: task_def.task_type.clone(),
                    input: task_input,
                    workflow_state: workflow_state.clone(),
                };
                
                // 提交任务执行
                let execution_future = self.task_executor.execute_task(task_context);
                futures.push(execution_future);
                
                // 记录任务开始执行
                task_executions.insert(task_id.clone(), TaskExecution {
                    task_id: task_id.clone(),
                    start_time: Utc::now(),
                    end_time: None,
                    status: TaskStatus::Running,
                    result: None,
                    error: None,
                });
            }
            
            // 等待所有任务完成
            let results = futures::future::join_all(futures).await;
            
            // 处理任务结果
            for (i, result) in results.into_iter().enumerate() {
                let task_id = &pending_tasks[i];
                
                match result {
                    Ok(result) => {
                        // 更新任务执行状态
                        if let Some(execution) = task_executions.get_mut(task_id) {
                            execution.end_time = Some(Utc::now());
                            execution.status = TaskStatus::Completed;
                            execution.result = Some(result.clone());
                        }
                        
                        // 存储任务结果
                        task_results.insert(task_id.clone(), result);
                        
                        // 标记任务完成
                        completed_tasks.insert(task_id.clone());
                        
                        log::debug!("任务执行成功: task_id={}", task_id);
                    },
                    Err(e) => {
                        // 更新任务执行状态
                        if let Some(execution) = task_executions.get_mut(task_id) {
                            execution.end_time = Some(Utc::now());
                            execution.status = TaskStatus::Failed;
                            execution.error = Some(format!("任务执行失败: {}", e));
                        }
                        
                        log::error!("任务执行失败: task_id={}, error={}", task_id, e);
                        
                        // 根据任务配置决定是否继续
                        let task_def = task_schedule.get_task(task_id).unwrap();
                        
                        if task_def.is_critical {
                            // 关键任务失败，整个工作流失败
                            return Err(ExecutorError::CriticalTaskFailed(format!(
                                "关键任务执行失败: task_id={}, error={}", task_id, e
                            )));
                        } else {
                            // 非关键任务，记录错误但继续执行
                            log::warn!("非关键任务失败，继续执行工作流: task_id={}", task_id);
                            
                            // 标记任务完成（虽然失败）
                            completed_tasks.insert(task_id.clone());
                        }
                    }
                }
            }
            
            // 更新工作流执行状态
            workflow_state.tasks = task_executions.clone();
            if let Err(e) = self.workflow_storage.update_workflow_state(workflow_id, workflow_state).await {
                log::error!("更新工作流状态失败: workflow_id={}, error={}", workflow_id, e);
            }
            
            // 获取下一阶段可执行的任务
            pending_tasks = task_schedule.get_next_executable_tasks(&completed_tasks);
        }
        
        // 检查所有任务是否完成
        let all_tasks = task_schedule.get_all_tasks();
        let critical_tasks = task_schedule.get_critical_tasks();
        
        // 验证所有关键任务都完成了
        for task_id in critical_tasks {
            if !completed_tasks.contains(&task_id) {
                return Err(ExecutorError::IncompleteExecution(format!(
                    "关键任务未完成: task_id={}", task_id
                )));
            }
        }
        
        // 计算工作流输出
        let output = self.calculate_workflow_output(workflow_definition, &task_results)?;
        
        Ok(output)
    }
    
    /// 准备任务输入
    async fn prepare_task_input(
        &self,
        task_id: &str,
        task_def: &TaskDefinition,
        task_results: &HashMap<String, serde_json::Value>,
        workflow_state: &WorkflowState,
    ) -> Result<serde_json::Value, ExecutorError> {
        // 基础任务输入
        let mut task_input = json!({
            "task_id": task_id,
            "workflow_id": workflow_state.workflow_id,
            "execution_id": workflow_state.current_execution_id,
            "task_type": task_def.task_type,
            "workflow_state": {
                "status": workflow_state.status.to_string(),
                "start_time": workflow_state.start_time,
                "current_phase": workflow_state.current_phase,
            }
        });
        
        // 将工作流参数添加到任务输入
        if let Some(params) = &workflow_state.parameters {
            let input_obj = task_input.as_object_mut().unwrap();
            
            for (key, value) in params.as_object().unwrap() {
                input_obj.insert(format!("param_{}", key), value.clone());
            }
        }
        
        // 合并任务依赖的输出
        if let Some(dependencies) = &task_def.dependencies {
            let input_obj = task_input.as_object_mut().unwrap();
            
            for dep in dependencies {
                if let Some(result) = task_results.get(dep) {
                    input_obj.insert(format!("dep_{}", dep), result.clone());
                }
            }
        }
        
        // 合并任务特定参数
        if let Some(params) = &task_def.parameters {
            let input_obj = task_input.as_object_mut().unwrap();
            
            for (key, value) in params.as_object().unwrap() {
                input_obj.insert(key.clone(), value.clone());
            }
        }
        
        Ok(task_input)
    }
    
    /// 计算工作流输出
    fn calculate_workflow_output(
        &self,
        workflow_definition: &WorkflowDefinition,
        task_results: &HashMap<String, serde_json::Value>,
    ) -> Result<serde_json::Value, ExecutorError> {
        // 默认输出为空对象
        let mut output = json!({});
        
        // 如果工作流定义了输出映射，根据映射构建输出
        if let Some(output_mapping) = &workflow_definition.output_mapping {
            let output_obj = output.as_object_mut().unwrap();
            
            for (output_key, mapping) in output_mapping.as_object().unwrap() {
                if let Some(task_id) = mapping["task"].as_str() {
                    if let Some(result_path) = mapping["path"].as_str() {
                        if let Some(task_result) = task_results.get(task_id) {
                            // 根据路径提取值
                            let value = match extract_json_path(task_result, result_path) {
                                Some(val) => val,
                                None => {
                                    log::warn!(
                                        "无法从任务结果中提取路径值: task_id={}, path={}", 
                                        task_id, result_path
                                    );
                                    continue;
                                }
                            };
                            
                            output_obj.insert(output_key.clone(), value);
                        }
                    }
                }
            }
        } else {
            // 没有定义输出映射，使用最后一个任务的结果作为输出
            if let Some(last_task_id) = workflow_definition.final_tasks.first() {
                if let Some(result) = task_results.get(last_task_id) {
                    output = result.clone();
                }
            }
        }
        
        Ok(output)
    }
    
    /// 处理执行失败
    async fn handle_execution_failure(
        &self,
        workflow_id: &str,
        execution_id: &str,
        error_message: &str,
    ) -> Result<(), ExecutorError> {
        log::error!("工作流执行失败: workflow_id={}, execution_id={}, error={}", 
                   workflow_id, execution_id, error_message);
        
        // 获取工作流状态
        let mut workflow_state = match self.workflow_storage.get_workflow_state(workflow_id).await {
            Ok(state) => state,
            Err(e) => {
                log::error!("获取工作流状态失败: workflow_id={}, error={}", workflow_id, e);
                return Ok(());
            }
        };
        
        // 更新工作流状态
        workflow_state.status = WorkflowStatus::Failed;
        workflow_state.end_time = Some(Utc::now());
        workflow_state.error = Some(error_message.to_string());
        
        if let Err(e) = self.workflow_storage.update_workflow_state(workflow_id, &workflow_state).await {
            log::error!("更新工作流状态失败: workflow_id={}, error={}", workflow_id, e);
        }
        
        // 创建工作流失败事件
        let failed_event = Event {
            event_id: 0, // 将由事件存储分配
            event_type: EventType::WorkflowExecutionFailed,
            workflow_id: workflow_id.to_string(),
            execution_id: execution_id.to_string(),
            timestamp: Utc::now(),
            attributes: serde_json::json!({
                "error": error_message,
            }),
        };
        
        // 记录工作流失败事件
        if let Err(e) = self.workflow_storage.add_event(workflow_id, execution_id, &failed_event).await {
            log::error!("记录工作流失败事件失败: workflow_id={}, error={}", workflow_id, e);
        }
        
        // 执行后中间件（即使失败也执行）
        let workflow_definition = match self.workflow_storage.get_workflow_definition(&workflow_state.workflow_type).await {
            Ok(def) => def,
            Err(_) => return Ok(()),
        };
        
        for middleware in &self.execution_middleware {
            if let Err(e) = middleware.after_execution(workflow_id, execution_id, &workflow_definition, &workflow_state).await {
                log::warn!("执行后中间件失败: {}", e);
            }
        }
        
        // 记录执行指标
        self.metrics.record_workflow_execution_failed(
            workflow_id,
            &workflow_state.workflow_type,
            workflow_state.start_time.unwrap_or_else(Utc::now),
            Utc::now(),
            error_message,
        );
        
        Ok(())
    }
    
    /// 构建任务调度计划
    async fn build_task_schedule(
        &self,
        workflow_definition: &WorkflowDefinition,
        workflow_state: &WorkflowState,
    ) -> Result<TaskSchedule, ExecutorError> {
        // 如果是恢复执行，处理特殊逻辑
        if workflow_state.status == WorkflowStatus::Recovering {
            return self.build_recovery_task_schedule(workflow_definition, workflow_state).await;
        }
        
        // 创建新的任务调度计划
        let mut task_schedule = TaskSchedule::new();
        
        // 添加所有任务
        for task in &workflow_definition.tasks {
            task_schedule.add_task(task.clone());
        }
        
        // 构建任务依赖关系
        for task in &workflow_definition.tasks {
            if let Some(dependencies) = &task.dependencies {
                for dep in dependencies {
                    task_schedule.add_dependency(&task.id, dep);
                }
            }
        }
        
        // 标记初始任务
        if let Some(initial_tasks) = &workflow_definition.initial_tasks {
            for task_id in initial_tasks {
                task_schedule.set_as_initial(task_id);
            }
        }
        
        // 校验任务调度计划
        if !task_schedule.is_valid() {
            return Err(ExecutorError::InvalidTaskSchedule(
                "任务调度计划无效，可能存在循环依赖".to_string()
            ));
        }
        
        Ok(task_schedule)
    }
    
    /// 构建恢复任务调度计划
    async fn build_recovery_task_schedule(
        &self,
        workflow_definition: &WorkflowDefinition,
        workflow_state: &WorkflowState,
    ) -> Result<TaskSchedule, ExecutorError> {
        // 创建任务调度计划
        let mut task_schedule = TaskSchedule::new();
        
        // 添加所有任务
        for task in &workflow_definition.tasks {
            task_schedule.add_task(task.clone());
        }
        
        // 构建任务依赖关系
        for task in &workflow_definition.tasks {
            if let Some(dependencies) = &task.dependencies {
                for dep in dependencies {
                    task_schedule.add_dependency(&task.id, dep);
                }
            }
        }
        
        // 确定已完成的任务
        let mut completed_tasks = HashSet::new();
        
        if let Some(tasks) = &workflow_state.tasks {
            for (task_id, execution) in tasks {
                if execution.status == TaskStatus::Completed {
                    completed_tasks.insert(task_id.clone());
                }
            }
        }
        
        // 确定需要重新执行的任务
        let mut rerun_tasks = HashSet::new();
        
        // 如果有恢复信息，根据恢复策略确定需要重新执行的任务
        if let Some(recovery_info) = &workflow_state.recovery_info {
            match recovery_info.recovery_strategy.as_str() {
                "RESUME" => {
                    // 只重新执行未完成的任务
                    // 不需要额外操作，因为已完成的任务在completed_tasks中
                },
                "RERUN_FAILED" => {
                    // 重新执行失败的任务及其依赖
                    if let Some(tasks) = &workflow_state.tasks {
                        for (task_id, execution) in tasks {
                            if execution.status == TaskStatus::Failed {
                                // 将失败任务加入重新执行列表
                                rerun_tasks.insert(task_id.clone());
                                
                                // 将其所有下游任务也加入重新执行列表
                                let downstream = task_schedule.get_downstream_tasks(task_id);
                                for ds_task in downstream {
                                    rerun_tasks.insert(ds_task);
                                }
                            }
                        }
                    }
                },
                "RERUN_ALL" => {
                    // 重新执行所有任务
                    completed_tasks.clear();
                },
                _ => {
                    // 默认策略：重新执行未完成的任务
                }
            }
        }
        
        // 将要重新执行的任务从完成列表中移除
        for task_id in &rerun_tasks {
            completed_tasks.remove(task_id);
        }
        
        // 标记初始任务
        // 1. 原始初始任务中未完成的任务
        // 2. 已完成任务的下游任务中未完成的任务
        let mut initial_tasks = HashSet::new();
        
        if let Some(orig_initial) = &workflow_definition.initial_tasks {
            for task_id in orig_initial {
                if !completed_tasks.contains(task_id) {
                    initial_tasks.insert(task_id.clone());
                }
            }
        }
        
        // 找出已完成任务的直接下游任务
        for completed in &completed_tasks {
            let downstream = task_schedule.get_direct_downstream_tasks(completed);
            
            for ds_task in downstream {
                // 检查该下游任务的所有依赖是否都已完成
                let dependencies = task_schedule.get_dependencies(&ds_task);
                let mut all_deps_completed = true;
                
                for dep in dependencies {
                    if !completed_tasks.contains(&dep) {
                        all_deps_completed = false;
                        break;
                    }
                }
                
                // 如果所有依赖都已完成，且该任务未完成，则加入初始任务
                if all_deps_completed && !completed_tasks.contains(&ds_task) {
                    initial_tasks.insert(ds_task);
                }
            }
        }
        
        // 设置初始任务
        for task_id in initial_tasks {
            task_schedule.set_as_initial(&task_id);
        }
        
        // 从调度计划中移除已完成的任务
        for task_id in &completed_tasks {
            task_schedule.remove_task(task_id);
        }
        
        // 校验任务调度计划
        if !task_schedule.is_valid() {
            return Err(ExecutorError::InvalidTaskSchedule(
                "恢复任务调度计划无效，可能存在循环依赖".to_string()
            ));
        }
        
        Ok(task_schedule)
    }
    
    /// 等待队列清空
    async fn wait_for_queue_empty(&self, timeout: Duration) {
        let start = Instant::now();
        let wait_interval = Duration::from_millis(100);
        
        while start.elapsed() < timeout {
            let is_empty = self.task_queue.is_empty().await;
            
            if is_empty {
                return;
            }
            
            tokio::time::sleep(wait_interval).await;
        }
        
        log::warn!("等待任务队列清空超时，可能有任务未完成执行");
    }
}

/// 从JSON值中按路径提取值
fn extract_json_path(json: &serde_json::Value, path: &str) -> Option<serde_json::Value> {
    let parts = path.split('.').collect::<Vec<_>>();
    let mut current = json;
    
    for part in parts {
        match current {
            serde_json::Value::Object(obj) => {
                if let Some(value) = obj.get(part) {
                    current = value;
                } else {
                    return None;
                }
            },
            serde_json::Value::Array(arr) => {
                if let Ok(index) = part.parse::<usize>() {
                    if index < arr.len() {
                        current = &arr[index];
                    } else {
                        return None;
                    }
                } else {
                    return None;
                }
            },
            _ => return None,
        }
    }
    
    Some(current.clone())
}

/// 任务调度计划
struct TaskSchedule {
    /// 所有任务定义
    tasks: HashMap<String, TaskDefinition>,
    
    /// 任务依赖关系（任务ID -> 依赖任务ID列表）
    dependencies: HashMap<String, Vec<String>>,
    
    /// 任务下游关系（任务ID -> 下游任务ID列表）
    downstream: HashMap<String, Vec<String>>,
    
    /// 初始任务（没有依赖的任务）
    initial_tasks: HashSet<String>,
}

impl TaskSchedule {
    /// 创建新的任务调度计划
    fn new() -> Self {
        Self {
            tasks: HashMap::new(),
            dependencies: HashMap::new(),
            downstream: HashMap::new(),
            initial_tasks: HashSet::new(),
        }
    }
    
    /// 添加任务
    fn add_task(&mut self, task: TaskDefinition) {
        self.tasks.insert(task.id.clone(), task);
        self.dependencies.entry(task.id.clone()).or_insert_with(Vec::new);
        self.downstream.entry(task.id.clone()).or_insert_with(Vec::new);
    }
    
    /// 移除任务
    fn remove_task(&mut self, task_id: &str) {
        // 移除任务定义
        self.tasks.remove(task_id);
        
        // 移除依赖关系
        self.dependencies.remove(task_id);
        
        // 从其他任务的依赖中移除
        for deps in self.dependencies.values_mut() {
            deps.retain(|dep| dep != task_id);
        }
        
        // 移除下游关系
        self.downstream.remove(task_id);
        
        // 从其他任务的下游中移除
        for ds in self.downstream.values_mut() {
            ds.retain(|d| d != task_id);
        }
        
        // 从初始任务中移除
        self.initial_tasks.remove(task_id);
    }
    
    /// 添加任务依赖
    fn add_dependency(&mut self, task_id: &str, dependency: &str) {
        // 添加依赖关系
        if let Some(deps) = self.dependencies.get_mut(task_id) {
            if !deps.contains(&dependency.to_string()) {
                deps.push(dependency.to_string());
            }
        }
        
        // 添加下游关系
        if let Some(ds) = self.downstream.get_mut(dependency) {
            if !ds.contains(&task_id.to_string()) {
                ds.push(task_id.to_string());
            }
        } else {
            self.downstream.insert(dependency.to_string(), vec![task_id.to_string()]);
        }
        
        // 如果该任务在初始任务中，现在有了依赖，则移除
        if self.initial_tasks.contains(task_id) {
            self.initial_tasks.remove(task_id);
        }
    }
    
    /// 将任务设置为初始任务
    fn set_as_initial(&mut self, task_id: &str) {
        self.initial_tasks.insert(task_id.to_string());
    }
    
    /// 获取任务定义
    fn get_task(&self, task_id: &str) -> Option<&TaskDefinition> {
        self.tasks.get(task_id)
    }
    
    /// 获取任务依赖
    fn get_dependencies(&self, task_id: &str) -> Vec<String> {
        self.dependencies.get(task_id).cloned().unwrap_or_default()
    }
    
    /// 获取任务的直接下游任务
    fn get_direct_downstream_tasks(&self, task_id: &str) -> Vec<String> {
        self.downstream.get(task_id).cloned().unwrap_or_default()
    }
    
    /// 获取任务的所有下游任务（递归）
    fn get_downstream_tasks(&self, task_id: &str) -> HashSet<String> {
        let mut result = HashSet::new();
        let mut queue = VecDeque::new();
        
        // 添加直接下游任务
        if let Some(direct_downstream) = self.downstream.get(task_id) {
            for ds in direct_downstream {
                queue.push_back(ds.clone());
                result.insert(ds.clone());
            }
        }
        
        // 广度优先搜索
        while let Some(current) = queue.pop_front() {
            if let Some(next_downstream) = self.downstream.get(&current) {
                for ds in next_downstream {
                    if !result.contains(ds) {
                        queue.push_back(ds.clone());
                        result.insert(ds.clone());
                    }
                }
            }
        }
        
        result
    }
    
    /// 获取初始任务
    fn get_initial_tasks(&self) -> Vec<String> {
        self.initial_tasks.iter().cloned().collect()
    }
    
    /// 获取关键任务
    fn get_critical_tasks(&self) -> Vec<String> {
        self.tasks.values()
            .filter(|task| task.is_critical)
            .map(|task| task.id.clone())
            .collect()
    }
    
    /// 获取所有任务
    fn get_all_tasks(&self) -> Vec<String> {
        self.tasks.keys().cloned().collect()
    }
    
    /// 获取下一批可执行的任务
    fn get_next_executable_tasks(&self, completed_tasks: &HashSet<String>) -> Vec<String> {
        let mut executable = Vec::new();
        
        // 检查每个未完成的任务
        for (task_id, _) in &self.tasks {
            // 如果任务已完成，跳过
            if completed_tasks.contains(task_id) {
                continue;
            }
            
            // 检查所有依赖是否已完成
            let dependencies = self.get_dependencies(task_id);
            let mut all_deps_completed = true;
            
            for dep in dependencies {
                if !completed_tasks.contains(&dep) {
                    all_deps_completed = false;
                    break;
                }
            }
            
            if all_deps_completed {
                executable.push(task_id.clone());
            }
        }
        
        executable
    }
    
    /// 验证任务调度计划是否有效（无循环依赖）
    fn is_valid(&self) -> bool {
        // 如果没有任务，认为有效
        if self.tasks.is_empty() {
            return true;
        }
        
        // 检查是否有任务依赖不存在的任务
        for (task_id, deps) in &self.

            /// 验证任务调度计划是否有效（无循环依赖）
    fn is_valid(&self) -> bool {
        // 如果没有任务，认为有效
        if self.tasks.is_empty() {
            return true;
        }
        
        // 检查是否有任务依赖不存在的任务
        for (task_id, deps) in &self.dependencies {
            for dep in deps {
                if !self.tasks.contains_key(dep) {
                    return false;
                }
            }
        }
        
        // 检查循环依赖
        let mut visited = HashSet::new();
        let mut stack = HashSet::new();
        
        // 对每个未访问的任务执行深度优先搜索
        for task_id in self.tasks.keys() {
            if !visited.contains(task_id) {
                if self.has_cycle(task_id, &mut visited, &mut stack) {
                    return false;
                }
            }
        }
        
        true
    }
    
    /// 检查是否存在循环依赖（使用深度优先搜索）
    fn has_cycle(&self, task_id: &str, visited: &mut HashSet<String>, stack: &mut HashSet<String>) -> bool {
        // 标记为已访问
        visited.insert(task_id.to_string());
        stack.insert(task_id.to_string());
        
        // 检查所有依赖
        if let Some(deps) = self.dependencies.get(task_id) {
            for dep in deps {
                // 如果依赖未访问，递归检查
                if !visited.contains(dep) {
                    if self.has_cycle(dep, visited, stack) {
                        return true;
                    }
                } 
                // 如果依赖在当前递归栈中，存在循环
                else if stack.contains(dep) {
                    return true;
                }
            }
        }
        
        // 从递归栈中移除
        stack.remove(task_id);
        
        false
    }
}

/// 实现分布式工作流调度循环
impl DistributedWorkflowExecutor {
    /// 启动调度循环
    pub async fn start_scheduling_loop(&self) -> Result<(), ExecutorError> {
        // 已经在运行中，返回错误
        if self.running.load(Ordering::SeqCst) {
            return Err(ExecutorError::AlreadyRunning("调度循环已在运行中".to_string()));
        }
        
        // 标记为运行中
        self.running.store(true, Ordering::SeqCst);
        
        // 克隆引用以在异步任务中使用
        let executor = self.clone();
        let running = self.running.clone();
        let shutdown_rx = self.shutdown_rx.clone();
        
        // 启动调度循环
        tokio::spawn(async move {
            log::info!("启动分布式工作流调度循环");
            
            // 创建主调度任务
            let scheduling_task = async {
                while running.load(Ordering::SeqCst) {
                    // 执行一轮调度
                    if let Err(e) = executor.run_scheduling_cycle().await {
                        log::error!("调度循环出错: {}", e);
                    }
                    
                    // 等待下一轮调度
                    tokio::time::sleep(Duration::from_millis(executor.config.scheduling_interval_ms)).await;
                }
            };
            
            // 监听关闭信号
            let shutdown_handler = async {
                let _ = shutdown_rx.changed().await;
                log::info!("收到关闭信号，停止调度循环");
                running.store(false, Ordering::SeqCst);
            };
            
            // 同时运行两个任务，任一完成即退出
            tokio::select! {
                _ = scheduling_task => {},
                _ = shutdown_handler => {},
            }
            
            log::info!("分布式工作流调度循环已停止");
        });
        
        Ok(())
    }
    
    /// 执行一轮调度
    async fn run_scheduling_cycle(&self) -> Result<(), ExecutorError> {
        log::debug!("开始执行调度周期");
        
        // 1. 查询待处理的工作流
        let pending_workflows = self.workflow_storage.get_pending_workflows(
            self.config.max_workflows_per_cycle
        ).await?;
        
        if !pending_workflows.is_empty() {
            log::info!("发现 {} 个待处理工作流", pending_workflows.len());
        }
        
        // 2. 处理每个工作流
        for workflow in pending_workflows {
            // 尝试获取锁
            let lock_key = format!("workflow:execution:{}", workflow.id);
            let lock_result = self.lock_service.try_lock(&lock_key, self.config.lock_ttl_seconds).await;
            
            match lock_result {
                Ok(lock) => {
                    // 克隆引用以在异步任务中使用
                    let executor = self.clone();
                    let workflow_id = workflow.id.clone();
                    let lock_service = self.lock_service.clone();
                    
                    // 提交工作流执行任务
                    tokio::spawn(async move {
                        let execution_result = executor.execute_workflow(&workflow_id).await;
                        
                        if let Err(e) = &execution_result {
                            log::error!("工作流执行失败: workflow_id={}, error={}", workflow_id, e);
                        }
                        
                        // 释放锁
                        if let Err(e) = lock_service.unlock(&lock_key, &lock).await {
                            log::warn!("释放工作流执行锁失败: lock_key={}, error={}", lock_key, e);
                        }
                    });
                },
                Err(e) => {
                    log::debug!("无法获取工作流执行锁: workflow_id={}, error={}", workflow.id, e);
                    // 跳过当前工作流，下一轮再尝试
                    continue;
                }
            }
        }
        
        // 3. 检查活跃工作流的状态
        self.check_active_workflows().await?;
        
        // 4. 清理过期的工作流状态
        self.cleanup_expired_workflows().await?;
        
        log::debug!("调度周期执行完成");
        
        Ok(())
    }
    
    /// 检查活跃工作流的状态
    async fn check_active_workflows(&self) -> Result<(), ExecutorError> {
        // 获取所有活跃工作流
        let active_workflows = {
            let guard = self.active_workflows.read().await;
            guard.keys().cloned().collect::<Vec<_>>()
        };
        
        for workflow_id in active_workflows {
            // 获取工作流状态
            match self.workflow_storage.get_workflow_state(&workflow_id).await {
                Ok(state) => {
                    // 检查工作流是否已完成或失败
                    if state.status == WorkflowStatus::Completed || state.status == WorkflowStatus::Failed {
                        // 从活跃工作流中移除
                        let mut guard = self.active_workflows.write().await;
                        guard.remove(&workflow_id);
                        
                        log::info!("工作流已结束，从活跃列表中移除: workflow_id={}, status={:?}", 
                                  workflow_id, state.status);
                    }
                },
                Err(e) => {
                    log::warn!("检查工作流状态失败: workflow_id={}, error={}", workflow_id, e);
                }
            }
        }
        
        Ok(())
    }
    
    /// 清理过期的工作流状态
    async fn cleanup_expired_workflows(&self) -> Result<(), ExecutorError> {
        // 只在配置了清理周期时执行
        if let Some(ttl_days) = self.config.workflow_state_ttl_days {
            // 清理完成时间超过TTL的工作流
            let expired_count = self.workflow_storage.cleanup_expired_workflow_states(ttl_days).await?;
            
            if expired_count > 0 {
                log::info!("已清理 {} 个过期工作流状态", expired_count);
            }
        }
        
        Ok(())
    }
    
    /// 停止调度循环
    pub async fn stop_scheduling_loop(&self) -> Result<(), ExecutorError> {
        // 未在运行中，返回错误
        if !self.running.load(Ordering::SeqCst) {
            return Err(ExecutorError::NotRunning("调度循环未运行".to_string()));
        }
        
        log::info!("正在停止分布式工作流调度循环");
        
        // 发送关闭信号
        if let Err(e) = self.shutdown_tx.send(true) {
            log::error!("发送关闭信号失败: {}", e);
        }
        
        // 等待任务队列清空
        self.wait_for_queue_empty(Duration::from_secs(self.config.shutdown_timeout_seconds)).await;
        
        // 标记为未运行
        self.running.store(false, Ordering::SeqCst);
        
        log::info!("分布式工作流调度循环已停止");
        
        Ok(())
    }
}

/// 在分布式集群中执行工作流任务的任务执行器
pub struct DistributedTaskExecutor {
    /// 集群管理器
    cluster_manager: Arc<dyn ClusterManager>,
    
    /// 任务处理器注册表
    task_handlers: Arc<HashMap<String, Arc<dyn TaskHandler>>>,
    
    /// 任务调度策略
    scheduling_strategy: Arc<dyn TaskSchedulingStrategy>,
    
    /// 任务存储
    task_storage: Arc<dyn TaskStorage>,
    
    /// 工作流状态管理器
    state_manager: Arc<dyn StateManager>,
    
    /// 执行指标收集器
    metrics: Arc<dyn MetricsCollector>,
    
    /// 执行配置
    config: TaskExecutorConfig,
}

impl DistributedTaskExecutor {
    /// 创建分布式任务执行器
    pub fn new(
        cluster_manager: Arc<dyn ClusterManager>,
        task_handlers: HashMap<String, Arc<dyn TaskHandler>>,
        scheduling_strategy: Arc<dyn TaskSchedulingStrategy>,
        task_storage: Arc<dyn TaskStorage>,
        state_manager: Arc<dyn StateManager>,
        metrics: Arc<dyn MetricsCollector>,
        config: TaskExecutorConfig,
    ) -> Self {
        Self {
            cluster_manager,
            task_handlers: Arc::new(task_handlers),
            scheduling_strategy,
            task_storage,
            state_manager,
            metrics,
            config,
        }
    }
    
    /// 执行任务
    pub async fn execute_task(&self, context: TaskExecutionContext) -> Result<serde_json::Value, ExecutorError> {
        let task_id = context.task_id.clone();
        let task_type = context.task_type.clone();
        
        // 1. 选择最佳执行节点
        log::debug!("为任务选择执行节点: task_id={}, type={}", task_id, task_type);
        
        let executing_node = match self.select_execution_node(&context).await {
            Ok(node) => node,
            Err(e) => {
                log::error!("为任务选择执行节点失败: task_id={}, error={}", task_id, e);
                return Err(e);
            }
        };
        
        // 2. 确定执行模式（本地或远程）
        let is_local_execution = executing_node.node_id == self.cluster_manager.get_local_node_id();
        
        // 3. 执行任务
        let start_time = Instant::now();
        let result = if is_local_execution {
            // 本地执行
            log::debug!("在本地节点执行任务: task_id={}, type={}", task_id, task_type);
            self.execute_task_locally(context).await
        } else {
            // 远程执行
            log::debug!("在远程节点执行任务: task_id={}, node={}, type={}", 
                       task_id, executing_node.node_id, task_type);
            self.execute_task_remotely(context, &executing_node).await
        };
        
        // 4. 记录执行指标
        let execution_time = start_time.elapsed();
        self.metrics.record_task_execution(
            &task_type,
            execution_time.as_millis() as u64,
            result.is_ok(),
        );
        
        // 返回结果
        result
    }
    
    /// 本地执行任务
    async fn execute_task_locally(&self, context: TaskExecutionContext) -> Result<serde_json::Value, ExecutorError> {
        let task_id = context.task_id.clone();
        let task_type = context.task_type.clone();
        
        // 1. 获取任务处理器
        let handler = match self.task_handlers.get(&task_type) {
            Some(handler) => handler.clone(),
            None => {
                return Err(ExecutorError::HandlerNotFound(format!(
                    "未找到任务处理器: task_type={}", task_type
                )));
            }
        };
        
        // 2. 创建执行上下文（超时控制）
        let timeout = self.config.task_execution_timeout;
        let execution_result = tokio::time::timeout(timeout, handler.handle_task(context)).await;
        
        // 3. 处理执行结果
        match execution_result {
            Ok(result) => {
                match result {
                    Ok(output) => {
                        log::info!("任务执行成功: task_id={}, type={}", task_id, task_type);
                        Ok(output)
                    },
                    Err(e) => {
                        log::error!("任务执行失败: task_id={}, type={}, error={}", task_id, task_type, e);
                        Err(ExecutorError::TaskFailed(format!(
                            "任务执行失败: task_id={}, error={}", task_id, e
                        )))
                    }
                }
            },
            Err(_) => {
                log::error!("任务执行超时: task_id={}, type={}, timeout={:?}", task_id, task_type, timeout);
                Err(ExecutorError::TaskTimeout(format!(
                    "任务执行超时: task_id={}, timeout={:?}", task_id, timeout
                )))
            }
        }
    }
    
    /// 远程执行任务
    async fn execute_task_remotely(
        &self, 
        context: TaskExecutionContext, 
        node: &ClusterNode
    ) -> Result<serde_json::Value, ExecutorError> {
        let task_id = context.task_id.clone();
        
        // 1. 序列化任务上下文
        let context_json = match serde_json::to_string(&context) {
            Ok(json) => json,
            Err(e) => {
                return Err(ExecutorError::SerializationError(format!(
                    "序列化任务上下文失败: task_id={}, error={}", task_id, e
                )));
            }
        };
        
        // 2. 构建远程执行请求
        let request = TaskExecutionRequest {
            task_id: context.task_id.clone(),
            task_type: context.task_type.clone(),
            context_json,
            request_id: uuid::Uuid::new_v4().to_string(),
            source_node_id: self.cluster_manager.get_local_node_id(),
            timestamp: Utc::now(),
        };
        
        // 3. 发送执行请求
        log::debug!("发送远程任务执行请求: task_id={}, node={}", task_id, node.node_id);
        
        let response = match self.cluster_manager.send_task_execution_request(node, request).await {
            Ok(resp) => resp,
            Err(e) => {
                return Err(ExecutorError::RemoteExecutionError(format!(
                    "发送远程任务执行请求失败: task_id={}, node={}, error={}", 
                    task_id, node.node_id, e
                )));
            }
        };
        
        // 4. 处理远程执行响应
        if response.success {
            if let Some(result) = response.result {
                log::info!("远程任务执行成功: task_id={}, node={}", task_id, node.node_id);
                Ok(result)
            } else {
                Err(ExecutorError::RemoteExecutionError(format!(
                    "远程任务执行成功但结果为空: task_id={}, node={}", task_id, node.node_id
                )))
            }
        } else {
            let error_message = response.error.unwrap_or_else(|| "未知错误".to_string());
            log::error!("远程任务执行失败: task_id={}, node={}, error={}", task_id, node.node_id, error_message);
            
            Err(ExecutorError::RemoteExecutionError(format!(
                "远程任务执行失败: task_id={}, node={}, error={}", 
                task_id, node.node_id, error_message
            )))
        }
    }
    
    /// 选择最佳执行节点
    async fn select_execution_node(&self, context: &TaskExecutionContext) -> Result<ClusterNode, ExecutorError> {
        // 1. 获取可用集群节点
        let nodes = self.cluster_manager.get_available_nodes().await?;
        
        if nodes.is_empty() {
            return Err(ExecutorError::NoNodesAvailable("没有可用的执行节点".to_string()));
        }
        
        // 2. 使用调度策略选择最佳节点
        let selected_node = self.scheduling_strategy.select_node(context, &nodes).await?;
        
        log::debug!("为任务选择了执行节点: task_id={}, node={}", context.task_id, selected_node.node_id);
        
        Ok(selected_node)
    }
}

/// 资源感知的任务调度策略
pub struct ResourceAwareSchedulingStrategy {
    /// 集群管理器
    cluster_manager: Arc<dyn ClusterManager>,
    
    /// 执行历史记录存储
    execution_history: Arc<dyn ExecutionHistoryStorage>,
    
    /// 资源权重配置
    resource_weights: HashMap<String, f64>,
    
    /// 调度配置
    config: SchedulingConfig,
}

impl ResourceAwareSchedulingStrategy {
    /// 创建资源感知的任务调度策略
    pub fn new(
        cluster_manager: Arc<dyn ClusterManager>,
        execution_history: Arc<dyn ExecutionHistoryStorage>,
        resource_weights: HashMap<String, f64>,
        config: SchedulingConfig,
    ) -> Self {
        Self {
            cluster_manager,
            execution_history,
            resource_weights,
            config,
        }
    }
    
    /// 为给定任务估算资源需求
    async fn estimate_resource_requirements(
        &self,
        context: &TaskExecutionContext,
    ) -> Result<HashMap<String, f64>, ExecutorError> {
        // 默认资源需求
        let mut resource_requirements = HashMap::new();
        resource_requirements.insert("cpu".to_string(), 1.0);
        resource_requirements.insert("memory".to_string(), 256.0); // MB
        resource_requirements.insert("disk".to_string(), 10.0);    // MB
        
        // 获取任务历史执行记录
        let task_type = &context.task_type;
        let history = self.execution_history.get_task_execution_history(task_type, 10).await?;
        
        if !history.is_empty() {
            // 计算历史资源使用的平均值
            let mut total_cpu = 0.0;
            let mut total_memory = 0.0;
            let mut total_disk = 0.0;
            let mut count = 0;
            
            for record in &history {
                if let Some(resources) = &record.resource_usage {
                    total_cpu += resources.get("cpu").cloned().unwrap_or(0.0);
                    total_memory += resources.get("memory").cloned().unwrap_or(0.0);
                    total_disk += resources.get("disk").cloned().unwrap_or(0.0);
                    count += 1;
                }
            }
            
            if count > 0 {
                // 更新资源需求为历史平均值，并添加一定的安全边界
                let safety_factor = 1.2; // 20%的安全边界
                resource_requirements.insert("cpu".to_string(), (total_cpu / count as f64) * safety_factor);
                resource_requirements.insert("memory".to_string(), (total_memory / count as f64) * safety_factor);
                resource_requirements.insert("disk".to_string(), (total_disk / count as f64) * safety_factor);
            }
        }
        
        // 基于任务输入大小调整资源需求
        if let Some(input_size) = self.estimate_input_size(&context.input) {
            // 根据输入大小调整内存需求
            let memory_req = resource_requirements.get_mut("memory").unwrap();
            *memory_req = (*memory_req).max(input_size as f64 * 2.0); // 内存至少是输入大小的2倍
        }
        
        Ok(resource_requirements)
    }
    
    /// 估算输入数据大小（KB）
    fn estimate_input_size(&self, input: &serde_json::Value) -> Option<usize> {
        // 简单估算：序列化JSON并计算字节大小
        match serde_json::to_string(input) {
            Ok(json) => Some(json.len() / 1024), // 转为KB
            Err(_) => None,
        }
    }
    
    /// 计算节点的负载比例（0-1，越低越好）
    fn calculate_node_load_ratio(&self, node: &ClusterNode, required_resources: &HashMap<String, f64>) -> f64 {
        let mut weighted_ratio = 0.0;
        let mut total_weight = 0.0;
        
        // 计算每种资源的加权负载比例
        for (resource, required) in required_resources {
            if let Some(capacity) = node.capacity.get(resource) {
                if let Some(used) = node.resource_usage.get(resource) {
                    if *capacity > 0.0 {
                        // 计算资源使用比例
                        let current_ratio = *used / *capacity;
                        // 预测使用该节点后的负载比例
                        let projected_ratio = (*used + *required) / *capacity;
                        
                        // 获取资源权重
                        let weight = self.resource_weights.get(resource).cloned().unwrap_or(1.0);
                        
                        // 加权计算
                        weighted_ratio += projected_ratio * weight;
                        total_weight += weight;
                    }
                }
            }
        }
        
        // 返回平均加权比例
        if total_weight > 0.0 {
            weighted_ratio / total_weight
        } else {
            0.5 // 默认中等负载
        }
    }
}

/// 实现任务调度策略
#[async_trait]
impl TaskSchedulingStrategy for ResourceAwareSchedulingStrategy {
    /// 选择最合适的节点来执行任务
    async fn select_node(
        &self,
        context: &TaskExecutionContext,
        nodes: &[ClusterNode],
    ) -> Result<ClusterNode, ExecutorError> {
        // 1. 估算任务的资源需求
        let resource_requirements = self.estimate_resource_requirements(context).await?;
        
        // 2. 过滤掉不满足最低资源要求的节点
        let eligible_nodes: Vec<&ClusterNode> = nodes.iter()
            .filter(|node| {
                // 检查节点是否有足够的空闲资源
                for (resource, required) in &resource_requirements {
                    if let Some(capacity) = node.capacity.get(resource) {
                        if let Some(used) = node.resource_usage.get(resource) {
                            let available = capacity - used;
                            if available < required {
                                return false;
                            }
                        }
                    }
                }
                true
            })
            .collect();
        
        if eligible_nodes.is_empty() {
            return Err(ExecutorError::NoEligibleNodes(format!(
                "没有符合资源要求的节点: task_id={}, type={}", context.task_id, context.task_type
            )));
        }
        
        // 3. 对节点进行评分，选择最佳节点
        let mut best_node: Option<&ClusterNode> = None;
        let mut lowest_load_ratio = f64::MAX;
        
        for node in eligible_nodes {
            // 计算节点负载比例
            let load_ratio = self.calculate_node_load_ratio(node, &resource_requirements);
            
            // 检查是否负载更低
            if load_ratio < lowest_load_ratio {
                lowest_load_ratio = load_ratio;
                best_node = Some(node);
            }
        }
        
        match best_node {
            Some(node) => {
                log::debug!(
                    "选择的最佳节点: node={}, load_ratio={:.2}, task_id={}", 
                    node.node_id, lowest_load_ratio, context.task_id
                );
                Ok(node.clone())
            },
            None => {
                Err(ExecutorError::SchedulingFailed(format!(
                    "无法选择合适的执行节点: task_id={}, type={}", context.task_id, context.task_type
                )))
            }
        }
    }
}

/// 工作流拓扑结构分析器
pub struct WorkflowTopologyAnalyzer {
    /// 工作流状态存储
    state_storage: Arc<dyn WorkflowStateStorage>,
    
    /// 任务执行历史记录器
    execution_history: Arc<dyn ExecutionHistoryStorage>,
    
    /// 指标收集器
    metrics: Arc<dyn MetricsCollector>,
}

impl WorkflowTopologyAnalyzer {
    /// 创建工作流拓扑分析器
    pub fn new(
        state_storage: Arc<dyn WorkflowStateStorage>,
        execution_history: Arc<dyn ExecutionHistoryStorage>,
        metrics: Arc<dyn MetricsCollector>,
    ) -> Self {
        Self {
            state_storage,
            execution_history,
            metrics,
        }
    }
    
    /// 分析工作流依赖关系并生成执行计划
    pub async fn analyze_and_plan(
        &self,
        workflow_id: &str,
        instance_id: &str,
    ) -> Result<ExecutionPlan, AnalysisError> {
        // 1. 获取工作流定义和状态
        let definition = self.state_storage.get_workflow_definition(workflow_id).await?;
        let instance = self.state_storage.get_workflow_instance(instance_id).await?;
        
        // 记录开始时间
        let start_time = Instant::now();
        
        // 2. 构建任务依赖图
        let dependency_graph = self.build_task_dependency_graph(&definition);
        
        // 3. 检查是否存在循环依赖
        if let Err(e) = self.verify_no_cycles(&dependency_graph) {
            return Err(AnalysisError::CyclicDependency(format!(
                "工作流任务存在循环依赖: {}", e
            )));
        }
        
        // 4. 创建执行计划
        let mut plan = ExecutionPlan::new(instance_id.to_string(), workflow_id.to_string());
        
        // 5. 执行拓扑排序
        let sorted_tasks = self.topological_sort(&dependency_graph)?;
        
        // 6. 识别可并行执行的任务组
        let parallel_groups = self.identify_parallel_groups(&dependency_graph, &sorted_tasks);
        
        // 7. 估算每个任务的执行时间和资源需求
        let task_estimates = self.estimate_task_execution(&definition, &instance).await?;
        
        // 8. 为每个任务规划最佳执行位置
        self.plan_task_placements(&mut plan, &definition, &parallel_groups, &task_estimates).await?;
        
        // 9. 规划任务间的数据移动
        self.plan_data_movements(&mut plan, &definition, &dependency_graph).await?;
        
        // 10. 设置执行级别和优先级
        self.set_execution_levels_and_priorities(&mut plan, &parallel_groups);
        
        // 记录分析耗时
        let analysis_time = start_time.elapsed();
        self.metrics.record_workflow_analysis(
            workflow_id,
            analysis_time.as_millis() as u64,
            definition.tasks.len() as u32,
        );
        
        Ok(plan)
    }
    
    /// 构建任务依赖图
    fn build_task_dependency_graph(&self, workflow: &WorkflowDefinition) -> DependencyGraph {
        let mut graph = DependencyGraph::new();
        
        // 添加所有任务节点
        for task in &workflow.tasks {
            graph.add_node(task.id.clone());
        }
        
        // 添加直接依赖关系
        for task in &workflow.tasks {
            if let Some(depends_on) = &task.depends_on {
                for dep_id in depends_on {
                    graph.add_edge(dep_id.clone(), task.id.clone(), None);
                }
            }
        }
        
        // 添加数据依赖关系
        for task in &workflow.tasks {
            if let Some(inputs) = &task.inputs {
                for (input_name, input_def) in inputs {
                    if let Some(source_task) = &input_def.source_task {
                        // 只有来自其他任务的输入才构成依赖
                        if source_task != &task.id {
                            // 添加带有数据流信息的边
                            let data_info = DataFlowInfo {
                                from_task: source_task.clone(),
                                to_task: task.id.clone(),
                                output_name: input_def.source_output.clone().unwrap_or_default(),
                                input_name: input_name.clone(),
                                estimated_size: input_def.estimated_size,
                            };
                            
                            graph.add_edge(source_task.clone(), task.id.clone(), Some(data_info));
                        }
                    }
                }
            }
        }
        
        graph
    }
    
    /// 验证任务依赖图中不存在环
    fn verify_no_cycles(&self, graph: &DependencyGraph) -> Result<(), String> {
        // 使用深度优先搜索检测环
        let mut visited = HashSet::new();
        let mut rec_stack = HashSet::new();
        
        for node in graph.get_nodes() {
            if !visited.contains(&node) {
                if self.has_cycle_dfs(graph, &node, &mut visited, &mut rec_stack) {
                    return Err(format!("在任务 {} 开始的依赖路径中检测到环", node));
                }
            }
        }
        
        Ok(())
    }
    
    /// 深度优先搜索检测环
    fn has_cycle_dfs(
        &self,
        graph: &DependencyGraph,
        node: &str,
        visited: &mut HashSet<String>,
        rec_stack: &mut HashSet<String>,
    ) -> bool {
        // 标记当前节点为已访问
        visited.insert(node.to_string());
        rec_stack.insert(node.to_string());
        
        // 访问所有邻接节点
        if let Some(neighbors) = graph.get_outgoing_edges(node) {
            for (neighbor, _) in neighbors {
                // 如果邻接节点未访问，继续DFS
                if !visited.contains(neighbor) {
                    if self.has_cycle_dfs(graph, neighbor, visited, rec_stack) {
                        return true;
                    }
                }
                // 如果邻接节点在递归栈中，说明有环
                else if rec_stack.contains(neighbor) {
                    return true;
                }
            }
        }
        
        // 回溯时从递归栈中移除当前节点
        rec_stack.remove(node);
        
        false
    }
    
    /// 执行拓扑排序（Kahn算法）
    fn topological_sort(&self, graph: &DependencyGraph) -> Result<Vec<String>, AnalysisError> {
        // 计算每个节点的入度
        let mut in_degree = HashMap::new();
        for node in graph.get_nodes() {
            in_degree.insert(node.clone(), 0);
        }
        
        // 统计每个节点的入度
        for node in graph.get_nodes() {
            if let Some(outgoing) = graph.get_outgoing_edges(&node) {
                for (target, _) in outgoing {
                    *in_degree.entry(target.clone()).or_insert(0) += 1;
                }
            }
        }
        
        // 将所有入度为0的节点加入队列
        let mut queue = VecDeque::new();
        for (node, &degree) in &in_degree {
            if degree == 0 {
                queue.push_back(node.clone());
            }
        }
        
        // 拓扑排序结果
        let mut sorted = Vec::new();
        
        // BFS遍历
        while let Some(node) = queue.pop_front() {
            // 将当前节点加入排序结果
            sorted.push(node.clone());
            
            // 减少所有邻接节点的入度
            if let Some(outgoing) = graph.get_outgoing_edges(&node) {
                for (neighbor, _) in outgoing {
                    if let Some(degree) = in_degree.get_mut(neighbor) {
                        *degree -= 1;
                        
                        // 如果入度变为0，加入队列
                        if *degree == 0 {
                            queue.push_back(neighbor.clone());
                        }
                    }
                }
            }
        }
        
        // 检查是否所有节点都已处理
        if sorted.len() != graph.get_nodes().len() {
            return Err(AnalysisError::CyclicDependency(
                "拓扑排序未包含所有节点，可能存在环路".to_string()
            ));
        }
        
        Ok(sorted)
    }
    
    /// 识别可并行执行的任务组
    fn identify_parallel_groups(
        &self,
        graph: &DependencyGraph,
        sorted_tasks: &[String],
    ) -> Vec<Vec<String>> {
        // 计算每个节点的最早执行级别
        let mut levels = HashMap::new();
        
        // 初始化所有节点的级别为0
        for node in graph.get_nodes() {
            levels.insert(node.clone(), 0);
        }
        
        // 计算每个节点的级别
        for task_id in sorted_tasks {
            let current_level = *levels.get(task_id).unwrap_or(&0);
            
            // 更新所有依赖于当前任务的节点级别
            if let Some(outgoing) = graph.get_outgoing_edges(task_id) {
                for (dependent, _) in outgoing {
                    let dependent_level = levels.get_mut(dependent).unwrap();
                    *dependent_level = (*dependent_level).max(current_level + 1);
                }
            }
        }
        
        // 按执行级别分组
        let mut level_groups = HashMap::new();
        for (task_id, level) in &levels {
            level_groups.entry(*level).or_insert_with(Vec::new).push(task_id.clone());
        }
        
        // 将分组转换为向量
        let mut parallel_groups = Vec::new();
        let max_level = *levels.values().max().unwrap_or(&0);
        
        for level in 0..=max_level {
            if let Some(tasks) = level_groups.get(&level) {
                parallel_groups.push(tasks.clone());
            }
        }
        
        parallel_groups
    }
    
    /// 估算任务执行时间和资源需求
    async fn estimate_task_execution(
        &self,
        workflow: &WorkflowDefinition,
        instance: &WorkflowInstance,
    ) -> Result<HashMap<String, TaskEstimate>, AnalysisError> {
        let mut estimates = HashMap::new();
        
        for task in &workflow.tasks {
            // 获取任务历史执行数据
            let history = self.execution_history
                .get_task_execution_history(&task.type_name, 10)
                .await
                .map_err(|e| AnalysisError::HistoryAccessFailed(format!(
                    "无法获取任务执行历史: {}", e
                )))?;
            
            // 基于历史数据估算
            let estimate = self.calculate_task_estimate(task, &history, instance);
            estimates.insert(task.id.clone(), estimate);
        }
        
        Ok(estimates)
    }
    
    /// 基于历史数据计算任务估算
    fn calculate_task_estimate(
        &self,
        task: &TaskDefinition,
        history: &[TaskExecutionRecord],
        instance: &WorkflowInstance,
    ) -> TaskEstimate {
        // 默认估计值
        let mut estimate = TaskEstimate {
            execution_time_ms: 1000, // 默认1秒
            cpu_units: 1.0,          // 默认1个CPU单位
            memory_mb: 256.0,        // 默认256MB内存
            storage_mb: 10.0,        // 默认10MB存储
            network_priority: 0,     // 默认网络优先级
            preferred_location: None, // 无默认位置偏好
        };
        
        if history.is_empty() {
            // 如果没有历史数据，根据任务类型设置默认值
            match task.type_name.as_str() {
                "data_processing" => {
                    estimate.execution_time_ms = 5000; // 数据处理任务较长
                    estimate.cpu_units = 2.0;
                    estimate.memory_mb = 512.0;
                },
                "api_call" => {
                    estimate.execution_time_ms = 3000; // API调用有网络延迟
                    estimate.network_priority = 1;
                },
                "notification" => {
                    estimate.execution_time_ms = 500; // 通知任务较快
                    estimate.network_priority = 1;
                },
                "heavy_computation" => {
                    estimate.execution_time_ms = 8000; // 计算密集型任务
                    estimate.cpu_units = 4.0;
                    estimate.memory_mb = 1024.0;
                },
                _ => {}
            }
        } else {
            // 基于历史数据计算平均值，并添加一定安全边界
            let safety_factor = 1.2; // 20%的安全边界
            
            let mut total_time = 0;
            let mut total_cpu = 0.0;
            let mut total_memory = 0.0;
            let mut total_storage = 0.0;
            let count = history.len();
            
            for record in history {
                total_time += record.execution_time_ms;
                
                if let Some(resources) = &record.resource_usage {
                    total_cpu += resources.get("cpu").cloned().unwrap_or(1.0);
                    total_memory += resources.get("memory").cloned().unwrap_or(256.0);
                    total_storage += resources.get("storage").cloned().unwrap_or(10.0);
                }
            }
            
            // 计算平均值并应用安全因子
            estimate.execution_time_ms = ((total_time as f64) / (count as f64) * safety_factor) as u64;
            estimate.cpu_units = (total_cpu / (count as f64)) * safety_factor;
            estimate.memory_mb = (total_memory / (count as f64)) * safety_factor;
            estimate.storage_mb = (total_storage / (count as f64)) * safety_factor;
            
            // 基于任务类型设置网络优先级
            match task.type_name.as_str() {
                "api_call" | "notification" => {
                    estimate.network_priority = 1;
                },
                _ => {}
            }
        }
        
        // 分析数据局部性，找到最佳执行位置
        if let Some(inputs) = &task.inputs {
            for (_, input) in inputs {
                if let Some(location) = &input.preferred_location {
                    // 简单策略：使用第一个具有位置偏好的输入
                    estimate.preferred_location = Some(location.clone());
                    break;
                }
            }
        }
        
        estimate
    }
    
    /// 为每个任务规划最佳执行位置
    async fn plan_task_placements(
        &self,
        plan: &mut ExecutionPlan,
        workflow: &WorkflowDefinition,
        parallel_groups: &[Vec<String>],
        task_estimates: &HashMap<String, TaskEstimate>,
    ) -> Result<(), AnalysisError> {
        // 获取可用的执行节点
        let available_nodes = self.get_available_execution_nodes().await?;
        
        if available_nodes.is_empty() {
            return Err(AnalysisError::NoExecutionNodes("没有可用的执行节点".to_string()));
        }
        
        // 为每个并行组内的任务规划执行位置
        for (level, tasks) in parallel_groups.iter().enumerate() {
            // 首先尝试基于数据局部性分配任务
            let mut assigned_tasks = HashSet::new();
            
            // 检查有位置偏好的任务
            for task_id in tasks {
                if let Some(estimate) = task_estimates.get(task_id) {
                    if let Some(location) = &estimate.preferred_location {
                        // 查找与首选位置匹配的节点
                        if let Some(node) = available_nodes.iter().find(|n| &n.location == location) {
                            // 将任务分配给首选节点
                            plan.add_task_placement(task_id.clone(), node.id.clone(), estimate.clone());
                            assigned_tasks.insert(task_id.clone());
                        }
                    }
                }
            }
            
            // 为剩余任务选择节点（负载均衡）
            for task_id in tasks {
                if !assigned_tasks.contains(task_id) {
                    if let Some(estimate) = task_estimates.get(task_id) {
                        // 选择负载最低的节点
                        let selected_node = self.select_least_loaded_node(&available_nodes, estimate);
                        
                        // 将任务分配给选定的节点
                        plan.add_task_placement(task_id.clone(), selected_node.id.clone(), estimate.clone());
                    }
                }
            }
            
            // 设置执行级别
            for task_id in tasks {
                plan.set_task_execution_level(task_id.clone(), level as u32);
            }
        }
        
        Ok(())
    }
    
    /// 获取可用的执行节点
    async fn get_available_execution_nodes(&self) -> Result<Vec<ExecutionNode>, AnalysisError> {
        // 模拟一些执行节点用于演示
        // 在实际系统中，这里会查询集群管理器
        let mut nodes = Vec::new();
        
        nodes.push(ExecutionNode {
            id: "node-1".to_string(),
            location: "region-1".to_string(),
            capacity: {
                let mut cap = HashMap::new();
                cap.insert("cpu".to_string(), 8.0);
                cap.insert("memory".to_string(), 16384.0); // 16GB
                cap.insert("storage".to_string(), 102400.0); // 100GB
                cap
            },
            current_load: {
                let mut load = HashMap::new();
                load.insert("cpu".to_string(), 2.0);
                load.insert("memory".to_string(), 4096.0); // 4GB
                load.insert("storage".to_string(), 10240.0); // 10GB
                load
            },
            tags: {
                let mut tags = HashMap::new();
                tags.insert("role".to_string(), "worker".to_string());
                tags.insert("capability".to_string(), "general".to_string());
                tags
            }
        });
        
        nodes.push(ExecutionNode {
            id: "node-2".to_string(),
            location: "region-2".to_string(),
            capacity: {
                let mut cap = HashMap::new();
                cap.insert("cpu".to_string(), 16.0);
                cap.insert("memory".to_string(), 32768.0); // 32GB
                cap.insert("storage".to_string(), 204800.0); // 200GB
                cap
            },
            current_load: {
                let mut load = HashMap::new();
                load.insert("cpu".to_string(), 8.0);
                load.insert("memory".to_string(), 16384.0); // 16GB
                load.insert("storage".to_string(), 51200.0); // 50GB
                load
            },
            tags: {
                let mut tags = HashMap::new();
                tags.insert("role".to_string(), "worker".to_string());
                tags.insert("capability".to_string(), "compute".to_string());
                tags
            }
        });
        
        nodes.push(ExecutionNode {
            id: "node-3".to_string(),
            location: "region-1".to_string(),
            capacity: {
                let mut cap = HashMap::new();
                cap.insert("cpu".to_string(), 4.0);
                cap.insert("memory".to_string(), 8192.0); // 8GB
                cap.insert("storage".to_string(), 51200.0); // 50GB
                cap
            },
            current_load: {
                let mut load = HashMap::new();
                load.insert("cpu".to_string(), 1.0);
                load.insert("memory".to_string(), 2048.0); // 2GB
                load.insert("storage".to_string(), 5120.0); // 5GB
                load
            },
            tags: {
                let mut tags = HashMap::new();
                tags.insert("role".to_string(), "worker".to_string());
                tags.insert("capability".to_string(), "io".to_string());
                tags
            }
        });
        
        Ok(nodes)
    }
    
    /// 选择负载最低的节点
    fn select_least_loaded_node(
        &self,
        nodes: &[ExecutionNode],
        task_estimate: &TaskEstimate,
    ) -> &ExecutionNode {
        // 计算每个节点的加权负载比例
        let mut node_scores = Vec::new();
        
        for node in nodes {
            let mut score = 0.0;
            let mut factors = 0;
            
            // 计算CPU负载比例
            if let (Some(capacity), Some(load)) = (node.capacity.get("cpu"), node.current_load.get("cpu")) {
                if *capacity > 0.0 {
                    let ratio = (load + task_estimate.cpu_units) / *capacity;
                    score += ratio;
                    factors += 1;
                }
            }
            
            // 计算内存负载比例
            if let (Some(capacity), Some(load)) = (node.capacity.get("memory"), node.current_load.get("memory")) {
                if *capacity > 0.0 {
                    let ratio = (load + task_estimate.memory_mb) / *capacity;
                    score += ratio;
                    factors += 1;
                }
            }
            
            // 计算存储负载比例
            if let (Some(capacity), Some(load)) = (node.capacity.get("storage"), node.current_load.get("storage")) {
                if *capacity > 0.0 {
                    let ratio = (load + task_estimate.storage_mb) / *capacity;
                    score += ratio;
                    factors += 1;
                }
            }
            
            // 计算平均负载比例
            let avg_score = if factors > 0 { score / factors as f64 } else { 1.0 };
            
            // 添加位置偏好因素
            let location_bonus = if let Some(preferred) = &task_estimate.preferred_location {
                if preferred == &node.location { -0.2 } else { 0.0 }
            } else {
                0.0
            };
            
            // 最终分数（越低越好）
            node_scores.push((node, avg_score + location_bonus));
        }
        
        // 选择分数最低的节点
        if let Some((best_node, _)) = node_scores.iter().min_by(|(_, a), (_, b)| {
            a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal)
        }) {
            return best_node;
        }
        
        // 默认返回第一个节点
        &nodes[0]
    }
    
    /// 规划任务间的数据移动
    async fn plan_data_movements(
        &self,
        plan: &mut ExecutionPlan,
        workflow: &WorkflowDefinition,
        graph: &DependencyGraph,
    ) -> Result<(), AnalysisError> {
        // 遍历所有包含数据流的边
        for node in graph.get_nodes() {
            if let Some(outgoing) = graph.get_outgoing_edges(&node) {
                for (target, edge_data) in outgoing {
                    // 只处理包含数据流信息的边
                    if let Some(data_info) = edge_data {
                        // 获取源任务和目标任务的执行位置
                        let source_placement = plan.get_task_placement(&data_info.from_task);
                        let target_placement = plan.get_task_placement(&data_info.to_task);
                        
                        if let (Some(source), Some(target)) = (source_placement, target_placement) {
                            // 如果任务在不同节点上执行，需要规划数据移动
                            if source.node_id != target.node_id {
                                // 估算数据大小
                                let size_mb = data_info.estimated_size.unwrap_or(10.0); // 默认10MB
                                
                                // 添加数据移动计划
                                plan.add_data_movement(
                                    DataMovement {
                                        from_task: data_info.from_task.clone(),
                                        to_task: data_info.to_task.clone(),
                                        from_node: source.node_id.clone(),
                                        to_node: target.node_id.clone(),
                                        data_id: format!("{}_{}", data_info.output_name, data_info.input_name),
                                        size_mb,
                                        priority: 0, // 默认优先级
                                    }
                                );
                            }
                        }
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// 设置执行级别和优先级
    fn set_execution_levels_and_priorities(
        &self,
        plan: &mut ExecutionPlan,
        parallel_groups: &[Vec<String>],
    ) {
        // 设置每个任务的执行级别
        for (level, tasks) in parallel_groups.iter().enumerate() {
            for task_id in tasks {
                plan.set_task_execution_level(task_id.clone(), level as u32);
                
                // 设置优先级（级别越高，优先级越高）
                let priority = (parallel_groups.len() - level) as u32;
                plan.set_task_priority(task_id.clone(), priority);
            }
        }
        
        // 设置关键路径上任务的高优先级
        let critical_path = self.identify_critical_path(plan);
        for task_id in &critical_path {
            // 增加关键路径任务的优先级
            if let Some(priority) = plan.get_task_priority(task_id) {
                plan.set_task_priority(task_id.clone(), priority + 10);
            }
        }
    }
    
    /// 识别关键路径（最长执行路径）
    fn identify_critical_path(&self, plan: &ExecutionPlan) -> Vec<String> {
        // 简化的关键路径算法：选择每个级别中执行时间最长的任务
        let mut critical_path = Vec::new();
        let max_level = plan.get_max_execution_level();
        
        for level in 0..=max_level {
            let tasks_at_level = plan.get_tasks_at_level(level);
            
            // 找出当前级别中执行时间最长的任务
            let mut longest_task = None;
            let mut longest_time = 0;
            
            for task_id in &tasks_at_level {
                if let Some(placement) = plan.get_task_placement(task_id) {
                    if placement.estimate.execution_time_ms > longest_time {
                        longest_time = placement.estimate.execution_time_ms;
                        longest_task = Some(task_id.clone());
                    }
                }
            }
            
            if let Some(task) = longest_task {
                critical_path.push(task);
            }
        }
        
        critical_path
    }
}

/// 依赖图实现
pub struct DependencyGraph {
    /// 图的邻接表表示
    graph: HashMap<String, Vec<(String, Option<DataFlowInfo>)>>,
    
    /// 反向图（用于高效查询入边）
    reverse_graph: HashMap<String, Vec<(String, Option<DataFlowInfo>)>>,
}

/// 数据流信息
#[derive(Clone, Debug)]
pub struct DataFlowInfo {
    /// 源任务ID
    pub from_task: String,
    
    /// 目标任务ID
    pub to_task: String,
    
    /// 输出名称
    pub output_name: String,
    
    /// 输入名称
    pub input_name: String,
    
    /// 估计数据大小（MB）
    pub estimated_size: Option<f64>,
}

impl DependencyGraph {
    /// 创建新的依赖图
    pub fn new() -> Self {
        Self {
            graph: HashMap::new(),
            reverse_graph: HashMap::new(),
        }
    }

impl DependencyGraph {
    // 之前已实现了new方法
    
    /// 添加节点
    pub fn add_node(&mut self, node_id: String) {
        self.graph.entry(node_id.clone()).or_insert_with(Vec::new);
        self.reverse_graph.entry(node_id).or_insert_with(Vec::new);
    }
    
    /// 添加边
    pub fn add_edge(&mut self, from: String, to: String, data: Option<DataFlowInfo>) {
        // 确保节点存在
        self.graph.entry(from.clone()).or_insert_with(Vec::new);
        self.graph.entry(to.clone()).or_insert_with(Vec::new);
        self.reverse_graph.entry(from.clone()).or_insert_with(Vec::new);
        self.reverse_graph.entry(to.clone()).or_insert_with(Vec::new);
        
        // 添加正向边
        if let Some(edges) = self.graph.get_mut(&from) {
            edges.push((to.clone(), data.clone()));
        }
        
        // 添加反向边
        if let Some(edges) = self.reverse_graph.get_mut(&to) {
            edges.push((from, data));
        }
    }
    
    /// 获取所有节点
    pub fn get_nodes(&self) -> Vec<String> {
        self.graph.keys().cloned().collect()
    }
    
    /// 获取节点的出边
    pub fn get_outgoing_edges(&self, node: &str) -> Option<&Vec<(String, Option<DataFlowInfo>)>> {
        self.graph.get(node)
    }
    
    /// 获取节点的入边
    pub fn get_incoming_edges(&self, node: &str) -> Option<&Vec<(String, Option<DataFlowInfo>)>> {
        self.reverse_graph.get(node)
    }
    
    /// 获取节点的所有后继节点
    pub fn get_successors(&self, node: &str) -> Vec<String> {
        if let Some(edges) = self.graph.get(node) {
            edges.iter().map(|(successor, _)| successor.clone()).collect()
        } else {
            Vec::new()
        }
    }
    
    /// 获取节点的所有前驱节点
    pub fn get_predecessors(&self, node: &str) -> Vec<String> {
        if let Some(edges) = self.reverse_graph.get(node) {
            edges.iter().map(|(predecessor, _)| predecessor.clone()).collect()
        } else {
            Vec::new()
        }
    }
    
    /// 获取没有入边的节点（起始节点）
    pub fn get_source_nodes(&self) -> Vec<String> {
        self.graph.keys()
            .filter(|node| {
                self.get_incoming_edges(node).map_or(true, |edges| edges.is_empty())
            })
            .cloned()
            .collect()
    }
    
    /// 获取没有出边的节点（终止节点）
    pub fn get_sink_nodes(&self) -> Vec<String> {
        self.graph.keys()
            .filter(|node| {
                self.get_outgoing_edges(node).map_or(true, |edges| edges.is_empty())
            })
            .cloned()
            .collect()
    }
}

/// 任务资源估算
#[derive(Clone, Debug)]
pub struct TaskEstimate {
    /// 预估执行时间（毫秒）
    pub execution_time_ms: u64,
    
    /// CPU单位需求
    pub cpu_units: f64,
    
    /// 内存需求（MB）
    pub memory_mb: f64,
    
    /// 存储需求（MB）
    pub storage_mb: f64,
    
    /// 网络优先级（0-3，数字越大优先级越高）
    pub network_priority: u8,
    
    /// 偏好执行位置
    pub preferred_location: Option<String>,
}

/// 执行节点表示
#[derive(Clone, Debug)]
pub struct ExecutionNode {
    /// 节点ID
    pub id: String,
    
    /// 节点物理位置（区域/机房）
    pub location: String,
    
    /// 资源容量
    pub capacity: HashMap<String, f64>,
    
    /// 当前负载
    pub current_load: HashMap<String, f64>,
    
    /// 节点标签
    pub tags: HashMap<String, String>,
}

/// 任务放置信息
#[derive(Clone, Debug)]
pub struct TaskPlacement {
    /// 任务ID
    pub task_id: String,
    
    /// 执行节点ID
    pub node_id: String,
    
    /// 任务资源估算
    pub estimate: TaskEstimate,
    
    /// 执行级别
    pub execution_level: u32,
    
    /// 优先级
    pub priority: u32,
}

/// 数据移动
#[derive(Clone, Debug)]
pub struct DataMovement {
    /// 源任务ID
    pub from_task: String,
    
    /// 目标任务ID
    pub to_task: String,
    
    /// 源节点ID
    pub from_node: String,
    
    /// 目标节点ID
    pub to_node: String,
    
    /// 数据标识
    pub data_id: String,
    
    /// 数据大小（MB）
    pub size_mb: f64,
    
    /// 优先级
    pub priority: u8,
}

/// 执行计划
#[derive(Clone, Debug)]
pub struct ExecutionPlan {
    /// 工作流实例ID
    pub instance_id: String,
    
    /// 工作流定义ID
    pub workflow_id: String,
    
    /// 任务放置
    pub task_placements: HashMap<String, TaskPlacement>,
    
    /// 数据移动
    pub data_movements: Vec<DataMovement>,
    
    /// 任务优先级
    pub task_priorities: HashMap<String, u32>,
    
    /// 任务执行级别
    pub task_levels: HashMap<String, u32>,
    
    /// 当前工作流状态
    pub state: Option<WorkflowStateSnapshot>,
}

impl ExecutionPlan {
    /// 创建新的执行计划
    pub fn new(instance_id: String, workflow_id: String) -> Self {
        Self {
            instance_id,
            workflow_id,
            task_placements: HashMap::new(),
            data_movements: Vec::new(),
            task_priorities: HashMap::new(),
            task_levels: HashMap::new(),
            state: None,
        }
    }
    
    /// 添加任务放置
    pub fn add_task_placement(&mut self, task_id: String, node_id: String, estimate: TaskEstimate) {
        let placement = TaskPlacement {
            task_id: task_id.clone(),
            node_id,
            estimate,
            execution_level: 0,
            priority: 0,
        };
        
        self.task_placements.insert(task_id, placement);
    }
    
    /// 添加数据移动
    pub fn add_data_movement(&mut self, movement: DataMovement) {
        self.data_movements.push(movement);
    }
    
    /// 设置任务执行级别
    pub fn set_task_execution_level(&mut self, task_id: String, level: u32) {
        self.task_levels.insert(task_id.clone(), level);
        
        if let Some(placement) = self.task_placements.get_mut(&task_id) {
            placement.execution_level = level;
        }
    }
    
    /// 设置任务优先级
    pub fn set_task_priority(&mut self, task_id: String, priority: u32) {
        self.task_priorities.insert(task_id.clone(), priority);
        
        if let Some(placement) = self.task_placements.get_mut(&task_id) {
            placement.priority = priority;
        }
    }
    
    /// 获取任务放置信息
    pub fn get_task_placement(&self, task_id: &str) -> Option<&TaskPlacement> {
        self.task_placements.get(task_id)
    }
    
    /// 获取任务优先级
    pub fn get_task_priority(&self, task_id: &str) -> Option<u32> {
        self.task_priorities.get(task_id).cloned()
    }
    
    /// 获取最大执行级别
    pub fn get_max_execution_level(&self) -> u32 {
        self.task_levels.values().max().cloned().unwrap_or(0)
    }
    
    /// 获取指定级别的所有任务
    pub fn get_tasks_at_level(&self, level: u32) -> Vec<String> {
        self.task_levels.iter()
            .filter(|(_, &l)| l == level)
            .map(|(task_id, _)| task_id.clone())
            .collect()
    }
    
    /// 获取可执行的任务（同一执行级别且没有活跃的依赖）
    pub fn get_executable_tasks(&self, active_tasks: &HashSet<String>) -> Vec<String> {
        let min_level = self.task_levels.iter()
            .filter(|(task_id, _)| !active_tasks.contains(*task_id))
            .map(|(_, &level)| level)
            .min()
            .unwrap_or(0);
        
        self.task_levels.iter()
            .filter(|(task_id, &level)| level == min_level && !active_tasks.contains(*task_id))
            .map(|(task_id, _)| task_id.clone())
            .collect()
    }
    
    /// 估算执行计划总时间
    pub fn estimate_execution_time(&self) -> u64 {
        let mut level_times = HashMap::new();
        
        // 计算每个级别的最长执行时间
        for (task_id, &level) in &self.task_levels {
            if let Some(placement) = self.get_task_placement(task_id) {
                let current_max = level_times.entry(level).or_insert(0);
                *current_max = (*current_max).max(placement.estimate.execution_time_ms);
            }
        }
        
        // 计算总时间（各级别时间之和）
        let max_level = self.get_max_execution_level();
        let mut total_time = 0;
        
        for level in 0..=max_level {
            total_time += level_times.get(&level).cloned().unwrap_or(0);
        }
        
        total_time
    }
    
    /// 估算执行计划资源需求
    pub fn estimate_resource_requirements(&self) -> HashMap<String, f64> {
        let mut total_resources = HashMap::new();
        
        // 初始化资源类型
        total_resources.insert("cpu".to_string(), 0.0);
        total_resources.insert("memory".to_string(), 0.0);
        total_resources.insert("storage".to_string(), 0.0);
        
        // 按执行级别计算资源需求
        let max_level = self.get_max_execution_level();
        
        for level in 0..=max_level {
            let tasks_at_level = self.get_tasks_at_level(level);
            let mut level_resources = HashMap::new();
            
            // 初始化当前级别资源计数
            level_resources.insert("cpu".to_string(), 0.0);
            level_resources.insert("memory".to_string(), 0.0);
            level_resources.insert("storage".to_string(), 0.0);
            
            // 累加当前级别所有任务的资源需求
            for task_id in &tasks_at_level {
                if let Some(placement) = self.get_task_placement(task_id) {
                    *level_resources.entry("cpu".to_string()).or_insert(0.0) += placement.estimate.cpu_units;
                    *level_resources.entry("memory".to_string()).or_insert(0.0) += placement.estimate.memory_mb;
                    *level_resources.entry("storage".to_string()).or_insert(0.0) += placement.estimate.storage_mb;
                }
            }
            
            // 更新总资源需求（取每级别的最大值）
            for (resource, &amount) in &level_resources {
                if let Some(current) = total_resources.get_mut(resource) {
                    *current = (*current).max(amount);
                }
            }
        }
        
        total_resources
    }
    
    /// 获取执行计划可视化表示
    pub fn get_visualization(&self) -> String {
        // 创建mermaid格式的执行计划图表
        let mut mermaid = String::from("graph TB\n");
        
        // 添加任务节点
        for (task_id, placement) in &self.task_placements {
            let label = format!("{}\\n({})", task_id, placement.node_id);
            mermaid.push_str(&format!("    {}[\"{}\"]\n", task_id, label));
        }
        
        // 添加数据移动
        for movement in &self.data_movements {
            mermaid.push_str(&format!("    {} -- \"{}\" --> {}\n", 
                movement.from_task, 
                format!("{}MB", movement.size_mb),
                movement.to_task
            ));
        }
        
        // 按执行级别对节点分组
        let max_level = self.get_max_execution_level();
        
        for level in 0..=max_level {
            let tasks = self.get_tasks_at_level(level);
            if !tasks.is_empty() {
                mermaid.push_str(&format!("    subgraph \"Level {}\"\n", level));
                for task in tasks {
                    mermaid.push_str(&format!("        {}\n", task));
                }
                mermaid.push_str("    end\n");
            }
        }
        
        mermaid
    }
}

/// 工作流状态快照
#[derive(Clone, Debug)]
pub struct WorkflowStateSnapshot {
    /// 创建时间
    pub created_at: DateTime<Utc>,
    
    /// 启动时间
    pub started_at: Option<DateTime<Utc>>,
    
    /// 完成时间
    pub completed_at: Option<DateTime<Utc>>,
    
    /// 工作流状态
    pub state: WorkflowState,
    
    /// 完成的任务
    pub completed_tasks: HashSet<String>,
    
    /// 活跃的任务
    pub active_tasks: HashSet<String>,
    
    /// 待处理的任务
    pub pending_tasks: HashSet<String>,
    
    /// 失败的任务
    pub failed_tasks: HashMap<String, String>,
    
    /// 任务完成顺序
    pub task_completion_order: Vec<String>,
    
    /// 任务结果映射
    pub task_results: HashMap<String, serde_json::Value>,
    
    /// 最后更新时间
    pub last_updated: DateTime<Utc>,
}

/// 工作流状态
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum WorkflowState {
    /// 创建但未启动
    Created,
    
    /// 正在执行
    Running,
    
    /// 暂停
    Paused,
    
    /// 已完成
    Completed,
    
    /// 失败
    Failed,
    
    /// 已取消
    Cancelled,
    
    /// 已超时
    TimedOut,
}

/// 分析错误
#[derive(Debug, thiserror::Error)]
pub enum AnalysisError {
    #[error("工作流状态访问失败: {0}")]
    StateAccessFailed(String),
    
    #[error("任务执行历史访问失败: {0}")]
    HistoryAccessFailed(String),
    
    #[error("存在循环依赖: {0}")]
    CyclicDependency(String),
    
    #[error("资源不足: {0}")]
    InsufficientResources(String),
    
    #[error("找不到可用执行节点: {0}")]
    NoExecutionNodes(String),
    
    #[error("内部错误: {0}")]
    InternalError(String),
}

/// 实现基于拓扑的多级调度器
pub struct TopologyAwareScheduler {
    /// 工作流拓扑分析器
    topology_analyzer: Arc<WorkflowTopologyAnalyzer>,
    
    /// 节点管理器
    node_manager: Arc<dyn NodeManager>,
    
    /// 任务执行器
    task_executor: Arc<dyn TaskExecutor>,
    
    /// 调度配置
    config: SchedulerConfig,
    
    /// 指标收集器
    metrics: Arc<dyn MetricsCollector>,
    
    /// 运行状态
    running: AtomicBool,
    
    /// 活动工作流跟踪
    active_workflows: Mutex<HashMap<String, ActiveWorkflowInfo>>,
}

/// 活动工作流信息
#[derive(Clone, Debug)]
pub struct ActiveWorkflowInfo {
    /// 工作流实例ID
    pub instance_id: String,
    
    /// 工作流定义ID
    pub workflow_id: String,
    
    /// 执行计划
    pub execution_plan: ExecutionPlan,
    
    /// 活跃任务
    pub active_tasks: HashSet<String>,
    
    /// 完成任务
    pub completed_tasks: HashSet<String>,
    
    /// 失败任务
    pub failed_tasks: HashMap<String, String>,
    
    /// 上次调度时间
    pub last_scheduled: DateTime<Utc>,
    
    /// 开始时间
    pub started_at: DateTime<Utc>,
    
    /// 更新时间
    pub updated_at: DateTime<Utc>,
}

/// 调度配置
#[derive(Clone, Debug)]
pub struct SchedulerConfig {
    /// 调度周期（毫秒）
    pub scheduling_interval_ms: u64,
    
    /// 最大并行工作流数
    pub max_parallel_workflows: usize,
    
    /// 每个工作流最大并行任务数
    pub max_parallel_tasks_per_workflow: usize,
    
    /// 任务超时时间（毫秒）
    pub task_timeout_ms: u64,
    
    /// 是否启用数据局部性优化
    pub enable_data_locality: bool,
    
    /// 是否启用资源感知调度
    pub enable_resource_aware_scheduling: bool,
    
    /// 是否启用批量调度
    pub enable_batch_scheduling: bool,
    
    /// 批处理窗口大小（毫秒）
    pub batch_window_ms: u64,
}

impl TopologyAwareScheduler {
    /// 创建新的拓扑感知调度器
    pub fn new(
        topology_analyzer: Arc<WorkflowTopologyAnalyzer>,
        node_manager: Arc<dyn NodeManager>,
        task_executor: Arc<dyn TaskExecutor>,
        config: SchedulerConfig,
        metrics: Arc<dyn MetricsCollector>,
    ) -> Self {
        Self {
            topology_analyzer,
            node_manager,
            task_executor,
            config,
            metrics,
            running: AtomicBool::new(false),
            active_workflows: Mutex::new(HashMap::new()),
        }
    }
    
    /// 启动调度器
    pub async fn start(&self) -> Result<(), SchedulerError> {
        // 防止重复启动
        if self.running.swap(true, Ordering::SeqCst) {
            return Err(SchedulerError::AlreadyRunning);
        }
        
        // 启动调度循环
        let config = self.config.clone();
        let self_arc = Arc::new(self.clone());
        
        tokio::spawn(async move {
            let interval_duration = Duration::from_millis(config.scheduling_interval_ms);
            let mut interval = tokio::time::interval(interval_duration);
            
            while self_arc.running.load(Ordering::SeqCst) {
                interval.tick().await;
                
                // 执行调度周期
                if let Err(e) = self_arc.run_scheduling_cycle().await {
                    warn!("调度周期执行失败: {:?}", e);
                }
            }
        });
        
        Ok(())
    }
    
    /// 停止调度器
    pub fn stop(&self) {
        self.running.store(false, Ordering::SeqCst);
    }
    
    /// 提交工作流执行
    pub async fn submit_workflow(
        &self,
        workflow_id: &str,
        instance_id: &str,
    ) -> Result<(), SchedulerError> {
        // 验证是否已经在执行
        {
            let active_workflows = self.active_workflows.lock().await;
            if active_workflows.contains_key(instance_id) {
                return Err(SchedulerError::WorkflowAlreadyActive(instance_id.to_string()));
            }
        }
        
        // 分析工作流并生成执行计划
        let plan = self.topology_analyzer.analyze_and_plan(workflow_id, instance_id).await
            .map_err(|e| SchedulerError::PlanningFailed(e.to_string()))?;
        
        // 记录工作流开始时间
        let now = Utc::now();
        
        // 添加到活动工作流
        let workflow_info = ActiveWorkflowInfo {
            instance_id: instance_id.to_string(),
            workflow_id: workflow_id.to_string(),
            execution_plan: plan,
            active_tasks: HashSet::new(),
            completed_tasks: HashSet::new(),
            failed_tasks: HashMap::new(),
            last_scheduled: now,
            started_at: now,
            updated_at: now,
        };
        
        {
            let mut active_workflows = self.active_workflows.lock().await;
            active_workflows.insert(instance_id.to_string(), workflow_info);
        }
        
        Ok(())
    }
    
    /// 运行调度周期
    async fn run_scheduling_cycle(&self) -> Result<(), SchedulerError> {
        // 获取活跃工作流
        let mut workflow_updates = Vec::new();
        let mut completed_workflows = Vec::new();
        
        {
            let mut active_workflows = self.active_workflows.lock().await;
            
            for (instance_id, workflow_info) in active_workflows.iter_mut() {
                // 更新工作流状态
                if let Ok(updated) = self.update_workflow_status(workflow_info).await {
                    // 检查是否完成
                    if self.is_workflow_completed(workflow_info) {
                        completed_workflows.push(instance_id.clone());
                    } else {
                        workflow_updates.push((instance_id.clone(), updated));
                    }
                }
            }
            
            // 移除已完成的工作流
            for instance_id in &completed_workflows {
                active_workflows.remove(instance_id);
            }
        }
        
        // 批量处理工作流更新
        for (instance_id, should_schedule) in workflow_updates {
            if should_schedule {
                // 调度工作流任务
                if let Err(e) = self.schedule_workflow_tasks(&instance_id).await {
                    warn!("工作流任务调度失败 {}: {:?}", instance_id, e);
                }
            }
        }
        
        // 处理已完成的工作流
        for instance_id in completed_workflows {
            info!("工作流已完成: {}", instance_id);
            
            // 触发完成回调或通知
            // ...
        }
        
        Ok(())
    }
    
    /// 更新工作流状态
    async fn update_workflow_status(&self, info: &mut ActiveWorkflowInfo) -> Result<bool, SchedulerError> {
        let mut needs_scheduling = false;
        let now = Utc::now();
        
        // 检查活跃任务状态
        let mut completed = Vec::new();
        let mut failed = HashMap::new();
        
        for task_id in &info.active_tasks {
            match self.task_executor.get_task_status(task_id).await {
                Ok(status) => {
                    match status.state {
                        TaskState::Completed => {
                            completed.push(task_id.clone());
                            needs_scheduling = true;
                        },
                        TaskState::Failed => {
                            failed.insert(task_id.clone(), status.error.unwrap_or_else(|| "未知错误".to_string()));
                            needs_scheduling = true;
                        },
                        _ => { /* 仍在执行中 */ }
                    }
                },
                Err(e) => {
                    warn!("无法获取任务状态 {}: {:?}", task_id, e);
                    // 可以实现任务状态检查超时或错误处理逻辑
                }
            }
        }
        
        // 更新已完成和失败的任务
        for task_id in completed {
            info.active_tasks.remove(&task_id);
            info.completed_tasks.insert(task_id);
        }
        
        for (task_id, error) in failed {
            info.active_tasks.remove(&task_id);
            info.failed_tasks.insert(task_id, error);
            
            // 处理任务失败策略（如重试、终止工作流等）
            // ...
        }
        
        // 如果没有活跃任务，也需要调度
        if info.active_tasks.is_empty() && !self.is_workflow_completed(info) {
            needs_scheduling = true;
        }
        
        // 更新最后调度时间
        info.updated_at = now;
        
        Ok(needs_scheduling)
    }
    
    /// 调度工作流任务
    async fn schedule_workflow_tasks(&self, instance_id: &str) -> Result<(), SchedulerError> {
        let mut active_workflows = self.active_workflows.lock().await;
        
        if let Some(workflow_info) = active_workflows.get_mut(instance_id) {
            // 检查是否可以调度更多任务
            if workflow_info.active_tasks.len() >= self.config.max_parallel_tasks_per_workflow {
                return Ok(());
            }
            
            // 获取可执行的任务
            let executable_tasks = workflow_info.execution_plan.get_executable_tasks(
                &workflow_info.active_tasks
            );
            
            if executable_tasks.is_empty() {
                // 没有可执行的任务，但仍有活跃任务或未完成的任务
                if !workflow_info.active_tasks.is_empty() {
                    return Ok(());
                }
                
                // 检查工作流是否已完成
                if self.is_workflow_completed(workflow_info) {
                    return Ok(());
                }
                
                // 如果没有可执行任务，但仍有待执行的任务，可能有依赖问题
                warn!("工作流 {} 无可执行任务但未完成", instance_id);
                return Err(SchedulerError::NoExecutableTasks(instance_id.to_string()));
            }
            
            // 计算本次可调度的任务数量
            let available_slots = self.config.max_parallel_tasks_per_workflow - workflow_info.active_tasks.len();
            let tasks_to_schedule = executable_tasks.iter()
                .take(available_slots)
                .cloned()
                .collect::<Vec<_>>();
            
            // 调度任务
            for task_id in tasks_to_schedule {
                // 获取任务放置信息
                if let Some(placement) = workflow_info.execution_plan.get_task_placement(&task_id) {
                    // 提交任务执行
                    if let Err(e) = self.submit_task(workflow_info, &task_id, placement).await {
                        warn!("任务提交失败 {}: {:?}", task_id, e);
                        workflow_info.failed_tasks.insert(task_id, e.to_string());
                    } else {
                        // 添加到活跃任务
                        workflow_info.active_tasks.insert(task_id);
                    }
                }
            }
            
            // 更新调度时间
            workflow_info.last_scheduled = Utc::now();
        } else {
            return Err(SchedulerError::WorkflowNotFound(instance_id.to_string()));
        }
        
        Ok(())
    }
    
    /// 提交任务执行
    async fn submit_task(
        &self,
        workflow_info: &ActiveWorkflowInfo,
        task_id: &str,
        placement: &TaskPlacement,
    ) -> Result<(), SchedulerError> {
        // 构建任务执行参数
        let execution_params = TaskExecutionParams {
            task_id: task_id.to_string(),
            workflow_id: workflow_info.workflow_id.clone(),
            instance_id: workflow_info.instance_id.clone(),
            node_id: placement.node_id.

    /// 提交任务执行
    async fn submit_task(
        &self,
        workflow_info: &ActiveWorkflowInfo,
        task_id: &str,
        placement: &TaskPlacement,
    ) -> Result<(), SchedulerError> {
        // 构建任务执行参数
        let execution_params = TaskExecutionParams {
            task_id: task_id.to_string(),
            workflow_id: workflow_info.workflow_id.clone(),
            instance_id: workflow_info.instance_id.clone(),
            node_id: placement.node_id.clone(),
            cpu_units: placement.estimate.cpu_units,
            memory_mb: placement.estimate.memory_mb,
            storage_mb: placement.estimate.storage_mb,
            timeout_ms: self.config.task_timeout_ms,
            priority: placement.priority,
        };
        
        // 执行任务
        match self.task_executor.execute_task(execution_params).await {
            Ok(_) => {
                info!("任务已提交执行: workflow={}, task={}, node={}",
                    workflow_info.instance_id, task_id, placement.node_id);
                Ok(())
            },
            Err(e) => {
                error!("任务提交失败: workflow={}, task={}, node={}, error={:?}",
                    workflow_info.instance_id, task_id, placement.node_id, e);
                Err(SchedulerError::TaskSubmissionFailed(e.to_string()))
            }
        }
    }
    
    /// 检查工作流是否已完成
    fn is_workflow_completed(&self, info: &ActiveWorkflowInfo) -> bool {
        // 没有活跃任务，且所有任务都已完成或失败
        if !info.active_tasks.is_empty() {
            return false;
        }
        
        // 获取所有任务
        let total_tasks = info.execution_plan.task_placements.len();
        let completed_and_failed = info.completed_tasks.len() + info.failed_tasks.len();
        
        total_tasks == completed_and_failed
    }
}

/// 调度器错误
#[derive(Debug, thiserror::Error)]
pub enum SchedulerError {
    #[error("调度器已经运行")]
    AlreadyRunning,
    
    #[error("工作流不存在: {0}")]
    WorkflowNotFound(String),
    
    #[error("工作流已活跃: {0}")]
    WorkflowAlreadyActive(String),
    
    #[error("规划失败: {0}")]
    PlanningFailed(String),
    
    #[error("没有可执行任务: {0}")]
    NoExecutableTasks(String),
    
    #[error("任务提交失败: {0}")]
    TaskSubmissionFailed(String),
    
    #[error("节点不可用: {0}")]
    NodeUnavailable(String),
    
    #[error("资源不足: {0}")]
    InsufficientResources(String),
    
    #[error("内部错误: {0}")]
    InternalError(String),
}

/// 任务执行参数
#[derive(Clone, Debug)]
pub struct TaskExecutionParams {
    /// 任务ID
    pub task_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 实例ID
    pub instance_id: String,
    
    /// 节点ID
    pub node_id: String,
    
    /// CPU单位需求
    pub cpu_units: f64,
    
    /// 内存需求（MB）
    pub memory_mb: f64,
    
    /// 存储需求（MB）
    pub storage_mb: f64,
    
    /// 超时时间（毫秒）
    pub timeout_ms: u64,
    
    /// 优先级
    pub priority: u32,
}

/// 任务状态
#[derive(Clone, Debug)]
pub struct TaskStatus {
    /// 任务ID
    pub task_id: String,
    
    /// 任务状态
    pub state: TaskState,
    
    /// 开始时间
    pub start_time: Option<DateTime<Utc>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 错误信息
    pub error: Option<String>,
    
    /// 进度（0-100）
    pub progress: u8,
    
    /// 更新时间
    pub last_updated: DateTime<Utc>,
}

/// 任务状态
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum TaskState {
    /// 待执行
    Pending,
    
    /// 已调度
    Scheduled,
    
    /// 正在执行
    Running,
    
    /// 已完成
    Completed,
    
    /// 失败
    Failed,
    
    /// 已取消
    Cancelled,
    
    /// 已超时
    TimedOut,
}

/// 任务执行器接口
#[async_trait]
pub trait TaskExecutor: Send + Sync {
    /// 执行任务
    async fn execute_task(&self, params: TaskExecutionParams) -> Result<(), ExecutionError>;
    
    /// 获取任务状态
    async fn get_task_status(&self, task_id: &str) -> Result<TaskStatus, ExecutionError>;
    
    /// 取消任务
    async fn cancel_task(&self, task_id: &str) -> Result<(), ExecutionError>;
    
    /// 获取任务结果
    async fn get_task_result(&self, task_id: &str) -> Result<Option<serde_json::Value>, ExecutionError>;
}

/// 执行错误
#[derive(Debug, thiserror::Error)]
pub enum ExecutionError {
    #[error("任务不存在: {0}")]
    TaskNotFound(String),
    
    #[error("节点不存在: {0}")]
    NodeNotFound(String),
    
    #[error("资源不足: {0}")]
    InsufficientResources(String),
    
    #[error("执行失败: {0}")]
    ExecutionFailed(String),
    
    #[error("任务已经在执行中: {0}")]
    TaskAlreadyRunning(String),
    
    #[error("任务已超时: {0}")]
    TaskTimedOut(String),
    
    #[error("任务已取消: {0}")]
    TaskCancelled(String),
    
    #[error("内部错误: {0}")]
    InternalError(String),
}

/// 节点管理器接口
#[async_trait]
pub trait NodeManager: Send + Sync {
    /// 获取所有节点
    async fn get_all_nodes(&self) -> Result<Vec<ExecutionNode>, NodeManagerError>;
    
    /// 获取节点信息
    async fn get_node(&self, node_id: &str) -> Result<ExecutionNode, NodeManagerError>;
    
    /// 获取可用节点
    async fn get_available_nodes(&self) -> Result<Vec<ExecutionNode>, NodeManagerError>;
    
    /// 更新节点负载
    async fn update_node_load(&self, node_id: &str, resources: HashMap<String, f64>) -> Result<(), NodeManagerError>;
    
    /// 检查节点状态
    async fn check_node_health(&self, node_id: &str) -> Result<bool, NodeManagerError>;
    
    /// 获取节点负载
    async fn get_node_load(&self, node_id: &str) -> Result<HashMap<String, f64>, NodeManagerError>;
}

/// 节点管理器错误
#[derive(Debug, thiserror::Error)]
pub enum NodeManagerError {
    #[error("节点不存在: {0}")]
    NodeNotFound(String),
    
    #[error("节点不可用: {0}")]
    NodeUnavailable(String),
    
    #[error("节点已存在: {0}")]
    NodeAlreadyExists(String),
    
    #[error("内部错误: {0}")]
    InternalError(String),
}

/// 指标收集器接口
#[async_trait]
pub trait MetricsCollector: Send + Sync {
    /// 记录工作流提交
    async fn record_workflow_submission(&self, workflow_id: &str, instance_id: &str);
    
    /// 记录工作流完成
    async fn record_workflow_completion(&self, instance_id: &str, duration_ms: u64, succeeded: bool);
    
    /// 记录任务提交
    async fn record_task_submission(&self, task_id: &str, instance_id: &str, node_id: &str);
    
    /// 记录任务完成
    async fn record_task_completion(&self, task_id: &str, node_id: &str, duration_ms: u64, succeeded: bool);
    
    /// 记录节点负载
    async fn record_node_load(&self, node_id: &str, load: &HashMap<String, f64>);
    
    /// 记录资源使用
    async fn record_resource_usage(&self, resource_type: &str, amount: f64);
    
    /// 记录调度统计
    async fn record_scheduling_metrics(&self, 
        active_workflows: usize, 
        queued_workflows: usize, 
        active_tasks: usize, 
        scheduling_time_ms: u64);
}

/// 资源管理器
pub struct ResourceManager {
    /// 可用资源池
    resource_pool: RwLock<ResourcePool>,
    
    /// 资源分配记录
    allocations: RwLock<HashMap<String, ResourceAllocation>>,
    
    /// 队列管理器
    queue_manager: Arc<dyn QueueManager>,
    
    /// 指标收集器
    metrics_collector: Arc<dyn MetricsCollector>,
}

/// 资源池
#[derive(Clone, Debug)]
pub struct ResourcePool {
    /// CPU资源（核心数）
    pub cpu: f64,
    
    /// 内存资源（MB）
    pub memory: f64,
    
    /// 存储资源（MB）
    pub storage: f64,
    
    /// 已分配CPU
    pub allocated_cpu: f64,
    
    /// 已分配内存
    pub allocated_memory: f64,
    
    /// 已分配存储
    pub allocated_storage: f64,
}

impl ResourcePool {
    /// 创建新的资源池
    pub fn new(cpu: f64, memory: f64, storage: f64) -> Self {
        Self {
            cpu,
            memory,
            storage,
            allocated_cpu: 0.0,
            allocated_memory: 0.0,
            allocated_storage: 0.0,
        }
    }
    
    /// 检查是否有足够资源
    pub fn has_enough_resources(&self, cpu: f64, memory: f64, storage: f64) -> bool {
        let available_cpu = self.cpu - self.allocated_cpu;
        let available_memory = self.memory - self.allocated_memory;
        let available_storage = self.storage - self.allocated_storage;
        
        available_cpu >= cpu && available_memory >= memory && available_storage >= storage
    }
    
    /// 分配资源
    pub fn allocate_resources(&mut self, cpu: f64, memory: f64, storage: f64) -> Result<(), ResourceError> {
        if !self.has_enough_resources(cpu, memory, storage) {
            return Err(ResourceError::InsufficientResources(
                format!("请求: CPU={}, 内存={}MB, 存储={}MB; 可用: CPU={}, 内存={}MB, 存储={}MB",
                    cpu, memory, storage,
                    self.cpu - self.allocated_cpu,
                    self.memory - self.allocated_memory,
                    self.storage - self.allocated_storage)
            ));
        }
        
        self.allocated_cpu += cpu;
        self.allocated_memory += memory;
        self.allocated_storage += storage;
        
        Ok(())
    }
    
    /// 释放资源
    pub fn release_resources(&mut self, cpu: f64, memory: f64, storage: f64) -> Result<(), ResourceError> {
        self.allocated_cpu = (self.allocated_cpu - cpu).max(0.0);
        self.allocated_memory = (self.allocated_memory - memory).max(0.0);
        self.allocated_storage = (self.allocated_storage - storage).max(0.0);
        
        Ok(())
    }
    
    /// 获取CPU使用率
    pub fn get_cpu_usage_ratio(&self) -> f64 {
        if self.cpu == 0.0 {
            0.0
        } else {
            self.allocated_cpu / self.cpu
        }
    }
    
    /// 获取内存使用率
    pub fn get_memory_usage_ratio(&self) -> f64 {
        if self.memory == 0.0 {
            0.0
        } else {
            self.allocated_memory / self.memory
        }
    }
    
    /// 获取存储使用率
    pub fn get_storage_usage_ratio(&self) -> f64 {
        if self.storage == 0.0 {
            0.0
        } else {
            self.allocated_storage / self.storage
        }
    }
    
    /// 获取总体使用率
    pub fn get_overall_usage_ratio(&self) -> f64 {
        (self.get_cpu_usage_ratio() + self.get_memory_usage_ratio() + self.get_storage_usage_ratio()) / 3.0
    }
}

/// 资源分配
#[derive(Clone, Debug)]
pub struct ResourceAllocation {
    /// 分配ID
    pub id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 分配时间
    pub allocation_time: DateTime<Utc>,
    
    /// CPU分配
    pub cpu: f64,
    
    /// 内存分配（MB）
    pub memory: f64,
    
    /// 存储分配（MB）
    pub storage: f64,
    
    /// 资源限制
    pub limits: Option<ResourceLimits>,
    
    /// 分配节点
    pub nodes: Vec<String>,
}

/// 资源限制
#[derive(Clone, Debug)]
pub struct ResourceLimits {
    /// CPU限制
    pub cpu_limit: f64,
    
    /// 内存限制（MB）
    pub memory_limit: f64,
    
    /// 存储限制（MB）
    pub storage_limit: f64,
    
    /// 网络带宽限制（Mbps）
    pub network_limit: Option<f64>,
    
    /// IO操作限制（IOPS）
    pub io_ops_limit: Option<f64>,
}

/// 资源错误
#[derive(Debug, thiserror::Error)]
pub enum ResourceError {
    #[error("资源不足: {0}")]
    InsufficientResources(String),
    
    #[error("分配不存在: {0}")]
    AllocationNotFound(String),
    
    #[error("资源超限: {0}")]
    ResourceLimitExceeded(String),
    
    #[error("内部错误: {0}")]
    InternalError(String),
}

/// 队列管理器接口
#[async_trait]
pub trait QueueManager: Send + Sync {
    /// 将工作流加入队列
    async fn enqueue(&self, workflow_id: &str, requirements: ResourceRequirements) -> Result<(), QueueError>;
    
    /// 从队列中获取下一个工作流
    async fn dequeue(&self) -> Result<Option<QueuedWorkflow>, QueueError>;
    
    /// 获取队列长度
    async fn get_queue_length(&self) -> Result<usize, QueueError>;
    
    /// 检查工作流是否在队列中
    async fn is_queued(&self, workflow_id: &str) -> Result<bool, QueueError>;
    
    /// 通知资源已分配
    async fn notify_allocated(&self, workflow_id: &str, allocation: &ResourceAllocation) -> Result<(), QueueError>;
    
    /// 从队列中移除工作流
    async fn remove(&self, workflow_id: &str) -> Result<(), QueueError>;
}

/// 队列错误
#[derive(Debug, thiserror::Error)]
pub enum QueueError {
    #[error("工作流已在队列中: {0}")]
    WorkflowAlreadyQueued(String),
    
    #[error("工作流不在队列中: {0}")]
    WorkflowNotQueued(String),
    
    #[error("队列已满")]
    QueueFull,
    
    #[error("内部错误: {0}")]
    InternalError(String),
}

/// 等待队列中的工作流
#[derive(Clone, Debug)]
pub struct QueuedWorkflow {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 资源需求
    pub requirements: ResourceRequirements,
    
    /// 优先级
    pub priority: u8,
    
    /// 加入队列时间
    pub enqueued_at: DateTime<Utc>,
    
    /// 预计开始时间
    pub estimated_start: Option<DateTime<Utc>>,
}

/// 资源需求
#[derive(Clone, Debug)]
pub struct ResourceRequirements {
    /// 最小CPU需求
    pub min_cpu: f64,
    
    /// 最小内存需求（MB）
    pub min_memory: f64,
    
    /// 最小存储需求（MB）
    pub min_storage: f64,
    
    /// 首选CPU需求
    pub preferred_cpu: Option<f64>,
    
    /// 首选内存需求（MB）
    pub preferred_memory: Option<f64>,
    
    /// 首选存储需求（MB）
    pub preferred_storage: Option<f64>,
    
    /// 首选执行位置
    pub preferred_location: Option<String>,
    
    /// 是否弹性分配
    pub elastic: bool,
}

impl ResourceManager {
    /// 创建新的资源管理器
    pub fn new(
        cpu: f64,
        memory: f64,
        storage: f64,
        queue_manager: Arc<dyn QueueManager>,
        metrics_collector: Arc<dyn MetricsCollector>,
    ) -> Self {
        Self {
            resource_pool: RwLock::new(ResourcePool::new(cpu, memory, storage)),
            allocations: RwLock::new(HashMap::new()),
            queue_manager,
            metrics_collector,
        }
    }
    
    /// 分配资源
    pub async fn allocate_resources(
        &self,
        workflow_id: &str,
        requirements: &ResourceRequirements,
    ) -> Result<ResourceAllocation, ResourceError> {
        // 确定要分配的资源量
        let cpu = requirements.preferred_cpu.unwrap_or(requirements.min_cpu);
        let memory = requirements.preferred_memory.unwrap_or(requirements.min_memory);
        let storage = requirements.preferred_storage.unwrap_or(requirements.min_storage);
        
        // 尝试分配资源
        {
            let mut pool = self.resource_pool.write().await;
            
            if !pool.has_enough_resources(cpu, memory, storage) {
                // 如果启用了弹性分配，尝试分配最小资源
                if requirements.elastic && requirements.min_cpu < cpu &&
                   pool.has_enough_resources(requirements.min_cpu, requirements.min_memory, requirements.min_storage) {
                    
                    // 分配最小资源
                    pool.allocate_resources(
                        requirements.min_cpu, 
                        requirements.min_memory, 
                        requirements.min_storage
                    )?;
                    
                    // 创建分配记录（使用最小值）
                    let allocation = ResourceAllocation {
                        id: Uuid::new_v4().to_string(),
                        workflow_id: workflow_id.to_string(),
                        allocation_time: Utc::now(),
                        cpu: requirements.min_cpu,
                        memory: requirements.min_memory,
                        storage: requirements.min_storage,
                        limits: None,
                        nodes: Vec::new(), // 暂时还没有分配到具体节点
                    };
                    
                    // 记录分配
                    {
                        let mut allocations = self.allocations.write().await;
                        allocations.insert(workflow_id.to_string(), allocation.clone());
                    }
                    
                    // 记录指标
                    self.metrics_collector
                        .record_resource_usage("cpu", requirements.min_cpu)
                        .await;
                    self.metrics_collector
                        .record_resource_usage("memory", requirements.min_memory)
                        .await;
                    self.metrics_collector
                        .record_resource_usage("storage", requirements.min_storage)
                        .await;
                    
                    return Ok(allocation);
                }
                
                // 资源不足，将工作流加入队列
                if let Err(e) = self.queue_manager.enqueue(workflow_id, requirements.clone()).await {
                    return Err(ResourceError::InternalError(format!("无法将工作流加入队列: {}", e)));
                }
                
                return Err(ResourceError::InsufficientResources(
                    format!("资源不足，工作流 {} 已加入队列", workflow_id)
                ));
            }
            
            // 分配资源
            pool.allocate_resources(cpu, memory, storage)?;
        }
        
        // 创建分配记录
        let allocation = ResourceAllocation {
            id: Uuid::new_v4().to_string(),
            workflow_id: workflow_id.to_string(),
            allocation_time: Utc::now(),
            cpu,
            memory,
            storage,
            limits: None,
            nodes: Vec::new(), // 暂时还没有分配到具体节点
        };
        
        // 记录分配
        {
            let mut allocations = self.allocations.write().await;
            allocations.insert(workflow_id.to_string(), allocation.clone());
        }
        
        // 记录指标
        self.metrics_collector
            .record_resource_usage("cpu", cpu)
            .await;
        self.metrics_collector
            .record_resource_usage("memory", memory)
            .await;
        self.metrics_collector
            .record_resource_usage("storage", storage)
            .await;
        
        Ok(allocation)
    }
    
    /// 释放资源
    pub async fn release_resources(&self, workflow_id: &str) -> Result<(), ResourceError> {
        // 查找分配
        let allocation = {
            let allocations = self.allocations.read().await;
            match allocations.get(workflow_id) {
                Some(allocation) => allocation.clone(),
                None => {
                    return Err(ResourceError::AllocationNotFound(workflow_id.to_string()));
                }
            }
        };
        
        // 释放资源
        {
            let mut pool = self.resource_pool.write().await;
            pool.release_resources(allocation.cpu, allocation.memory, allocation.storage)?;
        }
        
        // 移除分配记录
        {
            let mut allocations = self.allocations.write().await;
            allocations.remove(workflow_id);
        }
        
        // 尝试从队列中分配下一个工作流
        self.process_queue().await?;
        
        Ok(())
    }
    
    /// 处理队列
    async fn process_queue(&self) -> Result<(), ResourceError> {
        // 尝试从队列中获取下一个工作流
        if let Some(queued_workflow) = self.queue_manager.dequeue().await.map_err(|e| 
            ResourceError::InternalError(format!("队列操作失败: {}", e)))? {
            
            // 尝试分配资源
            match self.allocate_resources(&queued_workflow.workflow_id, &queued_workflow.requirements).await {
                Ok(allocation) => {
                    // 通知资源已分配
                    self.queue_manager.notify_allocated(&queued_workflow.workflow_id, &allocation).await
                        .map_err(|e| ResourceError::InternalError(format!("通知队列失败: {}", e)))?;
                    
                    // 记录队列统计
                    let queue_length = self.queue_manager.get_queue_length().await
                        .map_err(|e| ResourceError::InternalError(format!("获取队列长度失败: {}", e)))?;
                    
                    self.metrics_collector
                        .record_scheduling_metrics(
                            self.allocations.read().await.len(),
                            queue_length,
                            0, // 这里没有统计任务数
                            0,
                        )
                        .await;
                },
                Err(e) => {
                    // 资源仍然不足，放回队列
                    if matches!(e, ResourceError::InsufficientResources(_)) {
                        self.queue_manager.enqueue(&queued_workflow.workflow_id, queued_workflow.requirements).await
                            .map_err(|e| ResourceError::InternalError(format!("重新加入队列失败: {}", e)))?;
                    } else {
                        return Err(e);
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// 获取资源使用统计
    pub async fn get_resource_usage(&self) -> ResourceUsageStats {
        let pool = self.resource_pool.read().await;
        
        ResourceUsageStats {
            total_cpu: pool.cpu,
            used_cpu: pool.allocated_cpu,
            total_memory: pool.memory,
            used_memory: pool.allocated_memory,
            total_storage: pool.storage,
            used_storage: pool.allocated_storage,
            cpu_usage_ratio: pool.get_cpu_usage_ratio(),
            memory_usage_ratio: pool.get_memory_usage_ratio(),
            storage_usage_ratio: pool.get_storage_usage_ratio(),
            overall_usage_ratio: pool.get_overall_usage_ratio(),
        }
    }
    
    /// 获取分配信息
    pub async fn get_allocation(&self, workflow_id: &str) -> Option<ResourceAllocation> {
        let allocations = self.allocations.read().await;
        allocations.get(workflow_id).cloned()
    }
    
    /// 获取所有分配
    pub async fn get_all_allocations(&self) -> Vec<ResourceAllocation> {
        let allocations = self.allocations.read().await;
        allocations.values().cloned().collect()
    }
    
    /// 获取队列长度
    pub async fn get_queue_length(&self) -> Result<usize, ResourceError> {
        self.queue_manager.get_queue_length().await.map_err(|e| 
            ResourceError::InternalError(format!("获取队列长度失败: {}", e)))
    }
}

/// 资源使用统计
#[derive(Clone, Debug)]
pub struct ResourceUsageStats {
    /// 总CPU资源
    pub total_cpu: f64,
    
    /// 已使用CPU资源
    pub used_cpu: f64,
    
    /// 总内存资源（MB）
    pub total_memory: f64,
    
    /// 已使用内存资源（MB）
    pub used_memory: f64,
    
    /// 总存储资源（MB）
    pub total_storage: f64,
    
    /// 已使用存储资源（MB）
    pub used_storage: f64,
    
    /// CPU使用率
    pub cpu_usage_ratio: f64,
    
    /// 内存使用率
    pub memory_usage_ratio: f64,
    
    /// 存储使用率
    pub storage_usage_ratio: f64,
    
    /// 总体使用率
    pub overall_usage_ratio: f64,
}

/// 基本任务执行器实现
pub struct BasicTaskExecutor {
    /// 节点管理器
    node_manager: Arc<dyn NodeManager>,
    
    /// 任务函数注册表
    function_registry: RwLock<HashMap<String, Arc<dyn TaskFunction>>>,
    
    /// 任务状态
    task_statuses: RwLock<HashMap<String, TaskStatus>>,
    
    /// 任务结果
    task_results: RwLock<HashMap<String, serde_json::Value>>,
    
    /// 指标收集器
    metrics_collector: Arc<dyn MetricsCollector>,
}

/// 任务函数接口
#[async_trait]
pub trait TaskFunction: Send + Sync {
    /// 执行任务
    async fn execute(
        &self,
        input: serde_json::Value,
        context: TaskContext,
    ) -> Result<serde_json::Value, TaskError>;
    
    /// 取消任务
    async fn cancel(&self, context: TaskContext) -> Result<(), TaskError>;
    
    /// 获取函数名称
    fn name(&self) -> &str;
    
    /// 获取资源需求
    fn resource_requirements(&self) -> ResourceRequirements;
}

/// 任务上下文
#[derive(Clone, Debug)]
pub struct TaskContext {
    /// 任务ID
    pub task_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 实例ID
    pub instance_id: String,
    
    /// 
    /// 
/// 任务上下文
#[derive(Clone, Debug)]
pub struct TaskContext {
    /// 任务ID
    pub task_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 实例ID
    pub instance_id: String,
    
    /// 节点ID
    pub node_id: String,
    
    /// 开始时间
    pub start_time: DateTime<Utc>,
    
    /// 超时（毫秒）
    pub timeout_ms: u64,
    
    /// 任务参数
    pub parameters: HashMap<String, serde_json::Value>,
    
    /// 工作流变量
    pub workflow_variables: HashMap<String, serde_json::Value>,
    
    /// 任务取消标记
    pub cancelled: Arc<AtomicBool>,
    
    /// 任务进度更新回调
    pub progress_callback: Option<Arc<dyn Fn(u8) + Send + Sync>>,
}

impl TaskContext {
    /// 检查任务是否被取消
    pub fn is_cancelled(&self) -> bool {
        self.cancelled.load(Ordering::Relaxed)
    }
    
    /// 检查任务是否超时
    pub fn is_timed_out(&self) -> bool {
        let elapsed = Utc::now() - self.start_time;
        elapsed.num_milliseconds() > self.timeout_ms as i64
    }
    
    /// 更新进度
    pub fn update_progress(&self, progress: u8) {
        if let Some(callback) = &self.progress_callback {
            callback(progress);
        }
    }
    
    /// 从上下文中获取值
    pub fn get_parameter<T: DeserializeOwned>(&self, name: &str) -> Result<T, TaskError> {
        if let Some(value) = self.parameters.get(name) {
            serde_json::from_value(value.clone())
                .map_err(|e| TaskError::InvalidInput(format!("参数解析失败 {}: {}", name, e)))
        } else {
            Err(TaskError::MissingInput(format!("缺少必需参数: {}", name)))
        }
    }
    
    /// 从上下文中获取可选值
    pub fn get_optional_parameter<T: DeserializeOwned>(&self, name: &str) -> Result<Option<T>, TaskError> {
        if let Some(value) = self.parameters.get(name) {
            if value.is_null() {
                return Ok(None);
            }
            serde_json::from_value(value.clone())
                .map(Some)
                .map_err(|e| TaskError::InvalidInput(format!("参数解析失败 {}: {}", name, e)))
        } else {
            Ok(None)
        }
    }
    
    /// 获取工作流变量
    pub fn get_workflow_variable<T: DeserializeOwned>(&self, name: &str) -> Result<T, TaskError> {
        if let Some(value) = self.workflow_variables.get(name) {
            serde_json::from_value(value.clone())
                .map_err(|e| TaskError::InvalidInput(format!("工作流变量解析失败 {}: {}", name, e)))
        } else {
            Err(TaskError::MissingWorkflowVariable(format!("缺少工作流变量: {}", name)))
        }
    }
    
    /// 获取可选工作流变量
    pub fn get_optional_workflow_variable<T: DeserializeOwned>(&self, name: &str) -> Result<Option<T>, TaskError> {
        if let Some(value) = self.workflow_variables.get(name) {
            if value.is_null() {
                return Ok(None);
            }
            serde_json::from_value(value.clone())
                .map(Some)
                .map_err(|e| TaskError::InvalidInput(format!("工作流变量解析失败 {}: {}", name, e)))
        } else {
            Ok(None)
        }
    }
}

/// 任务错误
#[derive(Debug, thiserror::Error)]
pub enum TaskError {
    #[error("缺少输入: {0}")]
    MissingInput(String),
    
    #[error("输入格式无效: {0}")]
    InvalidInput(String),
    
    #[error("缺少工作流变量: {0}")]
    MissingWorkflowVariable(String),
    
    #[error("执行错误: {0}")]
    ExecutionFailed(String),
    
    #[error("任务超时")]
    Timeout,
    
    #[error("任务取消")]
    Cancelled,
    
    #[error("数据访问错误: {0}")]
    DataAccessError(String),
    
    #[error("资源不足: {0}")]
    ResourceConstraintViolation(String),
    
    #[error("并发限制: {0}")]
    ConcurrencyLimitExceeded(String),
    
    #[error("内部错误: {0}")]
    InternalError(String),
}

impl BasicTaskExecutor {
    /// 创建新的基本任务执行器
    pub fn new(
        node_manager: Arc<dyn NodeManager>,
        metrics_collector: Arc<dyn MetricsCollector>,
    ) -> Self {
        Self {
            node_manager,
            function_registry: RwLock::new(HashMap::new()),
            task_statuses: RwLock::new(HashMap::new()),
            task_results: RwLock::new(HashMap::new()),
            metrics_collector,
        }
    }
    
    /// 注册任务函数
    pub fn register_function(&self, function: Arc<dyn TaskFunction>) -> Result<(), String> {
        let mut registry = self.function_registry.write().unwrap();
        let function_name = function.name().to_string();
        
        if registry.contains_key(&function_name) {
            return Err(format!("函数已注册: {}", function_name));
        }
        
        registry.insert(function_name, function);
        Ok(())
    }
    
    /// 获取任务函数
    fn get_function(&self, function_name: &str) -> Result<Arc<dyn TaskFunction>, ExecutionError> {
        let registry = self.function_registry.read().unwrap();
        
        registry.get(function_name).cloned().ok_or_else(|| {
            ExecutionError::TaskNotFound(format!("未找到函数: {}", function_name))
        })
    }
    
    /// 更新任务状态
    async fn update_task_status(&self, task_id: &str, state: TaskState, error: Option<String>) {
        let mut statuses = self.task_statuses.write().await;
        
        let now = Utc::now();
        let status = statuses.entry(task_id.to_string()).or_insert_with(|| {
            TaskStatus {
                task_id: task_id.to_string(),
                state: TaskState::Pending,
                start_time: None,
                end_time: None,
                error: None,
                progress: 0,
                last_updated: now,
            }
        });
        
        status.state = state;
        status.last_updated = now;
        status.error = error;
        
        match state {
            TaskState::Running => {
                if status.start_time.is_none() {
                    status.start_time = Some(now);
                }
            }
            TaskState::Completed | TaskState::Failed | TaskState::Cancelled | TaskState::TimedOut => {
                status.end_time = Some(now);
            }
            _ => {}
        }
    }
}

#[async_trait]
impl TaskExecutor for BasicTaskExecutor {
    async fn execute_task(&self, params: TaskExecutionParams) -> Result<(), ExecutionError> {
        // 检查节点
        let node = self.node_manager.get_node(&params.node_id).await
            .map_err(|e| ExecutionError::NodeNotFound(format!("获取节点失败: {}", e)))?;
        
        // 检查节点状态
        let is_healthy = self.node_manager.check_node_health(&params.node_id).await
            .map_err(|e| ExecutionError::NodeNotFound(format!("检查节点健康状态失败: {}", e)))?;
        
        if !is_healthy {
            return Err(ExecutionError::NodeUnavailable(format!("节点不健康: {}", params.node_id)));
        }
        
        // 检查节点负载
        let node_load = self.node_manager.get_node_load(&params.node_id).await
            .map_err(|e| ExecutionError::InternalError(format!("获取节点负载失败: {}", e)))?;
        
        // 获取任务状态
        let task_status = self.get_task_status(&params.task_id).await?;
        
        // 检查任务是否已经在执行
        if task_status.state == TaskState::Running {
            return Err(ExecutionError::TaskAlreadyRunning(params.task_id.clone()));
        }
        
        // 提取任务类型
        let task_type = {
            let parts: Vec<&str> = params.task_id.split(':').collect();
            if parts.len() < 2 {
                return Err(ExecutionError::ExecutionFailed(
                    format!("无效的任务ID格式: {}", params.task_id)
                ));
            }
            parts[0].to_string()
        };
        
        // 获取任务函数
        let function = self.get_function(&task_type)?;
        
        // 更新任务状态为运行中
        self.update_task_status(&params.task_id, TaskState::Running, None).await;
        
        // 记录任务提交
        self.metrics_collector.record_task_submission(
            &params.task_id,
            &params.instance_id,
            &params.node_id,
        ).await;
        
        // 创建取消标志
        let cancelled = Arc::new(AtomicBool::new(false));
        let cancelled_clone = cancelled.clone();
        
        // 创建进度回调
        let progress_callback = {
            let task_id = params.task_id.clone();
            let statuses = self.task_statuses.clone();
            
            Arc::new(move |progress: u8| {
                let task_id_copy = task_id.clone();
                let statuses_copy = statuses.clone();
                
                tokio::spawn(async move {
                    let mut statuses = statuses_copy.write().await;
                    if let Some(status) = statuses.get_mut(&task_id_copy) {
                        status.progress = progress;
                        status.last_updated = Utc::now();
                    }
                });
            }) as Arc<dyn Fn(u8) + Send + Sync>
        };
        
        // 创建任务上下文
        let context = TaskContext {
            task_id: params.task_id.clone(),
            workflow_id: params.workflow_id.clone(),
            instance_id: params.instance_id.clone(),
            node_id: params.node_id.clone(),
            start_time: Utc::now(),
            timeout_ms: params.timeout_ms,
            parameters: HashMap::new(), // TODO: 从实际存储中获取任务参数
            workflow_variables: HashMap::new(), // TODO: 从工作流状态中获取变量
            cancelled: cancelled_clone,
            progress_callback: Some(progress_callback),
        };
        
        // 创建超时处理
        let timeout_duration = Duration::from_millis(params.timeout_ms);
        let task_id = params.task_id.clone();
        let self_clone = self.clone();
        
        let timeout_handle = tokio::spawn(async move {
            tokio::time::sleep(timeout_duration).await;
            
            // 检查任务是否仍在运行
            let status = self_clone.get_task_status(&task_id).await
                .unwrap_or(TaskStatus {
                    task_id: task_id.clone(),
                    state: TaskState::Pending,
                    start_time: None,
                    end_time: None,
                    error: None,
                    progress: 0,
                    last_updated: Utc::now(),
                });
            
            if status.state == TaskState::Running {
                // 任务仍在运行，标记为取消
                cancelled.store(true, Ordering::Relaxed);
                
                // 更新状态为超时
                self_clone.update_task_status(
                    &task_id,
                    TaskState::TimedOut,
                    Some(format!("任务超时: {}ms", params.timeout_ms)),
                ).await;
            }
        });
        
        // 执行任务
        let start_time = Instant::now();
        let task_id = params.task_id.clone();
        let node_id = params.node_id.clone();
        let self_clone = self.clone();
        
        // 在单独的线程中执行任务函数
        let handle = tokio::spawn(async move {
            let input = serde_json::Value::Null; // TODO: 从参数获取实际输入
            
            match function.execute(input, context.clone()).await {
                Ok(result) => {
                    // 更新任务状态
                    self_clone.update_task_status(&task_id, TaskState::Completed, None).await;
                    
                    // 保存任务结果
                    {
                        let mut results = self_clone.task_results.write().await;
                        results.insert(task_id.clone(), result);
                    }
                    
                    let duration_ms = start_time.elapsed().as_millis() as u64;
                    
                    // 记录任务完成
                    self_clone.metrics_collector.record_task_completion(
                        &task_id,
                        &node_id,
                        duration_ms,
                        true,
                    ).await;
                    
                    Ok(())
                },
                Err(e) => {
                    let error_message = e.to_string();
                    let state = match e {
                        TaskError::Timeout => TaskState::TimedOut,
                        TaskError::Cancelled => TaskState::Cancelled,
                        _ => TaskState::Failed,
                    };
                    
                    // 更新任务状态
                    self_clone.update_task_status(&task_id, state, Some(error_message.clone())).await;
                    
                    let duration_ms = start_time.elapsed().as_millis() as u64;
                    
                    // 记录任务完成（失败）
                    self_clone.metrics_collector.record_task_completion(
                        &task_id,
                        &node_id,
                        duration_ms,
                        false,
                    ).await;
                    
                    Err(ExecutionError::ExecutionFailed(error_message))
                }
            }
        });
        
        // 等待执行完成或取消
        tokio::select! {
            result = handle => {
                // 取消超时处理
                timeout_handle.abort();
                
                // 返回执行结果
                match result {
                    Ok(Ok(())) => Ok(()),
                    Ok(Err(e)) => Err(e),
                    Err(e) => Err(ExecutionError::InternalError(format!("任务执行中断: {}", e))),
                }
            },
            _ = timeout_handle => {
                // 任务已超时，已被超时处理程序处理
                Err(ExecutionError::TaskTimedOut(params.task_id))
            }
        }
    }
    
    async fn get_task_status(&self, task_id: &str) -> Result<TaskStatus, ExecutionError> {
        let statuses = self.task_statuses.read().await;
        
        statuses.get(task_id).cloned().ok_or_else(|| {
            ExecutionError::TaskNotFound(format!("任务不存在: {}", task_id))
        })
    }
    
    async fn cancel_task(&self, task_id: &str) -> Result<(), ExecutionError> {
        // 获取任务状态
        let status = self.get_task_status(task_id).await?;
        
        // 只能取消正在运行的任务
        if status.state != TaskState::Running {
            return Err(ExecutionError::ExecutionFailed(
                format!("无法取消非运行状态的任务: {:?}", status.state)
            ));
        }
        
        // 更新任务状态
        self.update_task_status(task_id, TaskState::Cancelled, Some("任务已取消".to_string())).await;
        
        Ok(())
    }
    
    async fn get_task_result(&self, task_id: &str) -> Result<Option<serde_json::Value>, ExecutionError> {
        // 获取任务状态
        let status = self.get_task_status(task_id).await?;
        
        // 只有已完成的任务才有结果
        if status.state != TaskState::Completed {
            return Ok(None);
        }
        
        // 获取任务结果
        let results = self.task_results.read().await;
        
        Ok(results.get(task_id).cloned())
    }
}

/// 系统任务函数基础实现
#[derive(Clone)]
pub struct SystemTaskFunction {
    name: String,
    handler: Arc<dyn Fn(serde_json::Value, TaskContext) -> BoxFuture<'static, Result<serde_json::Value, TaskError>> + Send + Sync>,
    resource_requirements: ResourceRequirements,
}

impl SystemTaskFunction {
    /// 创建新的系统任务函数
    pub fn new<F, Fut>(
        name: &str,
        resource_requirements: ResourceRequirements,
        handler: F,
    ) -> Self
    where
        F: Fn(serde_json::Value, TaskContext) -> Fut + Send + Sync + 'static,
        Fut: Future<Output = Result<serde_json::Value, TaskError>> + Send + 'static,
    {
        Self {
            name: name.to_string(),
            handler: Arc::new(move |input, context| {
                Box::pin(handler(input, context))
            }),
            resource_requirements,
        }
    }
}

#[async_trait]
impl TaskFunction for SystemTaskFunction {
    async fn execute(
        &self,
        input: serde_json::Value,
        context: TaskContext,
    ) -> Result<serde_json::Value, TaskError> {
        // 执行处理程序
        (self.handler)(input, context).await
    }
    
    async fn cancel(&self, _context: TaskContext) -> Result<(), TaskError> {
        // 系统任务通过上下文中的取消标志处理取消
        Ok(())
    }
    
    fn name(&self) -> &str {
        &self.name
    }
    
    fn resource_requirements(&self) -> ResourceRequirements {
        self.resource_requirements.clone()
    }
}

/// 创建系统任务函数库
pub fn create_system_task_library() -> Vec<Arc<dyn TaskFunction>> {
    let mut functions: Vec<Arc<dyn TaskFunction>> = Vec::new();
    
    // 延迟任务
    functions.push(Arc::new(SystemTaskFunction::new(
        "delay",
        ResourceRequirements {
            min_cpu: 0.1,
            min_memory: 5.0,
            min_storage: 1.0,
            preferred_cpu: Some(0.1),
            preferred_memory: Some(10.0),
            preferred_storage: Some(1.0),
            preferred_location: None,
            elastic: true,
        },
        |input, context| async move {
            // 解析延迟时间
            let delay_ms: u64 = if let Ok(delay) = context.get_parameter("delay_ms") {
                delay
            } else if let Ok(delay_str) = context.get_parameter::<String>("delay") {
                // 尝试解析持续时间字符串（例如 "5s", "10ms"）
                parse_duration(&delay_str)
                    .map_err(|_| TaskError::InvalidInput(format!("无效的延迟格式: {}", delay_str)))?
                    .as_millis() as u64
            } else {
                return Err(TaskError::MissingInput("缺少 delay 或 delay_ms 参数".to_string()));
            };
            
            // 创建取消监听器
            let cancelled = context.cancelled.clone();
            
            // 每200ms检查一次取消状态
            let mut elapsed: u64 = 0;
            while elapsed < delay_ms {
                if cancelled.load(Ordering::Relaxed) {
                    return Err(TaskError::Cancelled);
                }
                
                let step = std::cmp::min(200, delay_ms - elapsed);
                tokio::time::sleep(Duration::from_millis(step)).await;
                elapsed += step;
                
                // 更新进度
                let progress = ((elapsed as f64 / delay_ms as f64) * 100.0) as u8;
                context.update_progress(std::cmp::min(progress, 100));
            }
            
            Ok(serde_json::json!({
                "delayed_ms": delay_ms,
                "completed_at": Utc::now().to_rfc3339()
            }))
        }
    )));
    
    // HTTP请求任务
    functions.push(Arc::new(SystemTaskFunction::new(
        "http",
        ResourceRequirements {
            min_cpu: 0.5,
            min_memory: 50.0,
            min_storage: 10.0,
            preferred_cpu: Some(1.0),
            preferred_memory: Some(100.0),
            preferred_storage: Some(20.0),
            preferred_location: None,
            elastic: true,
        },
        |input, context| async move {
            // 解析HTTP请求参数
            let url: String = context.get_parameter("url")?;
            let method: String = context.get_parameter("method").unwrap_or_else(|_| "GET".to_string());
            let headers: Option<HashMap<String, String>> = context.get_optional_parameter("headers")?;
            let body: Option<serde_json::Value> = context.get_optional_parameter("body")?;
            let timeout_ms: u64 = context.get_optional_parameter("timeout_ms")?.unwrap_or(30000);
            
            // 创建HTTP客户端
            let client = reqwest::Client::builder()
                .timeout(Duration::from_millis(timeout_ms))
                .build()
                .map_err(|e| TaskError::InternalError(format!("创建HTTP客户端失败: {}", e)))?;
            
            // 构建请求
            let mut request_builder = match method.to_uppercase().as_str() {
                "GET" => client.get(&url),
                "POST" => client.post(&url),
                "PUT" => client.put(&url),
                "DELETE" => client.delete(&url),
                "PATCH" => client.patch(&url),
                "HEAD" => client.head(&url),
                _ => return Err(TaskError::InvalidInput(format!("不支持的HTTP方法: {}", method))),
            };
            
            // 添加请求头
            if let Some(headers_map) = headers {
                for (key, value) in headers_map {
                    request_builder = request_builder.header(key, value);
                }
            }
            
            // 添加请求体
            if let Some(body_value) = body {
                request_builder = request_builder.json(&body_value);
            }
            
            // 创建取消监听器
            let cancelled = context.cancelled.clone();
            
            // 发送请求并获取响应
            let response = {
                let request = request_builder.build()
                    .map_err(|e| TaskError::ExecutionFailed(format!("构建请求失败: {}", e)))?;
                
                let cancel_token = CancellationToken::new();
                let cancel_guard = cancel_token.clone();
                
                // 监听取消事件
                let cancel_task = tokio::spawn(async move {
                    while !cancelled.load(Ordering::Relaxed) {
                        tokio::time::sleep(Duration::from_millis(100)).await;
                    }
                    cancel_token.cancel();
                });
                
                // 发送请求
                let response = client.execute(request).await
                    .map_err(|e| TaskError::ExecutionFailed(format!("HTTP请求失败: {}", e)))?;
                
                // 取消监听任务
                cancel_task.abort();
                
                response
            };
            
            // 处理响应
            let status = response.status().as_u16();
            let headers = response.headers().clone();
            
            // 解析响应体
            context.update_progress(50);
            
            let body = response.text().await
                .map_err(|e| TaskError::ExecutionFailed(format!("读取响应体失败: {}", e)))?;
            
            context.update_progress(100);
            
            // 构建响应结果
            let mut headers_map = HashMap::new();
            for (key, value) in headers.iter() {
                if let Ok(value_str) = value.to_str() {
                    headers_map.insert(key.as_str().to_string(), value_str.to_string());
                }
            }
            
            // 尝试将响应体解析为JSON
            let body_value = match serde_json::from_str::<serde_json::Value>(&body) {
                Ok(json) => json,
                Err(_) => serde_json::Value::String(body),
            };
            
            Ok(serde_json::json!({
                "status": status,
                "headers": headers_map,
                "body": body_value
            }))
        }
    )));
    
    // 数据转换任务
    functions.push(Arc::new(SystemTaskFunction::new(
        "transform",
        ResourceRequirements {
            min_cpu: 0.5,
            min_memory: 50.0,
            min_storage: 5.0,
            preferred_cpu: Some(1.0),
            preferred_memory: Some(100.0),
            preferred_storage: Some(10.0),
            preferred_location: None,
            elastic: true,
        },
        |input, context| async move {
            // 解析转换参数
            let data: serde_json::Value = context.get_parameter("data")?;
            let transform_spec: serde_json::Value = context.get_parameter("transform")?;
            
            // 根据转换规则处理数据
            let result = apply_transformation(data, transform_spec)
                .map_err(|e| TaskError::ExecutionFailed(format!("数据转换失败: {}", e)))?;
            
            context.update_progress(100);
            
            Ok(result)
        }
    )));
    
    // 条件任务
    functions.push(Arc::new(SystemTaskFunction::new(
        "condition",
        ResourceRequirements {
            min_cpu: 0.2,
            min_memory: 20.0,
            min_storage: 5.0,
            preferred_cpu: Some(0.5),
            preferred_memory: Some(50.0),
            preferred_storage: Some(10.0),
            preferred_location: None,
            elastic: true,
        },
        |input, context| async move {
            // 解析条件参数
            let condition: String = context.get_parameter("condition")?;
            let data: serde_json::Value = context.get_parameter("data")?;
            
            // 评估条件
            let result = evaluate_condition(&condition, &data)
                .map_err(|e| TaskError::ExecutionFailed(format!("条件评估失败: {}", e)))?;
            
            context.update_progress(100);
            
            Ok(serde_json::json!({
                "result": result
            }))
        }
    )));
    
    functions
}

// 辅助函数：解析持续时间字符串
fn parse_duration(s: &str) -> Result<Duration, ()> {
    let s = s.trim();
    
    if s.is_empty() {
        return Err(());
    }
    
    let mut result = Duration::from_secs(0);
    let mut current_number = String::new();
    
    for c in s.chars() {
        if c.is_digit(10) {
            current_number.push(c);
        } else if ['s', 'm', 'h', 'd'].contains(&c) {
            let value = current_number.parse::<u64>().map_err(|_| ())?;
            current_number.clear();
            
            match c {
                's' => result += Duration::from_secs(value),
                'm' => result += Duration::from_secs(value * 60),
                'h' => result += Duration::from_secs(value * 3600),
                'd' => result += Duration::from_secs(value * 86400),
                _ => return Err(()),
            }
        } else if c == 'm' && s.ends_with("ms") {
            let value = current_number.parse::<u64>().map_err(|_| ())?;
            current_number.clear();
            result += Duration::from_millis(value);
            break;
        } else {
            return Err(());
        }
    }
    
    if !current_number.is_empty() {
        let value = current_number
/// 工作流状态管理器
pub struct WorkflowStateManager {
    /// 存储引擎
    storage: Arc<dyn WorkflowStateStorage>,
    
    /// 缓存
    cache: Mutex<LruCache<String, WorkflowState>>,
    
    /// 事件总线
    event_bus: Arc<EventBus>,
    
    /// 指标收集器
    metrics: Arc<dyn MetricsCollector>,
}

impl WorkflowStateManager {
    /// 创建新的工作流状态管理器
    pub fn new(
        storage: Arc<dyn WorkflowStateStorage>,
        event_bus: Arc<EventBus>,
        metrics: Arc<dyn MetricsCollector>,
        cache_size: usize,
    ) -> Self {
        Self {
            storage,
            cache: Mutex::new(LruCache::new(NonZeroUsize::new(cache_size).unwrap())),
            event_bus,
            metrics,
        }
    }
    
    /// 创建新的工作流实例
    pub async fn create_workflow_instance(
        &self,
        workflow_id: &str,
        version: u32,
        input: HashMap<String, serde_json::Value>,
        correlation_id: Option<String>,
        options: WorkflowOptions,
    ) -> Result<String, StateError> {
        // 生成实例ID
        let instance_id = Uuid::new_v4().to_string();
        
        // 创建初始状态
        let state = WorkflowState {
            instance_id: instance_id.clone(),
            workflow_id: workflow_id.to_string(),
            version,
            status: WorkflowStatus::Created,
            input,
            variables: HashMap::new(),
            task_results: HashMap::new(),
            active_tasks: Vec::new(),
            completed_tasks: HashMap::new(),
            failed_tasks: HashMap::new(),
            create_time: Utc::now(),
            start_time: None,
            end_time: None,
            last_updated: Utc::now(),
            correlation_id,
            schedule_options: options,
        };
        
        // 持久化状态
        self.storage.save_workflow_state(&state).await?;
        
        // 添加到缓存
        {
            let mut cache = self.cache.lock().unwrap();
            cache.put(instance_id.clone(), state);
        }
        
        // 发布工作流创建事件
        self.event_bus.publish(WorkflowEvent {
            event_type: WorkflowEventType::WorkflowCreated,
            instance_id: instance_id.clone(),
            workflow_id: workflow_id.to_string(),
            task_id: None,
            timestamp: Utc::now(),
            data: Some(serde_json::json!({
                "version": version,
                "correlation_id": correlation_id,
            })),
        }).await;
        
        // 记录指标
        self.metrics.record_workflow_creation(&instance_id, workflow_id).await;
        
        Ok(instance_id)
    }
    
    /// 获取工作流状态
    pub async fn get_workflow_state(&self, instance_id: &str) -> Result<WorkflowState, StateError> {
        // 先从缓存获取
        {
            let mut cache = self.cache.lock().unwrap();
            if let Some(state) = cache.get(instance_id) {
                return Ok(state.clone());
            }
        }
        
        // 从存储获取
        let state = self.storage.get_workflow_state(instance_id).await?;
        
        // 添加到缓存
        {
            let mut cache = self.cache.lock().unwrap();
            cache.put(instance_id.to_string(), state.clone());
        }
        
        Ok(state)
    }
    
    /// 更新工作流状态
    pub async fn update_workflow_state(&self, state: &WorkflowState) -> Result<(), StateError> {
        // 持久化状态
        self.storage.save_workflow_state(state).await?;
        
        // 更新缓存
        {
            let mut cache = self.cache.lock().unwrap();
            cache.put(state.instance_id.clone(), state.clone());
        }
        
        // 记录指标
        match state.status {
            WorkflowStatus::Running => {
                if state.start_time.is_none() {
                    // 首次进入运行状态，记录启动指标
                    self.metrics.record_workflow_start(&state.instance_id, &state.workflow_id).await;
                }
            },
            WorkflowStatus::Completed => {
                // 记录完成指标
                if let Some(start_time) = state.start_time {
                    if let Some(end_time) = state.end_time {
                        let duration = end_time.signed_duration_since(start_time).num_milliseconds() as u64;
                        self.metrics.record_workflow_completion(
                            &state.instance_id, 
                            &state.workflow_id, 
                            duration, 
                            true,
                        ).await;
                    }
                }
            },
            WorkflowStatus::Failed | WorkflowStatus::Cancelled | WorkflowStatus::TimedOut => {
                // 记录失败指标
                if let Some(start_time) = state.start_time {
                    if let Some(end_time) = state.end_time {
                        let duration = end_time.signed_duration_since(start_time).num_milliseconds() as u64;
                        self.metrics.record_workflow_completion(
                            &state.instance_id, 
                            &state.workflow_id, 
                            duration, 
                            false,
                        ).await;
                    }
                }
            },
            _ => {}
        }
        
        Ok(())
    }
    
    /// 更新工作流状态
    pub async fn update_workflow_status(
        &self,
        instance_id: &str,
        status: WorkflowStatus,
        error: Option<String>,
    ) -> Result<(), StateError> {
        // 获取当前状态
        let mut state = self.get_workflow_state(instance_id).await?;
        
        // 更新状态
        state.status = status;
        state.last_updated = Utc::now();
        
        match status {
            WorkflowStatus::Running => {
                if state.start_time.is_none() {
                    state.start_time = Some(Utc::now());
                }
            },
            WorkflowStatus::Completed | WorkflowStatus::Failed | WorkflowStatus::Cancelled | WorkflowStatus::TimedOut => {
                state.end_time = Some(Utc::now());
                
                // 发布工作流结束事件
                let event_type = match status {
                    WorkflowStatus::Completed => WorkflowEventType::WorkflowCompleted,
                    WorkflowStatus::Failed => WorkflowEventType::WorkflowFailed,
                    WorkflowStatus::Cancelled => WorkflowEventType::WorkflowCancelled,
                    WorkflowStatus::TimedOut => WorkflowEventType::WorkflowTimedOut,
                    _ => unreachable!(),
                };
                
                self.event_bus.publish(WorkflowEvent {
                    event_type,
                    instance_id: instance_id.to_string(),
                    workflow_id: state.workflow_id.clone(),
                    task_id: None,
                    timestamp: Utc::now(),
                    data: error.map(|e| serde_json::json!({ "error": e })),
                }).await;
            },
            _ => {}
        }
        
        // 保存更新后的状态
        self.update_workflow_state(&state).await
    }
    
    /// 记录任务结果
    pub async fn record_task_result(
        &self,
        instance_id: &str,
        task_id: &str,
        result: TaskResult,
    ) -> Result<(), StateError> {
        // 获取当前状态
        let mut state = self.get_workflow_state(instance_id).await?;
        
        // 更新任务结果
        state.task_results.insert(task_id.to_string(), result.clone());
        
        // 移除活动任务
        state.active_tasks.retain(|t| t != task_id);
        
        // 根据结果类型更新任务状态
        match result.status {
            TaskStatus::Completed => {
                state.completed_tasks.insert(task_id.to_string(), Utc::now());
            },
            TaskStatus::Failed => {
                state.failed_tasks.insert(
                    task_id.to_string(),
                    TaskError {
                        code: result.error_code.unwrap_or_else(|| "TASK_FAILED".to_string()),
                        message: result.error_message.unwrap_or_else(|| "任务执行失败".to_string()),
                        details: result.error_details,
                    },
                );
            },
            _ => {}
        }
        
        state.last_updated = Utc::now();
        
        // 保存更新后的状态
        self.update_workflow_state(&state).await
    }
    
    /// 添加活动任务
    pub async fn add_active_task(
        &self,
        instance_id: &str,
        task_id: &str,
    ) -> Result<(), StateError> {
        // 获取当前状态
        let mut state = self.get_workflow_state(instance_id).await?;
        
        // 添加活动任务
        if !state.active_tasks.contains(&task_id.to_string()) {
            state.active_tasks.push(task_id.to_string());
        }
        
        state.last_updated = Utc::now();
        
        // 保存更新后的状态
        self.update_workflow_state(&state).await
    }
    
    /// 设置工作流变量
    pub async fn set_workflow_variable(
        &self,
        instance_id: &str,
        key: &str,
        value: serde_json::Value,
    ) -> Result<(), StateError> {
        // 获取当前状态
        let mut state = self.get_workflow_state(instance_id).await?;
        
        // 设置变量
        state.variables.insert(key.to_string(), value);
        state.last_updated = Utc::now();
        
        // 保存更新后的状态
        self.update_workflow_state(&state).await
    }
    
    /// 获取工作流变量
    pub async fn get_workflow_variable(
        &self,
        instance_id: &str,
        key: &str,
    ) -> Result<Option<serde_json::Value>, StateError> {
        // 获取当前状态
        let state = self.get_workflow_state(instance_id).await?;
        
        // 获取变量
        Ok(state.variables.get(key).cloned())
    }
    
    /// 获取所有未完成的工作流
    pub async fn get_pending_workflows(&self) -> Result<Vec<WorkflowState>, StateError> {
        let states = self.storage.get_workflow_states_by_status(
            &[WorkflowStatus::Created, WorkflowStatus::Running, WorkflowStatus::Suspended],
        ).await?;
        
        // 更新缓存
        {
            let mut cache = self.cache.lock().unwrap();
            for state in &states {
                cache.put(state.instance_id.clone(), state.clone());
            }
        }
        
        Ok(states)
    }
    
    /// 清除工作流状态
    pub async fn purge_workflow_state(&self, instance_id: &str) -> Result<(), StateError> {
        // 从存储中删除
        self.storage.delete_workflow_state(instance_id).await?;
        
        // 从缓存中删除
        {
            let mut cache = self.cache.lock().unwrap();
            cache.pop(instance_id);
        }
        
        Ok(())
    }
}

/// 工作流执行引擎
pub struct WorkflowExecutionEngine {
    /// 工作流注册表
    registry: Arc<WorkflowRegistry>,
    
    /// 状态管理器
    state_manager: Arc<WorkflowStateManager>,
    
    /// 任务执行器
    task_executor: Arc<dyn TaskExecutor>,
    
    /// 事件总线
    event_bus: Arc<EventBus>,
    
    /// 调度器
    scheduler: Arc<Mutex<HashMap<String, CancellationToken>>>,
    
    /// 工作流超时检查器
    timeout_checker: Arc<Mutex<HashMap<String, CancellationToken>>>,
    
    /// 工作流恢复检查器
    recovery_checker: Arc<tokio::sync::Mutex<HashSet<String>>>,
    
    /// 任务调度信号量
    concurrency_limit: Arc<Semaphore>,
    
    /// 运行状态标记
    running: Arc<AtomicBool>,
    
    /// 日志记录器
    logger: Logger,
}

impl WorkflowExecutionEngine {
    /// 创建新的工作流执行引擎
    pub fn new(
        registry: Arc<WorkflowRegistry>,
        state_manager: Arc<WorkflowStateManager>,
        task_executor: Arc<dyn TaskExecutor>,
        event_bus: Arc<EventBus>,
        concurrency: usize,
        logger: Logger,
    ) -> Self {
        Self {
            registry,
            state_manager,
            task_executor,
            event_bus,
            scheduler: Arc::new(Mutex::new(HashMap::new())),
            timeout_checker: Arc::new(Mutex::new(HashMap::new())),
            recovery_checker: Arc::new(tokio::sync::Mutex::new(HashSet::new())),
            concurrency_limit: Arc::new(Semaphore::new(concurrency)),
            running: Arc::new(AtomicBool::new(false)),
            logger,
        }
    }
    
    /// 启动工作流执行引擎
    pub async fn start(&self) -> Result<(), EngineError> {
        // 避免重复启动
        if self.running.swap(true, Ordering::Relaxed) {
            return Err(EngineError::AlreadyRunning);
        }
        
        info!(self.logger, "启动工作流执行引擎");
        
        // 恢复未完成的工作流
        self.recover_pending_workflows().await?;
        
        // 启动定期恢复检查
        let recovery_checker = self.recovery_checker.clone();
        let state_manager = self.state_manager.clone();
        let engine = self.clone();
        let running = self.running.clone();
        let logger = self.logger.clone();
        
        tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(60));
            
            while running.load(Ordering::Relaxed) {
                interval.tick().await;
                
                // 查找未完成的工作流
                match state_manager.get_pending_workflows().await {
                    Ok(workflows) => {
                        for workflow in workflows {
                            let instance_id = workflow.instance_id.clone();
                            
                            // 检查是否已经在恢复中
                            let mut checker = recovery_checker.lock().await;
                            if !checker.contains(&instance_id) {
                                // 标记为恢复中
                                checker.insert(instance_id.clone());
                                
                                // 恢复工作流
                                let engine_clone = engine.clone();
                                let recovery_checker_clone = recovery_checker.clone();
                                let instance_id_clone = instance_id.clone();
                                let logger_clone = logger.clone();
                                
                                tokio::spawn(async move {
                                    match engine_clone.resume_workflow(&instance_id_clone).await {
                                        Ok(_) => {
                                            debug!(logger_clone, "已恢复工作流"; "instance_id" => &instance_id_clone);
                                        },
                                        Err(e) => {
                                            error!(logger_clone, "恢复工作流失败"; 
                                                "instance_id" => &instance_id_clone, 
                                                "error" => %e);
                                        }
                                    }
                                    
                                    // 恢复完成后移除标记
                                    let mut checker = recovery_checker_clone.lock().await;
                                    checker.remove(&instance_id_clone);
                                });
                            }
                        }
                    },
                    Err(e) => {
                        error!(logger, "获取未完成工作流失败"; "error" => %e);
                    }
                }
            }
        });
        
        Ok(())
    }
    
    /// 停止工作流执行引擎
    pub async fn stop(&self) {
        info!(self.logger, "停止工作流执行引擎");
        
        // 标记为已停止
        self.running.store(false, Ordering::Relaxed);
        
        // 取消所有正在执行的工作流
        {
            let schedulers = self.scheduler.lock().unwrap();
            for token in schedulers.values() {
                token.cancel();
            }
        }
        
        // 取消所有超时检查器
        {
            let timeout_checkers = self.timeout_checker.lock().unwrap();
            for token in timeout_checkers.values() {
                token.cancel();
            }
        }
    }
    
    /// 启动工作流
    pub async fn start_workflow(
        &self,
        workflow_id: &str,
        version: Option<u32>,
        input: HashMap<String, serde_json::Value>,
        correlation_id: Option<String>,
        options: Option<WorkflowOptions>,
    ) -> Result<String, EngineError> {
        // 获取工作流定义
        let workflow = self.registry.get_workflow(workflow_id, version).ok_or_else(|| {
            EngineError::WorkflowNotFound(workflow_id.to_string())
        })?;
        
        // 使用提供的选项或默认选项
        let options = options.unwrap_or_else(|| WorkflowOptions {
            timeout_ms: 3600000, // 默认1小时超时
            retry_policy: None,
            task_priorities: HashMap::new(),
        });
        
        // 创建工作流实例
        let instance_id = self.state_manager.create_workflow_instance(
            workflow_id,
            workflow.version,
            input,
            correlation_id,
            options,
        ).await?;
        
        // 异步启动工作流
        let engine = self.clone();
        let instance_id_clone = instance_id.clone();
        
        tokio::spawn(async move {
            if let Err(e) = engine.execute_workflow(&instance_id_clone).await {
                error!(engine.logger, "执行工作流失败"; 
                    "instance_id" => &instance_id_clone, 
                    "error" => %e);
            }
        });
        
        Ok(instance_id)
    }
    
    /// 恢复未完成的工作流
    async fn recover_pending_workflows(&self) -> Result<(), EngineError> {
        info!(self.logger, "恢复未完成的工作流");
        
        // 获取所有未完成的工作流
        let workflows = self.state_manager.get_pending_workflows().await.map_err(|e| {
            EngineError::StateError(format!("获取未完成工作流失败: {}", e))
        })?;
        
        info!(self.logger, "找到未完成的工作流"; "count" => workflows.len());
        
        // 恢复每个工作流
        for workflow in workflows {
            let instance_id = workflow.instance_id.clone();
            
            // 检查是否已经在恢复中
            let mut checker = self.recovery_checker.lock().await;
            if !checker.contains(&instance_id) {
                // 标记为恢复中
                checker.insert(instance_id.clone());
                
                // 恢复工作流
                let engine = self.clone();
                let recovery_checker = self.recovery_checker.clone();
                let instance_id_clone = instance_id.clone();
                let logger = self.logger.clone();
                
                tokio::spawn(async move {
                    match engine.resume_workflow(&instance_id_clone).await {
                        Ok(_) => {
                            debug!(logger, "已恢复工作流"; "instance_id" => &instance_id_clone);
                        },
                        Err(e) => {
                            error!(logger, "恢复工作流失败"; 
                                "instance_id" => &instance_id_clone, 
                                "error" => %e);
                        }
                    }
                    
                    // 恢复完成后移除标记
                    let mut checker = recovery_checker.lock().await;
                    checker.remove(&instance_id_clone);
                });
            }
        }
        
        Ok(())
    }
    
    /// 恢复工作流
    async fn resume_workflow(&self, instance_id: &str) -> Result<(), EngineError> {
        debug!(self.logger, "恢复工作流"; "instance_id" => instance_id);
        
        // 获取工作流状态
        let state = self.state_manager.get_workflow_state(instance_id).await.map_err(|e| {
            EngineError::StateError(format!("获取工作流状态失败: {}", e))
        })?;
        
        // 检查工作流状态是否是终止状态
        if state.is_terminal_state() {
            debug!(self.logger, "工作流已处于终止状态，无需恢复"; 
                "instance_id" => instance_id, 
                "status" => ?state.status);
            return Ok(());
        }
        
        // 开始执行工作流
        self.execute_workflow(instance_id).await
    }
    
    /// 执行工作流
    async fn execute_workflow(&self, instance_id: &str) -> Result<(), EngineError> {
        debug!(self.logger, "执行工作流"; "instance_id" => instance_id);
        
        // 获取工作流状态
        let state = self.state_manager.get_workflow_state(instance_id).await.map_err(|e| {
            EngineError::StateError(format!("获取工作流状态失败: {}", e))
        })?;
        
        // 获取工作流定义
        let workflow = self.registry.get_workflow(&state.workflow_id, Some(state.version)).ok_or_else(|| {
            EngineError::WorkflowNotFound(state.workflow_id.clone())
        })?;
        
        // 更新工作流状态为运行中
        self.state_manager.update_workflow_status(
            instance_id,
            WorkflowStatus::Running,
            None,
        ).await.map_err(|e| {
            EngineError::StateError(format!("更新工作流状态失败: {}", e))
        })?;
        
        // 创建取消标记
        let cancellation_token = CancellationToken::new();
        let token_clone = cancellation_token.clone();
        
        // 注册取消标记
        {
            let mut schedulers = self.scheduler.lock().unwrap();
            schedulers.insert(instance_id.to_string(), token_clone);
        }
        
        // 设置工作流超时
        let timeout_token = self.setup_workflow_timeout(instance_id, state.schedule_options.timeout_ms).await?;
        
        // 构建任务依赖图
        let task_graph = build_task_graph(&workflow.tasks);
        
        // 获取可执行任务
        let mut executable_tasks = get_executable_tasks(
            &task_graph,
            &state.completed_tasks,
            &state.failed_tasks,
        );
        
        // 使用特定上下文执行工作流
        let engine = self.clone();
        let instance_id = instance_id.to_string();
        
        tokio::spawn(async move {
            // 创建工作流上下文
            let workflow_ctx = WorkflowExecutionContext {
                instance_id: instance_id.clone(),
                cancellation_token: cancellation_token.clone(),
            };
            
            // 执行任务，直到没有可执行任务或取消
            while !executable_tasks.is_empty() {
                // 检查是否已取消
                if cancellation_token.is_cancelled() {
                    debug!(engine.logger, "工作流已取消"; "instance_id" => &instance_id);
                    
                    // 更新工作流状态为已取消
                    if let Err(e) = engine.state_manager.update_workflow_status(
                        &instance_id,
                        WorkflowStatus::Cancelled,
                        Some("工作流已取消".to_string()),
                    ).await {
                        error!(engine.logger, "更新工作流状态失败"; 
                            "instance_id" => &instance_id, 
                            "error" => %e);
                    }
                    
                    // 清理
                    engine.cleanup_workflow(&instance_id).await;
                    return;
                }
                
                // 并行执行可执行任务
                let mut join_handles = Vec::new();
                
                for task_id in &executable_tasks {
                    // 获取任务
                    let task = match workflow.tasks.get(task_id) {
                        Some(t) => t,
                        None => {
                            error!(engine.logger, "任务不存在"; 
                                "instance_id" => &instance_id, 
                                "task_id" => task_id);
                            continue;
                        }
                    };
                    
                    // 添加到活动任务中
                    if let Err(e) = engine.state_manager.add_active_task(&instance_id, task_id).await {
                        error!(engine.logger, "添加活动任务失败"; 
                            "instance_id" => &instance_id, 
                            "task_id" => task_id, 
                            "error" => %e);
                        continue;
                    }
                    
                    // 发布任务开始事件
                    let _ = engine.event_bus.publish(WorkflowEvent {
                        event_type: WorkflowEventType::TaskStarted,
                        instance_id: instance_id.clone(),
                        workflow_id: workflow.id.clone(),
                        task_id: Some(task_id.clone()),
                        timestamp: Utc::now(),
                        data: None,
                    }).await;
                    
                    // 异步执行任务
                    let engine_clone = engine.clone();
                    let instance_id_clone = instance_id.clone();
                    let task_id_clone = task_id.clone();
                    let workflow_ctx_clone = workflow_ctx.clone();
                    let semaphore = engine.concurrency_limit.clone();
                    
                    let handle = tokio::spawn(async move {
                        // 获取信号量许可
                        let _permit = match semaphore.acquire().await {
                            Ok(permit) => permit,
                            Err(_) => {
                                error!(engine_clone.logger, "获取信号量许可失败"; 
                                    "instance_id" => &instance_id_clone, 
                                    "task_id" => &task_id_clone);
                                return;
                            }
                        };
                        
                        // 执行任务
                        let result = engine_clone.execute_task(&instance_id_clone, &task_id_clone, &workflow_ctx_clone).await;
                        
                        // 处理结果
                        match result {
                            Ok(_) => {
                                debug!(engine_clone.logger, "任务执行成功"; 
                                    "instance_id" => &instance_id_clone, 
                                    "task_id" => &task_id_clone);
                            },
                            Err(e) => {
                                error!(engine_clone.logger, "任务执行失败"; 
                                    "instance_id" => &instance_id_clone, 
                                    "task_id" => &task_id_clone, 
                                    "error" => %e);
                            }
                        }
                    });
                    
                    join_handles.push(handle);
                }
                
                // 等待所有任务完成
                for handle in join_handles {
                    let _ = handle.await;
                }
                
                // 获取更新后的工作流状态
                let state = match engine.state_manager.get_workflow_state(&instance_id).await {
                    Ok(s) => s,
                    Err(e) => {
                        error!(engine.logger, "获取工作流状态失败"; 
                            "instance_id" => &instance_id, 
                            "error" => %e);
                        break;
                    }
                };
                
                // 检查工作流是否已完成或失败
                if state.is_terminal_state() {
                    debug!(engine.logger, "工作流已终止"; 
                        "instance_id" => &instance_id, 
                        "status" => ?state.status);
                    
                    // 清理
                    engine.cleanup_workflow(&instance_id).await;
                    return;
                }
                
                // 更新可执行任务
                executable_tasks = get_executable_tasks(
                    &task_graph,
                    &state.completed_tasks,
                    &state.failed_tasks,
);
}
}
// 检查工作流状态
let state = match self.state_manager.get_workflow_state(&instance_id).await {
Ok(s) => s,
Err(e) => {
error!(self.logger, "获取工作流状态失败";
"instance_id" => &instance_id,
"error" => %e);
return Err(EngineError::StateError(format!("获取工作流状态失败: {}", e)));
}
};
// 确定工作流的最终状态
if !state.is_terminal_state() {
let final_status = if state.failed_tasks.is_empty() {
WorkflowStatus::Completed
} else {
WorkflowStatus::Failed
};
// 更新工作流状态
if let Err(e) = self.state_manager.update_workflow_status(
&instance_id,
final_status,
None,
).await {
error!(self.logger, "更新工作流状态失败";
"instance_id" => &instance_id,
"error" => %e);
}
}
// 清理工作流资源
self.cleanup_workflow(&instance_id).await;
Ok(())
}
/// 执行单个任务
async fn execute_task(
&self,
instance_id: &str,
task_id: &str,
workflow_ctx: &WorkflowExecutionContext,
) -> Result<TaskResult, EngineError> {
debug!(self.logger, "执行任务"; "instance_id" => instance_id, "task_id" => task_id);
// 获取工作流状态
let state = self.state_manager.get_workflow_state(instance_id).await.map_err(|e| {
EngineError::StateError(format!("获取工作流状态失败: {}", e))
})?;
// 获取工作流定义
let workflow = self.registry.get_workflow(&state.workflow_id, Some(state.version)).ok_or_else(|| {
EngineError::WorkflowNotFound(state.workflow_id.clone())
})?;
// 获取任务定义
let task = workflow.tasks.get(task_id).ok_or_else(|| {
EngineError::TaskNotFound(task_id.to_string())
})?;
// 准备任务上下文
let task_ctx = TaskContext {
task_id: task_id.to_string(),
workflow_id: state.workflow_id.clone(),
instance_id: instance_id.to_string(),
node_id: "".to_string(), // 当前未使用
start_time: Utc::now(),
timeout: Duration::from_millis(task.timeout.unwrap_or(60000)),
parameters: task.parameters.clone(),
workflow_variables: state.variables.clone(),
cancelled: Arc::new(AtomicBool::new(false)),
progress_callback: None,
};
// 创建进度回调
let event_bus = self.event_bus.clone();
let instance_id_clone = instance_id.to_string();
let workflow_id_clone = state.workflow_id.clone();
let task_id_clone = task_id.to_string();
let progress_callback = Box::new(move |progress: f64, message: Option<String>| {
let event = WorkflowEvent {
event_type: WorkflowEventType::TaskProgress,
instance_id: instance_id_clone.clone(),
workflow_id: workflow_id_clone.clone(),
task_id: Some(task_id_clone.clone()),
timestamp: Utc::now(),
data: Some(serde_json::json!({
"progress": progress,
"message": message,
})),
};
let event_bus = event_bus.clone();
tokio::spawn(async move {
let _ = event_bus.publish(event).await;
});
});
// 设置进度回调
let mut task_ctx_with_callback = task_ctx.clone();
task_ctx_with_callback.progress_callback = Some(progress_callback);
// 设置取消监听
let cancelled = task_ctx.cancelled.clone();
let cancellation_token = workflow_ctx.cancellation_token.clone();
tokio::spawn(async move {
if cancellation_token.cancelled().await {
cancelled.store(true, Ordering::SeqCst);
}
});
// 执行任务
let task_start = Instant::now();
let result = match self.task_executor.execute_task(&task.task_type, task_ctx_with_callback).await {
Ok(result) => {
// 成功完成
let execution_time = task_start.elapsed().as_millis() as u64;
TaskResult {
task_id: task_id.to_string(),
status: TaskStatus::Completed,
output: result,
execution_time,
error_code: None,
error_message: None,
error_details: None,
}
},
Err(e) => {
// 执行失败
let execution_time = task_start.elapsed().as_millis() as u64;
let error_message = e.to_string();
error!(self.logger, "任务执行失败";
"instance_id" => instance_id,
"task_id" => task_id,
"error" => %error_message);
TaskResult {
task_id: task_id.to_string(),
status: TaskStatus::Failed,
output: serde_json::Value::Null,
execution_time,
error_code: Some("EXECUTION_FAILED".to_string()),
error_message: Some(error_message),
error_details: None,
}
}
};
// 发布任务完成事件
let event_type = match result.status {
TaskStatus::Completed => WorkflowEventType::TaskCompleted,
TaskStatus::Failed => WorkflowEventType::TaskFailed,
_ => WorkflowEventType::TaskUpdated,
};
let event_data = match result.status {
TaskStatus::Completed => {
serde_json::json!({
"execution_time": result.execution_time,
"output": result.output,
})
},
TaskStatus::Failed => {
serde_json::json!({
"execution_time": result.execution_time,
"error_code": result.error_code,
"error_message": result.error_message,
})
},
_ => serde_json::Value::Null,
};
let _ = self.event_bus.publish(WorkflowEvent {
event_type,
instance_id: instance_id.to_string(),
workflow_id: state.workflow_id.clone(),
task_id: Some(task_id.to_string()),
timestamp: Utc::now(),
data: Some(event_data),
}).await;
// 记录任务结果
if let Err(e) = self.state_manager.record_task_result(instance_id, task_id, result.clone()).await {
error!(self.logger, "记录任务结果失败";
"instance_id" => instance_id,
"task_id" => task_id,
"error" => %e);
}
// 检查是否存在后处理操作
if result.status == TaskStatus::Completed {
if let Some(post_actions) = task.post_actions.as_ref() {
for action in post_actions {
match action {
PostAction::SetVariable { variable, value_expression } => {
// 从输出中提取变量值
if let Some(value) = extract_value_from_expression(&result.output, value_expression) {
if let Err(e) = self.state_manager.set_workflow_variable(
instance_id,
variable,
value,
).await {
error!(self.logger, "设置工作流变量失败";
"instance_id" => instance_id,
"variable" => variable,
"error" => %e);
}
}
},
// 其他后处理操作...
}
}
}
}
Ok(result)
}
/// 设置工作流超时
async fn setup_workflow_timeout(
&self,
instance_id: &str,
timeout_ms: u64,
) -> Result<CancellationToken, EngineError> {
let timeout_token = CancellationToken::new();
let token_clone = timeout_token.clone();
// 注册超时令牌
{
let mut timeout_checkers = self.timeout_checker.lock().unwrap();
timeout_checkers.insert(instance_id.to_string(), token_clone.clone());
}
// 设置工作流超时
if timeout_ms > 0 {
let instance_id = instance_id.to_string();
let state_manager = self.state_manager.clone();
let scheduler = self.scheduler.clone();
let timeout_checker = self.timeout_checker.clone();
let logger = self.logger.clone();
tokio::spawn(async move {
let duration = Duration::from_millis(timeout_ms);
tokio::select! {
_ = tokio::time::sleep(duration) => {
// 超时触发
info!(logger, "工作流执行超时"; "instance_id" => &instance_id, "timeout_ms" => timeout_ms);
// 更新工作流状态
if let Err(e) = state_manager.update_workflow_status(
&instance_id,
WorkflowStatus::TimedOut,
Some(format!("工作流执行超时 ({} ms)", timeout_ms)),
).await {
error!(logger, "更新工作流状态失败";
"instance_id" => &instance_id,
"error" => %e);
}
// 取消工作流执行
{
let schedulers = scheduler.lock().unwrap();
if let Some(token) = schedulers.get(&instance_id) {
token.cancel();
}
}
}
_ = token_clone.cancelled() => {
// 超时检查被取消
debug!(logger, "取消工作流超时检查"; "instance_id" => &instance_id);
}
}
// 清理超时检查器
let mut timeout_checkers = timeout_checker.lock().unwrap();
timeout_checkers.remove(&instance_id);
});
}
Ok(timeout_token)
}
/// 清理工作流资源
async fn cleanup_workflow(&self, instance_id: &str) {
debug!(self.logger, "清理工作流资源"; "instance_id" => instance_id);
// 移除调度器
{
let mut schedulers = self.scheduler.lock().unwrap();
schedulers.remove(instance_id);
}
// 移除超时检查器
{
let mut timeout_checkers = self.timeout_checker.lock().unwrap();
if let Some(token) = timeout_checkers.remove(instance_id) {
token.cancel();
}
}
}
/// 取消工作流
pub async fn cancel_workflow(&self, instance_id: &str) -> Result<(), EngineError> {
info!(self.logger, "取消工作流"; "instance_id" => instance_id);
// 获取取消令牌
let token = {
let schedulers = self.scheduler.lock().unwrap();
schedulers.get(instance_id).cloned()
};
// 如果找到令牌，取消执行
if let Some(token) = token {
token.cancel();
// 更新工作流状态
self.state_manager.update_workflow_status(
instance_id,
WorkflowStatus::Cancelled,
Some("工作流已手动取消".to_string()),
).await.map_err(|e| {
EngineError::StateError(format!("更新工作流状态失败: {}", e))
})?;
// 清理资源
self.cleanup_workflow(instance_id).await;
Ok(())
} else {
Err(EngineError::WorkflowNotRunning(instance_id.to_string()))
}
}
/// 获取工作流状态
pub async fn get_workflow_status(&self, instance_id: &str) -> Result<WorkflowStatus, EngineError> {
let state = self.state_manager.get_workflow_state(instance_id).await.map_err(|e| {
EngineError::StateError(format!("获取工作流状态失败: {}", e))
})?;
Ok(state.status)
}
/// 获取工作流详细状态
pub async fn get_workflow_details(&self, instance_id: &str) -> Result<WorkflowExecutionDetails, EngineError> {
let state = self.state_manager.get_workflow_state(instance_id).await.map_err(|e| {
EngineError::StateError(format!("获取工作流状态失败: {}", e))
})?;
// 获取工作流定义
let workflow = self.registry.get_workflow(&state.workflow_id, Some(state.version)).ok_or_else(|| {
EngineError::WorkflowNotFound(state.workflow_id.clone())
})?;
// 构建任务状态
let mut task_states = HashMap::new();
for (task_id, task) in &workflow.tasks {
let status = if state.completed_tasks.contains_key(task_id) {
TaskStatus::Completed
} else if state.failed_tasks.contains_key(task_id) {
TaskStatus::Failed
} else if state.active_tasks.contains(task_id) {
TaskStatus::Running
} else {
TaskStatus::Pending
};
let task_result = state.task_results.get(task_id).cloned();
task_states.insert(task_id.clone(), TaskExecutionState {
task_id: task_id.clone(),
task_name: task.name.clone(),
task_type: task.task_type.clone(),
status,
start_time: None, // 需要记录任务开始时间
end_time: match status {
TaskStatus::Completed => state.completed_tasks.get(task_id).cloned(),
TaskStatus::Failed => Some(state.last_updated),
_ => None,
},
result: task_result,
error: state.failed_tasks.get(task_id).cloned(),
});
}
Ok(WorkflowExecutionDetails {
instance_id: state.instance_id,
workflow_id: state.workflow_id,
version: state.version,
status: state.status,
create_time: state.create_time,
start_time: state.start_time,
end_time: state.end_time,
last_updated: state.last_updated,
tasks: task_states,
variables: state.variables,
correlation_id: state.correlation_id,
})
}
}
/// 构建任务依赖图
fn build_task_graph(tasks: &HashMap<String, TaskDefinition>) -> HashMap<String, Vec<String>> {
let mut graph = HashMap::new();
for (task_id, task) in tasks {
let mut dependencies = Vec::new();
// 添加显式依赖
if let Some(deps) = &task.depends_on {
dependencies.extend(deps.iter().cloned());
}
graph.insert(task_id.clone(), dependencies);
}
graph
}
/// 获取可执行任务
fn get_executable_tasks(
graph: &HashMap<String, Vec<String>>,
completed_tasks: &HashMap<String, DateTime<Utc>>,
failed_tasks: &HashMap<String, TaskError>,
) -> Vec<String> {
let mut executable = Vec::new();
'outer: for (task_id, dependencies) in graph {
// 跳过已完成或失败的任务
if completed_tasks.contains_key(task_id) || failed_tasks.contains_key(task_id) {
continue;
}
// 检查所有依赖是否已完成
for dep in dependencies {
if !completed_tasks.contains_key(dep) {
continue 'outer;
}
}
// 所有依赖都已完成，可以执行此任务
executable.push(task_id.clone());
}
executable
}
/// 提取变量值
fn extract_value_from_expression(
data: &serde_json::Value,
expression: &str,
) -> Option<serde_json::Value> {
// 简单的json路径解析
let parts: Vec<&str> = expression.split('.').collect();
let mut current = data;
for part in parts {
if let Some(value) = current.get(part) {
current = value;
} else {
return None;
}
}
Some(current.clone())
}
/// 工作流执行上下文
#[derive(Clone)]
struct WorkflowExecutionContext {
/// 实例ID
instance_id: String,
/// 取消令牌
cancellation_token: CancellationToken,
}
/// 工作流执行详情
#[derive(Debug, Clone)]
pub struct WorkflowExecutionDetails {
/// 实例ID
pub instance_id: String,
/// 工作流ID
pub workflow_id: String,
/// 版本
pub version: u32,
/// 状态
pub status: WorkflowStatus,
/// 创建时间
pub create_time: DateTime<Utc>,
/// 开始时间
pub start_time: Option<DateTime<Utc>>,
/// 结束时间
pub end_time: Option<DateTime<Utc>>,
/// 最后更新时间
pub last_updated: DateTime<Utc>,
/// 任务状态
pub tasks: HashMap<String, TaskExecutionState>,
/// 变量
pub variables: HashMap<String, serde_json::Value>,
/// 关联ID
pub correlation_id: Option<String>,
}
/// 任务执行状态
#[derive(Debug, Clone)]
pub struct TaskExecutionState {
/// 任务ID
pub task_id: String,
/// 任务名称
pub task_name: String,
/// 任务类型
pub task_type: String,
/// 状态
pub status: TaskStatus,
/// 开始时间
pub start_time: Option<DateTime<Utc>>,
/// 结束时间
pub end_time: Option<DateTime<Utc>>,
/// 结果
pub result: Option<TaskResult>,
/// 错误
pub error: Option<TaskError>,

/// 工作流错误处理策略
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ErrorHandlingStrategy {
    /// 失败立即终止工作流
    FailFast,
    
    /// 继续执行不依赖失败任务的任务
    ContinueOnError,
    
    /// 重试指定次数
    Retry { 
        /// 最大重试次数
        max_attempts: u32, 
        /// 重试间隔(毫秒)
        backoff_ms: u64,
        /// 指数退避因子
        backoff_factor: f64,
        /// 最大退避时间(毫秒)
        max_backoff_ms: u64,
    },
    
    /// 回滚到检查点
    RollbackToCheckpoint { 
        /// 检查点ID
        checkpoint_id: String 
    },
    
    /// 运行补偿工作流
    RunCompensation {
        /// 补偿工作流ID
        workflow_id: String,
    },
}

/// 错误处理器
struct ErrorHandler {
    /// 日志记录器
    logger: Logger,
    
    /// 工作流状态管理器
    state_manager: Arc<dyn WorkflowStateManager>,
    
    /// 工作流注册表
    registry: Arc<WorkflowRegistry>,
    
    /// 事件总线
    event_bus: Arc<dyn EventBus>,
    
    /// 工作流引擎
    engine: Weak<WorkflowExecutionEngine>,
}

impl ErrorHandler {
    /// 创建错误处理器
    pub fn new(
        logger: Logger,
        state_manager: Arc<dyn WorkflowStateManager>,
        registry: Arc<WorkflowRegistry>,
        event_bus: Arc<dyn EventBus>,
        engine: Weak<WorkflowExecutionEngine>,
    ) -> Self {
        Self {
            logger,
            state_manager,
            registry,
            event_bus,
            engine,
        }
    }
    
    /// 处理任务错误
    pub async fn handle_task_error(
        &self,
        instance_id: &str,
        task_id: &str,
        error: &TaskError,
    ) -> Result<ErrorHandlingAction, EngineError> {
        // 获取工作流状态
        let state = self.state_manager.get_workflow_state(instance_id).await
            .map_err(|e| EngineError::StateError(format!("获取工作流状态失败: {}", e)))?;
        
        // 获取工作流定义
        let workflow = self.registry.get_workflow(&state.workflow_id, Some(state.version))
            .ok_or_else(|| EngineError::WorkflowNotFound(state.workflow_id.clone()))?;
        
        // 获取任务定义
        let task = workflow.tasks.get(task_id)
            .ok_or_else(|| EngineError::TaskNotFound(task_id.to_string()))?;
        
        // 获取错误处理策略
        let strategy = task.error_strategy.clone().unwrap_or(
            workflow.default_error_strategy.clone().unwrap_or(ErrorHandlingStrategy::FailFast)
        );
        
        // 根据策略处理错误
        match strategy {
            ErrorHandlingStrategy::FailFast => {
                // 标记工作流为失败
                self.state_manager.update_workflow_status(
                    instance_id,
                    WorkflowStatus::Failed,
                    Some(format!("任务失败: {}", error.message)),
                ).await.map_err(|e| EngineError::StateError(format!("更新工作流状态失败: {}", e)))?;
                
                // 发布工作流失败事件
                let _ = self.event_bus.publish(WorkflowEvent {
                    event_type: WorkflowEventType::WorkflowFailed,
                    instance_id: instance_id.to_string(),
                    workflow_id: state.workflow_id.clone(),
                    task_id: Some(task_id.to_string()),
                    timestamp: Utc::now(),
                    data: Some(serde_json::json!({
                        "error_code": error.code,
                        "error_message": error.message,
                    })),
                }).await;
                
                Ok(ErrorHandlingAction::TerminateWorkflow)
            },
            
            ErrorHandlingStrategy::ContinueOnError => {
                // 记录错误但继续执行
                info!(self.logger, "任务失败但继续执行工作流"; 
                    "instance_id" => instance_id, 
                    "task_id" => task_id, 
                    "error" => %error.message);
                
                Ok(ErrorHandlingAction::ContinueWorkflow)
            },
            
            ErrorHandlingStrategy::Retry { max_attempts, backoff_ms, backoff_factor, max_backoff_ms } => {
                // 获取当前重试次数
                let current_attempts = state.task_retry_counts.get(task_id).copied().unwrap_or(0);
                
                if current_attempts < max_attempts {
                    // 计算退避时间
                    let backoff = calculate_backoff(
                        current_attempts,
                        backoff_ms,
                        backoff_factor,
                        max_backoff_ms,
                    );
                    
                    // 更新重试计数
                    self.state_manager.increment_retry_count(instance_id, task_id).await
                        .map_err(|e| EngineError::StateError(format!("更新重试计数失败: {}", e)))?;
                    
                    info!(self.logger, "重试任务"; 
                        "instance_id" => instance_id, 
                        "task_id" => task_id, 
                        "attempt" => current_attempts + 1, 
                        "max_attempts" => max_attempts,
                        "backoff_ms" => backoff);
                    
                    Ok(ErrorHandlingAction::RetryTask { after_ms: backoff })
                } else {
                    // 达到最大重试次数，标记工作流为失败
                    warn!(self.logger, "任务达到最大重试次数"; 
                        "instance_id" => instance_id, 
                        "task_id" => task_id, 
                        "max_attempts" => max_attempts);
                    
                    self.state_manager.update_workflow_status(
                        instance_id,
                        WorkflowStatus::Failed,
                        Some(format!("任务失败(已重试{}次): {}", max_attempts, error.message)),
                    ).await.map_err(|e| EngineError::StateError(format!("更新工作流状态失败: {}", e)))?;
                    
                    Ok(ErrorHandlingAction::TerminateWorkflow)
                }
            },
            
            ErrorHandlingStrategy::RollbackToCheckpoint { checkpoint_id } => {
                // 获取检查点状态
                if let Some(checkpoint) = state.checkpoints.get(&checkpoint_id) {
                    info!(self.logger, "回滚到检查点"; 
                        "instance_id" => instance_id, 
                        "task_id" => task_id, 
                        "checkpoint_id" => &checkpoint_id);
                    
                    // 回滚工作流状态
                    self.state_manager.rollback_to_checkpoint(instance_id, &checkpoint_id).await
                        .map_err(|e| EngineError::StateError(format!("回滚到检查点失败: {}", e)))?;
                    
                    // 重启工作流执行
                    if let Some(engine) = self.engine.upgrade() {
                        tokio::spawn(async move {
                            if let Err(e) = engine.resume_workflow(instance_id).await {
                                error!(engine.logger, "恢复工作流失败"; 
                                    "instance_id" => instance_id, 
                                    "error" => %e);
                            }
                        });
                    }
                    
                    Ok(ErrorHandlingAction::RestartFromCheckpoint)
                } else {
                    // 检查点不存在，标记工作流为失败
                    error!(self.logger, "检查点不存在"; 
                        "instance_id" => instance_id, 
                        "checkpoint_id" => &checkpoint_id);
                    
                    self.state_manager.update_workflow_status(
                        instance_id,
                        WorkflowStatus::Failed,
                        Some(format!("回滚失败: 检查点 {} 不存在", checkpoint_id)),
                    ).await.map_err(|e| EngineError::StateError(format!("更新工作流状态失败: {}", e)))?;
                    
                    Ok(ErrorHandlingAction::TerminateWorkflow)
                }
            },
            
            ErrorHandlingStrategy::RunCompensation { workflow_id } => {
                // 启动补偿工作流
                info!(self.logger, "启动补偿工作流"; 
                    "instance_id" => instance_id, 
                    "task_id" => task_id, 
                    "compensation_workflow_id" => &workflow_id);
                
                if let Some(engine) = self.engine.upgrade() {
                    // 准备补偿工作流的输入参数
                    let input = serde_json::json!({
                        "instance_id": instance_id,
                        "workflow_id": state.workflow_id,
                        "task_id": task_id,
                        "error": {
                            "code": error.code,
                            "message": error.message,
                            "details": error.details,
                        },
                        "state": {
                            "variables": state.variables,
                        }
                    });
                    
                    // 启动补偿工作流
                    match engine.start_workflow(&workflow_id, None, input.as_object().unwrap().clone(), Default::default()).await {
                        Ok(compensation_instance_id) => {
                            // 记录补偿工作流实例ID
                            if let Err(e) = self.state_manager.set_workflow_variable(
                                instance_id,
                                "compensation_instance_id",
                                serde_json::Value::String(compensation_instance_id),
                            ).await {
                                error!(self.logger, "设置补偿工作流实例ID变量失败"; 
                                    "instance_id" => instance_id, 
                                    "error" => %e);
                            }
                            
                            Ok(ErrorHandlingAction::ContinueWorkflow)
                        },
                        Err(e) => {
                            // 启动补偿工作流失败
                            error!(self.logger, "启动补偿工作流失败"; 
                                "instance_id" => instance_id, 
                                "compensation_workflow_id" => &workflow_id, 
                                "error" => %e);
                            
                            self.state_manager.update_workflow_status(
                                instance_id,
                                WorkflowStatus::Failed,
                                Some(format!("启动补偿工作流失败: {}", e)),
                            ).await.map_err(|e| EngineError::StateError(format!("更新工作流状态失败: {}", e)))?;
                            
                            Ok(ErrorHandlingAction::TerminateWorkflow)
                        }
                    }
                } else {
                    error!(self.logger, "工作流引擎不可用，无法启动补偿工作流"; "instance_id" => instance_id);
                    Ok(ErrorHandlingAction::TerminateWorkflow)
                }
            },
        }
    }
}

/// 错误处理动作
enum ErrorHandlingAction {
    /// 终止工作流
    TerminateWorkflow,
    
    /// 继续执行工作流
    ContinueWorkflow,
    
    /// 重试任务
    RetryTask { after_ms: u64 },
    
    /// 从检查点重启
    RestartFromCheckpoint,
}

/// 计算退避时间
fn calculate_backoff(
    attempt: u32,
    base_ms: u64,
    factor: f64,
    max_ms: u64,
) -> u64 {
    let backoff = base_ms as f64 * factor.powi(attempt as i32);
    backoff.min(max_ms as f64) as u64
}

impl WorkflowExecutionEngine {
    /// 恢复工作流执行
    pub async fn resume_workflow(&self, instance_id: &str) -> Result<(), EngineError> {
        info!(self.logger, "恢复工作流执行"; "instance_id" => instance_id);
        
        // 获取工作流状态
        let state = self.state_manager.get_workflow_state(instance_id).await
            .map_err(|e| EngineError::StateError(format!("获取工作流状态失败: {}", e)))?;
        
        // 检查工作流是否可以恢复
        if state.status != WorkflowStatus::Suspended && state.status != WorkflowStatus::Paused {
            return Err(EngineError::InvalidWorkflowState(format!(
                "工作流状态不是已暂停或已挂起，无法恢复: {:?}", state.status
            )));
        }
        
        // 更新工作流状态
        self.state_manager.update_workflow_status(
            instance_id,
            WorkflowStatus::Running,
            None,
        ).await.map_err(|e| EngineError::StateError(format!("更新工作流状态失败: {}", e)))?;
        
        // 获取工作流定义
        let workflow = self.registry.get_workflow(&state.workflow_id, Some(state.version))
            .ok_or_else(|| EngineError::WorkflowNotFound(state.workflow_id.clone()))?;
        
        // 构建任务依赖图
        let task_graph = build_task_graph(&workflow.tasks);
        
        // 创建工作流上下文
        let cancellation_token = CancellationToken::new();
        let context = WorkflowExecutionContext {
            instance_id: instance_id.to_string(),
            cancellation_token: cancellation_token.clone(),
        };
        
        // 注册取消令牌
        {
            let mut schedulers = self.scheduler.lock().unwrap();
            schedulers.insert(instance_id.to_string(), cancellation_token);
        }
        
        // 恢复工作流执行
        let engine = self.clone();
        let instance_id = instance_id.to_string();
        
        tokio::spawn(async move {
            if let Err(e) = engine.execute_workflow_internal(&instance_id, &task_graph, context).await {
                error!(engine.logger, "工作流执行失败"; 
                    "instance_id" => &instance_id, 
                    "error" => %e);
            }
        });
        
        Ok(())
    }
}

/// 创建检查点
impl WorkflowStateManager {
    /// 创建工作流检查点
    pub async fn create_checkpoint(
        &self,
        instance_id: &str,
        checkpoint_id: &str,
        description: Option<String>,
    ) -> Result<(), StateError> {
        // 获取当前工作流状态
        let mut state = self.get_workflow_state(instance_id).await?;
        
        // 创建检查点
        let checkpoint = WorkflowCheckpoint {
            checkpoint_id: checkpoint_id.to_string(),
            timestamp: Utc::now(),
            description: description.unwrap_or_else(|| format!("检查点 {}", checkpoint_id)),
            completed_tasks: state.completed_tasks.clone(),
            task_results: state.task_results.clone(),
            variables: state.variables.clone(),
        };
        
        // 保存检查点
        state.checkpoints.insert(checkpoint_id.to_string(), checkpoint);
        
        // 保存更新后的状态
        self.save_workflow_state(&state).await
    }
}

/// 工作流检查点
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowCheckpoint {
    /// 检查点ID
    pub checkpoint_id: String,
    
    /// 创建时间
    pub timestamp: DateTime<Utc>,
    
    /// 描述
    pub description: String,
    
    /// 已完成任务
    pub completed_tasks: HashMap<String, DateTime<Utc>>,
    
    /// 任务结果
    pub task_results: HashMap<String, TaskResult>,
    
    /// 工作流变量
    pub variables: HashMap<String, serde_json::Value>,
}

```

下面我们将讨论工作流追踪和监控系统的实现：

```rust
/// 工作流追踪器接口
#[async_trait]
pub trait WorkflowTracer: Send + Sync {
    /// 记录工作流开始事件
    async fn trace_workflow_start(
        &self,
        instance_id: &str,
        workflow_id: &str,
        version: u32,
        correlation_id: Option<&str>,
    ) -> Result<(), TracingError>;
    
    /// 记录工作流结束事件
    async fn trace_workflow_end(
        &self,
        instance_id: &str,
        status: WorkflowStatus,
        duration_ms: u64,
        error: Option<&str>,
    ) -> Result<(), TracingError>;
    
    /// 记录任务开始事件
    async fn trace_task_start(
        &self,
        instance_id: &str,
        task_id: &str,
        task_type: &str,
    ) -> Result<(), TracingError>;
    
    /// 记录任务结束事件
    async fn trace_task_end(
        &self,
        instance_id: &str,
        task_id: &str,
        status: TaskStatus,
        duration_ms: u64,
        error: Option<&str>,
    ) -> Result<(), TracingError>;
    
    /// 记录自定义事件
    async fn trace_custom_event(
        &self,
        instance_id: &str,
        event_type: &str,
        metadata: HashMap<String, String>,
    ) -> Result<(), TracingError>;
}

/// 追踪错误
#[derive(Debug, Error)]
pub enum TracingError {
    #[error("追踪存储错误: {0}")]
    StorageError(String),
    
    #[error("序列化错误: {0}")]
    SerializationError(String),
    
    #[error("无效的参数: {0}")]
    InvalidArgument(String),
    
    #[error("追踪服务不可用: {0}")]
    ServiceUnavailable(String),
}

/// 可观测性追踪器实现
pub struct ObservabilityTracer {
    /// 日志记录器
    logger: Logger,
    
    /// 度量收集器
    metrics_collector: Arc<dyn MetricsCollector>,
    
    /// 追踪存储
    trace_storage: Arc<dyn TraceStorage>,
    
    /// 分布式追踪客户端
    trace_client: Option<Arc<dyn DistributedTraceClient>>,
}

impl ObservabilityTracer {
    /// 创建追踪器
    pub fn new(
        logger: Logger,
        metrics_collector: Arc<dyn MetricsCollector>,
        trace_storage: Arc<dyn TraceStorage>,
        trace_client: Option<Arc<dyn DistributedTraceClient>>,
    ) -> Self {
        Self {
            logger,
            metrics_collector,
            trace_storage,
            trace_client,
        }
    }
}

#[async_trait]
impl WorkflowTracer for ObservabilityTracer {
    async fn trace_workflow_start(
        &self,
        instance_id: &str,
        workflow_id: &str,
        version: u32,
        correlation_id: Option<&str>,
    ) -> Result<(), TracingError> {
        // 记录工作流开始日志
        info!(self.logger, "工作流开始执行"; 
            "instance_id" => instance_id, 
            "workflow_id" => workflow_id, 
            "version" => version,
            "correlation_id" => correlation_id.unwrap_or(""),
        );
        
        // 递增工作流开始计数器
        self.metrics_collector.increment_counter(
            "workflow_starts_total",
            Some(&[
                ("workflow_id", workflow_id),
                ("version", &version.to_string()),
            ]),
        );
        
        // 创建工作流跟踪记录
        let trace = WorkflowTrace {
            instance_id: instance_id.to_string(),
            workflow_id: workflow_id.to_string(),
            version,
            correlation_id: correlation_id.map(|s| s.to_string()),
            start_time: Utc::now(),
            end_time: None,
            status: WorkflowStatus::Running,
            duration_ms: None,
            error: None,
            tasks: HashMap::new(),
        };
        
        // 保存到追踪存储
        self.trace_storage.save_workflow_trace(&trace).await.map_err(|e| {
            TracingError::StorageError(format!("保存工作流追踪失败: {}", e))
        })?;
        
        // 创建分布式追踪span(如果可用)
        if let Some(client) = &self.trace_client {
            let mut span_attrs = HashMap::new();
            span_attrs.insert("workflow.instance_id".to_string(), instance_id.to_string());
            span_attrs.insert("workflow.id".to_string(), workflow_id.to_string());
            span_attrs.insert("workflow.version".to_string(), version.to_string());
            
            if let Some(corr_id) = correlation_id {
                span_attrs.insert("workflow.correlation_id".to_string(), corr_id.to_string());
            }
            
            client.start_span(
                instance_id,
                &format!("workflow:{}", workflow_id),
                span_attrs,
            ).await.map_err(|e| {
                TracingError::ServiceUnavailable(format!("创建追踪span失败: {}", e))
            })?;
        }
        
        Ok(())
    }
    
    async fn trace_workflow_end(
        &self,
        instance_id: &str,
        status: WorkflowStatus,
        duration_ms: u64,
        error: Option<&str>,
    ) -> Result<(), TracingError> {
        // 记录工作流结束日志
        if let Some(err) = error {
            warn!(self.logger, "工作流执行结束"; 
                "instance_id" => instance_id, 
                "status" => ?status, 
                "duration_ms" => duration_ms,
                "error" => err,
            );
        } else {
            info!(self.logger, "工作流执行结束"; 
                "instance_id" => instance_id, 
                "status" => ?status, 
                "duration_ms" => duration_ms,
            );
        }
        
        // 更新计数器和直方图
        self.metrics_collector.increment_counter(
            "workflow_completions_total",
            Some(&[
                ("status", status.as_str()),
            ]),
        );
        
        self.metrics_collector.record_histogram(
            "workflow_duration_milliseconds",
            duration_ms as f64,
            None,
        );
        
        // 更新工作流追踪记录
        let mut trace = self.trace_storage.get_workflow_trace(instance_id).await.map_err(|e| {
            TracingError::StorageError(format!("获取工作流追踪失败: {}", e))
        })?;
        
        trace.status = status;
        trace.end_time = Some(Utc::now());
        trace.duration_ms = Some(duration_ms);
        trace.error = error.map(|s| s.to_string());
        
        // 保存更新后的追踪记录
        self.trace_storage.save_workflow_trace(&trace).await.map_err(|e| {
            TracingError::StorageError(format!("保存工作流追踪失败: {}", e))
        })?;
        
        // 结束分布式追踪span
        if let Some(client) = &self.trace_client {
            let mut span_attrs = HashMap::new();
            span_attrs.insert("workflow.status".to_string(), status.as_str().to_string());
            span_attrs.insert("workflow.duration_ms".to_string(), duration_ms.to_string());
            
            if let Some(err) = error {
                span_attrs.insert("workflow.error".to_string(), err.to_string());
            }
            
            client.end_span(instance_id, span_attrs).await.map_err(|e| {
                TracingError::ServiceUnavailable(format!("结束追踪span失败: {}", e))
            })?;
        }
        
        Ok(())
    }
    
    async fn trace_task_start(
        &self,
        instance_id: &str,
        task_id: &str,
        task_type: &str,
    ) -> Result<(), TracingError> {
        // 记录任务开始日志
        debug!(self.logger, "任务开始执行"; 
            "instance_id" => instance_id, 
            "task_id" => task_id, 
            "task_type" => task_type,
        );
        
        // 递增任务开始计数器
        self.metrics_collector.increment_counter(
            "task_starts_total",
            Some(&[
                ("task_type", task_type),
            ]),
        );
        
        // 获取工作流追踪记录
        let mut trace = self.trace_storage.get_workflow_trace(instance_id).await.map_err(|e| {
            TracingError::StorageError(format!("获取工作流追踪失败: {}", e))
        })?;
        
        // 添加任务追踪记录
        let task_trace = TaskTrace {
            task_id: task_id.to_string(),
            task_type: task_type.to_string(),
            start_time: Utc::now(),
            end_time: None,
            status: TaskStatus::Running,
            duration_ms: None,
            error: None,
        };
        
        trace.tasks.insert(task_id.to_string(), task_trace);
        
        // 保存更新后的追踪记录
        self.trace_storage.save_workflow_trace(&trace).await.map_err(|e| {
            TracingError::StorageError(format!("保存工作流追踪失败: {}", e))
        })?;
        
        // 创建分布式追踪span
        if let Some(client) = &self.trace_client {
            let span_id = format!("{}-{}", instance_id, task_id);
            
            let mut span_attrs = HashMap::new();
            span_attrs.insert("task.id".to_string(), task_id.to_string());
            span_attrs.insert("task.type".to_string(), task_type.to_string());
            
            client.start_span(
                &span_id,
                &format!("task:{}", task_type),
                span_attrs,
            ).await.map_err(|e| {
                TracingError::ServiceUnavailable(format!("创建任务追踪span失败: {}", e))
            })?;
            
            // 设置父span关系
            client.set_parent_span(&span_id, instance_id).await.map_err(|e| {
                TracingError::ServiceUnavailable(format!("设置父span关系失败: {}", e))
            })?;
        }
        
        Ok(())
    }
    
    async fn trace_task_end(
        &self,
        instance_id: &str,
        task_id: &str,
        status: TaskStatus,
        duration_ms: u64,
        error: Option<&str>,
    ) -> Result<(), TracingError> {
        // 记录任务结束日志
        if let Some(err) = error {
            warn!(self.logger, "任务执行结束"; 
                "instance_id" => instance_id, 
                "task_id" => task_id, 
                "status" => ?status, 
                "duration_ms" => duration_ms,
                "error" => err,
            );
        } else {
            debug!(self.logger, "任务执行结束"; 
                "instance_id" => instance_id, 
                "task_id" => task_id, 
                "status" => ?status, 
                "duration_ms" => duration_ms,
            );
        }
        
        // 更新计数器和直方图
        self.metrics_collector.increment_counter(
            "task_completions_total",
            Some(&[
                ("status", status.as_str()),
            ]),
        );
        
        self.metrics_collector.record_histogram(
            "task_duration_milliseconds",
            duration_ms as f64,
            None,
        );
        
        // 获取工作流追踪记录
        let mut trace = self.trace_storage.get_workflow_trace(instance_id).await.map_err(|e| {
            TracingError::StorageError(format!("获取工作流追踪失败: {}", e))
        })?;
        
        // 更新任务追踪记录
        if let Some(task_trace) = trace.tasks.get_mut(task_id) {
            task_trace.status = status;
            task_trace.end_time = Some(Utc::now());
            task_trace.duration_ms = Some(duration_ms);
            task_trace.error = error.map(|s| s.to_string());
            
            // 保存更新后的追踪记录
            self.trace_storage.save_workflow_trace(&trace).await.map_err(|e| {
                TracingError::StorageError(format!("保存工作流追踪失败: {}", e))
            })?;
        } else {
            return Err(TracingError::InvalidArgument(format!("任务 {} 不存在于工作流追踪中", task_id)));
        }
        
        // 结束分布式追踪span
        if let Some(client) = &self.trace_client {
            let span_id = format!("{}-{}", instance_id, task_id);
            
            let mut span_attrs = HashMap::new();
            span_attrs.insert("task.status".to_string(), status.as_str().to_string());
            span_attrs.insert("task.duration_ms".to_string(), duration_ms.to_string());
            
            if let Some(err) = error {
                span_attrs.insert("task.error".to_string(), err.to_string());
            }
            
            client.end_span(&span_id, span_attrs).await.map_err(|e| {
                TracingError::ServiceUnavailable(format!("结束任务追踪span失败: {}", e))
            })?;
        }
        
        Ok(())
    }
    
    async fn trace_custom_event(
        &self,
        instance_id: &str,
        event_type: &str,
        metadata: HashMap<String, String>,
    ) -> Result<(), TracingError> {
        // 记录自定义事件日志
        debug!(self.logger, "工作流自定义事件"; 
            "instance_id" => instance_id, 
            "event_type" => event_type,
            "metadata" => ?metadata,
        );
        
        // 获取工作流追踪记录
        let trace = self.trace_storage.get_workflow_trace(instance_id).await.map_err(|e| {
            TracingError::StorageError(format!("获取工作流追踪失败: {}", e))
        })?;
        
        // 创建自定义事件记录
        let event = CustomTraceEvent {
            event_type: event_type.to_string(),
            timestamp: Utc::now(),
            metadata,
        };
        
        // 保存自定义事件
        self.trace_storage.save_custom_event(instance_id, &event).await.map_err(|e| {
            TracingError::StorageError(format!("保存自定义事件失败: {}", e))
        })?;
        
        // 记录分布式追踪事件
        if let Some(client) = &self.trace_client {
            let mut event_attrs = HashMap::new();
            event_attrs.insert("event.type".to_string(), event_type.to_string());
            
            for (k, v) in metadata {
                event_attrs.insert(format!("event.{}", k), v);
            }
            
            client.record_event(instance_id, event_type, event_attrs).await.map_err(|e| {
                TracingError::ServiceUnavailable(format!("记录分布式追踪事件失败: {}", e))
            })?;
        }
        
        Ok(())
    }
}

/// 工作流追踪记录
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowTrace {
    /// 实例ID
    pub instance_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: u32,
    
    /// 关联ID
    pub correlation_id: Option<String>,
    
    /// 开始时间
    pub start_time: DateTime<Utc>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 状态
    pub status: WorkflowStatus,
    
    /// 执行时长(毫秒)
    pub duration_ms: Option<u64>,
    
    /// 错误
    pub error: Option<String>,
    
    /// 任务追踪
    pub tasks: HashMap<String, TaskTrace>,
}

/// 任务追踪记录
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskTrace {
    /// 任务ID
    pub task_id: String,
    
    /// 任务类型
    pub task_type: String,
    
    /// 开始时间
    pub start_time: DateTime<Utc>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 状态
    pub status: TaskStatus,
    
    /// 执行时长(毫秒)
    pub duration_ms: Option<u64>,
    
    /// 错误
    pub error: Option<String>,
}

/// 自定义追踪事件
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CustomTraceEvent {
    /// 事件类型
    pub event_type: String,
    
    /// 时间戳
    pub timestamp: DateTime<Utc>,
    
    /// 元数据
    pub metadata: HashMap<String, String>,
}

/// 追踪存储接口
#[async_trait]
pub trait TraceStorage: Send + Sync {
    /// 保存工作流追踪
    async fn save_workflow_trace(&self, trace: &WorkflowTrace) -> Result<(), String>;
    
    /// 获取工作流追踪
    async fn get_workflow_trace(&self, instance_id: &str) -> Result<WorkflowTrace, String>;
    
    /// 保存自定义事件
    async fn save_custom_event(&self, instance_id: &str, event: &CustomTraceEvent) -> Result<(), String>;
    
    /// 查询工作流追踪
    async fn query_workflow_traces(
        &self,
        filter: &TraceQueryFilter,
        sort: &[TraceSortOption],
        page: Option<usize>,
        page_size: Option<usize>,
    ) -> Result<TraceQueryResult, String>;
}

/// 分布式追踪客户端接口
#[async_trait]
pub trait DistributedTraceClient: Send + Sync {
    /// 开始span
    async fn start_span(
        &self,
        span_id: &str,
        span_name: &str,
        attributes: HashMap<String, String>,
    ) -> Result<(), String>;
    
    /// 结束span
    async fn end_span(
        &self,
        span_id: &str,
        attributes: HashMap<String, String>,
    ) -> Result<(), String>;
    
    /// 设置父span
    async fn set_parent_span(
        &self,
        span_id: &str,
        parent_id: &str,
    ) -> Result<(), String>;
    
    /// 记录事件
    async fn record_event(
        &self,
        span_id: &str,
        event_name: &str,
        attributes: HashMap<String, String>,
    ) -> Result<(), String>;
}

```

接下来我们将讨论工作流可视化和性能分析组件：

```rust
/// 工作流可视化器
pub struct WorkflowVisualizer {
    /// 工作流注册表
    registry: Arc<WorkflowRegistry>,
    
    /// 工作流状态管理器
    state_manager: Arc<dyn WorkflowStateManager>,
    
    /// 追踪存储
    trace_storage: Arc<dyn TraceStorage>,
}

impl WorkflowVisualizer {
    /// 创建可视化器
    pub fn new(
        registry: Arc<WorkflowRegistry>,
        state_manager: Arc<dyn WorkflowStateManager>,
        trace_storage: Arc<dyn TraceStorage>,
    ) -> Self {
        Self {
            registry,
            state_manager,
            trace_storage,
        }
    }
    
    /// 生成工作流DAG可视化
    pub async fn generate_workflow_dag(
        &self,
        workflow_id: &str,
        version: Option<u32>,
    ) -> Result<WorkflowDagVisualization, VisualizationError> {
        // 获取工作流定义
        let workflow = self.registry.get_workflow(workflow_id, version)
            .ok_or_else(|| VisualizationError::WorkflowNotFound(workflow_id.to_string()))?;
        
        // 构建节点和边
        let mut nodes = Vec::new();
        let mut edges = Vec::new();
        
        // 添加任务节点
        for (task_id, task) in &workflow.tasks {
            let node = DagNode {
                id: task_id.clone(),
                label: task.name.clone(),
                node_type: NodeType::Task,
                task_type: Some(task.task_type.clone()),
                metadata: HashMap::new(),
            };
            
            nodes.push(node);
            
            // 添加依赖边
            if let Some(deps) = &task.depends_on {
                for dep_id in deps {
                    let edge = DagEdge {
                        from: dep_id.clone(),
                        to: task_id.clone(),
                        edge_type: EdgeType::Dependency,
                        label: None,
                        metadata: HashMap::new(),
                    };
                    
                    edges.push(edge);
                }
            }
        }
        
        // 生成可视化结果
        let dag = WorkflowDagVisualization {
            workflow_id: workflow_id.to_string(),
            version: workflow.version,
            nodes,
            edges,
        };
        
        Ok(dag)
    }
    
    /// 生成工作流实例可视化
    pub async fn generate_instance_visualization(
        &self,
        instance_id: &str,
    ) -> Result<InstanceVisualization, VisualizationError> {
        // 获取工作流状态
        let state = self.state_manager.get_workflow_state(instance_id).await
            .map_err(|e| VisualizationError::StateError(format!("获取工作流状态失败: {}", e)))?;
        
        // 获取工作流定义
        let workflow = self.registry.get_workflow(&state.workflow_id, Some(state.version))
            .ok_or_else(|| VisualizationError::WorkflowNotFound(state.workflow_id.clone()))?;
        
        // 获取工作流追踪
        let trace = self.trace_storage.get_workflow_trace(instance_id).await
            .map_err(|e| VisualizationError::TraceError(format!("获取工作流追踪失败: {}", e)))?;
        
        // 构建节点和边
        let mut nodes = Vec::new();
        let mut edges = Vec::new();
        
        // 添加任务节点
        for (task_id, task) in &workflow.tasks {
            // 获取任务状态
            let status = if state.completed_tasks.contains_key(task_id) {
                TaskStatus::Completed
            } else if state.failed_tasks.contains_key(task_id) {
                TaskStatus::Failed
            } else if state.active_tasks.contains(task_id) {
                TaskStatus::Running
            } else {
                TaskStatus::Pending
            };
            
            // 获取任务执行时间
            let duration = trace.tasks.get(task_id)
                .and_then(|t| t.duration_ms);
            
            // 添加元数据
            let mut metadata = HashMap::new();
            metadata.insert("status".to_string(), status.as_str().to_string());
            
            if let Some(dur) = duration {
                metadata.insert("duration_ms".to_string(), dur.to_string());
            }
            
            if status == TaskStatus::Failed {
                if let Some(error) = state.failed_tasks.get(task_id) {
                    metadata.insert("error_code".to_string(), error.code.clone());
                    metadata.insert("error_message".to_string(), error.message.clone());
                }
            }
            
            let node = InstanceNode {
                id: task_id.clone(),
                label: task.name.clone(),
                node_type: NodeType::Task,
                task_type: Some(task.task_type.clone()),
                status,
                start_time: trace.tasks.get(task_id).map(|t| t.start_time),
                end_time: trace.tasks.get(task_id).and_then(|t| t.end_time),
                duration_ms: duration,
                metadata,
            };
            
            nodes.push(node);
            
            // 添加依赖边
            if let Some(deps) = &task.depends_on {
                for dep_id in deps {
                    let edge = InstanceEdge {
                        from: dep_id.clone(),
                        to: task_id.clone(),
                        edge_type: EdgeType::Dependency,
                        status: EdgeStatus::from_node_statuses(
                            nodes.iter().find(|n| &n.id == dep_id).map(|n| n.status).unwrap_or(TaskStatus::Pending),
                            status,
                        ),
                        label: None,
                        metadata: HashMap::new(),
                    };
                    
                    edges.push(edge);
                }
            }
        }
        
        // 构建可视化结果
        let visualization = InstanceVisualization {
            instance_id: instance_id.to_string(),
            workflow_id: state.workflow_id,
            version: state.version,
            status: state.status,
            create_time: state.create_time,
            start_time: state.start_time,
            end_time: state.end_time,
            duration_ms: state.end_time.map(|e| {
                state.start_time.map(|s| (e - s).num_milliseconds() as u64).unwrap_or(0)
            }),
            nodes,
            edges,
        };
        
        Ok(visualization)
    }
    
    /// 生成工作流Graphviz DOT表示
    pub async fn generate_dot_representation(
        &self,
        workflow_id: &str,
        version: Option<u32>,
    ) -> Result<String, VisualizationError> {
        let dag = self.generate_workflow_dag(workflow_id, version).await?;
        
        // 构建DOT表示
        let mut dot = String::new();
        dot.push_str(&format!("digraph \"{}\" {{\n", workflow_id));
        dot.push_str("  rankdir=LR;\n");
        dot.push_str("  node [shape=box, style=filled, color=lightblue];\n\n");
        
        // 添加节点
        for node in &dag.nodes {
            let label = if let Some(task_type) = &node.task_type {
                format!("{}\n({})", node.label, task_type)
            } else {
                node.label.clone()
            };
            
            dot.push_str(&format!("  \"{}\" [label=\"{}\"];\n", node.id, label));
        }
        
        dot.push_str("\n");
        
        // 添加边
        for edge in &dag.edges {
            if let Some(label) = &edge.label {
                dot.push_str(&format!("  \"{}\" -> \"{}\" [label=\"{}\"];\n", edge.from, edge.to, label));
            } else {
                dot.push_str(&format!("  \"{}\" -> \"{}\";\n", edge.from, edge.to));
            }
        }
        
        dot.push_str("}\n");
        
        Ok(dot)
    }
    
    /// 生成工作流实例Graphviz DOT表示
    pub async fn generate_instance_dot(
        &self,
        instance_id: &str,
    ) -> Result<String, VisualizationError> {
        let viz = self.generate_instance_visualization(instance_id).await?;
        
        // 构建DOT表示
        let mut dot = String::new();
        dot.push_str(&format!("digraph \"Instance: {}\" {{\n", instance_id));
        dot.push_str("  rankdir=LR;\n");
        dot.push_str("  node [shape=box, style=filled];\n\n");
        
        // 添加节点
        for node in &viz.nodes {
            // 根据状态选择颜色
            let color = match node.status {
                TaskStatus::Completed => "lightgreen",
                TaskStatus::Failed => "lightcoral",
                TaskStatus::Running => "lightyellow",
                TaskStatus::Pending => "lightgray",
                _ => "lightblue",
            };
            
            // 构建标签
            let mut label = format!("{}", node.label);
            
            if let Some(task_type) = &node.task_type {
                label.push_str(&format!("\n({})", task_type));
            }
            
            if node.status != TaskStatus::Pending {
                label.push_str(&format!("\n[{}]", node.status.as_str()));
            }
            
            if let Some(duration) = node.duration_ms {
                label.push_str(&format!("\n{}ms", duration));
            }
            
            dot.push_str(&format!("  \"{}\" [label=\"{}\", fillcolor=\"{}\"];\n", 
                node.id, label, color));
        }
        
        dot.push_str("\n");
        
        // 添加边
        for edge in &viz.edges {
            // 根据状态选择样式
            let style = match edge.status {
                EdgeStatus::Completed => "solid",
                EdgeStatus::Active => "bold",
                EdgeStatus::Pending => "dashed",
                EdgeStatus::Failed => "dotted",
            };
            
            if let Some(label) = &edge.label {
                dot.push_str(&format!("  \"{}\" -> \"{}\" [label=\"{}\", style={}];\n", 
                    edge.from, edge.to, label, style));
            } else {
                dot.push_str(&format!("  \"{}\" -> \"{}\" [style={}];\n", 
                    edge.from, edge.to, style));
            }
        }
        
        // 添加工作流信息
        let status_color = match viz.status {
            WorkflowStatus::Completed => "green",
            WorkflowStatus::Failed | WorkflowStatus::TimedOut => "red",
            WorkflowStatus::Running => "blue",
            _ => "gray",
        };
        
        let mut info = format!("Workflow: {}\nVersion: {}\nStatus: {}\n", 
            viz.workflow_id, viz.version, viz.status.as_str());
        
        if let Some(duration) = viz.duration_ms {
            info.push_str(&format!("Duration: {} ms", duration));
        }
        
        dot.push_str(&format!("\n  subgraph cluster_info {{\n"));
        dot.push_str("    style=filled;\n");
        dot.push_str("    color=lightgray;\n");
        dot.push_str(&format!("    label=\"{}\";\n", instance_id));
        dot.push_str(&format!("    info [shape=note, label=\"{}\", color={}];\n", info, status_color));
        dot.push_str("  }\n");
        
        dot.push_str("}\n");
        
        Ok(dot)
    }
}

/// 工作流性能分析器
pub struct WorkflowPerformanceAnalyzer {
    /// 追踪存储
    trace_storage: Arc<dyn TraceStorage>,
    
    /// 工作流注册表
    registry: Arc<WorkflowRegistry>,
}

impl WorkflowPerformanceAnalyzer {
    /// 创建性能分析器
    pub fn new(
        trace_storage: Arc<dyn TraceStorage>,
        registry: Arc<WorkflowRegistry>,
    ) -> Self {
        Self {
            trace_storage,
            registry,
        }
    }
    
    /// 分析工作流性能
    pub async fn analyze_workflow_performance(
        &self,
        workflow_id: &str,
        version: Option<u32>,
        time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
        limit: Option<usize>,
    ) -> Result<WorkflowPerformanceAnalysis, AnalysisError> {
        // 构建查询过滤器
        let mut filter = TraceQueryFilter::new()
            .with_workflow_id(workflow_id.to_string());
        
        if let Some(ver) = version {
            filter = filter.with_version(ver);
        }
        
        if let Some((start, end)) = time_range {
            filter = filter.with_time_range(start, end);
        }
        
        // 执行查询
        let traces = self.trace_storage.query_workflow_traces(
            &filter,
            &[TraceSortOption::StartTimeDesc],
            Some(1),
            limit,
        ).await.map_err(|e| AnalysisError::TraceError(format!("查询工作流追踪失败: {}", e)))?;
        
        // 没有数据时返回空结果
        if traces.total_count == 0 {
            return Ok(WorkflowPerformanceAnalysis::empty(workflow_id, version));
        }
        
        // 获取工作流定义
        let workflow = if let Some(trace) = traces.items.first() {
            self.registry.get_workflow(workflow_id, Some(trace.version))
                .ok_or_else(|| AnalysisError::WorkflowNotFound(workflow_id.to_string()))?
        } else {
            return Ok(WorkflowPerformanceAnalysis::empty(workflow_id, version));
        };
        
        // 分析总体执行时间
        let mut total_durations = Vec::new();
        let mut success_count = 0;
        let mut failure_count = 0;
        
        for trace in &traces.items {
            if let Some(duration) = trace.duration_ms {
                total_durations.push(duration);
                
                if trace.status == WorkflowStatus::Completed {
                    success_count += 1;
                } else {
                    failure_count += 1;
                }
            }
        }
        
        // 分析任务执行时间
        let mut task_durations: HashMap<String, Vec<u64>> = HashMap::new();
        let mut critical_path_tasks = Vec::new();
        let mut bottleneck_tasks = Vec::new();
        
        for trace in &traces.items {
            // 收集任务执行时间
            for (task_id, task_trace) in &trace.tasks {
                if let Some(duration) = task_trace.duration_ms {
                    task_durations.entry(task_id.clone())
                        .or_insert_with(Vec::new)
                        .push(duration);
                }
            }
            
            // 对于已完成的工作流，识别关键路径
            if trace.status == WorkflowStatus::Completed {
                if let Some(path) = self.identify_critical_path(&workflow, trace) {
                    critical_path_tasks.extend(path);
                }
            }
        }
        
        // 计算任务统计信息
        let mut task_stats = HashMap::new();
        
        for (task_id, durations) in &task_durations {
            if durations.is_empty() {
                continue;
            }
            
            let task_def = workflow.tasks.get(task_id);
            
            let stats = TaskPerformanceStats {
                task_id: task_id.clone(),
                task_name: task_def.map(|t| t.name.clone()).unwrap_or_else(|| task_id.clone()),
                task_type: task_def.map(|t| t.task_type.clone()).unwrap_or_else(|| "unknown".to_string()),
                count: durations.len(),
                min_duration_ms: *durations.iter().min().unwrap(),
                max_duration_ms: *durations.iter().max().unwrap(),
                avg_duration_ms: durations.iter().sum::<u64>() / durations.len() as u64,
                percentile_90_ms: calculate_percentile(durations, 90.0),
                percentile_95_ms: calculate_percentile(durations, 95.0),
                percentile_99_ms: calculate_percentile(durations, 99.0),
            };
            
            task_stats.insert(task_id.clone(), stats);
        }
        
        // 识别瓶颈任务 (平均执行时间最长的前N个任务)
        bottleneck_tasks = task_stats.values()
            .sorted_by(|a, b| b.avg_duration_ms.cmp(&a.avg_duration_ms))
            .take(3)
            .map(|stats| stats.task_id.clone())
            .collect();
        
        // 构建关键路径分析
        let critical_path_analysis = if !critical_path_tasks.is_empty() {
            // 计算频率
            let mut path_frequencies = HashMap::new();
            for task_id in &critical_path_tasks {
                *path_frequencies.entry(task_id.clone()).or_insert(0) += 1;
            }
            
            // 找出最常见的关键路径
            let most_common_path: Vec<String> = path_frequencies.iter()
                .sorted_by(|a, b| b.1.cmp(a.1))
                .take(critical_path_tasks.len() / traces.items.len())
                .map(|(task_id, _)| task_id.clone())
                .collect();
            
            Some(CriticalPathAnalysis {
                path: most_common_path.clone(),
                path_names: most_common_path.iter()
                    .map(|id| workflow.tasks.get(id).map(|t| t.name.clone()).unwrap_or_else(|| id.clone()))
                    .collect(),
                estimated_duration_ms: most_common_path.iter()
                    .filter_map(|id| task_stats.get(id).map(|stats| stats.avg_duration_ms))
                    .sum(),
            })
        } else {
            None
        };
        
        // 计算总体统计信息
        let overall_stats = if !total_durations.is_empty() {
            OverallPerformanceStats {
                execution_count: total_durations.len(),
                success_count,
                failure_count,
                success_rate: if total_durations.is_empty() { 0.0 } else { success_count as f64 / total_durations.len() as f64 },
                min_duration_ms: *total_durations.iter().min().unwrap(),
                max_duration_ms: *total_durations.iter().max().unwrap(),
                avg_duration_ms: total_durations.iter().sum::<u64>() / total_durations.len() as u64,
                percentile_90_ms: calculate_percentile(&total_durations, 90.0),
                percentile_95_ms: calculate_percentile(&total_durations, 95.0),
                percentile_99_ms: calculate_percentile(&total_durations, 99.0),
            }
        } else {
            OverallPerformanceStats::default()
        };
        
        // 构建分析结果
        let analysis = WorkflowPerformanceAnalysis {
            workflow_id: workflow_id.to_string(),
            version: workflow.version,
            analyzed_instances: traces.items.len(),
            time_range: time_range.map(|(start, end)| (start, end)),
            overall_stats,
            task_stats,
            bottleneck_tasks,
            critical_path: critical_path_analysis,
            optimization_suggestions: self.generate_optimization_suggestions(
                &workflow,
                &overall_stats,
                &task_stats,
                &bottleneck_tasks,
                critical_path_analysis.as_ref(),
            ),
        };
        
        Ok(analysis)
    }
    
    /// 识别工作流的关键路径
    fn identify_critical_path(
        &self,
        workflow: &WorkflowDefinition,
        trace: &WorkflowTrace,
    ) -> Option<Vec<String>> {
        // 构建任务依赖图
        let task_graph = build_task_graph(&workflow.tasks);
        
        // 创建反向图 (用于从终点向起点追踪)
        let mut reverse_graph: HashMap<String, Vec<String>> = HashMap::new();
        for (task_id, deps) in &task_graph {
            for dep in deps {
                reverse_graph.entry(dep.clone())
                    .or_insert_with(Vec::new)
                    .push(task_id.clone());
            }
        }
        
        // 找出没有后继的任务(终点任务)
        let end_tasks: Vec<String> = task_graph.keys()
            .filter(|&task_id| {
                !reverse_graph.values().any(|deps| deps.contains(task_id))
            })
            .cloned()
            .collect();
        
        if end_tasks.is_empty() {
            return None;
        }
        
        // 为每个任务计算最长路径
        let mut task_end_times: HashMap<String, u64> = HashMap::new();
        let mut task_predecessors: HashMap<String, String> = HashMap::new();
        
        // 初始化起点任务
        for (task_id, deps) in &task_graph {
            if deps.is_empty() {
                if let Some(task_trace) = trace.tasks.get(task_id) {
                    if let Some(duration) = task_trace.duration_ms {
                        task_end_times.insert(task_id.clone(), duration);
                    }
                }
            }
        }
        
        // 拓扑排序并计算最长路径
        let mut visited = HashSet::new();
        let mut stack = Vec::new();
        
        // DFS收集拓扑排序
        fn visit(
            node: &str,
            graph: &HashMap<String, Vec<String>>,
            visited: &mut HashSet<String>,
            stack: &mut Vec<String>,
        ) {
            if visited.contains(node) {
                return;
            }
            
            visited.insert(node.to_string());
            
            if let Some(neighbors) = graph.get(node) {
                for neighbor in neighbors {
                    visit(neighbor, graph, visited, stack);
                }
            }
            
            stack.push(node.to_string());
        }
        
        // 对所有起点任务执行DFS
        for (task_id, deps) in &task_graph {
            if deps.is_empty() {
                visit(task_id, &reverse_graph, &mut visited, &mut stack);
            }
        }
        
        // 根据拓扑排序更新最长路径
        for task_id in stack {
            let current_end_time = *task_end_times.get(&task_id).unwrap_or(&0);
            
            if let Some(successors) = reverse_graph.get(&task_id) {
                for succ in successors {
                    if let Some(task_trace) = trace.tasks.get(succ) {
                        if let Some(duration) = task_trace.duration_ms {
                            let new_end_time = current_end_time + duration;
                            
                            if new_end_time > *task_end_times.get(succ).unwrap_or(&0) {
                                task_end_times.insert(succ.clone(), new_end_time);
                                task_predecessors.insert(succ.clone(), task_id.clone());
                            }
                        }
                    }
                }
            }
        }
        
        // 找到结束时间最晚的终点任务
        let mut latest_end_task = None;
        let mut latest_end_time = 0;
        
        for end_task in &end_tasks {
            if let Some(&end_time) = task_end_times.get(end_task) {
                if end_time > latest_end_time {
                    latest_end_time = end_time;
                    latest_end_task = Some(end_task.clone());
                }
            }
        }
        
        // 从终点任务回溯得到关键路径
        if let Some(end_task) = latest_end_task {
            let mut path = Vec::new();
            let mut current = end_task;
            
            path.push(current.clone());
            
            while let Some(pred) = task_predecessors.get(&current) {
                path.push(pred.clone());
                current = pred.clone();
            }
            
            // 反转路径(从起点到终点)
            path.reverse();
            return Some(path);
        }
        
        None
    }
    
    /// 生成优化建议
    fn generate_optimization_suggestions(
        &self,
        workflow: &WorkflowDefinition,
        overall_stats: &OverallPerformanceStats,
        task_stats: &HashMap<String, TaskPerformanceStats>,
        bottleneck_tasks: &[String],
        critical_path: Option<&CriticalPathAnalysis>,
    ) -> Vec<OptimizationSuggestion> {
        let mut suggestions = Vec::new();
        
        // 1. 瓶颈任务优化
        if !bottleneck_tasks.is_empty() {
            for task_id in bottleneck_tasks {
                if let Some(stats) = task_stats.get(task_id) {
                    // 如果任务平均执行时间超过工作流总时间的30%，建议优化
                    if stats.avg_duration_ms > overall_stats.avg_duration_ms * 30 / 100 {
                        let task_def = workflow.tasks.get(task_id);
                        
                        let suggestion = OptimizationSuggestion {
                            suggestion_type: SuggestionType::BottleneckOptimization,
                            target: SuggestionTarget::Task(task_id.clone()),
                            description: format!(
                                "任务 '{}' 是性能瓶颈，平均执行时间为 {} ms，占总执行时间的 {:.1}%", 
                                task_def.map(|t| t.name.as_str()).unwrap_or(task_id),
                                stats.avg_duration_ms,
                                stats.avg_duration_ms as f64 * 100.0 / overall_stats.avg_duration_ms as f64
                            ),
                            suggestion: match task_def.map(|t| t.task_type.as_str()) {
                                Some("http_request") => "考虑缓存请求结果或优化API调用频率".to_string(),
                                Some("database_query") => "优化数据库查询，添加索引或减少返回数据量".to_string(),
                                Some("file_processing") => "考虑使用流式处理或分块处理大文件".to_string(),
                                Some("compute") => "优化算法或考虑并行处理数据".to_string(),
                                _ => "分析任务实现，寻找优化机会".to_string(),
                            },
                            estimated_impact: SuggestionImpact::High,
                        };
                        
                        suggestions.push(suggestion);
                    }
                }
            }
        }
        
        // 2. 并行优化建议
        if let Some(path) = critical_path {
            // 检查关键路径上是否有可以并行的任务
            let mut parallelizable_groups = Vec::new();
            let mut current_group = Vec::new();
            
            for (i, task_id) in path.path.iter().enumerate() {
                let task_def = workflow.tasks.get(task_id);
                
                // 跳过已经有并行配置的任务
                if task_def.map(|t| t.execution_mode == ExecutionMode::Parallel).unwrap_or(false) {
                    continue;
                }
                
                // 检查当前任务是否与前一个任务没有直接依赖关系
                if i > 0 {
                    let prev_task_id = &path.path[i - 1];
                    
                    if let Some(task) = workflow.tasks.get(task_id) {
                        let has_direct_dependency = task.depends_on.as_ref()
                            .map(|deps| deps.contains(prev_task_id))
                            .unwrap_or(false);
                            
                        if !has_direct_dependency {
                            if current_group.is_empty() {
                                current_group.push(prev_task_id.clone());
                            }
                            current_group.push(task_id.clone());
                        } else if !current_group.is_empty() {
                            parallelizable_groups.push(current_group.clone());
                            current_group.clear();
                        }
                    }
                }
            }
            
            if !current_group.is_empty() {
                parallelizable_groups.push(current_group);
            }
            
            // 为可并行的任务组生成建议
            for group in parallelizable_groups {
                if group.len() >= 2 {
                    // 计算可能的时间节省
                    let sequential_time: u64 = group.iter()
                        .filter_map(|task_id| task_stats.get(task_id).map(|stats| stats.avg_duration_ms))
                        .sum();
                    
                    let parallel_time: u64 = group.iter()
                        .filter_map(|task_id| task_stats.get(task_id).map(|stats| stats.avg_duration_ms))
                        .max()
                        .unwrap_or(0);
                    
                    let time_saving = sequential_time.saturating_sub(parallel_time);
                    let percentage_saving = (time_saving as f64 * 100.0 / overall_stats.avg_duration_ms as f64).min(100.0);
                    
                    // 生成任务名称列表
                    let task_names: Vec<String> = group.iter()
                        .map(|task_id| workflow.tasks.get(task_id)
                            .map(|t| t.name.clone())
                            .unwrap_or_else(|| task_id.clone()))
                        .collect();
                    
                    let suggestion = OptimizationSuggestion {
                        suggestion_type: SuggestionType::ParallelExecution,
                        target: SuggestionTarget::TaskGroup(group.clone()),
                        description: format!(
                            "任务组 [{}] 可以并行执行，估计可节省 {} ms ({:.1}%)", 
                            task_names.join(", "),
                            time_saving,
                            percentage_saving
                        ),
                        suggestion: "修改工作流配置，允许这些任务并行执行".to_string(),
                        estimated_impact: if percentage_saving > 20.0 {
                            SuggestionImpact::High
                        } else if percentage_saving > 5.0 {
                            SuggestionImpact::Medium
                        } else {
                            SuggestionImpact::Low
                        },
                    };
                    
                    suggestions.push(suggestion);
                }
            }
        }
        
        // 3. 资源分配优化
        let high_variance_tasks: Vec<(&String, &TaskPerformanceStats)> = task_stats.iter()
            .filter(|(_, stats)| {
                stats.max_duration_ms > stats.avg_duration_ms * 2 &&
                stats.max_duration_ms - stats.min_duration_ms > stats.avg_duration_ms
            })
            .collect();
        
        for (task_id, stats) in high_variance_tasks {
            let task_def = workflow.tasks.get(task_id);
            let task_name = task_def.map(|t| t.name.as_str()).unwrap_or(task_id);
            
            let suggestion = OptimizationSuggestion {
                suggestion_type: SuggestionType::ResourceAllocation,
                target: SuggestionTarget::Task(task_id.to_string()),
                description: format!(
                    "任务 '{}' 执行时间变化很大 (最小: {} ms, 平均: {} ms, 最大: {} ms)",
                    task_name,
                    stats.min_duration_ms,
                    stats.avg_duration_ms,
                    stats.max_duration_ms
                ),
                suggestion: match task_def.map(|t| t.task_type.as_str()) {
                    Some("http_request") => "考虑增加超时设置和重试策略，监控外部服务健康状况".to_string(),
                    Some("database_query") => "检查数据库资源分配和索引使用情况，考虑添加连接池".to_string(),
                    Some("compute") => "优化资源分配或增加计算资源，考虑使用缓存".to_string(),
                    _ => "分析资源使用情况，确保任务有足够且稳定的资源".to_string(),
                },
                estimated_impact: SuggestionImpact::Medium,
            };
            
            suggestions.push(suggestion);
        }
        
        // 4. 错误处理优化
        if overall_stats.failure_rate() > 0.05 {  // 失败率大于5%
            suggestions.push(OptimizationSuggestion {
                suggestion_type: SuggestionType::ErrorHandling,
                target: SuggestionTarget::Workflow,
                description: format!(
                    "工作流失败率较高 ({:.1}%)，考虑改进错误处理策略",
                    overall_stats.failure_rate() * 100.0
                ),
                suggestion: "添加更健壮的错误处理和重试机制，特别是针对外部服务依赖".to_string(),
                estimated_impact: SuggestionImpact::High,
            });
        }
        
        // 5. 检查点优化
        if overall_stats.avg_duration_ms > 60000 {  // 平均执行时间超过一分钟
            suggestions.push(OptimizationSuggestion {
                suggestion_type: SuggestionType::Checkpointing,
                target: SuggestionTarget::Workflow,
                description: format!(
                    "工作流平均执行时间较长 ({} ms)，建议添加检查点以支持恢复", 
                    overall_stats.avg_duration_ms
                ),
                suggestion: "在关键任务完成后添加检查点，以便在失败时从检查点恢复".to_string(),
                estimated_impact: SuggestionImpact::Medium,
            });
        }
        
        // 返回所有建议
        suggestions
    }
}

/// 节点类型
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum NodeType {
    /// 任务节点
    Task,
    
    /// 控制节点
    Control,
    
    /// 事件节点
    Event,
    
    /// 网关节点
    Gateway,
}

/// 边类型
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum EdgeType {
    /// 依赖关系
    Dependency,
    
    /// 控制流
    ControlFlow,
    
    /// 数据流
    DataFlow,
}

/// 边状态
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum EdgeStatus {
    /// 已完成
    Completed,
    
    /// 活动中
    Active,
    
    /// 等待中
    Pending,
    
    /// 失败
    Failed,
}

impl EdgeStatus {
    /// 根据两个节点的状态确定边的状态
    pub fn from_node_statuses(from_status: TaskStatus, to_status: TaskStatus) -> Self {
        match (from_status, to_status) {
            (TaskStatus::Completed, TaskStatus::Completed) => EdgeStatus::Completed,
            (TaskStatus::Completed, TaskStatus::Running) => EdgeStatus::Active,
            (TaskStatus::Running, _) | (_, TaskStatus::Running) => EdgeStatus::Active,
            (TaskStatus::Completed, TaskStatus::Pending) => EdgeStatus::Pending,
            (TaskStatus::Failed, _) => EdgeStatus::Failed,
            (_, TaskStatus::Failed) => EdgeStatus::Failed,
            _ => EdgeStatus::Pending,
        }
    }
}

/// DAG节点
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DagNode {
    /// 节点ID
    pub id: String,
    
    /// 节点标签
    pub label: String,
    
    /// 节点类型
    pub node_type: NodeType,
    
    /// 任务类型
    pub task_type: Option<String>,
    
    /// 元数据
    pub metadata: HashMap<String, String>,
}

/// DAG边
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DagEdge {
    /// 起始节点
    pub from: String,
    
    /// 目标节点
    pub to: String,
    
    /// 边类型
    pub edge_type: EdgeType,
    
    /// 边标签
    pub label: Option<String>,
    
    /// 元数据
    pub metadata: HashMap<String, String>,
}

/// 工作流DAG可视化
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowDagVisualization {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: u32,
    
    /// 节点
    pub nodes: Vec<DagNode>,
    
    /// 边
    pub edges: Vec<DagEdge>,
}

/// 实例节点
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InstanceNode {
    /// 节点ID
    pub id: String,
    
    /// 节点标签
    pub label: String,
    
    /// 节点类型
    pub node_type: NodeType,
    
    /// 任务类型
    pub task_type: Option<String>,
    
    /// 状态
    pub status: TaskStatus,
    
    /// 开始时间
    pub start_time: Option<DateTime<Utc>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 执行时长
    pub duration_ms: Option<u64>,
    
    /// 元数据
    pub metadata: HashMap<String, String>,
}

/// 实例边
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InstanceEdge {
    /// 起始节点
    pub from: String,
    
    /// 目标节点
    pub to: String,
    
    /// 边类型
    pub edge_type: EdgeType,
    
    /// 边状态
    pub status: EdgeStatus,
    
    /// 边标签
    pub label: Option<String>,
    
    /// 元数据
    pub metadata: HashMap<String, String>,
}

/// 实例可视化
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InstanceVisualization {
    /// 实例ID
    pub instance_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: u32,
    
    /// 状态
    pub status: WorkflowStatus,
    
    /// 创建时间
    pub create_time: DateTime<Utc>,
    
    /// 开始时间
    pub start_time: Option<DateTime<Utc>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 执行时长
    pub duration_ms: Option<u64>,
    
    /// 节点
    pub nodes: Vec<InstanceNode>,
    
    /// 边
    pub edges: Vec<InstanceEdge>,
}

/// 可视化错误
#[derive(Debug, Error)]
pub enum VisualizationError {
    #[error("工作流未找到: {0}")]
    WorkflowNotFound(String),
    
    #[error("工作流实例未找到: {0}")]
    InstanceNotFound(String),
    
    #[error("状态错误: {0}")]
    StateError(String),
    
    #[error("追踪错误: {0}")]
    TraceError(String),
    
    #[error("其他错误: {0}")]
    Other(String),
}

/// 工作流性能分析
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowPerformanceAnalysis {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: u32,
    
    /// 分析的实例数量
    pub analyzed_instances: usize,
    
    /// 时间范围
    pub time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
    
    /// 总体统计
    pub overall_stats: OverallPerformanceStats,
    
    /// 任务统计
    pub task_stats: HashMap<String, TaskPerformanceStats>,
    
    /// 瓶颈任务列表
    pub bottleneck_tasks: Vec<String>,
    
    /// 关键路径分析
    pub critical_path: Option<CriticalPathAnalysis>,
    
    /// 优化建议
    pub optimization_suggestions: Vec<OptimizationSuggestion>,
}

impl WorkflowPerformanceAnalysis {
    /// 创建空分析结果
    pub fn empty(workflow_id: &str, version: Option<u32>) -> Self {
        Self {
            workflow_id: workflow_id.to_string(),
            version: version.unwrap_or(0),
            analyzed_instances: 0,
            time_range: None,
            overall_stats: OverallPerformanceStats::default(),
            task_stats: HashMap::new(),
            bottleneck_tasks: Vec::new(),
            critical_path: None,
            optimization_suggestions: Vec::new(),
        }
    }
}

/// 总体性能统计
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OverallPerformanceStats {
    /// 执行次数
    pub execution_count: usize,
    
    /// 成功次数
    pub success_count: usize,
    
    /// 失败次数
    pub failure_count: usize,
    
    /// 成功率
    pub success_rate: f64,
    
    /// 最小执行时间(毫秒)
    pub min_duration_ms: u64,
    
    /// 最大执行时间(毫秒)
    pub max_duration_ms: u64,
    
    /// 平均执行时间(毫秒)
    pub avg_duration_ms: u64,
    
    /// 90%执行时间(毫秒)
    pub percentile_90_ms: u64,
    
    /// 95%执行时间(毫秒)
    pub percentile_95_ms: u64,
    
    /// 99%执行时间(毫秒)
    pub percentile_99_ms: u64,
}

impl OverallPerformanceStats {
    /// 获取失败率
    pub fn failure_rate(&self) -> f64 {
        1.0 - self.success_rate
    }
}

impl Default for OverallPerformanceStats {
    fn default() -> Self {
        Self {
            execution_count: 0,
            success_count: 0,
            failure_count: 0,
            success_rate: 0.0,
            min_duration_ms: 0,
            max_duration_ms: 0,
            avg_duration_ms: 0,
            percentile_90_ms: 0,
            percentile_95_ms: 0,
            percentile_99_ms: 0,
        }
    }
}

/// 任务性能统计
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskPerformanceStats {
    /// 任务ID
    pub task_id: String,
    
    /// 任务名称
    pub task_name: String,
    
    /// 任务类型
    pub task_type: String,
    
    /// 执行次数
    pub count: usize,
    
    /// 最小执行时间(毫秒)
    pub min_duration_ms: u64,
    
    /// 最大执行时间(毫秒)
    pub max_duration_ms: u64,
    
    /// 平均执行时间(毫秒)
    pub avg_duration_ms: u64,
    
    /// 90%执行时间(毫秒)
    pub percentile_90_ms: u64,
    
    /// 95%执行时间(毫秒)
    pub percentile_95_ms: u64,
    
    /// 99%执行时间(毫秒)
    pub percentile_99_ms: u64,
}

/// 关键路径分析
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CriticalPathAnalysis {
    /// 关键路径(任务ID)
    pub path: Vec<String>,
    
    /// 关键路径(任务名称)
    pub path_names: Vec<String>,
    
    /// 估计路径执行时间(毫秒)
    pub estimated_duration_ms: u64,
}

/// 优化建议
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OptimizationSuggestion {
    /// 建议类型
    pub suggestion_type: SuggestionType,
    
    /// 目标
    pub target: SuggestionTarget,
    
    /// 描述
    pub description: String,
    
    /// 建议
    pub suggestion: String,
    
    /// 估计影响
    pub estimated_impact: SuggestionImpact,
}

/// 建议类型
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SuggestionType {
    /// 瓶颈优化
    BottleneckOptimization,
    
    /// 并行执行
    ParallelExecution,
    
    /// 资源分配
    ResourceAllocation,
    
    /// 错误处理
    ErrorHandling,
    
    /// 检查点
    Checkpointing,
    
    /// 数据局部性
    DataLocality,
    
    /// 其他
    Other,
}

/// 目标类型
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SuggestionTarget {
    /// 针对整个工作流
    Workflow,
    
    /// 针对特定任务
    Task(String),
    
    /// 针对任务组
    TaskGroup(Vec<String>),
}

/// 估计影响
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SuggestionImpact {
    /// 高影响
    High,
    
    /// 中等影响
    Medium,
    
    /// 低影响
    Low,
}

/// 追踪查询过滤器
#[derive(Debug, Clone)]
pub struct TraceQueryFilter {
    /// 工作流ID
    workflow_id: Option<String>,
    
    /// 实例ID
    instance_id: Option<String>,
    
    /// 工作流版本
    version: Option<u32>,
    
    /// 工作流状态
    status: Option<WorkflowStatus>,
    
    /// 关联ID
    correlation_id: Option<String>,
    
    /// 时间范围
    time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
    
    /// 最小执行时间
    min_duration_ms: Option<u64>,
    
    /// 最大执行时间
    max_duration_ms: Option<u64>,
}

impl TraceQueryFilter {
    /// 创建新的查询过滤器
    pub fn new() -> Self {
        Self {
            workflow_id: None,
            instance_id: None,
            version: None,
            status: None,
            correlation_id: None,
            time_range: None,
            min_duration_ms: None,
            max_duration_ms: None,
        }
    }
    
    /// 设置工作流ID
    pub fn with_workflow_id(mut self, workflow_id: String) -> Self {
        self.workflow_id = Some(workflow_id);
        self
    }
    
    /// 设置实例ID
    pub fn with_instance_id(mut self, instance_id: String) -> Self {
        self.instance_id = Some(instance_id);
        self
    }
    
    /// 设置版本
    pub fn with_version(mut self, version: u32) -> Self {
        self.version = Some(version);
        self
    }
    
    /// 设置状态
    pub fn with_status(mut self, status: WorkflowStatus) -> Self {
        self.status = Some(status);
        self
    }
    
    /// 设置关联ID
    pub fn with_correlation_id(mut self, correlation_id: String) -> Self {
        self.correlation_id = Some(correlation_id);
        self
    }
    
    /// 设置时间范围
    pub fn with_time_range(mut self, start: DateTime<Utc>, end: DateTime<Utc>) -> Self {
        self.time_range = Some((start, end));
        self
    }
    
    /// 设置最小执行时间
    pub fn with_min_duration(mut self, min_duration_ms: u64) -> Self {
        self.min_duration_ms = Some(min_duration_ms);
        self
    }
    
    /// 设置最大执行时间
    pub fn with_max_duration(mut self, max_duration_ms: u64) -> Self {
        self.max_duration_ms = Some(max_duration_ms);
        self
    }
}

/// 追踪排序选项
#[derive(Debug, Clone)]
pub enum TraceSortOption {
    /// 开始时间递增
    StartTimeAsc,
    
    /// 开始时间递减
    StartTimeDesc,
    
    /// 执行时间递增
    DurationAsc,
    
    /// 执行时间递减
    DurationDesc,
}

/// 追踪查询结果
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TraceQueryResult {
    /// 总记录数
    pub total_count: usize,
    
    /// 记录
    pub items: Vec<WorkflowTrace>,
}

/// 计算百分位数
fn calculate_percentile(values: &[u64], percentile: f64) -> u64 {
    if values.is_empty() {
        return 0;
    }
    
    let mut sorted = values.to_vec();
    sorted.sort_unstable();
    
    let index = ((percentile / 100.0) * (sorted.len() as f64 - 1.0)) as usize;
    sorted[index]
}

/// 分析错误
#[derive(Debug, Error)]
pub enum AnalysisError {
    #[error("工作流未找到: {0}")]
    WorkflowNotFound(String),
    
    #[error("工作流实例未找到: {0}")]
    InstanceNotFound(String),
    
    #[error("状态错误: {0}")]
    StateError(String),
    
    #[error("追踪错误: {0}")]
    TraceError(String),
    
    #[error("其他错误: {0}")]
    Other(String),
}

```

最后，我们来实现工作流运行时统计和健康监控组件：

```rust
/// 工作流监控服务
pub struct WorkflowMonitoringService {
    /// 日志记录器
    logger: Logger,
    
    /// 工作流引擎
    engine: Arc<WorkflowExecutionEngine>,
    
    /// 状态管理器
    state_manager: Arc<dyn WorkflowStateManager>,
    
    /// 度量收集器
    metrics_collector: Arc<dyn MetricsCollector>,
    
    /// 警报管理器
    alerting_manager: Arc<dyn AlertingManager>,
    
    /// 系统健康状态
    health_state: Arc<RwLock<SystemHealthState>>,
    
    /// 最后更新时间
    last_update: Arc<AtomicI64>,
    
    /// 监控线程运行标志
    is_running: Arc<AtomicBool>,
}

impl WorkflowMonitoringService {
    /// 创建监控服务
    pub fn new(
        logger: Logger,
        engine: Arc<WorkflowExecutionEngine>,
        state_manager: Arc<dyn WorkflowStateManager>,
        metrics_collector: Arc<dyn MetricsCollector>,
        alerting_manager: Arc<dyn AlertingManager>,
    ) -> Self {
        Self {
            logger,
            engine,
            state_manager,
            metrics_collector,
            alerting_manager,
            health_state: Arc::new(RwLock::new(SystemHealthState::default())),
            last_update: Arc::new(AtomicI64::new(0)),
            is_running: Arc::new(AtomicBool::new(false)),
        }
    }
    
    /// 启动监控服务
    pub async fn start(&self, interval_seconds: u64) -> Result<(), MonitoringError> {
        if self.is_running.swap(true, Ordering::SeqCst) {
            return Err(MonitoringError::AlreadyRunning("监控服务已运行".to_string()));
        }
        
        info!(self.logger, "启动工作流监控服务"; "interval_seconds" => interval_seconds);
        
        // 初始化监控
        self.initialize_health_state().await?;
        
        // 启动监控线程
        let logger = self.logger.clone();
        let state_manager = self.state_manager.clone();
        let metrics_collector = self.metrics_collector.clone();
        let alerting_manager = self.alerting_manager.clone();
        let health_state = self.health_state.clone();
        let last_update = self.last_update.clone();
        let is_running = self.is_running.clone();
        
        tokio::spawn(async move {
            let interval_duration = Duration::from_secs(interval_seconds);
            let mut interval = tokio::time::interval(interval_duration);
            
            while is_running.load(Ordering::SeqCst) {
                interval.tick().await;
                
                match Self::collect_and_analyze_metrics(
                    &logger,
                    state_manager.as_ref(),
                    metrics_collector.as_ref(),
                    alerting_manager.as_ref(),
                    health_state.clone(),
                ).await {
                    Ok(()) => {
                        last_update.store(Utc::now().timestamp(), Ordering::SeqCst);
                    },
                    Err(e) => {
                        error!(logger, "监控指标收集失败"; "error" => %e);
                    }
                }
            }
            
            info!(logger, "工作流监控服务已停止");
        });
        
        Ok(())
    }
    
    /// 停止监控服务
    pub async fn stop(&self) -> Result<(), MonitoringError> {
        if !self.is_running.swap(false, Ordering::SeqCst) {
            return Err(MonitoringError::NotRunning("监控服务未运行".to_string()));
        }
        
        info!(self.logger, "正在停止工作流监控服务");
        Ok(())
    }
    
    /// 获取系统健康状态
    pub async fn get_health_state(&self) -> SystemHealthState {
        self.health_state.read().await.clone()
    }
    
    /// 获取工作流运行时统计
    pub async fn get_runtime_statistics(&self) -> Result<WorkflowRuntimeStatistics, MonitoringError> {
        let health_state = self.health_state.read().await;
        let now = Utc::now();
        let last_update = Utc.timestamp(self.last_update.load(Ordering::SeqCst), 0);
        
        let stats = WorkflowRuntimeStatistics {
            timestamp: now,
            last_update,
            active_workflows: health_state.active_workflows,
            completed_workflows: health_state.completed_workflows,
            failed_workflows: health_state.failed_workflows,
            pending_tasks: health_state.pending_tasks,
            active_tasks: health_state.active_tasks,
            completed_tasks: health_state.completed_tasks,
            failed_tasks: health_state.failed_tasks,
            average_workflow_duration_ms: health_state.average_workflow_duration_ms,
            average_task_duration_ms: health_state.average_task_duration_ms,
            resource_utilization: health_state.resource_utilization.clone(),
            system_load: health_state.system_load,
            slowest_workflows: health_state.slowest_workflows.clone(),
            most_failed_tasks: health_state.most_failed_tasks.clone(),
        };
        
        Ok(stats)
    }
    
    /// 获取工作流详细统计
    pub async fn get_detailed_statistics(
        &self,
        filter: &StatisticsFilter,
    ) -> Result<DetailedWorkflowStatistics, MonitoringError> {
        // 构建状态查询
        let state_filter = match filter {
            StatisticsFilter::ByWorkflowId(workflow_id) => {
                StateQueryFilter::new().with_workflow_id(workflow_id.clone())
            },
            StatisticsFilter::ByTimeRange(start, end) => {
                StateQueryFilter::new().with_time_range(*start, *end)
            },
            StatisticsFilter::ByStatus(status) => {
                StateQueryFilter::new().with_status(*status)
            },
            StatisticsFilter::ByCombination { workflow_id, status, time_range } => {
                let mut filter = StateQueryFilter::new();
                
                if let Some(wf_id) = workflow_id {
                    filter = filter.with_workflow_id(wf_id.clone());
                }
                
                if let Some(st) = status {
                    filter = filter.with_status(*st);
                }
                
                if let Some((start, end)) = time_range {
                    filter = filter.with_time_range(*start, *end);
                }
                
                filter
            },
        };
        
        // 查询工作流状态
        let states = self.state_manager.query_workflow_states(&state_filter).await
            .map_err(|e| MonitoringError::StateQueryError(format!("查询工作流状态失败: {}", e)))?;
        
        if states.items.is_empty() {
            return Ok(DetailedWorkflowStatistics::empty());
        }
        
        // 分析工作流状态
        let mut workflow_stats = HashMap::new();
        let mut total_duration = 0u64;
        let mut total_completed = 0usize;
        let mut total_failed = 0usize;
        let mut total_pending = 0usize;
        let mut total_running = 0usize;
        
        for state in &states.items {
            // 更新工作流统计
            let workflow_entry = workflow_stats.entry(state.workflow_id.clone())
                .or_insert_with(|| WorkflowTypeStatistics {
                    workflow_id: state.workflow_id.clone(),
                    total_instances: 0,
                    completed_instances: 0,
                    failed_instances: 0,
                    running_instances: 0,
                    pending_instances: 0,
                    average_duration_ms: 0,
                    success_rate: 0.0,
                    task_statistics: HashMap::new(),
                });
            
            workflow_entry.total_instances += 1;
            
            // 统计工作流状态
            match state.status {
                WorkflowStatus::Completed => {
                    workflow_entry.completed_instances += 1;
                    total_completed += 1;
                    
                    // 计算时长
                    if let (Some(start), Some(end)) = (state.start_time, state.end_time) {
                        let duration = (end - start).num_milliseconds().max(0) as u64;
                        total_duration += duration;
                        
                        // 更新平均时长
                        let current_total = workflow_entry.average_duration_ms * (workflow_entry.completed_instances - 1) as u64;
                        workflow_entry.average_duration_ms = (current_total + duration) / workflow_entry.completed_instances as u64;
                    }
                },
                WorkflowStatus::Failed | WorkflowStatus::TimedOut | WorkflowStatus::Cancelled => {
                    workflow_entry.failed_instances += 1;
                    total_failed += 1;
                },
                WorkflowStatus::Running | WorkflowStatus::Recovering => {
                    workflow_entry.running_instances += 1;
                    total_running += 1;
                },
                WorkflowStatus::Created | WorkflowStatus::Suspended | WorkflowStatus::Paused => {
                    workflow_entry.pending_instances += 1;
                    total_pending += 1;
                },
            }
            
            // 更新任务统计
            for (task_id, completion_time) in &state.completed_tasks {
                let task_entry = workflow_entry.task_statistics.entry(task_id.clone())
                    .or_insert_with(|| TaskTypeStatistics {
                        task_id: task_id.clone(),
                        total_executions: 0,
                        completed_executions: 0,
                        failed_executions: 0,
                        average_duration_ms: 0,
                        success_rate: 0.0,
                    });
                
                task_entry.total_executions += 1;
                task_entry.completed_executions += 1;
                
                // 更新平均时长(如果有任务结果)
                if let Some(result) = state.task_results.get(task_id) {
                    let current_total = task_entry.average_duration_ms * (task_entry.completed_executions - 1) as u64;
                    task_entry.average_duration_ms = (current_total + result.execution_time) / task_entry.completed_executions as u64;
                }
            }
            
            // 更新失败任务统计
            for (task_id, _) in &state.failed_tasks {
                let task_entry = workflow_entry.task_statistics.entry(task_id.clone())
                    .or_insert_with(|| TaskTypeStatistics {
                        task_id: task_id.clone(),
                        total_executions: 0,
                        completed_executions: 0,
                        failed_executions: 0,
                        average_duration_ms: 0,
                        success_rate: 0.0,
                    });
                
                task_entry.total_executions += 1;
                task_entry.failed_executions += 1;
            }
        }
        
        // 计算成功率
        for stats in workflow_stats.values_mut() {
            stats.success_rate = if stats.total_instances > 0 {
                stats.completed_instances as f64 / stats.total_instances as f64
            } else {
                0.0
            };
            
            for task_stats in stats.task_statistics.values_mut() {
                task_stats.success_rate = if task_stats.total_executions > 0 {
                    task_stats.completed_executions as f64 / task_stats.total_executions as f64
                } else {
                    0.0
                };
            }
        }
        
        // 计算总体平均时长
        let average_duration = if total_completed > 0 {
            total_duration / total_completed as u64
        } else {
            0
        };
        
        // 构建结果
        let total_instances = total_completed + total_failed + total_running + total_pending;
        let success_rate = if total_instances > 0 {
            total_completed as f64 / total_instances as f64
        } else {
            0.0
        };
        
        let detailed_stats = DetailedWorkflowStatistics {
            total_instances,
            completed_instances: total_completed,
            failed_instances: total_failed,
            running_instances: total_running,
            pending_instances: total_pending,
            average_duration_ms: average_duration,
            success_rate,
            workflow_statistics: workflow_stats,
            time_range: filter.time_range(),
        };
        
        Ok(detailed_stats)
    }
    
    /// 初始化健康状态
    async fn initialize_health_state(&self) -> Result<(), MonitoringError> {
        let mut health_state = self.health_state.write().await;
        
        // 查询活动工作流
        let active_filter = StateQueryFilter::new()
            .with_status(WorkflowStatus::Running);
        
        let active_states = self.state_manager.query_workflow_states(&active_filter).await
            .map_err(|e| MonitoringError::StateQueryError(format!("查询活动工作流失败: {}", e)))?;
        
        health_state.active_workflows = active_states.total_count;
        
        // 计算活动任务
        let mut active_tasks = 0;
        for state in &active_states.items {
            active_tasks += state.active_tasks.len();
        }
        health_state.active_tasks = active_tasks;
        
        // 查询最近完成的工作流
        let completed_filter = StateQueryFilter::new()
            .with_status(WorkflowStatus::Completed)
            .with_time_range(
                Utc::now() - Duration::hours(24),
                Utc::now(),
            )
            .with_limit(100);
        
        let completed_states = self.state_manager.query_workflow_states(&completed_filter).await
            .map_err(|e| MonitoringError::StateQueryError(format!("查询完成工作流失败: {}", e)))?;
        
        // 计算平均时长
        let mut total_duration = 0u64;
        let mut total_workflows = 0usize;
        
        for state in &completed_states.items {
            if let (Some(start), Some(end)) = (state.start_time, state.end_time) {
                let duration = (end - start).num_milliseconds().max(0) as u64;
                total_duration += duration;
                total_workflows += 1;
            }
        }
        
        if total_workflows > 0 {
            health_state.average_workflow_duration_ms = total_duration / total_workflows as u64;
        }
        
        // 设置最后更新时间
        self.last_update.store(Utc::now().timestamp(), Ordering::SeqCst);
        
        Ok(())
    }
    
    /// 收集和分析指标
    async fn collect_and_analyze_metrics(
        logger: &Logger,
        state_manager: &dyn WorkflowStateManager,
        metrics_collector: &dyn MetricsCollector,
        alerting_manager: &dyn AlertingManager,
        health_state: Arc<RwLock<SystemHealthState>>,
    ) -> Result<(), MonitoringError> {
        // 查询工作流状态
        let active_filter = StateQueryFilter::new()
            .with_status(WorkflowStatus::Running);
        
        let completed_filter = StateQueryFilter::new()
            .with_status(WorkflowStatus::Completed)
            .with_time_range(
                Utc::now() - Duration::hours(1),
                Utc::now(),
            );
        
        let failed_filter = StateQueryFilter::new()
            .with_statuses(vec![
                WorkflowStatus::Failed,
                WorkflowStatus::TimedOut,
                WorkflowStatus::Cancelled,
            ])
            .with_time_range(
                Utc::now() - Duration::hours(1),
                Utc::now(),
            );
        
        // 并行查询所有状态
        let (active_states, completed_states, failed_states) = tokio::join!(
            state_manager.query_workflow_states(&active_filter),
            state_manager.query_workflow_states(&completed_filter),
            state_manager.query_workflow_states(&failed_filter),
        );
        
        let active_states = active_states
            .map_err(|e| MonitoringError::StateQueryError(format!("查询活动工作流失败: {}", e)))?;
        
        let completed_states = completed_states
            .map_err(|e| MonitoringError::StateQueryError(format!("查询完成工作流失败: {}", e)))?;
        
        let failed_states = failed_states
            .map_err(|e| MonitoringError::StateQueryError(format!("查询失败工作流失败: {}", e)))?;
        
        // 更新健康状态
        let mut state = health_state.write().await;
        
        // 更新工作流计数
        state.active_workflows = active_states.total_count;
        state.completed_workflows = completed_states.total_count;
        state.failed_workflows = failed_states.total_count;
        
        // 计算任务统计
        let mut active_tasks = 0;
        let mut pending_tasks = 0;
        let mut completed_tasks = 0;
        let mut failed_tasks = 0;
        
        // 活动工作流中的任务
        for workflow in &active_states.items {
            active_tasks += workflow.active_tasks.len();
            pending_tasks += workflow.pending_tasks.len();
            completed_tasks += workflow.completed_tasks.len();
            failed_tasks += workflow.failed_tasks.len();
        }
        
        // 完成和失败工作流中的任务
        for workflow in completed_states.items.iter().chain(failed_states.items.iter()) {
            completed_tasks += workflow.completed_tasks.len();
            failed_tasks += workflow.failed_tasks.len();
        }
        
        state.active_tasks = active_tasks;
        state.pending_tasks = pending_tasks;
        state.completed_tasks = completed_tasks;
        state.failed_tasks = failed_tasks;
        
        // 计算工作流平均时长
        let mut total_workflow_duration = 0u64;
        let mut total_completed_workflows = 0usize;
        
        for workflow in &completed_states.items {
            if let (Some(start), Some(end)) = (workflow.start_time, workflow.end_time) {
                let duration = (end - start).num_milliseconds().max(0) as u64;
                total_workflow_duration += duration;
                total_completed_workflows += 1;
            }
        }
        
        if total_completed_workflows > 0 {
            state.average_workflow_duration_ms = total_workflow_duration / total_completed_workflows as u64;
        }
        
        // 计算任务平均时长
        let mut total_task_duration = 0u64;
        let mut total_tasks = 0usize;
        
        for workflow in completed_states.items.iter().chain(active_states.items.iter()) {
            for (_, result) in &workflow.task_results {
                if result.status == TaskStatus::Completed {
                    total_task_duration += result.execution_time;
                    total_tasks += 1;
                }
            }
        }
        
        if total_tasks > 0 {
            state.average_task_duration_ms = total_task_duration / total_tasks as u64;
        }
        
        // 收集资源利用率
        let mut resource_utilization = HashMap::new();
        
        // CPU利用率
        if let Ok(cpu_usage) = get_system_cpu_usage() {
            resource_utilization.insert("cpu_usage".to_string(), cpu_usage);
            metrics_collector.record_gauge("system.cpu_usage", cpu_usage, None);
        }
        
        // 内存利用率
        if let Ok(memory_usage) = get_system_memory_usage() {
            resource_utilization.insert("memory_usage".to_string(), memory_usage);
            metrics_collector.record_gauge("system.memory_usage", memory_usage, None);
        }
        
        // 存储利用率
        if let Ok(disk_usage) = get_system_disk_usage() {
            resource_utilization.insert("disk_usage".to_string(), disk_usage);
            metrics_collector.record_gauge("system.disk_usage", disk_usage, None);
        }
        
        state.resource_utilization = resource_utilization;
        
        // 更新系统负载
        if let Ok(load) = get_system_load() {
            state.system_load = load;
            metrics_collector.record_gauge("system.load_average", load, None);
        }
        
        // 找出最慢的工作流
        let mut slowest_workflows = Vec::new();
        
        for workflow in &completed_states.items {
            if let (Some(start), Some(end)) = (workflow.start_time, workflow.end_time) {
                let duration = (end - start).num_milliseconds().max(0) as u64;
                
                slowest_workflows.push(SlowWorkflow {
                    instance_id: workflow.instance_id.clone(),
                    workflow_id: workflow.workflow_id.clone(),
                    duration_ms: duration,
                    start_time: start,
                    end_time: end,
                });
            }
        }
        
        // 按时长排序，取前5个最慢的
        slowest_workflows.sort_by(|a, b| b.duration_ms.cmp(&a.duration_ms));
        state.slowest_workflows = slowest_workflows.into_iter().take(5).collect();
        
        // 找出失败率最高的任务
        let mut task_failure_counts = HashMap::new();
        
        for workflow in failed_states.items.iter().chain(completed_states.items.iter()) {
            for (task_id, _) in &workflow.failed_tasks {
                *task_failure_counts.entry(task_id.clone()).or_insert(0) += 1;
            }
        }
        
        let mut most_failed_tasks = Vec::new();
        
        for (task_id, count) in task_failure_counts {
            most_failed_tasks.push(FailedTask {
                task_id,
                failure_count: count,
            });
        }
        
        // 按失败次数排序，取前5个
        most_failed_tasks.sort_by(|a, b| b.failure_count.cmp(&a.failure_count));
        state.most_failed_tasks = most_failed_tasks.into_iter().take(5).collect();
        
        // 记录关键指标
        metrics_collector.record_gauge("workflows.active", state.active_workflows as f64, None);
        metrics_collector.record_gauge("workflows.completed", state.completed_workflows as f64, None);
        metrics_collector.record_gauge("workflows.failed", state.failed_workflows as f64, None);
        metrics_collector.record_gauge("tasks.active", state.active_tasks as f64, None);
        metrics_collector.record_gauge("tasks.pending", state.pending_tasks as f64, None);
        metrics_collector.record_gauge("tasks.completed", state.completed_tasks as f64, None);
        metrics_collector.record_gauge("tasks.failed", state.failed_tasks as f64, None);
        metrics_collector.record_gauge("workflows.avg_duration", state.average_workflow_duration_ms as f64, None);
        metrics_collector.record_gauge("tasks.avg_duration", state.average_task_duration_ms as f64, None);
        
        // 检查并发送警报
        Self::check_and_send_alerts(logger, alerting_manager, &state).await?;
        
        Ok(())
    }
    
    /// 检查并发送警报
    async fn check_and_send_alerts(
        logger: &Logger,
        alerting_manager: &dyn AlertingManager,
        state: &SystemHealthState,
    ) -> Result<(), MonitoringError> {
        // 检查系统资源警报
        if let Some(cpu_usage) = state.resource_utilization.get("cpu_usage") {
            if *cpu_usage > 90.0 {
                alerting_manager.send_alert(
                    AlertLevel::Warning,
                    "CPU使用率过高",
                    &format!("CPU使用率达到 {:.1}%，可能影响工作流执行性能", cpu_usage),
                    Some(json!({
                        "cpu_usage": cpu_usage,
                        "active_workflows": state.active_workflows,
                        "active_tasks": state.active_tasks,
                    })),
                ).await.map_err(|e| MonitoringError::AlertingError(format!("发送CPU警报失败: {}", e)))?;
                
                info!(logger, "发送CPU使用率警报"; "cpu_usage" => %cpu_usage);
            }
        }
        
        if let Some(memory_usage) = state.resource_utilization.get("memory_usage") {
            if *memory_usage > 90.0 {
                alerting_manager.send_alert(
                    AlertLevel::Warning,
                    "内存使用率过高",
                    &format!("内存使用率达到 {:.1}%，可能导致性能下降或OOM错误", memory_usage),
                    Some(json!({
                        "memory_usage": memory_usage,
                        "active_workflows": state.active_workflows,
                        "active_tasks": state.active_tasks,
                    })),
                ).await.map_err(|e| MonitoringError::AlertingError(format!("发送内存警报失败: {}", e)))?;
                
                info!(logger, "发送内存使用率警报"; "memory_usage" => %memory_usage);
            }
        }
        
        if let Some(disk_usage) = state.resource_utilization.get("disk_usage") {
            if *disk_usage > 95.0 {
                alerting_manager.send_alert(
                    AlertLevel::Critical,
                    "磁盘空间不足",
                    &format!("磁盘使用率达到 {:.1}%，接近容量上限，可能导致写入失败", disk_usage),
                    Some(json!({
                        "disk_usage": disk_usage,
                    })),
                ).await.map_err(|e| MonitoringError::AlertingError(format!("发送磁盘警报失败: {}", e)))?;
                
                info!(logger, "发送磁盘使用率警报"; "disk_usage" => %disk_usage);
            }
        }
        
        // 检查工作流健康状态
        if state.failed_workflows > 0 {
            let failure_rate = state.failed_workflows as f64 / 
                (state.completed_workflows + state.failed_workflows) as f64 * 100.0;
            
            if failure_rate > 20.0 {
                alerting_manager.send_alert(
                    AlertLevel::Critical,
                    "工作流失败率过高",
                    &format!("过去一小时内工作流失败率达到 {:.1}%，请检查系统稳定性", failure_rate),
                    Some(json!({
                        "failed_workflows": state.failed_workflows,
                        "completed_workflows": state.completed_workflows,
                        "failure_rate": failure_rate,
                        "most_failed_tasks": state.most_failed_tasks,
                    })),
                ).await.map_err(|e| MonitoringError::AlertingError(format!("发送工作流失败率警报失败: {}", e)))?;
                
                info!(logger, "发送工作流失败率警报"; "failure_rate" => %failure_rate);
            }
        }
        
        // 检查工作流执行时间
        if !state.slowest_workflows.is_empty() {
            let slowest = &state.slowest_workflows[0];
            
            if slowest.duration_ms > 3600000 { // 超过1小时
                alerting_manager.send_alert(
                    AlertLevel::Warning,
                    "工作流执行时间过长",
                    &format!("工作流 {} (实例 {}) 执行时间达到 {:.2} 分钟，可能存在性能问题",
                        slowest.workflow_id, slowest.instance_id, slowest.duration_ms as f64 / 60000.0),
                    Some(json!({
                        "instance_id": slowest.instance_id,
                        "workflow_id": slowest.workflow_id,
                        "duration_ms": slowest.duration_ms,
                        "start_time": slowest.start_time,
                        "end_time": slowest.end_time,
                    })),
                ).await.map_err(|e| MonitoringError::AlertingError(format!("发送工作流执行时间警报失败: {}", e)))?;
                
                info!(logger, "发送工作流执行时间警报"; 
                    "workflow_id" => &slowest.workflow_id, 
                    "duration_ms" => slowest.duration_ms);
            }
        }
        
        // 检查系统负载
        if state.system_load > 10.0 {
            alerting_manager.send_alert(
                AlertLevel::Warning,
                "系统负载过高",
                &format!("系统负载达到 {:.2}，可能导致工作流执行延迟", state.system_load),
                Some(json!({
                    "system_load": state.system_load,
                    "active_workflows": state.active_workflows,
                    "active_tasks": state.active_tasks,
                })),
            ).await.map_err(|e| MonitoringError::AlertingError(format!("发送系统负载警报失败: {}", e)))?;
            
            info!(logger, "发送系统负载警报"; "system_load" => %state.system_load);
        }
        
        Ok(())
    }
}

/// 系统健康状态
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemHealthState {
    /// 活动工作流数量
    pub active_workflows: usize,
    
    /// 已完成工作流数量
    pub completed_workflows: usize,
    
    /// 失败工作流数量
    pub failed_workflows: usize,
    
    /// 等待中任务数量
    pub pending_tasks: usize,
    
    /// 活动任务数量
    pub active_tasks: usize,
    
    /// 已完成任务数量
    pub completed_tasks: usize,
    
    /// 失败任务数量
    pub failed_tasks: usize,
    
    /// 平均工作流执行时间(毫秒)
    pub average_workflow_duration_ms: u64,
    
    /// 平均任务执行时间(毫秒)
    pub average_task_duration_ms: u64,
    
    /// 资源利用率
    pub resource_utilization: HashMap<String, f64>,
    
    /// 系统负载
    pub system_load: f64,
    
    /// 最慢工作流列表
    pub slowest_workflows: Vec<SlowWorkflow>,
    
    /// 失败最多的任务
    pub most_failed_tasks: Vec<FailedTask>,
}

impl Default for SystemHealthState {
    fn default() -> Self {
        Self {
            active_workflows: 0,
            completed_workflows: 0,
            failed_workflows: 0,
            pending_tasks: 0,
            active_tasks: 0,
            completed_tasks: 0,
            failed_tasks: 0,
            average_workflow_duration_ms: 0,
            average_task_duration_ms: 0,
            resource_utilization: HashMap::new(),
            system_load: 0.0,
            slowest_workflows: Vec::new(),
            most_failed_tasks: Vec::new(),
        }
    }
}

/// 工作流运行时统计
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowRuntimeStatistics {
    /// 时间戳
    pub timestamp: DateTime<Utc>,
    
    /// 最后更新时间
    pub last_update: DateTime<Utc>,
    
    /// 活动工作流数量
    pub active_workflows: usize,
    
    /// 已完成工作流数量
    pub completed_workflows: usize,
    
    /// 失败工作流数量
    pub failed_workflows: usize,
    
    /// 等待中任务数量
    pub pending_tasks: usize,
    
    /// 活动任务数量
    pub active_tasks: usize,
    
    /// 已完成任务数量
    pub completed_tasks: usize,
    
    /// 失败任务数量
    pub failed_tasks: usize,
    
    /// 平均工作流执行时间(毫秒)
    pub average_workflow_duration_ms: u64,
    
    /// 平均任务执行时间(毫秒)
    pub average_task_duration_ms: u64,
    
    /// 资源利用率
    pub resource_utilization: HashMap<String, f64>,
    
    /// 系统负载
    pub system_load: f64,
    
    /// 最慢工作流列表
    pub slowest_workflows: Vec<SlowWorkflow>,
    
    /// 失败最多的任务
    pub most_failed_tasks: Vec<FailedTask>,
}

/// 最慢工作流
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SlowWorkflow {
    /// 实例ID
    pub instance_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 执行时长(毫秒)
    pub duration_ms: u64,
    
    /// 开始时间
    pub start_time: DateTime<Utc>,
    
    /// 结束时间
    pub end_time: DateTime<Utc>,
}

/// 失败任务
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FailedTask {
    /// 任务ID
    pub task_id: String,
    
    /// 失败次数
    pub failure_count: usize,
}

/// 工作流类型统计
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowTypeStatistics {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 总实例数
    pub total_instances: usize,
    
    /// 已完成实例数
    pub completed_instances: usize,
    
    /// 失败实例数
    pub failed_instances: usize,
    
    /// 运行中实例数
    pub running_instances: usize,
    
    /// 等待中实例数
    pub pending_instances: usize,
    
    /// 平均执行时间(毫秒)
    pub average_duration_ms: u64,
    
    /// 成功率
    pub success_rate: f64,
    
    /// 任务统计
    pub task_statistics: HashMap<String, TaskTypeStatistics>,
}

/// 任务类型统计
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskTypeStatistics {
    /// 任务ID
    pub task_id: String,
    
    /// 总执行次数
    pub total_executions: usize,
    
    /// 成功执行次数
    pub completed_executions: usize,
    
    /// 失败执行次数
    pub failed_executions: usize,
    
    /// 平均执行时间(毫秒)
    pub average_duration_ms: u64,
    
    /// 成功率
    pub success_rate: f64,
}

/// 详细工作流统计
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetailedWorkflowStatistics {
    /// 总实例数
    pub total_instances: usize,
    
    /// 已完成实例数
    pub completed_instances: usize,
    
    /// 失败实例数
    pub failed_instances: usize,
    
    /// 运行中实例数
    pub running_instances: usize,
    
    /// 等待中实例数
    pub pending_instances: usize,
    
    /// 平均执行时间(毫秒)
    pub average_duration_ms: u64,
    
    /// 成功率
    pub success_rate: f64,
    
    /// 工作流统计
    pub workflow_statistics: HashMap<String, WorkflowTypeStatistics>,
    
    /// 时间范围
    pub time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
}

impl DetailedWorkflowStatistics {
    /// 创建空统计
    pub fn empty() -> Self {
        Self {
            total_instances: 0,
            completed_instances: 0,
            failed_instances: 0,
            running_instances: 0,
            pending_instances: 0,
            average_duration_ms: 0,
            success_rate: 0.0,
            workflow_statistics: HashMap::new(),
            time_range: None,
        }
    }
}

/// 统计过滤器
#[derive(Debug, Clone)]
pub enum StatisticsFilter {
    /// 按工作流ID过滤
    ByWorkflowId(String),
    
    /// 按时间范围过滤
    ByTimeRange(DateTime<Utc>, DateTime<Utc>),
    
    /// 按状态过滤
    ByStatus(WorkflowStatus),
    
    /// 组合过滤
    ByCombination {
        /// 工作流ID
        workflow_id: Option<String>,
        
        /// 状态
        status: Option<WorkflowStatus>,
        
        /// 时间范围
        time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
    },
}

impl StatisticsFilter {
    /// 获取时间范围
    pub fn time_range(&self) -> Option<(DateTime<Utc>, DateTime<Utc>)> {
        match self {
            Self::ByTimeRange(start, end) => Some((*start, *end)),
            Self::ByCombination { time_range, .. } => *time_range,
            _ => None,
        }
    }
}

/// 监控错误
#[derive(Debug, Error)]
pub enum MonitoringError {
    #[error("状态查询错误: {0}")]
    StateQueryError(String),
    
    #[error("指标收集错误: {0}")]
    MetricsError(String),
    
    #[error("警报错误: {0}")]
    AlertingError(String),
    
    #[error("服务已运行: {0}")]
    AlreadyRunning(String),
    
    #[error("服务未运行: {0}")]
    NotRunning(String),
    
    #[error("系统错误: {0}")]
    SystemError(String),
}

/// 度量收集器接口
#[async_trait]
pub trait MetricsCollector: Send + Sync {
    /// 递增计数器
    fn increment_counter(&self, name: &str, labels: Option<&[(&str, &str)]>);
    
    /// 记录直方图值
    fn record_histogram(&self, name: &str, value: f64, labels: Option<&[(&str, &str)]>);
    
    /// 记录表指标
    fn record_gauge(&self, name: &str, value: f64, labels: Option<&[(&str, &str)]>);
    
    /// 记录定时器
    fn record_timer<F, R>(&self, name: &str, labels: Option<&[(&str, &str)]>, f: F) -> R
    where
        F: FnOnce() -> R;
        
    /// 设置表指标值
    fn set_gauge(&self, name: &str, value: f64, labels: Option<&[(&str, &str)]>);
}

/// 警报级别
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum AlertLevel {
    /// 信息
    Info,
    
    /// 警告
    Warning,
    
    /// 错误
    Error,
    
    /// 严重
    Critical,
}

/// 警报管理器接口
#[async_trait]
pub trait AlertingManager: Send + Sync {
    /// 发送警报
    async fn send_alert(
        &self,
        level: AlertLevel,
        title: &str,
        message: &str,
        data: Option<serde_json::Value>,
    ) -> Result<(), String>;
    
    /// 解决警报
    async fn resolve_alert(&self, alert_id: &str) -> Result<(), String>;
    
    /// 获取活动警报
    async fn get_active_alerts(&self) -> Result<Vec<Alert>, String>;
}

/// 警报
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Alert {
    /// 警报ID
    pub id: String,
    
    /// 警报级别
    pub level: AlertLevel,
    
    /// 标题
    pub title: String,
    
    /// 消息
    pub message: String,
    
    /// 数据
    pub data: Option<serde_json::Value>,
    
    /// 创建时间
    pub created_at: DateTime<Utc>,
    
    /// 解决时间
    pub resolved_at: Option<DateTime<Utc>>,
}

/// 获取系统CPU使用率
fn get_system_cpu_usage() -> Result<f64, String> {
    // 实现CPU使用率获取
    // 在实际应用中，通过系统API或库来获取
    #[cfg(target_os = "linux")]
    {
        match std::fs::read_to_string("/proc/stat") {
            Ok(stat) => {
                // 解析/proc/stat获取CPU使用率
                let lines: Vec<&str> = stat.lines().collect();
                if lines.is_empty() {
                    return Err("无法读取CPU统计信息".to_string());
                }
                
                let cpu_line = lines[0];
                let fields: Vec<&str> = cpu_line.split_whitespace().collect();
                if fields.len() < 8 {
                    return Err("CPU统计信息格式无效".to_string());
                }
                
                let user = fields[1].parse::<u64>().unwrap_or(0);
                let nice = fields[2].parse::<u64>().unwrap_or(0);
                let system = fields[3].parse::<u64>().unwrap_or(0);
                let idle = fields[4].parse::<u64>().unwrap_or(0);
                
                let total = user + nice + system + idle;
                let usage = if total > 0 {
                    (total - idle) as f64 * 100.0 / total as f64
                } else {
                    0.0
                };
                
                Ok(usage)
            },
            Err(e) => Err(format!("读取系统CPU信息失败: {}", e)),
        }
    }
    
    #[cfg(not(target_os = "linux"))]
    {
        // 默认返回一个模拟值，实际应用中需要根据操作系统实现
        Ok(50.0)
    }
}

/// 获取系统内存使用率
fn get_system_memory_usage() -> Result<f64, String> {
    // 实现内存使用率获取
    #[cfg(target_os = "linux")]
    {
        match std::fs::read_to_string("/proc/meminfo") {
            Ok(meminfo) => {
                let mut total = 0u64;
                let mut available = 0u64;
                
                for line in meminfo.lines() {
                    if line.starts_with("MemTotal:") {
                        let parts: Vec<&str> = line.split_whitespace().collect();
                        if parts.len() >= 2 {
                            total = parts[1].parse::<u64>().unwrap_or(0);
                        }
                    } else if line.starts_with("MemAvailable:") {
                        let parts: Vec<&str> = line.split_whitespace().collect();
                        if parts.len() >= 2 {
                            available = parts[1].parse::<u64>().unwrap_or(0);
                        }
                    }
                }
                
                if total > 0 {
                    let used = total - available;
                    let usage = used as f64 * 100.0 / total as f64;
                    Ok(usage)
                } else {
                    Err("无法解析内存信息".to_string())
                }
            },
            Err(e) => Err(format!("读取系统内存信息失败: {}", e)),
        }
    }
    
    #[cfg(not(target_os = "linux"))]
    {
        // 默认返回一个模拟值
        Ok(60.0)
    }
}

/// 获取系统磁盘使用率
fn get_system_disk_usage() -> Result<f64, String> {
    // 实现磁盘使用率获取
    #[cfg(target_os = "linux")]
    {
        use std::process::Command;
        
        let output = Command::new("df")
            .args(&["-h", "/"]) // 检查根目录磁盘使用情况
            .output();
            
        match output {
            Ok(out) => {
                if !out.status.success() {
                    return Err("执行df命令失败".to_string());
                }
                
                let stdout = String::from_utf8_lossy(&out.stdout);
                let lines: Vec<&str> = stdout.lines().collect();
                
                if lines.len() < 2 {
                    return Err("df命令输出格式无效".to_string());
                }
                
                let fields: Vec<&str> = lines[1].split_whitespace().collect();
                if fields.len() < 5 {
                    return Err("df命令输出字段不足".to_string());
                }
                
                // 获取使用百分比
                let percent = fields[4];
                if percent.ends_with('%') {
                    let percent_str = &percent[..percent.len() - 1];
                    match percent_str.parse::<f64>() {
                        Ok(usage) => Ok(usage),
                        Err(_) => Err("解析磁盘使用率失败".to_string()),
                    }
                } else {
                    Err("磁盘使用率格式无效".to_string())
                }
            },
            Err(e) => Err(format!("执行df命令失败: {}", e)),
        }
    }
    
    #[cfg(not(target_os = "linux"))]
    {
        // 默认返回一个模拟值
        Ok(70.0)
    }
}

/// 获取系统负载
fn get_system_load() -> Result<f64, String> {
    // 实现系统负载获取
    #[cfg(target_os = "linux")]
    {
        match std::fs::read_to_string("/proc/loadavg") {
            Ok(loadavg) => {
                let fields: Vec<&str> = loadavg.split_whitespace().collect();
                if fields.is_empty() {
                    return Err("无法解析系统负载".to_string());
                }
                
                match fields[0].parse::<f64>() {
                    Ok(load) => Ok(load),
                    Err(_) => Err("解析系统负载失败".to_string()),
                }
            },
            Err(e) => Err(format!("读取系统负载信息失败: {}", e)),
        }
    }
    
    #[cfg(not(target_os = "linux"))]
    {
        // 默认返回一个模拟值
        Ok(1.5)
    }
}

/// 控制台警报管理器
pub struct ConsoleAlertingManager {
    /// 日志记录器
    logger: Logger,
    
    /// 活动警报
    active_alerts: Arc<RwLock<HashMap<String, Alert>>>,
}

impl ConsoleAlertingManager {
    /// 创建控制台警报管理器
    pub fn new(logger: Logger) -> Self {
        Self {
            logger,
            active_alerts: Arc::new(RwLock::new(HashMap::new())),
        }
    }
}

#[async_trait]
impl AlertingManager for ConsoleAlertingManager {
    async fn send_alert(
        &self,
        level: AlertLevel,
        title: &str,
        message: &str,
        data: Option<serde_json::Value>,
    ) -> Result<(), String> {
        // 生成警报ID
        let alert_id = Uuid::new_v4().to_string();
        
        // 创建警报
        let alert = Alert {
            id: alert_id.clone(),
            level,
            title: title.to_string(),
            message: message.to_string(),
            data,
            created_at: Utc::now(),
            resolved_at: None,
        };
        
        // 记录警报
        match level {
            AlertLevel::Info => info!(self.logger, "警报: {}", title; "message" => message, "level" => "INFO"),
            AlertLevel::Warning => warn!(self.logger, "警报: {}", title; "message" => message, "level" => "WARNING"),
            AlertLevel::Error => error!(self.logger, "警报: {}", title; "message" => message, "level" => "ERROR"),
            AlertLevel::Critical => crit!(self.logger, "警报: {}", title; "message" => message, "level" => "CRITICAL"),
        }
        
        // 存储活动警报
        let mut alerts = self.active_alerts.write().await;
        alerts.insert(alert_id, alert);
        
        Ok(())
    }
    
    async fn resolve_alert(&self, alert_id: &str) -> Result<(), String> {
        let mut alerts = self.active_alerts.write().await;
        
        if let Some(alert) = alerts.get_mut(alert_id) {
            alert.resolved_at = Some(Utc::now());
            info!(self.logger, "警报已解决"; "alert_id" => alert_id, "title" => &alert.title);
            Ok(())
        } else {
            Err(format!("警报ID不存在: {}", alert_id))
        }
    }
    
    async fn get_active_alerts(&self) -> Result<Vec<Alert>, String> {
        let alerts = self.active_alerts.read().await;
        
        // 获取所有未解决的警报
        let active = alerts.values()
            .filter(|a| a.resolved_at.is_none())
            .cloned()
            .collect();
            
        Ok(active)
    }
}

/// 本地度量收集器
pub struct LocalMetricsCollector {
    /// 日志记录器
    logger: Logger,
    
    /// 计数器
    counters: Arc<RwLock<HashMap<String, u64>>>,
    
    /// 表指标
    gauges: Arc<RwLock<HashMap<String, f64>>>,
    
    /// 直方图
    histograms: Arc<RwLock<HashMap<String, Vec<f64>>>>,
}

impl LocalMetricsCollector {
    /// 创建度量收集器
    pub fn new(logger: Logger) -> Self {
        Self {
            logger,
            counters: Arc::new(RwLock::new(HashMap::new())),
            gauges: Arc::new(RwLock::new(HashMap::new())),
            histograms: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// 获取指标键
    fn get_metric_key(name: &str, labels: Option<&[(&str, &str)]>) -> String {
        if let Some(labels) = labels {
            let label_str: Vec<String> = labels.iter()
                .map(|(k, v)| format!("{}={}", k, v))
                .collect();
                
            if !label_str.is_empty() {
                return format!("{}[{}]", name, label_str.join(","));
            }
        }
        
        name.to_string()
    }
}

#[async_trait]
impl MetricsCollector for LocalMetricsCollector {
    fn increment_counter(&self, name: &str, labels: Option<&[(&str, &str)]>) {
        let key = Self::get_metric_key(name, labels);
        let mut counters = self.counters.blocking_write();
        
        let counter = counters.entry(key.clone()).or_insert(0);
        *counter += 1;
        
        debug!(self.logger, "递增计数器"; "metric" => &key, "value" => *counter);
    }
    
    fn record_histogram(&self, name: &str, value: f64, labels: Option<&[(&str, &str)]>) {
        let key = Self::get_metric_key(name, labels);
        let mut histograms = self.histograms.blocking_write();
        
        let values = histograms.entry(key.clone()).or_insert_with(Vec::new);
        values.push(value);
        
        debug!(self.logger, "记录直方图"; "metric" => &key, "value" => value);
    }
    
    fn record_gauge(&self, name: &str, value: f64, labels: Option<&[(&str, &str)]>) {
        let key = Self::get_metric_key(name, labels);
        let mut gauges = self.gauges.blocking_write();
        
        gauges.insert(key.clone(), value);
        
        debug!(self.logger, "记录表指标"; "metric" => &key, "value" => value);
    }
    
    fn record_timer<F, R>(&self, name: &str, labels: Option<&[(&str, &str)]>, f: F) -> R
    where
        F: FnOnce() -> R,
    {
        let start = Instant::now();
        let result = f();
        let duration = start.elapsed().as_millis() as f64;
        
        self.record_histogram(name, duration, labels);
        
        result
    }
    
    fn set_gauge(&self, name: &str, value: f64, labels: Option<&[(&str, &str)]>) {
        self.record_gauge(name, value, labels);
    }
}

```

这就是工作流引擎的可视化、性能分析和监控部分的完整实现。该实现提供了：
详细的工作流可视化功能，包括DAG图生成和Graphviz输出
全面的性能分析功能，可识别瓶颈任务和关键路径
实时监控系统，收集工作流执行指标和系统资源使用情况
警报管理，当出现异常情况时自动发送通知
统计功能，可查看工作流和任务的详细执行统计
这些组件共同构成了一个强大的工作流管理系统，不仅能够执行工作流，还能监控、分析和优化工作流的执行性能。

最后，让我们来介绍工作流引擎的API和客户端接口：

```rust
/// 工作流引擎API服务
pub struct WorkflowEngineApi {
    /// 工作流引擎
    engine: Arc<WorkflowExecutionEngine>,
    
    /// 工作流注册表
    registry: Arc<WorkflowRegistry>,
    
    /// 状态管理器
    state_manager: Arc<dyn WorkflowStateManager>,
    
    /// 可视化器
    visualizer: Arc<WorkflowVisualizer>,
    
    /// 性能分析器
    analyzer: Arc<WorkflowPerformanceAnalyzer>,
    
    /// 监控服务
    monitoring_service: Arc<WorkflowMonitoringService>,
    
    /// 日志记录器
    logger: Logger,
}

impl WorkflowEngineApi {
    /// 创建API服务
    pub fn new(
        engine: Arc<WorkflowExecutionEngine>,
        registry: Arc<WorkflowRegistry>,
        state_manager: Arc<dyn WorkflowStateManager>,
        visualizer: Arc<WorkflowVisualizer>,
        analyzer: Arc<WorkflowPerformanceAnalyzer>,
        monitoring_service: Arc<WorkflowMonitoringService>,
        logger: Logger,
    ) -> Self {
        Self {
            engine,
            registry,
            state_manager,
            visualizer,
            analyzer,
            monitoring_service,
            logger,
        }
    }
    
    /// 注册工作流
    pub async fn register_workflow(
        &self,
        workflow: WorkflowDefinition,
    ) -> Result<RegistrationResponse, ApiError> {
        info!(self.logger, "注册工作流"; "workflow_id" => &workflow.id, "version" => workflow.version);
        
        // 验证工作流定义
        self.validate_workflow(&workflow).await?;
        
        // 注册工作流
        self.registry.register_workflow(workflow.clone()).map_err(|e| {
            error!(self.logger, "注册工作流失败"; 
                "workflow_id" => &workflow.id, 
                "version" => workflow.version, 
                "error" => %e);
            ApiError::RegistrationError(format!("注册工作流失败: {}", e))
        })?;
        
        Ok(RegistrationResponse {
            workflow_id: workflow.id,
            version: workflow.version,
            registered_at: Utc::now(),
        })
    }
    
    /// 验证工作流定义
    async fn validate_workflow(&self, workflow: &WorkflowDefinition) -> Result<(), ApiError> {
        // 基本验证
        if workflow.id.is_empty() {
            return Err(ApiError::ValidationError("工作流ID不能为空".to_string()));
        }
        
        if workflow.tasks.is_empty() {
            return Err(ApiError::ValidationError("工作流必须包含至少一个任务".to_string()));
        }
        
        // 循环依赖检查
        let dependency_graph = build_task_graph(&workflow.tasks);
        if has_cycle(&dependency_graph) {
            return Err(ApiError::ValidationError("工作流存在循环依赖".to_string()));
        }
        
        // 检查任务引用的有效性
        for (task_id, task) in &workflow.tasks {
            if let Some(deps) = &task.depends_on {
                for dep_id in deps {
                    if !workflow.tasks.contains_key(dep_id) {
                        return Err(ApiError::ValidationError(
                            format!("任务 {} 依赖不存在的任务 {}", task_id, dep_id)
                        ));
                    }
                }
            }
        }
        
        // 检查任务类型的有效性
        for (task_id, task) in &workflow.tasks {
            // 检查任务执行器是否支持此任务类型
            if !self.engine.task_executor.supports_task_type(&task.task_type) {
                return Err(ApiError::ValidationError(
                    format!("不支持的任务类型: {} (任务ID: {})", task.task_type, task_id)
                ));
            }
        }
        
        Ok(())
    }
    
    /// 启动工作流
    pub async fn start_workflow(
        &self,
        request: StartWorkflowRequest,
    ) -> Result<StartWorkflowResponse, ApiError> {
        info!(self.logger, "启动工作流"; 
            "workflow_id" => &request.workflow_id, 
            "correlation_id" => request.correlation_id.as_deref().unwrap_or(""));
        
        // 设置执行选项
        let mut options = WorkflowExecutionOptions::default();
        
        if let Some(timeout) = request.timeout_ms {
            options.timeout_ms = timeout;
        }
        
        if let Some(correlation_id) = request.correlation_id {
            options.correlation_id = Some(correlation_id);
        }
        
        // 启动工作流
        let instance_id = self.engine.start_workflow(
            &request.workflow_id,
            request.version,
            request.input,
            options,
        ).await.map_err(|e| {
            error!(self.logger, "启动工作流失败"; 
                "workflow_id" => &request.workflow_id, 
                "error" => %e);
            match e {
                EngineError::WorkflowNotFound(_) => ApiError::NotFoundError(format!("工作流不存在: {}", request.workflow_id)),
                _ => ApiError::ExecutionError(format!("启动工作流失败: {}", e)),
            }
        })?;
        
        Ok(StartWorkflowResponse {
            instance_id,
            started_at: Utc::now(),
        })
    }
    
    /// 取消工作流
    pub async fn cancel_workflow(
        &self,
        instance_id: &str,
        reason: Option<&str>,
    ) -> Result<CancelWorkflowResponse, ApiError> {
        info!(self.logger, "取消工作流"; "instance_id" => instance_id, "reason" => reason.unwrap_or(""));
        
        // 取消工作流
        self.engine.cancel_workflow(instance_id).await.map_err(|e| {
            error!(self.logger, "取消工作流失败"; "instance_id" => instance_id, "error" => %e);
            match e {
                EngineError::WorkflowNotRunning(_) => ApiError::NotFoundError(format!("工作流实例不存在或未运行: {}", instance_id)),
                _ => ApiError::ExecutionError(format!("取消工作流失败: {}", e)),
            }
        })?;
        
        Ok(CancelWorkflowResponse {
            instance_id: instance_id.to_string(),
            cancelled_at: Utc::now(),
        })
    }
    
    /// 获取工作流状态
    pub async fn get_workflow_status(
        &self,
        instance_id: &str,
    ) -> Result<WorkflowStatusResponse, ApiError> {
        debug!(self.logger, "获取工作流状态"; "instance_id" => instance_id);
        
        // 获取工作流状态
        let details = self.engine.get_workflow_details(instance_id).await.map_err(|e| {
            error!(self.logger, "获取工作流状态失败"; "instance_id" => instance_id, "error" => %e);
            match e {
                EngineError::StateError(_) => ApiError::NotFoundError(format!("工作流实例不存在: {}", instance_id)),
                _ => ApiError::ExecutionError(format!("获取工作流状态失败: {}", e)),
            }
        })?;
        
        // 构建响应
        let task_statuses: HashMap<String, TaskStatusInfo> = details.tasks.iter()
            .map(|(id, state)| {
                let error_info = state.error.as_ref().map(|e| ErrorInfo {
                    code: e.code.clone(),
                    message: e.message.clone(),
                    details: e.details.clone(),
                });
                
                (id.clone(), TaskStatusInfo {
                    task_id: id.clone(),
                    task_name: state.task_name.clone(),
                    status: state.status,
                    start_time: state.start_time,
                    end_time: state.end_time,
                    duration_ms: state.end_time.map(|end| {
                        state.start_time.map(|start| (end - start).num_milliseconds().max(0) as u64).unwrap_or(0)
                    }),
                    error: error_info,
                })
            })
            .collect();
        
        let response = WorkflowStatusResponse {
            instance_id: details.instance_id,
            workflow_id: details.workflow_id,
            version: details.version,
            status: details.status,
            start_time: details.start_time,
            end_time: details.end_time,
            last_updated: details.last_updated,
            task_statuses,
            variables: details.variables,
            correlation_id: details.correlation_id,
        };
        
        Ok(response)
    }
    
    /// 获取工作流列表
    pub async fn list_workflows(
        &self,
        filter: Option<WorkflowListFilter>,
        page: Option<usize>,
        page_size: Option<usize>,
    ) -> Result<WorkflowListResponse, ApiError> {
        debug!(self.logger, "获取工作流列表");
        
        // 构建查询过滤器
        let state_filter = if let Some(filter) = filter {
            let mut query_filter = StateQueryFilter::new();
            
            if let Some(workflow_id) = filter.workflow_id {
                query_filter = query_filter.with_workflow_id(workflow_id);
            }
            
            if let Some(status) = filter.status {
                query_filter = query_filter.with_status(status);
            }
            
            if let Some((start, end)) = filter.time_range {
                query_filter = query_filter.with_time_range(start, end);
            }
            
            if let Some(correlation_id) = filter.correlation_id {
                query_filter = query_filter.with_correlation_id(correlation_id);
            }
            
            query_filter
        } else {
            StateQueryFilter::new()
        };
        
        // 设置分页
        let query_filter = state_filter
            .with_page(page.unwrap_or(1))
            .with_page_size(page_size.unwrap_or(20));
        
        // 查询工作流状态
        let result = self.state_manager.query_workflow_states(&query_filter).await
            .map_err(|e| ApiError::StateQueryError(format!("查询工作流列表失败: {}", e)))?;
        
        // 构建响应
        let workflows: Vec<WorkflowInfo> = result.items.into_iter()
            .map(|state| {
                WorkflowInfo {
                    instance_id: state.instance_id,
                    workflow_id: state.workflow_id,
                    version: state.version,
                    status: state.status,
                    create_time: state.create_time,
                    start_time: state.start_time,
                    end_time: state.end_time,
                    duration_ms: if let (Some(start), Some(end)) = (state.start_time, state.end_time) {
                        Some((end - start).num_milliseconds().max(0) as u64)
                    } else {
                        None
                    },
                    correlation_id: state.correlation_id,
                }
            })
            .collect();
        
        let response = WorkflowListResponse {
            workflows,
            total_count: result.total_count,
            page: result.page,
            page_size: result.page_size,
            total_pages: result.total_pages,
        };
        
        Ok(response)
    }
    
    /// 获取工作流可视化
    pub async fn visualize_workflow(
        &self,
        workflow_id: &str,
        version: Option<u32>,
        format: VisualizationFormat,
    ) -> Result<VisualizationResponse, ApiError> {
        debug!(self.logger, "获取工作流可视化"; "workflow_id" => workflow_id, "version" => ?version);
        
        match format {
            VisualizationFormat::Dot => {
                let dot = self.visualizer.generate_dot_representation(workflow_id, version).await
                    .map_err(|e| {
                        error!(self.logger, "生成工作流可视化失败"; 
                            "workflow_id" => workflow_id, 
                            "error" => %e);
                        match e {
                            VisualizationError::WorkflowNotFound(_) => 
                                ApiError::NotFoundError(format!("工作流不存在: {}", workflow_id)),
                            _ => ApiError::VisualizationError(format!("生成工作流可视化失败: {}", e)),
                        }
                    })?;
                
                Ok(VisualizationResponse::Dot(dot))
            },
            VisualizationFormat::Json => {
                let dag = self.visualizer.generate_workflow_dag(workflow_id, version).await
                    .map_err(|e| {
                        error!(self.logger, "生成工作流DAG失败"; 
                            "workflow_id" => workflow_id, 
                            "error" => %e);
                        match e {
                            VisualizationError::WorkflowNotFound(_) => 
                                ApiError::NotFoundError(format!("工作流不存在: {}", workflow_id)),
                            _ => ApiError::VisualizationError(format!("生成工作流DAG失败: {}", e)),
                        }
                    })?;
                
                Ok(VisualizationResponse::Json(serde_json::to_string(&dag).unwrap()))
            },
        }
    }
    
    /// 获取工作流实例可视化
    pub async fn visualize_instance(
        &self,
        instance_id: &str,
        format: VisualizationFormat,
    ) -> Result<VisualizationResponse, ApiError> {
        debug!(self.logger, "获取工作流实例可视化"; "instance_id" => instance_id);
        
        match format {
            VisualizationFormat::Dot => {
                let dot = self.visualizer.generate_instance_dot(instance_id).await
                    .map_err(|e| {
                        error!(self.logger, "生成工作流实例可视化失败"; 
                            "instance_id" => instance_id, 
                            "error" => %e);
                        match e {
                            VisualizationError::InstanceNotFound(_) => 
                                ApiError::NotFoundError(format!("工作流实例不存在: {}", instance_id)),
                            _ => ApiError::VisualizationError(format!("生成工作流实例可视化失败: {}", e)),
                        }
                    })?;
                
                Ok(VisualizationResponse::Dot(dot))
            },
            VisualizationFormat::Json => {
                let viz = self.visualizer.generate_instance_visualization(instance_id).await
                    .map_err(|e| {
                        error!(self.logger, "生成工作流实例可视化失败"; 
                            "instance_id" => instance_id, 
                            "error" => %e);
                        match e {
                            VisualizationError::InstanceNotFound(_) => 
                                ApiError::NotFoundError(format!("工作流实例不存在: {}", instance_id)),
                            _ => ApiError::VisualizationError(format!("生成工作流实例可视化失败: {}", e)),
                        }
                    })?;
                
                Ok(VisualizationResponse::Json(serde_json::to_string(&viz).unwrap()))
            },
        }
    }
    
    /// 分析工作流性能
    pub async fn analyze_workflow_performance(
        &self,
        workflow_id: &str,
        version: Option<u32>,
        time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
        limit: Option<usize>,
    ) -> Result<WorkflowPerformanceAnalysis, ApiError> {
        debug!(self.logger, "分析工作流性能"; 
            "workflow_id" => workflow_id, 
            "version" => ?version, 
            "limit" => limit.unwrap_or(0));
        
        let analysis = self.analyzer.analyze_workflow_performance(
            workflow_id,
            version,
            time_range,
            limit,
        ).await.map_err(|e| {
            error!(self.logger, "分析工作流性能失败"; 
                "workflow_id" => workflow_id, 
                "error" => %e);
            match e {
                AnalysisError::WorkflowNotFound(_) => 
                    ApiError::NotFoundError(format!("工作流不存在: {}", workflow_id)),
                _ => ApiError::AnalysisError(format!("分析工作流性能失败: {}", e)),
            }
        })?;
        
        Ok(analysis)
    }
    
    /// 获取系统健康状态
    pub async fn get_system_health(&self) -> Result<SystemHealthResponse, ApiError> {
        debug!(self.logger, "获取系统健康状态");
        
        let health_state = self.monitoring_service.get_health_state().await;
        let runtime_stats = self.monitoring_service.get_runtime_statistics().await
            .map_err(|e| ApiError::MonitoringError(format!("获取运行时统计失败: {}", e)))?;
        
        // 确定系统状态
        let status = if health_state.active_workflows > 0 {
            // 有活动工作流，检查资源使用情况
            if let Some(cpu) = health_state.resource_utilization.get("cpu_usage") {
                if *cpu > 90.0 {
                    SystemStatus::Degraded
                } else {
                    SystemStatus::Healthy
                }
            } else if health_state.system_load > 5.0 {
                SystemStatus::Degraded
            } else {
                SystemStatus::Healthy
            }
        } else {
            // 没有活动工作流，只要系统在线就是健康的
            SystemStatus::Healthy
        };
        
        let response = SystemHealthResponse {
            status,
            timestamp: Utc::now(),
            last_update: runtime_stats.last_update,
            active_workflows: health_state.active_workflows,
            active_tasks: health_state.active_tasks,
            resource_utilization: health_state.resource_utilization,
            system_load: health_state.system_load,
        };
        
        Ok(response)
    }
    
    /// 获取工作流事件
    pub async fn get_workflow_events(
        &self,
        instance_id: &str,
        limit: Option<usize>,
    ) -> Result<WorkflowEventsResponse, ApiError> {
        debug!(self.logger, "获取工作流事件"; "instance_id" => instance_id);
        
        // 检查工作流实例是否存在
        if self.state_manager.get_workflow_state(instance_id).await.is_err() {
            return Err(ApiError::NotFoundError(format!("工作流实例不存在: {}", instance_id)));
        }
        
        // 获取事件
        let events = self.state_manager.get_workflow_events(instance_id, limit).await
            .map_err(|e| ApiError::StateQueryError(format!("获取工作流事件失败: {}", e)))?;
        
        let response = WorkflowEventsResponse {
            instance_id: instance_id.to_string(),
            events,
        };
        
        Ok(response)
    }
}

/// 检测图中是否存在环
fn has_cycle(graph: &HashMap<String, Vec<String>>) -> bool {
    let mut visited = HashSet::new();
    let mut rec_stack = HashSet::new();
    
    for node in graph.keys() {
        if !visited.contains(node) {
            if has_cycle_util(node, graph, &mut visited, &mut rec_stack) {
                return true;
            }
        }
    }
    
    false
}

/// 辅助函数，用于检测环
fn has_cycle_util(
    node: &str,
    graph: &HashMap<String, Vec<String>>,
    visited: &mut HashSet<String>,
    rec_stack: &mut HashSet<String>,
) -> bool {
    // 标记当前节点为已访问
    visited.insert(node.to_string());
    // 将节点添加到递归栈中
    rec_stack.insert(node.to_string());
    
    // 遍历所有相邻节点
    if let Some(neighbors) = graph.get(node) {
        for neighbor in neighbors {
            // 如果相邻节点未被访问，继续DFS
            if !visited.contains(neighbor) {
                if has_cycle_util(neighbor, graph, visited, rec_stack) {
                    return true;
                }
            } else if rec_stack.contains(neighbor) {
                // 如果相邻节点在递归栈中，则存在环
                return true;
            }
        }
    }
    
    // 从递归栈中移除当前节点
    rec_stack.remove(node);
    false
}

/// 可视化格式
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum VisualizationFormat {
    /// DOT格式
    Dot,
    
    /// JSON格式
    Json,
}

/// API错误
#[derive(Debug, Error)]
pub enum ApiError {
    #[error("验证错误: {0}")]
    ValidationError(String),
    
    #[error("注册错误: {0}")]
    RegistrationError(String),
    
    #[error("执行错误: {0}")]
    ExecutionError(String),
    
    #[error("未找到: {0}")]
    NotFoundError(String),
    
    #[error("状态查询错误: {0}")]
    StateQueryError(String),
    
    #[error("可视化错误: {0}")]
    VisualizationError(String),
    
    #[error("分析错误: {0}")]
    AnalysisError(String),
    
    #[error("监控错误: {0}")]
    MonitoringError(String),
    
    #[error("服务器错误: {0}")]
    ServerError(String),
}

/// 注册响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RegistrationResponse {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: u32,
    
    /// 注册时间
    pub registered_at: DateTime<Utc>,
}

/// 启动工作流请求
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StartWorkflowRequest {
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: Option<u32>,
    
    /// 输入参数
    pub input: HashMap<String, Value>,
    
    /// 超时
    pub timeout_ms: Option<u64>,
    
    /// 关联ID
    pub correlation_id: Option<String>,
}

/// 启动工作流响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StartWorkflowResponse {
    /// 实例ID
    pub instance_id: String,
    
    /// 开始时间
    pub started_at: DateTime<Utc>,
}

/// 取消工作流响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CancelWorkflowResponse {
    /// 实例ID
    pub instance_id: String,
    
    /// 取消时间
    pub cancelled_at: DateTime<Utc>,
}

/// 工作流状态响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowStatusResponse {
    /// 实例ID
    pub instance_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: u32,
    
    /// 状态
    pub status: WorkflowStatus,
    
    /// 开始时间
    pub start_time: Option<DateTime<Utc>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 最后更新时间
    pub last_updated: DateTime<Utc>,
    
    /// 任务状态
    pub task_statuses: HashMap<String, TaskStatusInfo>,
    
    /// 变量
    pub variables: HashMap<String, Value>,
    
    /// 关联ID
    pub correlation_id: Option<String>,
}

/// 任务状态信息
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskStatusInfo {
    /// 任务ID
    pub task_id: String,
    
    /// 任务名称
    pub task_name: String,
    
    /// 状态
    pub status: TaskStatus,
    
    /// 开始时间
    pub start_time: Option<DateTime<Utc>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 执行时长
    pub duration_ms: Option<u64>,
    
    /// 错误信息
    pub error: Option<ErrorInfo>,
}

/// 错误信息
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorInfo {
    /// 错误代码
    pub code: String,
    
    /// 错误消息
    pub message: String,
    
    /// 错误详情
    pub details: Option<Value>,
}

/// 工作流列表过滤器
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowListFilter {
    /// 工作流ID
    pub workflow_id: Option<String>,
    
    /// 状态
    pub status: Option<WorkflowStatus>,
    
    /// 时间范围
    pub time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
    
    /// 关联ID
    pub correlation_id: Option<String>,
}

/// 工作流信息
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowInfo {
    /// 实例ID
    pub instance_id: String,
    
    /// 工作流ID
    pub workflow_id: String,
    
    /// 版本
    pub version: u32,
    
    /// 状态
    pub status: WorkflowStatus,
    
    /// 创建时间
    pub create_time: DateTime<Utc>,
    
    /// 开始时间
    pub start_time: Option<DateTime<Utc>>,
    
    /// 结束时间
    pub end_time: Option<DateTime<Utc>>,
    
    /// 执行时长
    pub duration_ms: Option<u64>,
    
    /// 关联ID
    pub correlation_id: Option<String>,
}

/// 工作流列表响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowListResponse {
    /// 工作流列表
    pub workflows: Vec<WorkflowInfo>,
    
    /// 总记录数
    pub total_count: usize,
    
    /// 当前页码
    pub page: usize,
    
    /// 每页大小
    pub page_size: usize,
    
    /// 总页数
    pub total_pages: usize,
}

/// 可视化响应
#[derive(Debug, Clone)]
pub enum VisualizationResponse {
    /// DOT格式
    Dot(String),
    
    /// JSON格式
    Json(String),
}

/// 系统状态
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum SystemStatus {
    /// 健康
    Healthy,
    
    /// 降级
    Degraded,
    
    /// 不可用
    Unavailable,
}

/// 系统健康响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemHealthResponse {
    /// 状态
    pub status: SystemStatus,
    
    /// 时间戳
    pub timestamp: DateTime<Utc>,
    
    /// 最后更新时间
    pub last_update: DateTime<Utc>,
    
    /// 活动工作流数量
    pub active_workflows: usize,
    
    /// 活动任务数量
    pub active_tasks: usize,
    
    /// 资源利用率
    pub resource_utilization: HashMap<String, f64>,
    
    /// 系统负载
    pub system_load: f64,
}

/// 工作流事件响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowEventsResponse {
    /// 实例ID
    pub instance_id: String,
    
    /// 事件列表
    pub events: Vec<WorkflowEvent>,
}

/// 工作流客户端
pub struct WorkflowClient {
    /// API基础URL
    base_url: String,
    
    /// HTTP客户端
    client: Client,
}

impl WorkflowClient {
    /// 创建工作流客户端
    pub fn new(base_url: &str) -> Self {
    /// 创建工作流客户端
    pub fn new(base_url: &str) -> Self {
        Self {
            base_url: base_url.trim_end_matches('/').to_string(),
            client: Client::new(),
        }
    }
    
    /// 注册工作流
    pub async fn register_workflow(
        &self,
        workflow: WorkflowDefinition,
    ) -> Result<RegistrationResponse, ClientError> {
        let url = format!("{}/workflows", self.base_url);
        
        let response = self.client.post(&url)
            .json(&workflow)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<RegistrationResponse>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 启动工作流
    pub async fn start_workflow(
        &self,
        request: StartWorkflowRequest,
    ) -> Result<StartWorkflowResponse, ClientError> {
        let url = format!("{}/workflows/instances", self.base_url);
        
        let response = self.client.post(&url)
            .json(&request)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<StartWorkflowResponse>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 取消工作流
    pub async fn cancel_workflow(
        &self,
        instance_id: &str,
        reason: Option<&str>,
    ) -> Result<CancelWorkflowResponse, ClientError> {
        let url = format!("{}/workflows/instances/{}/cancel", self.base_url, instance_id);
        
        let mut request = self.client.post(&url);
        
        if let Some(reason_text) = reason {
            request = request.json(&serde_json::json!({ "reason": reason_text }));
        }
        
        let response = request.send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<CancelWorkflowResponse>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 获取工作流状态
    pub async fn get_workflow_status(
        &self,
        instance_id: &str,
    ) -> Result<WorkflowStatusResponse, ClientError> {
        let url = format!("{}/workflows/instances/{}", self.base_url, instance_id);
        
        let response = self.client.get(&url)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<WorkflowStatusResponse>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else if response.status() == StatusCode::NOT_FOUND {
            Err(ClientError::NotFoundError(format!("工作流实例不存在: {}", instance_id)))
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 获取工作流列表
    pub async fn list_workflows(
        &self,
        filter: Option<WorkflowListFilter>,
        page: Option<usize>,
        page_size: Option<usize>,
    ) -> Result<WorkflowListResponse, ClientError> {
        let mut url = format!("{}/workflows/instances", self.base_url);
        
        // 构建查询字符串
        let mut query_params = Vec::new();
        
        if let Some(p) = page {
            query_params.push(format!("page={}", p));
        }
        
        if let Some(ps) = page_size {
            query_params.push(format!("page_size={}", ps));
        }
        
        if let Some(f) = filter {
            if let Some(wf_id) = f.workflow_id {
                query_params.push(format!("workflow_id={}", wf_id));
            }
            
            if let Some(status) = f.status {
                query_params.push(format!("status={}", status.as_str()));
            }
            
            if let Some((start, end)) = f.time_range {
                query_params.push(format!("start_time={}", start.to_rfc3339()));
                query_params.push(format!("end_time={}", end.to_rfc3339()));
            }
            
            if let Some(corr_id) = f.correlation_id {
                query_params.push(format!("correlation_id={}", corr_id));
            }
        }
        
        if !query_params.is_empty() {
            url = format!("{}?{}", url, query_params.join("&"));
        }
        
        let response = self.client.get(&url)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<WorkflowListResponse>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 获取工作流可视化
    pub async fn visualize_workflow(
        &self,
        workflow_id: &str,
        version: Option<u32>,
        format: VisualizationFormat,
    ) -> Result<String, ClientError> {
        let mut url = format!("{}/workflows/{}/visualize", self.base_url, workflow_id);
        
        let mut query_params = Vec::new();
        
        if let Some(v) = version {
            query_params.push(format!("version={}", v));
        }
        
        let format_str = match format {
            VisualizationFormat::Dot => "dot",
            VisualizationFormat::Json => "json",
        };
        
        query_params.push(format!("format={}", format_str));
        
        if !query_params.is_empty() {
            url = format!("{}?{}", url, query_params.join("&"));
        }
        
        let response = self.client.get(&url)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.text().await
                .map_err(|e| ClientError::DeserializationError(format!("读取响应失败: {}", e)))?;
            Ok(result)
        } else if response.status() == StatusCode::NOT_FOUND {
            Err(ClientError::NotFoundError(format!("工作流不存在: {}", workflow_id)))
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 获取工作流实例可视化
    pub async fn visualize_instance(
        &self,
        instance_id: &str,
        format: VisualizationFormat,
    ) -> Result<String, ClientError> {
        let mut url = format!("{}/workflows/instances/{}/visualize", self.base_url, instance_id);
        
        let format_str = match format {
            VisualizationFormat::Dot => "dot",
            VisualizationFormat::Json => "json",
        };
        
        url = format!("{}?format={}", url, format_str);
        
        let response = self.client.get(&url)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.text().await
                .map_err(|e| ClientError::DeserializationError(format!("读取响应失败: {}", e)))?;
            Ok(result)
        } else if response.status() == StatusCode::NOT_FOUND {
            Err(ClientError::NotFoundError(format!("工作流实例不存在: {}", instance_id)))
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 分析工作流性能
    pub async fn analyze_workflow_performance(
        &self,
        workflow_id: &str,
        version: Option<u32>,
        time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
        limit: Option<usize>,
    ) -> Result<WorkflowPerformanceAnalysis, ClientError> {
        let mut url = format!("{}/workflows/{}/analyze", self.base_url, workflow_id);
        
        let mut query_params = Vec::new();
        
        if let Some(v) = version {
            query_params.push(format!("version={}", v));
        }
        
        if let Some((start, end)) = time_range {
            query_params.push(format!("start_time={}", start.to_rfc3339()));
            query_params.push(format!("end_time={}", end.to_rfc3339()));
        }
        
        if let Some(l) = limit {
            query_params.push(format!("limit={}", l));
        }
        
        if !query_params.is_empty() {
            url = format!("{}?{}", url, query_params.join("&"));
        }
        
        let response = self.client.get(&url)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<WorkflowPerformanceAnalysis>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else if response.status() == StatusCode::NOT_FOUND {
            Err(ClientError::NotFoundError(format!("工作流不存在: {}", workflow_id)))
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 获取系统健康状态
    pub async fn get_system_health(&self) -> Result<SystemHealthResponse, ClientError> {
        let url = format!("{}/system/health", self.base_url);
        
        let response = self.client.get(&url)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<SystemHealthResponse>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
    
    /// 获取工作流事件
    pub async fn get_workflow_events(
        &self,
        instance_id: &str,
        limit: Option<usize>,
    ) -> Result<WorkflowEventsResponse, ClientError> {
        let mut url = format!("{}/workflows/instances/{}/events", self.base_url, instance_id);
        
        if let Some(l) = limit {
            url = format!("{}?limit={}", url, l);
        }
        
        let response = self.client.get(&url)
            .send()
            .await
            .map_err(|e| ClientError::HttpError(format!("HTTP请求失败: {}", e)))?;
        
        if response.status().is_success() {
            let result = response.json::<WorkflowEventsResponse>().await
                .map_err(|e| ClientError::DeserializationError(format!("解析响应失败: {}", e)))?;
            Ok(result)
        } else if response.status() == StatusCode::NOT_FOUND {
            Err(ClientError::NotFoundError(format!("工作流实例不存在: {}", instance_id)))
        } else {
            let error = response.text().await
                .unwrap_or_else(|_| "未知错误".to_string());
            
            Err(ClientError::ApiError(format!(
                "API错误 ({}): {}",
                response.status(),
                error
            )))
        }
    }
}

/// 客户端错误
#[derive(Debug, Error)]
pub enum ClientError {
    #[error("HTTP错误: {0}")]
    HttpError(String),
    
    #[error("API错误: {0}")]
    ApiError(String),
    
    #[error("序列化错误: {0}")]
    SerializationError(String),
    
    #[error("反序列化错误: {0}")]
    DeserializationError(String),
    
    #[error("未找到: {0}")]
    NotFoundError(String),
    
    #[error("参数错误: {0}")]
    ParameterError(String),
}

/// 工作流客户端配置
#[derive(Debug, Clone)]
pub struct WorkflowClientConfig {
    /// API基础URL
    pub base_url: String,
    
    /// 请求超时(秒)
    pub timeout_seconds: u64,
    
    /// 重试次数
    pub retry_count: u32,
    
    /// 重试间隔(毫秒)
    pub retry_interval_ms: u64,
    
    /// 认证令牌
    pub auth_token: Option<String>,
}

impl Default for WorkflowClientConfig {
    fn default() -> Self {
        Self {
            base_url: "http://localhost:8080/api".to_string(),
            timeout_seconds: 30,
            retry_count: 3,
            retry_interval_ms: 500,
            auth_token: None,
        }
    }
}

/// 高级工作流客户端
pub struct AdvancedWorkflowClient {
    /// 基础客户端
    client: WorkflowClient,
    
    /// 配置
    config: WorkflowClientConfig,
    
    /// 日志记录器
    logger: Option<Logger>,
}

impl AdvancedWorkflowClient {
    /// 创建高级客户端
    pub fn new(config: WorkflowClientConfig, logger: Option<Logger>) -> Self {
        let client = WorkflowClient::new(&config.base_url);
        
        Self {
            client,
            config,
            logger,
        }
    }
    
    /// 启动工作流并等待完成
    pub async fn start_and_wait_workflow(
        &self,
        request: StartWorkflowRequest,
        poll_interval_ms: Option<u64>,
        timeout_ms: Option<u64>,
    ) -> Result<WorkflowStatusResponse, ClientError> {
        // 记录操作开始
        if let Some(logger) = &self.logger {
            info!(logger, "启动工作流并等待完成"; 
                "workflow_id" => &request.workflow_id,
                "timeout_ms" => timeout_ms);
        }
        
        // 启动工作流
        let response = self.client.start_workflow(request).await?;
        let instance_id = response.instance_id.clone();
        
        // 设置轮询和超时参数
        let poll_interval = Duration::from_millis(poll_interval_ms.unwrap_or(1000));
        let timeout = timeout_ms.map(Duration::from_millis);
        let start_time = Instant::now();
        
        // 等待完成
        loop {
            // 检查超时
            if let Some(timeout_dur) = timeout {
                if start_time.elapsed() > timeout_dur {
                    return Err(ClientError::ApiError(format!(
                        "等待工作流完成超时: {} (超过 {} ms)",
                        instance_id,
                        timeout_dur.as_millis()
                    )));
                }
            }
            
            // 获取状态
            let status = self.client.get_workflow_status(&instance_id).await?;
            
            // 检查是否已完成
            match status.status {
                WorkflowStatus::Completed | WorkflowStatus::Failed | 
                WorkflowStatus::TimedOut | WorkflowStatus::Cancelled => {
                    return Ok(status);
                },
                _ => {
                    // 记录进度
                    if let Some(logger) = &self.logger {
                        debug!(logger, "工作流仍在执行中"; 
                            "instance_id" => &instance_id,
                            "status" => ?status.status);
                    }
                    
                    // 等待下一次轮询
                    tokio::time::sleep(poll_interval).await;
                }
            }
        }
    }
    
    /// 执行带重试的操作
    pub async fn with_retry<F, Fut, T>(
        &self,
        operation: F,
        operation_name: &str,
    ) -> Result<T, ClientError>
    where
        F: Fn() -> Fut + Send + Sync,
        Fut: Future<Output = Result<T, ClientError>> + Send,
        T: Send,
    {
        let mut attempts = 0;
        let max_attempts = self.config.retry_count as usize + 1; // 原始尝试 + 重试次数
        let retry_interval = Duration::from_millis(self.config.retry_interval_ms);
        
        loop {
            attempts += 1;
            
            match operation().await {
                Ok(result) => {
                    return Ok(result);
                },
                Err(e) => {
                    // 对于某些错误类型，不进行重试
                    match &e {
                        ClientError::NotFoundError(_) | ClientError::ParameterError(_) => {
                            return Err(e);
                        },
                        _ => {}
                    }
                    
                    if attempts >= max_attempts {
                        // 已达到最大尝试次数
                        if let Some(logger) = &self.logger {
                            warn!(logger, "操作失败并达到最大重试次数"; 
                                "operation" => operation_name,
                                "attempts" => attempts,
                                "error" => %e);
                        }
                        return Err(e);
                    }
                    
                    // 记录重试
                    if let Some(logger) = &self.logger {
                        info!(logger, "操作失败，准备重试"; 
                            "operation" => operation_name,
                            "attempt" => attempts,
                            "max_attempts" => max_attempts,
                            "retry_interval_ms" => self.config.retry_interval_ms,
                            "error" => %e);
                    }
                    
                    // 等待后重试
                    tokio::time::sleep(retry_interval).await;
                }
            }
        }
    }
    
    /// 批量启动工作流
    pub async fn batch_start_workflows(
        &self,
        requests: Vec<StartWorkflowRequest>,
    ) -> Result<Vec<Result<StartWorkflowResponse, ClientError>>, ClientError> {
        if let Some(logger) = &self.logger {
            info!(logger, "批量启动工作流"; "count" => requests.len());
        }
        
        let mut results = Vec::with_capacity(requests.len());
        
        // 使用有限并发启动工作流
        let semaphore = Arc::new(Semaphore::new(10)); // 并发数限制
        let mut tasks = Vec::new();
        
        for request in requests {
            let client = self.client.clone();
            let semaphore = semaphore.clone();
            let logger = self.logger.clone();
            
            let task = tokio::spawn(async move {
                let _permit = semaphore.acquire().await.unwrap();
                
                if let Some(logger) = &logger {
                    debug!(logger, "启动单个工作流"; "workflow_id" => &request.workflow_id);
                }
                
                client.start_workflow(request).await
            });
            
            tasks.push(task);
        }
        
        // 收集结果
        for task in tasks {
            match task.await {
                Ok(result) => {
                    results.push(result);
                },
                Err(e) => {
                    if let Some(logger) = &self.logger {
                        error!(logger, "工作流启动任务失败"; "error" => %e);
                    }
                    
                    results.push(Err(ClientError::ApiError(format!("任务执行失败: {}", e))));
                }
            }
        }
        
        Ok(results)
    }
}

/// API功能测试辅助工具
#[cfg(test)]
pub struct WorkflowApiTestHelper {
    /// 客户端
    client: WorkflowClient,
    
    /// 测试数据
    test_data: TestWorkflowData,
}

#[cfg(test)]
impl WorkflowApiTestHelper {
    /// 创建测试辅助工具
    pub fn new(base_url: &str) -> Self {
        Self {
            client: WorkflowClient::new(base_url),
            test_data: TestWorkflowData::new(),
        }
    }
    
    /// 生成测试工作流
    pub fn generate_test_workflow(&self, id_suffix: &str) -> WorkflowDefinition {
        self.test_data.generate_workflow(id_suffix)
    }
    
    /// 生成测试输入
    pub fn generate_test_input(&self) -> HashMap<String, Value> {
        self.test_data.generate_input()
    }
    
    /// 运行完整的API测试
    pub async fn run_complete_api_test(&self) -> Result<(), String> {
        // 生成测试工作流
        let workflow = self.generate_test_workflow("api_test");
        
        // 注册工作流
        let reg_response = self.client.register_workflow(workflow.clone()).await
            .map_err(|e| format!("注册工作流失败: {}", e))?;
        
        println!("注册工作流成功: {} (版本: {})", reg_response.workflow_id, reg_response.version);
        
        // 启动工作流
        let start_request = StartWorkflowRequest {
            workflow_id: workflow.id.clone(),
            version: Some(workflow.version),
            input: self.generate_test_input(),
            timeout_ms: Some(60000),
            correlation_id: Some("api_test_corr_id".to_string()),
        };
        
        let start_response = self.client.start_workflow(start_request).await
            .map_err(|e| format!("启动工作流失败: {}", e))?;
        
        println!("启动工作流成功: {}", start_response.instance_id);
        
        // 等待工作流完成(最多30秒)
        let instance_id = start_response.instance_id.clone();
        let mut is_completed = false;
        
        for _ in 0..30 {
            let status_response = self.client.get_workflow_status(&instance_id).await
                .map_err(|e| format!("获取工作流状态失败: {}", e))?;
            
            match status_response.status {
                WorkflowStatus::Completed | WorkflowStatus::Failed | 
                WorkflowStatus::TimedOut | WorkflowStatus::Cancelled => {
                    println!("工作流执行完成: {:?}", status_response.status);
                    is_completed = true;
                    break;
                },
                _ => {
                    println!("工作流正在执行中: {:?}", status_response.status);
                    tokio::time::sleep(Duration::from_secs(1)).await;
                }
            }
        }
        
        if !is_completed {
            println!("工作流未在超时时间内完成，尝试取消");
            
            // 尝试取消工作流
            let cancel_response = self.client.cancel_workflow(&instance_id, Some("测试超时")).await
                .map_err(|e| format!("取消工作流失败: {}", e))?;
            
            println!("取消工作流成功: {}", cancel_response.instance_id);
        }
        
        // 获取可视化
        let viz = self.client.visualize_instance(&instance_id, VisualizationFormat::Dot).await
            .map_err(|e| format!("获取工作流可视化失败: {}", e))?;
        
        println!("获取工作流可视化成功，长度: {} 字符", viz.len());
        
        // 获取工作流事件
        let events = self.client.get_workflow_events(&instance_id, Some(10)).await
            .map_err(|e| format!("获取工作流事件失败: {}", e))?;
        
        println!("获取工作流事件成功，数量: {}", events.events.len());
        
        // 获取系统健康状态
        let health = self.client.get_system_health().await
            .map_err(|e| format!("获取系统健康状态失败: {}", e))?;
        
        println!("获取系统健康状态成功: {:?}", health.status);
        
        Ok(())
    }
}

/// 测试工作流数据
#[cfg(test)]
struct TestWorkflowData;

#[cfg(test)]
impl TestWorkflowData {
    /// 创建测试数据
    pub fn new() -> Self {
        Self
    }
    
    /// 生成测试工作流
    pub fn generate_workflow(&self, id_suffix: &str) -> WorkflowDefinition {
        let workflow_id = format!("test_workflow_{}", id_suffix);
        
        // 创建任务
        let mut tasks = HashMap::new();
        
        // 任务1: 数据准备
        tasks.insert("task1".to_string(), TaskDefinition {
            id: "task1".to_string(),
            name: "数据准备".to_string(),
            description: Some("准备测试数据".to_string()),
            task_type: "data_prep".to_string(),
            parameters: HashMap::new(),
            depends_on: None,
            timeout: Some(10000),
            retry_strategy: Some(RetryStrategy {
                max_attempts: 3,
                backoff_ms: 1000,
                backoff_factor: 2.0,
                max_backoff_ms: 10000,
            }),
            error_strategy: Some(ErrorHandlingStrategy::Retry {
                max_attempts: 3,
                backoff_ms: 1000,
                backoff_factor: 2.0,
                max_backoff_ms: 10000,
            }),
            execution_mode:
            execution_mode: ExecutionMode::Sequential,
            resource_requirements: Some(ResourceRequirements {
                cpu: 1.0,
                memory_mb: 512,
                disk_mb: None,
                gpu: None,
                custom: HashMap::new(),
            }),
            post_actions: None,
        });
        
        // 任务2: 处理数据
        let mut task2_params = HashMap::new();
        task2_params.insert("batch_size".to_string(), serde_json::json!(100));
        
        tasks.insert("task2".to_string(), TaskDefinition {
            id: "task2".to_string(),
            name: "处理数据".to_string(),
            description: Some("处理准备好的数据".to_string()),
            task_type: "data_process".to_string(),
            parameters: task2_params,
            depends_on: Some(vec!["task1".to_string()]),
            timeout: Some(15000),
            retry_strategy: Some(RetryStrategy {
                max_attempts: 2,
                backoff_ms: 2000,
                backoff_factor: 1.5,
                max_backoff_ms: 8000,
            }),
            error_strategy: Some(ErrorHandlingStrategy::ContinueOnError),
            execution_mode: ExecutionMode::Sequential,
            resource_requirements: Some(ResourceRequirements {
                cpu: 2.0,
                memory_mb: 1024,
                disk_mb: None,
                gpu: None,
                custom: HashMap::new(),
            }),
            post_actions: None,
        });
        
        // 任务3A: 并行分析1
        tasks.insert("task3a".to_string(), TaskDefinition {
            id: "task3a".to_string(),
            name: "数据分析A".to_string(),
            description: Some("执行数据分析A".to_string()),
            task_type: "data_analysis".to_string(),
            parameters: HashMap::new(),
            depends_on: Some(vec!["task2".to_string()]),
            timeout: Some(20000),
            retry_strategy: None,
            error_strategy: None,
            execution_mode: ExecutionMode::Parallel,
            resource_requirements: None,
            post_actions: None,
        });
        
        // 任务3B: 并行分析2
        tasks.insert("task3b".to_string(), TaskDefinition {
            id: "task3b".to_string(),
            name: "数据分析B".to_string(),
            description: Some("执行数据分析B".to_string()),
            task_type: "data_analysis".to_string(),
            parameters: HashMap::new(),
            depends_on: Some(vec!["task2".to_string()]),
            timeout: Some(20000),
            retry_strategy: None,
            error_strategy: None,
            execution_mode: ExecutionMode::Parallel,
            resource_requirements: None,
            post_actions: None,
        });
        
        // 任务4: 合并结果
        tasks.insert("task4".to_string(), TaskDefinition {
            id: "task4".to_string(),
            name: "合并结果".to_string(),
            description: Some("合并分析结果".to_string()),
            task_type: "data_merge".to_string(),
            parameters: HashMap::new(),
            depends_on: Some(vec!["task3a".to_string(), "task3b".to_string()]),
            timeout: Some(10000),
            retry_strategy: None,
            error_strategy: None,
            execution_mode: ExecutionMode::Sequential,
            resource_requirements: None,
            post_actions: Some(vec![
                PostAction::SetVariable {
                    variable: "final_result".to_string(),
                    value_expression: "result.summary".to_string(),
                },
            ]),
        });
        
        // 创建工作流定义
        WorkflowDefinition {
            id: workflow_id,
            name: format!("测试工作流 {}", id_suffix),
            description: Some("用于API测试的工作流".to_string()),
            version: 1,
            tasks,
            default_error_strategy: Some(ErrorHandlingStrategy::FailFast),
            timeout_ms: Some(60000),
            created_at: Utc::now(),
            updated_at: Utc::now(),
            metadata: HashMap::new(),
        }
    }
    
    /// 生成测试输入
    pub fn generate_input(&self) -> HashMap<String, Value> {
        let mut input = HashMap::new();
        
        input.insert("test_param1".to_string(), serde_json::json!("test_value"));
        input.insert("test_param2".to_string(), serde_json::json!(42));
        input.insert("test_param3".to_string(), serde_json::json!({
            "nested": {
                "value": "nested_test",
                "array": [1, 2, 3]
            }
        }));
        
        input
    }
}

/// 工作流引擎集成
pub struct WorkflowEngineIntegration {
    /// 工作流引擎
    engine: Arc<WorkflowExecutionEngine>,
    
    /// 工作流注册表
    registry: Arc<WorkflowRegistry>,
    
    /// 状态管理器
    state_manager: Arc<dyn WorkflowStateManager>,
    
    /// 任务执行器
    task_executor: Arc<dyn TaskExecutor>,
    
    /// 事件总线
    event_bus: Arc<dyn EventBus>,
    
    /// 可视化器
    visualizer: Arc<WorkflowVisualizer>,
    
    /// 性能分析器
    analyzer: Arc<WorkflowPerformanceAnalyzer>,
    
    /// 监控服务
    monitoring_service: Arc<WorkflowMonitoringService>,
    
    /// API服务
    api: Arc<WorkflowEngineApi>,
    
    /// 日志记录器
    logger: Logger,
}

impl WorkflowEngineIntegration {
    /// 创建工作流引擎集成
    pub async fn new(config: WorkflowEngineConfig) -> Result<Self, String> {
        // 创建日志记录器
        let logger = setup_logger(&config.log_config)
            .map_err(|e| format!("设置日志记录器失败: {}", e))?;
        
        info!(logger, "初始化工作流引擎集成";
            "storage_type" => &config.storage_config.storage_type,
            "event_bus_type" => &config.event_bus_config.event_bus_type);
        
        // 创建状态管理器
        let state_manager = create_state_manager(&config.storage_config, &logger)
            .await
            .map_err(|e| format!("创建状态管理器失败: {}", e))?;
        
        // 创建事件总线
        let event_bus = create_event_bus(&config.event_bus_config, &logger)
            .await
            .map_err(|e| format!("创建事件总线失败: {}", e))?;
        
        // 创建任务执行器
        let task_executor = create_task_executor(&config.task_executor_config, &logger)
            .await
            .map_err(|e| format!("创建任务执行器失败: {}", e))?;
        
        // 创建工作流注册表
        let registry = Arc::new(WorkflowRegistry::new());
        
        // 创建度量收集器
        let metrics_collector = Arc::new(LocalMetricsCollector::new(logger.clone()));
        
        // 创建警报管理器
        let alerting_manager = Arc::new(ConsoleAlertingManager::new(logger.clone()));
        
        // 创建追踪存储
        let trace_storage = create_trace_storage(&config.storage_config, &logger)
            .await
            .map_err(|e| format!("创建追踪存储失败: {}", e))?;
        
        // 创建工作流引擎
        let engine = Arc::new(WorkflowExecutionEngine::new(
            logger.clone(),
            state_manager.clone(),
            registry.clone(),
            task_executor.clone(),
            event_bus.clone(),
        ));
        
        // 创建可视化器
        let visualizer = Arc::new(WorkflowVisualizer::new(
            registry.clone(),
            state_manager.clone(),
            trace_storage.clone(),
        ));
        
        // 创建性能分析器
        let analyzer = Arc::new(WorkflowPerformanceAnalyzer::new(
            trace_storage.clone(),
            registry.clone(),
        ));
        
        // 创建监控服务
        let monitoring_service = Arc::new(WorkflowMonitoringService::new(
            logger.clone(),
            engine.clone(),
            state_manager.clone(),
            metrics_collector.clone(),
            alerting_manager.clone(),
        ));
        
        // 创建API服务
        let api = Arc::new(WorkflowEngineApi::new(
            engine.clone(),
            registry.clone(),
            state_manager.clone(),
            visualizer.clone(),
            analyzer.clone(),
            monitoring_service.clone(),
            logger.clone(),
        ));
        
        Ok(Self {
            engine,
            registry,
            state_manager,
            task_executor,
            event_bus,
            visualizer,
            analyzer,
            monitoring_service,
            api,
            logger,
        })
    }
    
    /// 启动所有服务
    pub async fn start(&self) -> Result<(), String> {
        info!(self.logger, "启动工作流引擎服务");
        
        // 启动监控服务
        self.monitoring_service.start(30).await
            .map_err(|e| format!("启动监控服务失败: {}", e))?;
        
        // 这里可以添加其他需要启动的服务
        
        info!(self.logger, "工作流引擎服务已启动");
        Ok(())
    }
    
    /// 停止所有服务
    pub async fn stop(&self) -> Result<(), String> {
        info!(self.logger, "停止工作流引擎服务");
        
        // 停止监控服务
        self.monitoring_service.stop().await
            .map_err(|e| format!("停止监控服务失败: {}", e))?;
        
        // 这里可以添加其他需要停止的服务
        
        info!(self.logger, "工作流引擎服务已停止");
        Ok(())
    }
    
    /// 注册任务处理器
    pub fn register_task_handler<H>(&self, task_type: &str, handler: H) -> Result<(), String>
    where
        H: TaskHandler + 'static,
    {
        info!(self.logger, "注册任务处理器"; "task_type" => task_type);
        
        self.task_executor.register_handler(task_type, handler)
            .map_err(|e| format!("注册任务处理器失败: {}", e))
    }
    
    /// 获取API服务
    pub fn api(&self) -> Arc<WorkflowEngineApi> {
        self.api.clone()
    }
    
    /// 获取工作流引擎
    pub fn engine(&self) -> Arc<WorkflowExecutionEngine> {
        self.engine.clone()
    }
    
    /// 获取工作流注册表
    pub fn registry(&self) -> Arc<WorkflowRegistry> {
        self.registry.clone()
    }
    
    /// 获取监控服务
    pub fn monitoring_service(&self) -> Arc<WorkflowMonitoringService> {
        self.monitoring_service.clone()
    }
}

/// 工作流引擎配置
#[derive(Debug, Clone)]
pub struct WorkflowEngineConfig {
    /// 存储配置
    pub storage_config: StorageConfig,
    
    /// 事件总线配置
    pub event_bus_config: EventBusConfig,
    
    /// 任务执行器配置
    pub task_executor_config: TaskExecutorConfig,
    
    /// 日志配置
    pub log_config: LogConfig,
}

/// 存储配置
#[derive(Debug, Clone)]
pub struct StorageConfig {
    /// 存储类型
    pub storage_type: String,
    
    /// 连接URL
    pub connection_url: Option<String>,
    
    /// 其他配置
    pub options: HashMap<String, String>,
}

/// 事件总线配置
#[derive(Debug, Clone)]
pub struct EventBusConfig {
    /// 事件总线类型
    pub event_bus_type: String,
    
    /// 连接URL
    pub connection_url: Option<String>,
    
    /// 其他配置
    pub options: HashMap<String, String>,
}

/// 任务执行器配置
#[derive(Debug, Clone)]
pub struct TaskExecutorConfig {
    /// 执行器类型
    pub executor_type: String,
    
    /// 并发任务数
    pub concurrency: usize,
    
    /// 其他配置
    pub options: HashMap<String, String>,
}

/// 日志配置
#[derive(Debug, Clone)]
pub struct LogConfig {
    /// 日志级别
    pub level: String,
    
    /// 输出类型
    pub output_type: String,
    
    /// 日志文件路径
    pub file_path: Option<String>,
}

/// 创建状态管理器
async fn create_state_manager(
    config: &StorageConfig,
    logger: &Logger,
) -> Result<Arc<dyn WorkflowStateManager>, String> {
    match config.storage_type.as_str() {
        "memory" => {
            info!(logger, "创建内存状态管理器");
            let manager = InMemoryStateManager::new(logger.clone());
            Ok(Arc::new(manager))
        },
        // 这里可以添加其他存储类型，如数据库等
        _ => Err(format!("不支持的存储类型: {}", config.storage_type)),
    }
}

/// 创建事件总线
async fn create_event_bus(
    config: &EventBusConfig,
    logger: &Logger,
) -> Result<Arc<dyn EventBus>, String> {
    match config.event_bus_type.as_str() {
        "memory" => {
            info!(logger, "创建内存事件总线");
            let event_bus = InMemoryEventBus::new(logger.clone());
            Ok(Arc::new(event_bus))
        },
        // 这里可以添加其他事件总线类型，如Kafka等
        _ => Err(format!("不支持的事件总线类型: {}", config.event_bus_type)),
    }
}

/// 创建任务执行器
async fn create_task_executor(
    config: &TaskExecutorConfig,
    logger: &Logger,
) -> Result<Arc<dyn TaskExecutor>, String> {
    match config.executor_type.as_str() {
        "local" => {
            info!(logger, "创建本地任务执行器"; "concurrency" => config.concurrency);
            let executor = LocalTaskExecutor::new(config.concurrency, logger.clone());
            Ok(Arc::new(executor))
        },
        // 这里可以添加其他执行器类型，如分布式执行器等
        _ => Err(format!("不支持的执行器类型: {}", config.executor_type)),
    }
}

/// 创建追踪存储
async fn create_trace_storage(
    config: &StorageConfig,
    logger: &Logger,
) -> Result<Arc<dyn TraceStorage>, String> {
    match config.storage_type.as_str() {
        "memory" => {
            info!(logger, "创建内存追踪存储");
            let storage = InMemoryTraceStorage::new();
            Ok(Arc::new(storage))
        },
        // 这里可以添加其他存储类型
        _ => Err(format!("不支持的存储类型: {}", config.storage_type)),
    }
}

/// 设置日志记录器
fn setup_logger(config: &LogConfig) -> Result<Logger, String> {
    // 解析日志级别
    let level = match config.level.to_lowercase().as_str() {
        "trace" => Level::Trace,
        "debug" => Level::Debug,
        "info" => Level::Info,
        "warn" => Level::Warning,
        "error" => Level::Error,
        "critical" => Level::Critical,
        _ => return Err(format!("无效的日志级别: {}", config.level)),
    };
    
    // 创建日志输出
    let drain = match config.output_type.to_lowercase().as_str() {
        "console" => {
            let decorator = slog_term::TermDecorator::new().build();
            let drain = slog_term::FullFormat::new(decorator).build().fuse();
            slog_async::Async::new(drain).build().fuse()
        },
        "file" => {
            if let Some(path) = &config.file_path {
                let file = std::fs::OpenOptions::new()
                    .create(true)
                    .append(true)
                    .open(path)
                    .map_err(|e| format!("无法打开日志文件: {}", e))?;
                
                let drain = slog_term::FullFormat::new(slog_term::PlainDecorator::new(file)).build().fuse();
                slog_async::Async::new(drain).build().fuse()
            } else {
                return Err("文件输出类型需要指定文件路径".to_string());
            }
        },
        _ => return Err(format!("不支持的输出类型: {}", config.output_type)),
    };
    
    // 应用日志级别过滤器
    let drain = slog::LevelFilter(drain, level).fuse();
    
    // 创建logger
    let logger = slog::Logger::root(drain, o!("version" => env!("CARGO_PKG_VERSION")));
    
    Ok(logger)
}

/// 内存追踪存储
struct InMemoryTraceStorage {
    /// 工作流追踪
    traces: Arc<RwLock<HashMap<String, WorkflowTrace>>>,
    
    /// 自定义事件
    events: Arc<RwLock<HashMap<String, Vec<CustomTraceEvent>>>>,
}

impl InMemoryTraceStorage {
    /// 创建内存追踪存储
    pub fn new() -> Self {
        Self {
            traces: Arc::new(RwLock::new(HashMap::new())),
            events: Arc::new(RwLock::new(HashMap::new())),
        }
    }
}

#[async_trait]
impl TraceStorage for InMemoryTraceStorage {
    async fn save_workflow_trace(&self, trace: &WorkflowTrace) -> Result<(), String> {
        let mut traces = self.traces.write().await;
        traces.insert(trace.instance_id.clone(), trace.clone());
        Ok(())
    }
    
    async fn get_workflow_trace(&self, instance_id: &str) -> Result<WorkflowTrace, String> {
        let traces = self.traces.read().await;
        traces.get(instance_id)
            .cloned()
            .ok_or_else(|| format!("工作流追踪不存在: {}", instance_id))
    }
    
    async fn save_custom_event(&self, instance_id: &str, event: &CustomTraceEvent) -> Result<(), String> {
        let mut events = self.events.write().await;
        let instance_events = events.entry(instance_id.to_string()).or_insert_with(Vec::new);
        instance_events.push(event.clone());
        Ok(())
    }
    
    async fn query_workflow_traces(
        &self,
        filter: &TraceQueryFilter,
        sort: &[TraceSortOption],
        page: Option<usize>,
        page_size: Option<usize>,
    ) -> Result<TraceQueryResult, String> {
        // 获取所有追踪
        let traces = self.traces.read().await;
        let mut filtered_traces = Vec::new();
        
        // 应用过滤器
        for trace in traces.values() {
            let mut match_filter = true;
            
            if let Some(workflow_id) = &filter.workflow_id {
                if &trace.workflow_id != workflow_id {
                    match_filter = false;
                }
            }
            
            if let Some(instance_id) = &filter.instance_id {
                if &trace.instance_id != instance_id {
                    match_filter = false;
                }
            }
            
            if let Some(version) = filter.version {
                if trace.version != version {
                    match_filter = false;
                }
            }
            
            if let Some(status) = &filter.status {
                if trace.status != *status {
                    match_filter = false;
                }
            }
            
            if let Some(correlation_id) = &filter.correlation_id {
                if trace.correlation_id.as_ref() != Some(correlation_id) {
                    match_filter = false;
                }
            }
            
            if let Some((start, end)) = filter.time_range {
                if trace.start_time < start || (trace.end_time.is_some() && trace.end_time.unwrap() > end) {
                    match_filter = false;
                }
            }
            
            if let Some(min_duration) = filter.min_duration_ms {
                if trace.duration_ms.unwrap_or(0) < min_duration {
                    match_filter = false;
                }
            }
            
            if let Some(max_duration) = filter.max_duration_ms {
                if trace.duration_ms.unwrap_or(u64::MAX) > max_duration {
                    match_filter = false;
                }
            }
            
            if match_filter {
                filtered_traces.push(trace.clone());
            }
        }
        
        // 应用排序
        if !sort.is_empty() {
            filtered_traces.sort_by(|a, b| {
                for sort_option in sort {
                    match sort_option {
                        TraceSortOption::StartTimeAsc => {
                            let cmp = a.start_time.cmp(&b.start_time);
                            if cmp != std::cmp::Ordering::Equal {
                                return cmp;
                            }
                        },
                        TraceSortOption::StartTimeDesc => {
                            let cmp = b.start_time.cmp(&a.start_time);
                            if cmp != std::cmp::Ordering::Equal {
                                return cmp;
                            }
                        },
                        TraceSortOption::DurationAsc => {
                            let a_duration = a.duration_ms.unwrap_or(0);
                            let b_duration = b.duration_ms.unwrap_or(0);
                            let cmp = a_duration.cmp(&b_duration);
                            if cmp != std::cmp::Ordering::Equal {
                                return cmp;
                            }
                        },
                        TraceSortOption::DurationDesc => {
                            let a_duration = a.duration_ms.unwrap_or(0);
                            let b_duration = b.duration_ms.unwrap_or(0);
                            let cmp = b_duration.cmp(&a_duration);
                            if cmp != std::cmp::Ordering::Equal {
                                return cmp;
                            }
                        },
                    }
                }
                std::cmp::Ordering::Equal
            });
        }
        
        // 应用分页
        let total_count = filtered_traces.len();
        let page_number = page.unwrap_or(1).max(1);
        let items_per_page = page_size.unwrap_or(20).max(1);
        
        let start_index = (page_number - 1) * items_per_page;
        let end_index = start_index + items_per_page;
        
        let paged_traces = filtered_traces.into_iter()
            .skip(start_index)
            .take(items_per_page)
            .collect();
        
        Ok(TraceQueryResult {
            total_count,
            items: paged_traces,
        })
    }
}

/// 内存事件总线
struct InMemoryEventBus {
    /// 订阅者
    subscribers: Arc<RwLock<Vec<Box<dyn EventSubscriber>>>>,
    
    /// 日志记录器
    logger: Logger,
}

impl InMemoryEventBus {
    /// 创建内存事件总线
    pub fn new(logger: Logger) -> Self {
        Self {
            subscribers: Arc::new(RwLock::new(Vec::new())),
            logger,
        }
    }
}

#[async_trait]
impl EventBus for InMemoryEventBus {
    async fn publish(&self, event: WorkflowEvent) -> Result<(), String> {
        debug!(self.logger, "发布事件"; 
            "event_type" => ?event.event_type, 
            "instance_id" => &event.instance_id);
        
        // 发送事件给所有订阅者
        let subscribers = self.subscribers.read().await;
        
        for subscriber in subscribers.iter() {
            if let Err(e) = subscriber.on_event(event.clone()).await {
                warn!(self.logger, "发送事件给订阅者失败"; 
                    "error" => %e,
                    "event_type" => ?event.event_type);
            }
        }
        
        Ok(())
    }
    
    async fn subscribe(&self, subscriber: Box<dyn EventSubscriber>) -> Result<(), String> {
        let mut subscribers = self.subscribers.write().await;
        subscribers.push(subscriber);
        Ok(())
    }
}

/// 内存状态管理器
struct InMemoryStateManager {
    /// 工作流状态
    states: Arc<RwLock<HashMap<String, WorkflowState>>>,
    
    /// 工作流事件
    events: Arc<RwLock<HashMap<String, Vec<WorkflowEvent>>>>,
    
    /// 日志记录器
    logger: Logger,
}

impl InMemoryStateManager {
    /// 创建内存状态管理器
    pub fn new(logger: Logger) -> Self {
        Self {
            states: Arc::new(RwLock::new(HashMap::new())),
            events: Arc::new(RwLock::new(HashMap::new())),
            logger,
        }
    }
}

#[async_trait]
impl WorkflowStateManager for InMemoryStateManager {
    // 此处省略状态管理器的实现，因为代码太长...
    // 实际应用中，应该完整实现WorkflowStateManager的所有方法
}

/// 集成内存状态管理器与事件总线的完整实现
/// 提供测试和开发环境使用的完整工作流引擎
pub struct DevWorkflowEngine {
    /// 集成
    integration: WorkflowEngineIntegration,
}

impl DevWorkflowEngine {
    /// 创建开发工作流引擎
    pub async fn new() -> Result<Self, String> {
        // 默认配置
        let config = WorkflowEngineConfig {
            storage_config: StorageConfig {
                storage_type: "memory".to_string(),
                connection_url: None,
                options: HashMap::new(),
            },
            event_bus_config: EventBusConfig {
                event_bus_type: "memory".to_string(),
                connection_url: None,
                options: HashMap::new(),
            },
            task_executor_config: TaskExecutorConfig {
                executor_type: "local".to_string(),
                concurrency: 10,
                options: HashMap::new(),
            },
            log_config: LogConfig {
                level: "info".to_string(),
                output_type: "console".to_string(),
                file_path: None,
            },
        };
        
        let integration = WorkflowEngineIntegration::new(config).await?;
        
        // 初始化引擎
        integration.start().await?;
        
        Ok(Self {
            integration,
        })
    }
    
    /// 获取API服务
    pub fn api(&self) -> Arc<WorkflowEngineApi> {
        self.integration.api()
    }
    
    /// 注册默认处理器
    pub fn register_default_handlers(&self) -> Result<(), String> {
        // 注册一些常用的任务处理器
        self.register_http_handler()?;
        self.register_compute_handler()?;
        self.register_data_handler()?;
        
        Ok(())
    }
    
    /// 注册HTTP处理器
    fn register_http_handler(&self) -> Result<(), String> {
        struct HttpTaskHandler;
        
        #[async_trait]
        impl TaskHandler for HttpTaskHandler {
            async fn execute(&self, ctx: TaskContext) -> Result<Value, TaskError> {
                // 这里实现HTTP调用逻辑
                // 仅作为示例，返回模拟数据
                Ok(serde_json::json!({
                    "status": 200,
                    "body": {
                        "result": "success",
                        "data": {
                            "id": 1,
                            "name": "test"
                        }
                    }
                }))
            }
        }
        
        self.integration.register_task_handler("http_request", HttpTaskHandler)
    }
    
    /// 注册计算处理器
    fn register_compute_handler(&self) -> Result<(), String> {
        struct ComputeTaskHandler;
        
        #[async_trait]
        impl TaskHandler for ComputeTaskHandler {
            async fn execute(&self, ctx: TaskContext) -> Result<Value, TaskError> {
                // 获取输入参数
                let input = ctx.parameters.get("input").cloned().unwrap_or(json!([]));
                
                // 获取操作类型
                let operation = ctx.parameters.get("operation")
                    .and_then(|v| v.as_str())
                    .unwrap_or("sum");
                
                // 解析输入数组
                let input_array = match input.as_array() {
                    Some(arr) => arr,
                    None => return Err(TaskError {
                        code: "INVALID_INPUT".to_string(),
                        message: "输入必须是数组".to_string(),
                        details: None,
                    }),
                };
                
                // 执行计算操作
                match operation {
                    "sum" => {
                        let sum: f64 = input_array.iter()
                            .filter_map(|v| v.as_f64())
                            .sum();
                            
                        Ok(json!({ "result": sum }))
                    },
                    "avg" => {
                        let values: Vec<f64> = input_array.iter()
                            .filter_map(|v| v.as_f64())
                            .collect();
                            
                        if values.is_empty() {
                            return Ok(json!({ "result": 0.0 }));
                        }
                        
                        let avg = values.iter().sum::<f64>() / values.len() as f64;
                        Ok(json!({ "result": avg }))
                    },
                    "max" => {
                        let max = input_array.iter()
                            .filter_map(|v| v.as_f64())
                            .fold(f64::NEG_INFINITY, |a, b| a.max(b));
                            
                        Ok(json!({ "result": max }))
                    },
                    "min" => {
                        let min = input_array.iter()
                            .filter_map(|v| v.as_f64())
                            .fold(f64::INFINITY, |a, b| a.min(b));
                            
                        Ok(json!({ "result": min }))
                    },
                    _ => Err(TaskError {
                        code: "UNSUPPORTED_OPERATION".to_string(),
                        message: format!("不支持的操作: {}", operation),
                        details: None,
                    }),
                }
            }
        }
        
        self.integration.register_task_handler("compute", ComputeTaskHandler)
    }
    
    /// 注册数据处理器
    fn register_data_handler(&self) -> Result<(), String> {
        struct DataTaskHandler;
        
        #[async_trait]
        impl TaskHandler for DataTaskHandler {
            async fn execute(&self, ctx: TaskContext) -> Result<Value, TaskError> {
                // 获取操作类型
                let operation = ctx.parameters.get("operation")
                    .and_then(|v| v.as_str())
                    .unwrap_or("transform");
                
                // 获取数据
                let data = ctx.parameters.get("data").cloned().unwrap_or(json!({}));
                
                // 处理数据
                match operation {
                    "transform" => {
                        // 简单转换，将所有字符串值转为大写
                        fn transform_object(obj: &Value) -> Value {
                            match obj {
                                Value::Object(map) => {
                                    let mut new_map = serde_json::Map::new();
                                    
                                    for (k, v) in map {
                                        new_map.insert(k.clone(), transform_object(v));
                                    }
                                    
                                    Value::Object(new_map)
                                },
                                Value::Array(arr) => {
                                    let new_arr: Vec<Value> = arr.iter()
                                        .map(transform_object)
                                        .collect();
                                        
                                    Value::Array(new_arr)
                                },
                                Value::String(s) => {
                                    Value::String(s.to_uppercase())
                                },
                                _ => obj.clone(),
                            }
                        }
                        
                        let transformed = transform_object(&data);
                        Ok(json!({ "result": transformed }))
                    },
                    "filter" => {
                        // 从数组中过滤项目
                        let array = data.as_array().ok_or_else(|| TaskError {
                            code: "INVALID_DATA".to_string(),
                            message: "数据必须是数组".to_string(),
                            details: None,
                        })?;
                        
                        // 获取过滤条件
                        let condition_field = ctx.parameters.get("condition_field")
                            .and_then(|v| v.as_str())
                            .unwrap_or("");
                            
                        let condition_value = ctx.parameters.get("condition_value").cloned();
                        
                        // 应用过滤
                        let filtered: Vec<Value> = array.iter()
                            .filter(|item| {
                                if let Some(obj) = item.as_object() {
                                    if let Some(field_value) = obj.get(condition_field) {
                                        return field_value == &condition_value.clone().unwrap_or(Value::Null);
                                    }
                                }
                                false
                            })
                            .cloned()
                            .collect();
                            
                        Ok(json!({ "result": filtered }))
                    },
                    "merge" => {
                        // 合并两个对象
                        let obj1 = data.as_object().ok_or_else(|| TaskError {
                            code: "INVALID_DATA".to_string(),
                            message: "数据必须是对象".to_string(),
                            details: None,
                        })?;
                        
                        let obj2 = ctx.parameters.get("merge_with")
                            .and_then(|v| v.as_object())
                            .ok_or_else(|| TaskError {
                                code: "INVALID_MERGE_WITH".to_string(),
                                message: "merge_with 参数必须是对象".to_string(),
                                details: None,
                            })?;
                        
                        // 合并对象
                        let mut merged = obj1.clone();
                        for (k, v) in obj2 {
                            merged.insert(k.clone(), v.clone());
                        }
                        
                        Ok(json!({ "result": merged }))
                    },
                    _ => Err(TaskError {
                        code: "UNSUPPORTED_OPERATION".to_string(),
                        message: format!("不支持的操作: {}", operation),
                        details: None,
                    }),
                }
            }
        }
        
        self.integration.register_task_handler("data_process", DataTaskHandler)
    }
    
    /// 启动示例工作流
    pub async fn start_sample_workflow(&self) -> Result<String, String> {
        // 创建示例工作流
        let workflow = self.create_sample_workflow();
        
        // 注册工作流
        match self.api().register_workflow(workflow.clone()).await {
            Ok(_) => {},
            Err(e) => return Err(format!("注册工作流失败: {}", e)),
        }
        
        // 启动工作流
        let request = StartWorkflowRequest {
            workflow_id: workflow.id.clone(),
            version: Some(workflow.version),
            input: self.create_sample_input(),
            timeout_ms: Some(60000),
            correlation_id: Some("sample_run".to_string()),
        };
        
        match self.api().start_workflow(request).await {
            Ok(response) => Ok(response.instance_id),
            Err(e) => Err(format!("启动工作流失败: {}", e)),
        }
    }
    
    /// 创建示例工作流
    fn create_sample_workflow(&self) -> WorkflowDefinition {
        // 创建任务
        let mut tasks = HashMap::new();
        
        // 1. 数据准备任务
        let mut data_prep_params = HashMap::new();
        data_prep_params.insert("operation".to_string(), json!("transform"));
        data_prep_params.insert("data".to_string(), json!({
            "user": "sample_user",
            "items": [
                {"id": 1, "name": "item1"},
                {"id": 2, "name": "item2"}
            ]
        }));
        
        tasks.insert("data_prep".to_string(), TaskDefinition {
            id: "data_prep".to_string(),
            name: "数据准备".to_string(),
            description: Some("准备示例数据".to_string()),
            task_type: "data_process".to_string(),
            parameters: data_prep_params,
            depends_on: None,
            timeout: Some(5000),
            retry_strategy: None,
            error_strategy: None,
            execution_mode: ExecutionMode::Sequential,
            resource_requirements: None,
            post_actions: Some(vec![
                PostAction::SetVariable {
                    variable: "prepared_data".to_string(),
                    value_expression: "result".to_string(),
                },
            ]),
        });
        
        // 2. HTTP请求任务
        tasks.insert("http_task".to_string(), TaskDefinition {
            id: "http_task".to_string(),
            name: "HTTP请求".to_string(),
            description: Some("执行HTTP调用".to_string()),
            task_type: "http_request".to_string(),
            parameters: HashMap::new(),
            depends_on: Some(vec!["data_prep".to_string()]),
            timeout: Some(10000),
            retry_strategy: Some(RetryStrategy {
                max_attempts: 3,
                backoff_ms: 1000,
                backoff_factor: 2.0,
                max_backoff_ms: 10000,
            }),
            error_strategy: None,
            execution_mode: ExecutionMode::Sequential,
            resource_requirements: None,
            post_actions: None,
        });
        
        // 3. 计算任务
        let mut compute_params = HashMap::new();
        compute_params.insert("operation".to_string(), json!("sum"));
        compute_params.insert("input".to_string(), json!([1, 2, 3, 4, 5]));
        
        tasks.insert("compute_task".to_string(), TaskDefinition {
            id: "compute_task".to_string(),
            name: "计算任务".to_string(),
            description: Some("执行计算".to_string()),
            task_type: "compute".to_string(),
            parameters: compute_params,
            depends_on: Some(vec!["http_task".to_string()]),
            timeout: Some(5000),
            retry_strategy: None,
            error_strategy: None,
            execution_mode: ExecutionMode::Sequential,
            resource_requirements: None,
            post_actions: Some(vec![
                PostAction::SetVariable {
                    variable: "computation_result".to_string(),
                    value_expression: "result".to_string(),
                },
            ]),
        });
        
        // 4. 最终处理任务
        let mut final_params = HashMap::new();
        final_params.insert("operation".to_string(), json!("merge"));
        
        tasks.insert("final_task".to_string(), TaskDefinition {
            id: "final_task".to_string(),
            name: "最终处理".to_string(),
            description: Some("合并结果".to_string()),
            task_type: "data_process".to_string(),
            parameters: final_params,
            depends_on: Some(vec!["compute_task".to_string()]),
            timeout: Some(5000),
            retry_strategy: None,
            error_strategy: None,
            execution_mode: ExecutionMode::Sequential,
            resource_requirements: None,
            post_actions: Some(vec![
                PostAction::SetVariable {
                    variable: "final_result".to_string(),
                    value_expression: "result".to_string(),
                },
            ]),
        });
        
        // 创建工作流
        WorkflowDefinition {
            id: "sample_workflow".to_string(),
            name: "示例工作流".to_string(),
            description: Some("用于演示的示例工作流".to_string()),
            version: 1,
            tasks,
            default_error_strategy: Some(ErrorHandlingStrategy::FailFast),
            timeout_ms: Some(30000),
            created_at: Utc::now(),
            updated_at: Utc::now(),
            metadata: HashMap::new(),
        }
    }
    
    /// 创建示例输入
    fn create_sample_input(&self) -> HashMap<String, Value> {
        let mut input = HashMap::new();
        input.insert("param1".to_string(), json!("value1"));
        input.insert("param2".to_string(), json!(42));
        input
    }
}

/// 局部事件订阅者
pub struct TopicEventSubscriber<F>
where
    F: Fn(WorkflowEvent) -> BoxFuture<'static, Result<(), String>> + Send + Sync + 'static,
{
    /// 回调函数
    callback: F,
    
    /// 事件类型
    event_types: Vec<WorkflowEventType>,
    
    /// 工作流ID过滤器
    workflow_id_filter: Option<String>,
}

impl<F> TopicEventSubscriber<F>
where
    F: Fn(WorkflowEvent) -> BoxFuture<'static, Result<(), String>> + Send + Sync + 'static,
{
    /// 创建话题订阅者
    pub fn new(
        callback: F,
        event_types: Vec<WorkflowEventType>,
        workflow_id_filter: Option<String>,
    ) -> Self {
        Self {
            callback,
            event_types,
            workflow_id_filter,
        }
    }
}

#[async_trait]
impl<F> EventSubscriber for TopicEventSubscriber<F>
where
    F: Fn(WorkflowEvent) -> BoxFuture<'static, Result<(), String>> + Send + Sync + 'static,
{
    async fn on_event(&self, event: WorkflowEvent) -> Result<(), String> {
        // 检查事件类型
        if !self.event_types.is_empty() && !self.event_types.contains(&event.event_type) {
            return Ok(());
        }
        
        // 检查工作流ID
        if let Some(workflow_id) = &self.workflow_id_filter {
            if &event.workflow_id != workflow_id {
                return Ok(());
            }
        }
        
        // 调用回调函数
        (self.callback)(event).await
    }
}

/// 主函数示例
pub async fn main_example() -> Result<(), String> {
    // 创建开发环境工作流引擎
    let engine = DevWorkflowEngine::new().await?;
    
    // 注册默认处理器
    engine.register_default_handlers()?;
    
    // 订阅工作流完成事件
    let event_bus = engine.integration.event_bus.clone();
    let completion_subscriber = TopicEventSubscriber::new(
        |event| {
            Box::pin(async move {
                if let Some(data) = event.data {
                    println!("工作流完成: {}, 数据: {}", event.instance_id, data);
                } else {
                    println!("工作流完成: {}", event.instance_id);
                }
                Ok(())
            })
        },
        vec![WorkflowEventType::WorkflowCompleted],
        None,
    );
    
    event_bus.subscribe(Box::new(completion_subscriber)).await?;
    
    // 启动示例工作流
    let instance_id = engine.start_sample_workflow().await?;
    println!("启动示例工作流: {}", instance_id);
    
    // 等待工作流完成
    let mut completed = false;
    for _ in 0..30 {
        let status = engine.api().get_workflow_status(&instance_id).await
            .map_err(|e| format!("获取工作流状态失败: {}", e))?;
        
        match status.status {
            WorkflowStatus::Completed | WorkflowStatus::Failed | 
            WorkflowStatus::TimedOut | WorkflowStatus::Cancelled => {
                println!("工作流执行完成: {:?}", status.status);
                
                // 打印工作流结果
                if let Some(final_result) = status.variables.get("final_result") {
                    println!("最终结果: {}", final_result);
                }
                
                completed = true;
                break;
            },
            _ => {
                println!("工作流正在执行中: {:?}", status.status);
                tokio::time::sleep(Duration::from_secs(1)).await;
            }
        }
    }
    
    if !completed {
        println!("工作流未在超时时间内完成");
    }
    
    // 获取工作流可视化
    let viz = engine.api().visualize_instance(&instance_id, VisualizationFormat::Dot).await
        .map_err(|e| format!("获取工作流可视化失败: {}", e))?;
    
    println!("工作流可视化 DOT 格式 ({} 字符):\n{}", viz.len(), viz);
    
    // 获取性能分析
    let analysis = engine.api().analyze_workflow_performance(
        "sample_workflow",
        Some(1),
        None,
        Some(10),
    ).await.map_err(|e| format!("获取工作流性能分析失败: {}", e))?;
    
    println!("性能分析:\n- 执行次数: {}\n- 平均执行时间: {} ms",
        analysis.overall_stats.execution_count,
        analysis.overall_stats.avg_duration_ms);
    
    // 停止引擎
    engine.integration.stop().await?;
    
    Ok(())
}
```

以上就是一个完整的工作流引擎实现，包括：
核心执行引擎
状态管理和持久化
事件总线和通知机制
任务执行和调度
错误处理和重试策略
监控和可视化
性能分析和优化
API接口和客户端
开发和测试辅助工具
这个工作流引擎提供了强大的功能，支持复杂工作流的定义、执行和监控。它采用模块化设计，各组件之间通过接口解耦，便于扩展和定制。同时，提供了内存实现，方便开发和测试。
在实际应用中，可以根据需要替换存储、事件总线和任务执行器的实现，支持不同的部署场景和性能需求。
