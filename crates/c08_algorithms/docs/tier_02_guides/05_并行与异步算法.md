# 05 å¹¶è¡Œä¸å¼‚æ­¥ç®—æ³•

> **æ–‡æ¡£ç±»å‹**: Tier 2 - å®è·µæŒ‡å—  
> **ç›®æ ‡è¯»è€…**: éœ€è¦æå‡ç®—æ³•æ€§èƒ½çš„å¼€å‘è€…  
> **é¢„è®¡å­¦ä¹ æ—¶é—´**: 3-4å°æ—¶  
> **å‰ç½®çŸ¥è¯†**: [æ€§èƒ½ä¼˜åŒ–å®è·µ](./04_æ€§èƒ½ä¼˜åŒ–å®è·µ.md)

**æœ€åæ›´æ–°**: 2025-10-23  
**é€‚ç”¨ç‰ˆæœ¬**: Rust 1.90+

---

## ğŸ“‹ ç›®å½•

- [05 å¹¶è¡Œä¸å¼‚æ­¥ç®—æ³•](#05-å¹¶è¡Œä¸å¼‚æ­¥ç®—æ³•)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ¯ å­¦ä¹ ç›®æ ‡](#-å­¦ä¹ ç›®æ ‡)
  - [1. Rayon æ•°æ®å¹¶è¡Œ](#1-rayon-æ•°æ®å¹¶è¡Œ)
    - [1.1 åŸºæœ¬å¹¶è¡Œè¿­ä»£å™¨](#11-åŸºæœ¬å¹¶è¡Œè¿­ä»£å™¨)
    - [1.2 å¹¶è¡Œæ’åº](#12-å¹¶è¡Œæ’åº)
    - [1.3 å¹¶è¡Œæœç´¢](#13-å¹¶è¡Œæœç´¢)
  - [2. ä»»åŠ¡å¹¶è¡Œæ¨¡å¼](#2-ä»»åŠ¡å¹¶è¡Œæ¨¡å¼)
    - [2.1 fork-join æ¨¡å¼](#21-fork-join-æ¨¡å¼)
    - [2.2 åˆ†æ²»ç®—æ³•](#22-åˆ†æ²»ç®—æ³•)
    - [2.3 å¹¶è¡Œç®¡é“](#23-å¹¶è¡Œç®¡é“)
  - [3. å¼‚æ­¥ç®—æ³•åŸºç¡€](#3-å¼‚æ­¥ç®—æ³•åŸºç¡€)
    - [3.1 Tokio å¼‚æ­¥è¿è¡Œæ—¶](#31-tokio-å¼‚æ­¥è¿è¡Œæ—¶)
    - [3.2 å¼‚æ­¥æµå¤„ç†](#32-å¼‚æ­¥æµå¤„ç†)
    - [3.3 å¹¶å‘æ§åˆ¶](#33-å¹¶å‘æ§åˆ¶)
  - [4. å¹¶å‘æ•°æ®ç»“æ„](#4-å¹¶å‘æ•°æ®ç»“æ„)
    - [4.1 åŸå­æ“ä½œ](#41-åŸå­æ“ä½œ)
    - [4.2 å¹¶å‘ HashMap](#42-å¹¶å‘-hashmap)
    - [4.3 æ— é”é˜Ÿåˆ—](#43-æ— é”é˜Ÿåˆ—)
  - [5. å¹¶è¡Œç®—æ³•æ¨¡å¼](#5-å¹¶è¡Œç®—æ³•æ¨¡å¼)
    - [5.1 Map-Reduce](#51-map-reduce)
    - [5.2 åˆ†åŒºå¹¶è¡Œ](#52-åˆ†åŒºå¹¶è¡Œ)
  - [6. å¼‚æ­¥ IO ç®—æ³•](#6-å¼‚æ­¥-io-ç®—æ³•)
    - [6.1 å¹¶å‘æ–‡ä»¶è¯»å–](#61-å¹¶å‘æ–‡ä»¶è¯»å–)
    - [6.2 å¼‚æ­¥ç½‘ç»œè¯·æ±‚](#62-å¼‚æ­¥ç½‘ç»œè¯·æ±‚)
  - [7. æ€§èƒ½æƒè¡¡](#7-æ€§èƒ½æƒè¡¡)
    - [7.1 ä¸²è¡Œ vs å¹¶è¡Œé˜ˆå€¼](#71-ä¸²è¡Œ-vs-å¹¶è¡Œé˜ˆå€¼)
    - [7.2 å¼€é”€æµ‹é‡](#72-å¼€é”€æµ‹é‡)
  - [8. å®æˆ˜æ¡ˆä¾‹](#8-å®æˆ˜æ¡ˆä¾‹)
    - [æ¡ˆä¾‹ 1: å¹¶è¡Œå›¾åƒå¤„ç†](#æ¡ˆä¾‹-1-å¹¶è¡Œå›¾åƒå¤„ç†)
    - [æ¡ˆä¾‹ 2: å¹¶è¡ŒçŸ©é˜µä¹˜æ³•](#æ¡ˆä¾‹-2-å¹¶è¡ŒçŸ©é˜µä¹˜æ³•)
    - [æ¡ˆä¾‹ 3: å¹¶è¡Œ Web çˆ¬è™«](#æ¡ˆä¾‹-3-å¹¶è¡Œ-web-çˆ¬è™«)
  - [ğŸ”— ç›¸å…³èµ„æº](#-ç›¸å…³èµ„æº)

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- âœ… æŒæ¡ Rayon æ•°æ®å¹¶è¡Œç¼–ç¨‹
- âœ… ç†è§£ä»»åŠ¡å¹¶è¡Œ vs æ•°æ®å¹¶è¡Œ
- âœ… ä½¿ç”¨ Tokio å®ç°å¼‚æ­¥ç®—æ³•
- âœ… é€‰æ‹©åˆé€‚çš„å¹¶å‘æ•°æ®ç»“æ„
- âœ… é¿å…å¸¸è§å¹¶è¡Œç¼–ç¨‹é™·é˜±
- âœ… æµ‹é‡å¹¶è¡Œç®—æ³•çš„åŠ é€Ÿæ¯”

---

## 1. Rayon æ•°æ®å¹¶è¡Œ

### 1.1 åŸºæœ¬å¹¶è¡Œè¿­ä»£å™¨

```rust
use rayon::prelude::*;

// ä¸²è¡Œæ±‚å’Œ
fn sum_serial(data: &[i32]) -> i32 {
    data.iter().sum()
}

// å¹¶è¡Œæ±‚å’Œ
fn sum_parallel(data: &[i32]) -> i32 {
    data.par_iter().sum()
}

// å¹¶è¡Œ map
fn square_all_parallel(data: &[i32]) -> Vec<i32> {
    data.par_iter()
        .map(|&x| x * x)
        .collect()
}

// å¹¶è¡Œ filter
fn filter_even_parallel(data: &[i32]) -> Vec<i32> {
    data.par_iter()
        .filter(|&&x| x % 2 == 0)
        .copied()
        .collect()
}
```

### 1.2 å¹¶è¡Œæ’åº

```rust
use rayon::prelude::*;

fn parallel_sort_example() {
    let mut data = vec![5, 3, 8, 1, 9, 2, 7, 4, 6];
    
    // å¹¶è¡Œæ’åº
    data.par_sort_unstable();
    
    println!("{:?}", data);
}

// è‡ªå®šä¹‰å¹¶è¡Œæ’åº
fn parallel_quicksort<T: Ord + Send>(arr: &mut [T]) {
    if arr.len() <= 1 {
        return;
    }
    
    let pivot = partition(arr);
    let (left, right) = arr.split_at_mut(pivot);
    
    // å¹¶è¡Œå¤„ç†å·¦å³ä¸¤éƒ¨åˆ†
    rayon::join(
        || parallel_quicksort(left),
        || parallel_quicksort(&mut right[1..]),
    );
}

fn partition<T: Ord>(arr: &mut [T]) -> usize {
    let len = arr.len();
    let pivot = len - 1;
    let mut i = 0;
    
    for j in 0..len - 1 {
        if arr[j] <= arr[pivot] {
            arr.swap(i, j);
            i += 1;
        }
    }
    
    arr.swap(i, pivot);
    i
}
```

### 1.3 å¹¶è¡Œæœç´¢

```rust
use rayon::prelude::*;

// å¹¶è¡ŒæŸ¥æ‰¾
fn parallel_find(data: &[i32], target: i32) -> Option<usize> {
    data.par_iter()
        .position_any(|&x| x == target)
}

// å¹¶è¡Œæœ€å¤§å€¼
fn parallel_max(data: &[i32]) -> Option<i32> {
    data.par_iter()
        .copied()
        .max()
}

// å¹¶è¡Œå½’çº¦
fn parallel_reduce(data: &[i32]) -> i32 {
    data.par_iter()
        .copied()
        .reduce(|| 0, |a, b| a + b)
}
```

---

## 2. ä»»åŠ¡å¹¶è¡Œæ¨¡å¼

### 2.1 fork-join æ¨¡å¼

```rust
use rayon::prelude::*;

// è®¡ç®—æ–æ³¢é‚£å¥‘æ•°ï¼ˆä»»åŠ¡å¹¶è¡Œï¼‰
fn fibonacci_parallel(n: u32) -> u64 {
    if n <= 1 {
        return n as u64;
    }
    
    if n < 20 {  // å°é—®é¢˜ç›´æ¥è®¡ç®—
        return fibonacci_serial(n);
    }
    
    // å¤§é—®é¢˜å¹¶è¡Œåˆ†è§£
    let (a, b) = rayon::join(
        || fibonacci_parallel(n - 1),
        || fibonacci_parallel(n - 2),
    );
    
    a + b
}

fn fibonacci_serial(n: u32) -> u64 {
    let (mut a, mut b) = (0, 1);
    for _ in 0..n {
        let temp = a;
        a = b;
        b = temp + b;
    }
    a
}
```

### 2.2 åˆ†æ²»ç®—æ³•

```rust
// å¹¶è¡Œå½’å¹¶æ’åº
fn parallel_merge_sort<T: Ord + Clone + Send>(arr: &[T]) -> Vec<T> {
    if arr.len() <= 1000 {
        // å°æ•°ç»„ä¸²è¡Œå¤„ç†
        let mut result = arr.to_vec();
        result.sort_unstable();
        return result;
    }
    
    let mid = arr.len() / 2;
    let (left, right) = arr.split_at(mid);
    
    // å¹¶è¡Œå¤„ç†ä¸¤éƒ¨åˆ†
    let (left_sorted, right_sorted) = rayon::join(
        || parallel_merge_sort(left),
        || parallel_merge_sort(right),
    );
    
    merge(&left_sorted, &right_sorted)
}

fn merge<T: Ord + Clone>(left: &[T], right: &[T]) -> Vec<T> {
    let mut result = Vec::with_capacity(left.len() + right.len());
    let (mut i, mut j) = (0, 0);
    
    while i < left.len() && j < right.len() {
        if left[i] <= right[j] {
            result.push(left[i].clone());
            i += 1;
        } else {
            result.push(right[j].clone());
            j += 1;
        }
    }
    
    result.extend_from_slice(&left[i..]);
    result.extend_from_slice(&right[j..]);
    result
}
```

### 2.3 å¹¶è¡Œç®¡é“

```rust
use rayon::prelude::*;

// å¤šé˜¶æ®µå¹¶è¡Œå¤„ç†
fn parallel_pipeline(data: Vec<String>) -> Vec<String> {
    data.into_par_iter()
        .map(|s| stage1_parse(&s))  // é˜¶æ®µ1ï¼šè§£æ
        .map(|d| stage2_validate(d))  // é˜¶æ®µ2ï¼šéªŒè¯
        .filter_map(|d| d.ok())  // è¿‡æ»¤é”™è¯¯
        .map(|d| stage3_transform(d))  // é˜¶æ®µ3ï¼šè½¬æ¢
        .collect()
}

fn stage1_parse(s: &str) -> ParsedData {
    // è§£æé€»è¾‘
    ParsedData { value: s.to_string() }
}

fn stage2_validate(data: ParsedData) -> Result<ParsedData, String> {
    // éªŒè¯é€»è¾‘
    if data.value.is_empty() {
        Err("Empty data".to_string())
    } else {
        Ok(data)
    }
}

fn stage3_transform(data: ParsedData) -> String {
    // è½¬æ¢é€»è¾‘
    data.value.to_uppercase()
}

#[derive(Clone)]
struct ParsedData {
    value: String,
}
```

---

## 3. å¼‚æ­¥ç®—æ³•åŸºç¡€

### 3.1 Tokio å¼‚æ­¥è¿è¡Œæ—¶

```rust
use tokio;

#[tokio::main]
async fn main() {
    // å¹¶å‘æ‰§è¡Œå¤šä¸ªå¼‚æ­¥ä»»åŠ¡
    let task1 = async_computation(1);
    let task2 = async_computation(2);
    let task3 = async_computation(3);
    
    let (result1, result2, result3) = tokio::join!(task1, task2, task3);
    
    println!("ç»“æœ: {}, {}, {}", result1, result2, result3);
}

async fn async_computation(id: i32) -> i32 {
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    id * 2
}
```

### 3.2 å¼‚æ­¥æµå¤„ç†

```rust
use tokio_stream::{self as stream, StreamExt};

async fn process_stream() {
    let mut stream = stream::iter(0..100);
    
    while let Some(item) = stream.next().await {
        let processed = process_item(item).await;
        println!("å¤„ç†ç»“æœ: {}", processed);
    }
}

async fn process_item(item: i32) -> i32 {
    // æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†
    tokio::time::sleep(tokio::time::Duration::from_micros(10)).await;
    item * 2
}
```

### 3.3 å¹¶å‘æ§åˆ¶

```rust
use tokio::sync::Semaphore;
use std::sync::Arc;

async fn controlled_concurrency(items: Vec<i32>, max_concurrent: usize) {
    let semaphore = Arc::new(Semaphore::new(max_concurrent));
    let mut tasks = Vec::new();
    
    for item in items {
        let permit = semaphore.clone();
        let task = tokio::spawn(async move {
            let _permit = permit.acquire().await.unwrap();
            process_with_limit(item).await
        });
        tasks.push(task);
    }
    
    for task in tasks {
        let _ = task.await;
    }
}

async fn process_with_limit(item: i32) -> i32 {
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    item * 2
}
```

---

## 4. å¹¶å‘æ•°æ®ç»“æ„

### 4.1 åŸå­æ“ä½œ

```rust
use std::sync::atomic::{AtomicUsize, Ordering};
use rayon::prelude::*;

// å¹¶è¡Œè®¡æ•°å™¨
fn parallel_count(data: &[i32]) -> usize {
    let counter = AtomicUsize::new(0);
    
    data.par_iter().for_each(|&x| {
        if x % 2 == 0 {
            counter.fetch_add(1, Ordering::Relaxed);
        }
    });
    
    counter.load(Ordering::Relaxed)
}
```

### 4.2 å¹¶å‘ HashMap

```rust
use dashmap::DashMap;
use rayon::prelude::*;

// å¹¶è¡Œç»Ÿè®¡è¯é¢‘
fn parallel_word_count(words: &[String]) -> DashMap<String, usize> {
    let counts = DashMap::new();
    
    words.par_iter().for_each(|word| {
        *counts.entry(word.clone()).or_insert(0) += 1;
    });
    
    counts
}
```

### 4.3 æ— é”é˜Ÿåˆ—

```rust
use crossbeam::queue::SegQueue;
use rayon::prelude::*;

// ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼
fn producer_consumer_example() {
    let queue = SegQueue::new();
    
    // ç”Ÿäº§è€…
    rayon::scope(|s| {
        for i in 0..100 {
            let q = &queue;
            s.spawn(move |_| {
                q.push(i);
            });
        }
    });
    
    // æ¶ˆè´¹è€…
    let mut results = Vec::new();
    while let Some(item) = queue.pop() {
        results.push(item);
    }
    
    println!("å¤„ç†äº† {} ä¸ªé¡¹ç›®", results.len());
}
```

---

## 5. å¹¶è¡Œç®—æ³•æ¨¡å¼

### 5.1 Map-Reduce

```rust
use rayon::prelude::*;

// å¹¶è¡Œ Map-Reduce
fn parallel_map_reduce(data: &[i32]) -> i32 {
    data.par_iter()
        .map(|&x| x * x)  // Map: å¹³æ–¹
        .sum()  // Reduce: æ±‚å’Œ
}

// å¤æ‚çš„ Map-Reduce
fn word_frequency_parallel(texts: &[String]) -> std::collections::HashMap<String, usize> {
    use std::collections::HashMap;
    
    texts.par_iter()
        .flat_map(|text| {
            // Map: åˆ†è¯å¹¶è®¡æ•°
            let mut local_counts = HashMap::new();
            for word in text.split_whitespace() {
                *local_counts.entry(word.to_string()).or_insert(0) += 1;
            }
            local_counts
        })
        .fold(HashMap::new, |mut acc, (word, count)| {
            // Reduce: åˆå¹¶è®¡æ•°
            *acc.entry(word).or_insert(0) += count;
            acc
        })
        .reduce(HashMap::new, |mut acc, map| {
            // æœ€ç»ˆåˆå¹¶
            for (word, count) in map {
                *acc.entry(word).or_insert(0) += count;
            }
            acc
        })
}
```

### 5.2 åˆ†åŒºå¹¶è¡Œ

```rust
use rayon::prelude::*;

// å¹¶è¡Œå¿«é€Ÿæ’åºï¼ˆåˆ†åŒºå¹¶è¡Œï¼‰
fn parallel_partition_sort<T: Ord + Send>(arr: &mut [T]) {
    if arr.len() <= 10000 {
        arr.sort_unstable();
        return;
    }
    
    let pivot_index = partition_inplace(arr);
    let (left, right) = arr.split_at_mut(pivot_index);
    
    rayon::join(
        || parallel_partition_sort(left),
        || parallel_partition_sort(&mut right[1..]),
    );
}

fn partition_inplace<T: Ord>(arr: &mut [T]) -> usize {
    let len = arr.len();
    let pivot = len - 1;
    let mut i = 0;
    
    for j in 0..len - 1 {
        if arr[j] <= arr[pivot] {
            arr.swap(i, j);
            i += 1;
        }
    }
    
    arr.swap(i, pivot);
    i
}
```

---

## 6. å¼‚æ­¥ IO ç®—æ³•

### 6.1 å¹¶å‘æ–‡ä»¶è¯»å–

```rust
use tokio::fs::File;
use tokio::io::{AsyncReadExt, AsyncWriteExt};

async fn parallel_file_read(paths: Vec<String>) -> Vec<String> {
    let tasks: Vec<_> = paths.into_iter()
        .map(|path| tokio::spawn(async move {
            read_file(&path).await
        }))
        .collect();
    
    let mut results = Vec::new();
    for task in tasks {
        if let Ok(Ok(content)) = task.await {
            results.push(content);
        }
    }
    
    results
}

async fn read_file(path: &str) -> Result<String, std::io::Error> {
    let mut file = File::open(path).await?;
    let mut contents = String::new();
    file.read_to_string(&mut contents).await?;
    Ok(contents)
}
```

### 6.2 å¼‚æ­¥ç½‘ç»œè¯·æ±‚

```rust
use reqwest;

async fn parallel_http_requests(urls: Vec<String>) -> Vec<String> {
    let tasks: Vec<_> = urls.into_iter()
        .map(|url| tokio::spawn(async move {
            fetch_url(&url).await
        }))
        .collect();
    
    let mut results = Vec::new();
    for task in tasks {
        if let Ok(Ok(response)) = task.await {
            results.push(response);
        }
    }
    
    results
}

async fn fetch_url(url: &str) -> Result<String, reqwest::Error> {
    let response = reqwest::get(url).await?;
    response.text().await
}
```

---

## 7. æ€§èƒ½æƒè¡¡

### 7.1 ä¸²è¡Œ vs å¹¶è¡Œé˜ˆå€¼

```rust
use rayon::prelude::*;

// è‡ªé€‚åº”å¹¶è¡Œ
fn adaptive_sum(data: &[i32]) -> i32 {
    const PARALLEL_THRESHOLD: usize = 10000;
    
    if data.len() < PARALLEL_THRESHOLD {
        // å°æ•°æ®ä¸²è¡Œå¤„ç†
        data.iter().sum()
    } else {
        // å¤§æ•°æ®å¹¶è¡Œå¤„ç†
        data.par_iter().sum()
    }
}
```

### 7.2 å¼€é”€æµ‹é‡

```rust
use std::time::Instant;
use rayon::prelude::*;

fn benchmark_parallel_overhead() {
    for size in [100, 1000, 10000, 100000] {
        let data: Vec<i32> = (0..size).collect();
        
        // ä¸²è¡Œ
        let start = Instant::now();
        let sum1: i32 = data.iter().sum();
        let serial_time = start.elapsed();
        
        // å¹¶è¡Œ
        let start = Instant::now();
        let sum2: i32 = data.par_iter().sum();
        let parallel_time = start.elapsed();
        
        println!("n={}: ä¸²è¡Œ={:?}, å¹¶è¡Œ={:?}, åŠ é€Ÿæ¯”={:.2}x", 
            size, serial_time, parallel_time,
            serial_time.as_nanos() as f64 / parallel_time.as_nanos() as f64
        );
        
        assert_eq!(sum1, sum2);
    }
}
```

---

## 8. å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ 1: å¹¶è¡Œå›¾åƒå¤„ç†

```rust
use rayon::prelude::*;

struct Image {
    data: Vec<u8>,
    width: usize,
    height: usize,
}

impl Image {
    fn parallel_blur(&mut self, radius: usize) {
        let old_data = self.data.clone();
        
        self.data.par_iter_mut()
            .enumerate()
            .for_each(|(i, pixel)| {
                let x = i % self.width;
                let y = i / self.width;
                *pixel = self.compute_blur(&old_data, x, y, radius);
            });
    }
    
    fn compute_blur(&self, data: &[u8], x: usize, y: usize, radius: usize) -> u8 {
        let mut sum = 0u32;
        let mut count = 0u32;
        
        for dy in -(radius as isize)..=(radius as isize) {
            for dx in -(radius as isize)..=(radius as isize) {
                let nx = (x as isize + dx).max(0).min(self.width as isize - 1) as usize;
                let ny = (y as isize + dy).max(0).min(self.height as isize - 1) as usize;
                
                sum += data[ny * self.width + nx] as u32;
                count += 1;
            }
        }
        
        (sum / count) as u8
    }
}
```

### æ¡ˆä¾‹ 2: å¹¶è¡ŒçŸ©é˜µä¹˜æ³•

```rust
use rayon::prelude::*;

fn parallel_matrix_multiply(a: &[Vec<f32>], b: &[Vec<f32>]) -> Vec<Vec<f32>> {
    let n = a.len();
    let m = b[0].len();
    
    (0..n).into_par_iter()
        .map(|i| {
            (0..m).map(|j| {
                (0..b.len())
                    .map(|k| a[i][k] * b[k][j])
                    .sum()
            }).collect()
        })
        .collect()
}
```

### æ¡ˆä¾‹ 3: å¹¶è¡Œ Web çˆ¬è™«

```rust
use tokio;
use reqwest;
use std::sync::Arc;
use tokio::sync::Semaphore;

#[tokio::main]
async fn main() {
    let urls = vec![
        "https://example.com/page1",
        "https://example.com/page2",
        "https://example.com/page3",
    ];
    
    let results = crawl_concurrent(urls, 2).await;
    
    for (url, content) in results {
        println!("æŠ“å– {}: {} å­—èŠ‚", url, content.len());
    }
}

async fn crawl_concurrent(urls: Vec<&str>, max_concurrent: usize) -> Vec<(String, String)> {
    let semaphore = Arc::new(Semaphore::new(max_concurrent));
    let tasks: Vec<_> = urls.into_iter()
        .map(|url| {
            let url = url.to_string();
            let sem = semaphore.clone();
            tokio::spawn(async move {
                let _permit = sem.acquire().await.unwrap();
                let content = fetch_page(&url).await.unwrap_or_default();
                (url, content)
            })
        })
        .collect();
    
    let mut results = Vec::new();
    for task in tasks {
        if let Ok(result) = task.await {
            results.push(result);
        }
    }
    
    results
}

async fn fetch_page(url: &str) -> Result<String, reqwest::Error> {
    let response = reqwest::get(url).await?;
    response.text().await
}
```

---

## ğŸ”— ç›¸å…³èµ„æº

**å†…éƒ¨æ–‡æ¡£**:

- [æ€§èƒ½ä¼˜åŒ–å®è·µ](./04_æ€§èƒ½ä¼˜åŒ–å®è·µ.md) - åŸºç¡€ä¼˜åŒ–
- [ç®—æ³•å¤æ‚åº¦åˆ†æ](./03_ç®—æ³•å¤æ‚åº¦åˆ†æ.md) - ç†è®ºåŸºç¡€
- [è¯¦ç»†æŒ‡å—](../guides/async_algorithms.md) - å®Œæ•´å‚è€ƒ

**å¤–éƒ¨èµ„æº**:

- ğŸ¦€ [Rayon æ–‡æ¡£](https://docs.rs/rayon/)
- ğŸ“˜ [Tokio æ•™ç¨‹](https://tokio.rs/tokio/tutorial)
- ğŸŒ [Async Book](https://rust-lang.github.io/async-book/)

**å¹¶å‘åº“**:

- [rayon](https://github.com/rayon-rs/rayon) - æ•°æ®å¹¶è¡Œ
- [tokio](https://tokio.rs/) - å¼‚æ­¥è¿è¡Œæ—¶
- [crossbeam](https://github.com/crossbeam-rs/crossbeam) - å¹¶å‘å·¥å…·
- [dashmap](https://github.com/xacrimon/dashmap) - å¹¶å‘ HashMap

---

**è¿”å›**: [Tier 2 ç´¢å¼•](./README.md) | **å®Œæˆ**: âœ… C08 Tier 2 å…¨éƒ¨å®Œæˆï¼

---

**æ–‡æ¡£ç»´æŠ¤**: Documentation Team  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-23  
**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ
