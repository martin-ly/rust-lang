# ç®—æ³•çŸ¥è¯†å›¾è°±ç³»ç»Ÿ (Algorithm Knowledge Graph)

**ç‰ˆæœ¬**: 1.0.0  
**Rustç‰ˆæœ¬**: 1.90.0  
**åˆ›å»ºæ—¥æœŸ**: 2025å¹´10æœˆ19æ—¥  
**ç‰¹æ€§**: çŸ¥è¯†å›¾è°± + å…³ç³»ç½‘ç»œ + æ¦‚å¿µæ˜ å°„

---

## ğŸ“Š çŸ¥è¯†å›¾è°±æ¦‚è§ˆ

æœ¬æ–‡æ¡£æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„ç®—æ³•çŸ¥è¯†å›¾è°±ï¼Œå±•ç¤ºç®—æ³•ä¹‹é—´çš„å…³ç³»ã€ä¾èµ–ã€æ¼”åŒ–è·¯å¾„å’Œåº”ç”¨åœºæ™¯ã€‚

```mermaid
graph TB
    %% æ ¸å¿ƒæ¦‚å¿µå±‚
    Algorithm[ç®—æ³•æ ¸å¿ƒ]
    DataStructure[æ•°æ®ç»“æ„]
    Complexity[å¤æ‚åº¦ç†è®º]
    Paradigm[è®¾è®¡èŒƒå¼]
    
    %% ç®—æ³•èŒƒå¼åˆ†ç±»
    Algorithm --> DivideConquer[åˆ†æ²»æ³•]
    Algorithm --> DynamicProgramming[åŠ¨æ€è§„åˆ’]
    Algorithm --> Greedy[è´ªå¿ƒç®—æ³•]
    Algorithm --> Backtracking[å›æº¯ç®—æ³•]
    Algorithm --> BranchBound[åˆ†æ”¯é™ç•Œ]
    
    %% æ•°æ®ç»“æ„åˆ†ç±»
    DataStructure --> Linear[çº¿æ€§ç»“æ„]
    DataStructure --> Tree[æ ‘å½¢ç»“æ„]
    DataStructure --> Graph[å›¾ç»“æ„]
    DataStructure --> Hash[æ•£åˆ—ç»“æ„]
    
    %% çº¿æ€§ç»“æ„ç»†åˆ†
    Linear --> Array[æ•°ç»„]
    Linear --> LinkedList[é“¾è¡¨]
    Linear --> Stack[æ ˆ]
    Linear --> Queue[é˜Ÿåˆ—]
    
    %% æ ‘å½¢ç»“æ„ç»†åˆ†
    Tree --> BinaryTree[äºŒå‰æ ‘]
    Tree --> BST[äºŒå‰æœç´¢æ ‘]
    Tree --> AVL[AVLæ ‘]
    Tree --> RedBlack[çº¢é»‘æ ‘]
    Tree --> BTree[Bæ ‘]
    Tree --> Heap[å †]
    
    %% å›¾ç»“æ„ç»†åˆ†
    Graph --> DirectedGraph[æœ‰å‘å›¾]
    Graph --> UndirectedGraph[æ— å‘å›¾]
    Graph --> WeightedGraph[åŠ æƒå›¾]
    Graph --> DAG[æœ‰å‘æ— ç¯å›¾]
    
    %% ç®—æ³•ä¸æ•°æ®ç»“æ„å…³ç³»
    DivideConquer -.uses.-> Array
    DynamicProgramming -.uses.-> Array
    Greedy -.uses.-> Heap
    Backtracking -.uses.-> Stack
    
    %% å¤æ‚åº¦å…³ç³»
    Complexity --> TimeComplexity[æ—¶é—´å¤æ‚åº¦]
    Complexity --> SpaceComplexity[ç©ºé—´å¤æ‚åº¦]
    
    style Algorithm fill:#ff6b6b
    style DataStructure fill:#4ecdc4
    style Complexity fill:#45b7d1
    style Paradigm fill:#96ceb4
```

---

## ğŸ¯ ç®—æ³•åˆ†ç±»çŸ¥è¯†å›¾è°±

### 1. æ’åºç®—æ³•çŸ¥è¯†å›¾è°±

```mermaid
graph LR
    Sorting[æ’åºç®—æ³•] --> Comparison[æ¯”è¾ƒæ’åº]
    Sorting --> NonComparison[éæ¯”è¾ƒæ’åº]
    
    %% æ¯”è¾ƒæ’åºåˆ†æ”¯
    Comparison --> Simple[ç®€å•æ’åº O-nÂ²]
    Comparison --> Advanced[é«˜çº§æ’åº O-n_log_n]
    
    Simple --> BubbleSort[å†’æ³¡æ’åº]
    Simple --> SelectionSort[é€‰æ‹©æ’åº]
    Simple --> InsertionSort[æ’å…¥æ’åº]
    
    Advanced --> MergeSort[å½’å¹¶æ’åº]
    Advanced --> QuickSort[å¿«é€Ÿæ’åº]
    Advanced --> HeapSort[å †æ’åº]
    
    %% éæ¯”è¾ƒæ’åºåˆ†æ”¯
    NonComparison --> CountingSort[è®¡æ•°æ’åº O-n+k]
    NonComparison --> RadixSort[åŸºæ•°æ’åº O-dÃ—n+k]
    NonComparison --> BucketSort[æ¡¶æ’åº O-n+k]
    
    %% Rust 1.90 ç‰¹æ€§åº”ç”¨
    MergeSort -.async.-> AsyncMerge[å¼‚æ­¥å½’å¹¶]
    QuickSort -.parallel.-> ParallelQuick[å¹¶è¡Œå¿«æ’]
    HeapSort -.const_generic.-> GenericHeap[æ³›å‹å †æ’åº]
    
    %% ç®—æ³•å…³ç³»
    MergeSort -->|åˆ†æ²»æ€æƒ³| DivideConquer
    QuickSort -->|åˆ†æ²»æ€æƒ³| DivideConquer
    HeapSort -->|ä½¿ç”¨| HeapStructure[å †æ•°æ®ç»“æ„]
    
    style Sorting fill:#ff6b6b
    style Comparison fill:#4ecdc4
    style NonComparison fill:#45b7d1
    style AsyncMerge fill:#ffd93d
    style ParallelQuick fill:#ffd93d
```

#### Rust 1.90 æ’åºç®—æ³•å®ç°ç¤ºä¾‹

```rust
use std::cmp::Ordering;

/// å½’å¹¶æ’åº - å±•ç¤º Rust 1.90 const generic ç‰¹æ€§
pub fn merge_sort_generic<T: Ord + Clone, const N: usize>(arr: &mut [T; N]) {
    if arr.len() <= 1 {
        return;
    }
    
    let mid = arr.len() / 2;
    let mut left = arr[..mid].to_vec();
    let mut right = arr[mid..].to_vec();
    
    merge_sort_slice(&mut left);
    merge_sort_slice(&mut right);
    
    merge(arr, &left, &right);
}

fn merge_sort_slice<T: Ord + Clone>(arr: &mut [T]) {
    if arr.len() <= 1 {
        return;
    }
    
    let mid = arr.len() / 2;
    let mut left = arr[..mid].to_vec();
    let mut right = arr[mid..].to_vec();
    
    merge_sort_slice(&mut left);
    merge_sort_slice(&mut right);
    
    merge(arr, &left, &right);
}

fn merge<T: Ord + Clone>(arr: &mut [T], left: &[T], right: &[T]) {
    let (mut i, mut j, mut k) = (0, 0, 0);
    
    while i < left.len() && j < right.len() {
        if left[i] <= right[j] {
            arr[k] = left[i].clone();
            i += 1;
        } else {
            arr[k] = right[j].clone();
            j += 1;
        }
        k += 1;
    }
    
    while i < left.len() {
        arr[k] = left[i].clone();
        i += 1;
        k += 1;
    }
    
    while j < right.len() {
        arr[k] = right[j].clone();
        j += 1;
        k += 1;
    }
}

/// å¼‚æ­¥å½’å¹¶æ’åº - Rust 1.90 async fn in trait
pub trait AsyncSort {
    async fn sort_async(&mut self) -> Result<(), Box<dyn std::error::Error + Send + Sync>>;
}

impl<T: Ord + Clone + Send + Sync> AsyncSort for Vec<T> {
    async fn sort_async(&mut self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        if self.len() <= 1 {
            return Ok(());
        }
        
        let mid = self.len() / 2;
        let mut left = self[..mid].to_vec();
        let mut right = self[mid..].to_vec();
        
        // å¹¶è¡Œå¼‚æ­¥æ’åº
        let (left_res, right_res) = tokio::join!(
            async { merge_sort_slice(&mut left); Ok::<_, Box<dyn std::error::Error + Send + Sync>>(()) },
            async { merge_sort_slice(&mut right); Ok::<_, Box<dyn std::error::Error + Send + Sync>>(()) }
        );
        
        left_res?;
        right_res?;
        
        merge(self, &left, &right);
        Ok(())
    }
}

/// å¹¶è¡Œå¿«é€Ÿæ’åº - ä½¿ç”¨ rayon
pub fn quick_sort_parallel<T: Ord + Send>(arr: &mut [T]) {
    use rayon::prelude::*;
    
    if arr.len() <= 1 {
        return;
    }
    
    if arr.len() < 1000 {
        // å°æ•°ç»„ä½¿ç”¨ä¸²è¡Œæ’åº
        arr.sort_unstable();
        return;
    }
    
    let pivot_idx = partition(arr);
    let (left, right) = arr.split_at_mut(pivot_idx);
    
    rayon::join(
        || quick_sort_parallel(left),
        || quick_sort_parallel(&mut right[1..])
    );
}

fn partition<T: Ord>(arr: &mut [T]) -> usize {
    let len = arr.len();
    let pivot_idx = len / 2;
    arr.swap(pivot_idx, len - 1);
    
    let mut i = 0;
    for j in 0..len - 1 {
        if arr[j] <= arr[len - 1] {
            arr.swap(i, j);
            i += 1;
        }
    }
    
    arr.swap(i, len - 1);
    i
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_merge_sort_generic() {
        let mut arr = [64, 34, 25, 12, 22, 11, 90];
        merge_sort_generic(&mut arr);
        assert_eq!(arr, [11, 12, 22, 25, 34, 64, 90]);
    }
    
    #[tokio::test]
    async fn test_async_sort() {
        let mut vec = vec![64, 34, 25, 12, 22, 11, 90];
        vec.sort_async().await.unwrap();
        assert_eq!(vec, vec![11, 12, 22, 25, 34, 64, 90]);
    }
    
    #[test]
    fn test_parallel_quick_sort() {
        let mut arr = vec![64, 34, 25, 12, 22, 11, 90];
        quick_sort_parallel(&mut arr);
        assert_eq!(arr, vec![11, 12, 22, 25, 34, 64, 90]);
    }
}
```

---

### 2. å›¾ç®—æ³•çŸ¥è¯†å›¾è°±

```mermaid
graph TB
    GraphAlgo[å›¾ç®—æ³•] --> Traversal[éå†ç®—æ³•]
    GraphAlgo --> ShortestPath[æœ€çŸ­è·¯å¾„]
    GraphAlgo --> MST[æœ€å°ç”Ÿæˆæ ‘]
    GraphAlgo --> Connectivity[è¿é€šæ€§]
    GraphAlgo --> Matching[åŒ¹é…ç®—æ³•]
    GraphAlgo --> Flow[ç½‘ç»œæµ]
    
    %% éå†ç®—æ³•
    Traversal --> DFS[æ·±åº¦ä¼˜å…ˆ DFS]
    Traversal --> BFS[å¹¿åº¦ä¼˜å…ˆ BFS]
    
    %% æœ€çŸ­è·¯å¾„
    ShortestPath --> Dijkstra[Dijkstra O-E+V_log_V]
    ShortestPath --> BellmanFord[Bellman-Ford O-VE]
    ShortestPath --> Floyd[Floyd-Warshall O-VÂ³]
    ShortestPath --> SPFA[SPFA å¹³å‡O-kE]
    ShortestPath --> AStar[A* å¯å‘å¼æœç´¢]
    
    %% æœ€å°ç”Ÿæˆæ ‘
    MST --> Prim[Prim O-E+V_log_V]
    MST --> Kruskal[Kruskal O-E_log_E]
    
    %% è¿é€šæ€§
    Connectivity --> Tarjan[Tarjan å¼ºè¿é€šåˆ†é‡]
    Connectivity --> Kosaraju[Kosaraju å¼ºè¿é€šåˆ†é‡]
    Connectivity --> UnionFind[å¹¶æŸ¥é›†]
    
    %% ç½‘ç»œæµ
    Flow --> FordFulkerson[Ford-Fulkerson]
    Flow --> EdmondsKarp[Edmonds-Karp]
    Flow --> Dinic[Dinic O-VÂ²E]
    
    %% æ•°æ®ç»“æ„ä¾èµ–
    Dijkstra -.uses.-> PriorityQueue[ä¼˜å…ˆé˜Ÿåˆ—]
    Prim -.uses.-> PriorityQueue
    Kruskal -.uses.-> UnionFind
    BFS -.uses.-> QueueStructure[é˜Ÿåˆ—]
    DFS -.uses.-> StackStructure[æ ˆ]
    
    %% Rust 1.90 ç‰¹æ€§
    Dijkstra -.async.-> AsyncDijkstra[å¼‚æ­¥ Dijkstra]
    BFS -.parallel.-> ParallelBFS[å¹¶è¡Œ BFS]
    
    style GraphAlgo fill:#ff6b6b
    style ShortestPath fill:#4ecdc4
    style MST fill:#45b7d1
    style Flow fill:#96ceb4
```

#### Rust 1.90 å›¾ç®—æ³•å®ç°ç¤ºä¾‹

```rust
use std::collections::{HashMap, BinaryHeap, VecDeque};
use std::cmp::Ordering;

/// å›¾çš„è¾¹è¡¨ç¤º
#[derive(Debug, Clone)]
pub struct Edge<V, W> {
    pub to: V,
    pub weight: W,
}

/// Dijkstra ç®—æ³•èŠ‚ç‚¹
#[derive(Debug, Clone, Eq, PartialEq)]
struct DijkstraNode<V, W> {
    vertex: V,
    distance: W,
}

impl<V: Eq, W: Ord> Ord for DijkstraNode<V, W> {
    fn cmp(&self, other: &Self) -> Ordering {
        other.distance.cmp(&self.distance)
    }
}

impl<V: Eq, W: Ord> PartialOrd for DijkstraNode<V, W> {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

/// Dijkstra æœ€çŸ­è·¯å¾„ - Rust 1.90 æ³›å‹çº¦æŸ
pub fn dijkstra<V, W>(
    graph: &HashMap<V, Vec<Edge<V, W>>>,
    start: V,
) -> HashMap<V, W>
where
    V: Eq + std::hash::Hash + Clone,
    W: Ord + Clone + Default + std::ops::Add<Output = W>,
{
    let mut distances: HashMap<V, W> = HashMap::new();
    let mut heap = BinaryHeap::new();
    
    distances.insert(start.clone(), W::default());
    heap.push(DijkstraNode {
        vertex: start,
        distance: W::default(),
    });
    
    while let Some(DijkstraNode { vertex, distance }) = heap.pop() {
        if let Some(&ref current_dist) = distances.get(&vertex) {
            if distance > current_dist.clone() {
                continue;
            }
        }
        
        if let Some(neighbors) = graph.get(&vertex) {
            for edge in neighbors {
                let new_distance = distance.clone() + edge.weight.clone();
                
                let is_shorter = distances
                    .get(&edge.to)
                    .map_or(true, |&ref d| new_distance < d.clone());
                
                if is_shorter {
                    distances.insert(edge.to.clone(), new_distance.clone());
                    heap.push(DijkstraNode {
                        vertex: edge.to.clone(),
                        distance: new_distance,
                    });
                }
            }
        }
    }
    
    distances
}

/// å¼‚æ­¥ Dijkstra - å±•ç¤º async fn in trait (Rust 1.90)
pub trait AsyncGraph<V, W> {
    async fn shortest_path(&self, start: V, end: V) -> Option<(Vec<V>, W)>;
}

pub struct AsyncGraphImpl<V, W> {
    pub adjacency_list: HashMap<V, Vec<Edge<V, W>>>,
}

impl<V, W> AsyncGraph<V, W> for AsyncGraphImpl<V, W>
where
    V: Eq + std::hash::Hash + Clone + Send + Sync + 'static,
    W: Ord + Clone + Default + std::ops::Add<Output = W> + Send + Sync + 'static,
{
    async fn shortest_path(&self, start: V, end: V) -> Option<(Vec<V>, W)> {
        // æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œï¼ˆå¦‚ä»è¿œç¨‹åŠ è½½å›¾æ•°æ®ï¼‰
        tokio::time::sleep(tokio::time::Duration::from_micros(1)).await;
        
        let distances = dijkstra(&self.adjacency_list, start.clone());
        
        distances.get(&end).map(|dist| {
            // ç®€åŒ–ç‰ˆï¼šåªè¿”å›è·ç¦»ï¼Œå®é™…åº”è¯¥é‡æ„è·¯å¾„
            (vec![start, end], dist.clone())
        })
    }
}

/// BFS å¹¿åº¦ä¼˜å…ˆæœç´¢
pub fn bfs<V>(
    graph: &HashMap<V, Vec<V>>,
    start: V,
) -> Vec<V>
where
    V: Eq + std::hash::Hash + Clone,
{
    let mut visited = std::collections::HashSet::new();
    let mut queue = VecDeque::new();
    let mut result = Vec::new();
    
    queue.push_back(start.clone());
    visited.insert(start);
    
    while let Some(vertex) = queue.pop_front() {
        result.push(vertex.clone());
        
        if let Some(neighbors) = graph.get(&vertex) {
            for neighbor in neighbors {
                if visited.insert(neighbor.clone()) {
                    queue.push_back(neighbor.clone());
                }
            }
        }
    }
    
    result
}

/// å¹¶è¡Œ BFS - ä½¿ç”¨ rayon
pub fn parallel_bfs<V>(
    graph: &HashMap<V, Vec<V>>,
    start: V,
) -> Vec<V>
where
    V: Eq + std::hash::Hash + Clone + Send + Sync,
{
    use rayon::prelude::*;
    use std::sync::{Arc, Mutex};
    
    let visited = Arc::new(Mutex::new(std::collections::HashSet::new()));
    let result = Arc::new(Mutex::new(Vec::new()));
    
    let mut current_level = vec![start.clone()];
    visited.lock().unwrap().insert(start);
    
    while !current_level.is_empty() {
        // å¤„ç†å½“å‰å±‚
        result.lock().unwrap().extend(current_level.clone());
        
        // å¹¶è¡Œè·å–ä¸‹ä¸€å±‚
        let next_level: Vec<V> = current_level
            .par_iter()
            .flat_map(|vertex| {
                graph.get(vertex).map(|neighbors| {
                    neighbors
                        .iter()
                        .filter(|n| {
                            let mut v = visited.lock().unwrap();
                            v.insert((*n).clone())
                        })
                        .cloned()
                        .collect::<Vec<_>>()
                }).unwrap_or_default()
            })
            .collect();
        
        current_level = next_level;
    }
    
    Arc::try_unwrap(result).unwrap().into_inner().unwrap()
}

/// å¹¶æŸ¥é›† (Union-Find) - è·¯å¾„å‹ç¼© + æŒ‰ç§©åˆå¹¶
pub struct UnionFind {
    parent: Vec<usize>,
    rank: Vec<usize>,
}

impl UnionFind {
    pub fn new(size: usize) -> Self {
        Self {
            parent: (0..size).collect(),
            rank: vec![0; size],
        }
    }
    
    pub fn find(&mut self, x: usize) -> usize {
        if self.parent[x] != x {
            self.parent[x] = self.find(self.parent[x]); // è·¯å¾„å‹ç¼©
        }
        self.parent[x]
    }
    
    pub fn union(&mut self, x: usize, y: usize) -> bool {
        let root_x = self.find(x);
        let root_y = self.find(y);
        
        if root_x == root_y {
            return false;
        }
        
        // æŒ‰ç§©åˆå¹¶
        match self.rank[root_x].cmp(&self.rank[root_y]) {
            Ordering::Less => self.parent[root_x] = root_y,
            Ordering::Greater => self.parent[root_y] = root_x,
            Ordering::Equal => {
                self.parent[root_y] = root_x;
                self.rank[root_x] += 1;
            }
        }
        
        true
    }
    
    pub fn connected(&mut self, x: usize, y: usize) -> bool {
        self.find(x) == self.find(y)
    }
}

/// Kruskal æœ€å°ç”Ÿæˆæ ‘
pub fn kruskal(n: usize, mut edges: Vec<(usize, usize, i32)>) -> (i32, Vec<(usize, usize)>) {
    // æŒ‰æƒé‡æ’åº
    edges.sort_by_key(|e| e.2);
    
    let mut uf = UnionFind::new(n);
    let mut mst = Vec::new();
    let mut total_weight = 0;
    
    for (u, v, w) in edges {
        if uf.union(u, v) {
            mst.push((u, v));
            total_weight += w;
            
            if mst.len() == n - 1 {
                break;
            }
        }
    }
    
    (total_weight, mst)
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_dijkstra() {
        let mut graph = HashMap::new();
        graph.insert("A", vec![
            Edge { to: "B", weight: 4 },
            Edge { to: "C", weight: 2 },
        ]);
        graph.insert("B", vec![
            Edge { to: "D", weight: 5 },
        ]);
        graph.insert("C", vec![
            Edge { to: "B", weight: 1 },
            Edge { to: "D", weight: 8 },
        ]);
        graph.insert("D", vec![]);
        
        let distances = dijkstra(&graph, "A");
        assert_eq!(distances.get("D"), Some(&7));
    }
    
    #[tokio::test]
    async fn test_async_dijkstra() {
        let mut graph_data = HashMap::new();
        graph_data.insert("A", vec![
            Edge { to: "B", weight: 4 },
            Edge { to: "C", weight: 2 },
        ]);
        graph_data.insert("B", vec![
            Edge { to: "D", weight: 5 },
        ]);
        graph_data.insert("C", vec![
            Edge { to: "B", weight: 1 },
            Edge { to: "D", weight: 8 },
        ]);
        graph_data.insert("D", vec![]);
        
        let graph = AsyncGraphImpl {
            adjacency_list: graph_data,
        };
        
        let result = graph.shortest_path("A", "D").await;
        assert!(result.is_some());
        let (_, distance) = result.unwrap();
        assert_eq!(distance, 7);
    }
    
    #[test]
    fn test_kruskal() {
        let edges = vec![
            (0, 1, 10),
            (0, 2, 6),
            (0, 3, 5),
            (1, 3, 15),
            (2, 3, 4),
        ];
        
        let (total_weight, mst) = kruskal(4, edges);
        assert_eq!(total_weight, 19);
        assert_eq!(mst.len(), 3);
    }
}
```

---

### 3. åŠ¨æ€è§„åˆ’çŸ¥è¯†å›¾è°±

```mermaid
graph TB
    DP[åŠ¨æ€è§„åˆ’] --> Linear[çº¿æ€§DP]
    DP --> Interval[åŒºé—´DP]
    DP --> Tree[æ ‘å½¢DP]
    DP --> State[çŠ¶æ€å‹ç¼©DP]
    DP --> Digit[æ•°ä½DP]
    DP --> Probability[æ¦‚ç‡DP]
    
    %% çº¿æ€§DP
    Linear --> LCS[æœ€é•¿å…¬å…±å­åºåˆ—]
    Linear --> LIS[æœ€é•¿é€’å¢å­åºåˆ—]
    Linear --> EditDistance[ç¼–è¾‘è·ç¦»]
    Linear --> Knapsack[èƒŒåŒ…é—®é¢˜]
    
    %% èƒŒåŒ…é—®é¢˜ç»†åˆ†
    Knapsack --> Knapsack01[0-1èƒŒåŒ…]
    Knapsack --> KnapsackComplete[å®Œå…¨èƒŒåŒ…]
    Knapsack --> KnapsackMultiple[å¤šé‡èƒŒåŒ…]
    Knapsack --> KnapsackGrouped[åˆ†ç»„èƒŒåŒ…]
    
    %% åŒºé—´DP
    Interval --> MatrixChain[çŸ©é˜µé“¾ä¹˜]
    Interval --> StoneGame[çŸ³å­åˆå¹¶]
    
    %% çŠ¶æ€å‹ç¼©DP
    State --> TSP[æ—…è¡Œå•†é—®é¢˜]
    State --> Assignment[æŒ‡æ´¾é—®é¢˜]
    
    %% ä¼˜åŒ–æŠ€æœ¯
    DP --> Optimization[ä¼˜åŒ–æŠ€æœ¯]
    Optimization --> ScrollArray[æ»šåŠ¨æ•°ç»„]
    Optimization --> MonotonicQueue[å•è°ƒé˜Ÿåˆ—]
    Optimization --> SlopeOptimization[æ–œç‡ä¼˜åŒ–]
    
    %% Rust 1.90 ç‰¹æ€§
    LCS -.parallel.-> ParallelLCS[å¹¶è¡ŒLCS]
    Knapsack01 -.async.-> AsyncKnapsack[å¼‚æ­¥èƒŒåŒ…]
    
    style DP fill:#ff6b6b
    style Linear fill:#4ecdc4
    style Interval fill:#45b7d1
    style State fill:#96ceb4
```

#### Rust 1.90 åŠ¨æ€è§„åˆ’å®ç°ç¤ºä¾‹

```rust
/// æœ€é•¿å…¬å…±å­åºåˆ— (LCS) - æ ‡å‡†å®ç°
pub fn lcs(text1: &str, text2: &str) -> usize {
    let m = text1.len();
    let n = text2.len();
    let text1: Vec<char> = text1.chars().collect();
    let text2: Vec<char> = text2.chars().collect();
    
    let mut dp = vec![vec![0; n + 1]; m + 1];
    
    for i in 1..=m {
        for j in 1..=n {
            if text1[i - 1] == text2[j - 1] {
                dp[i][j] = dp[i - 1][j - 1] + 1;
            } else {
                dp[i][j] = dp[i - 1][j].max(dp[i][j - 1]);
            }
        }
    }
    
    dp[m][n]
}

/// LCS - æ»šåŠ¨æ•°ç»„ä¼˜åŒ– (ç©ºé—´ O(n))
pub fn lcs_optimized(text1: &str, text2: &str) -> usize {
    let text1: Vec<char> = text1.chars().collect();
    let text2: Vec<char> = text2.chars().collect();
    let (m, n) = (text1.len(), text2.len());
    
    let mut prev = vec![0; n + 1];
    let mut curr = vec![0; n + 1];
    
    for i in 1..=m {
        for j in 1..=n {
            if text1[i - 1] == text2[j - 1] {
                curr[j] = prev[j - 1] + 1;
            } else {
                curr[j] = prev[j].max(curr[j - 1]);
            }
        }
        std::mem::swap(&mut prev, &mut curr);
    }
    
    prev[n]
}

/// å¹¶è¡Œ LCS - ä½¿ç”¨ rayon åŠ é€Ÿå¤§è§„æ¨¡è®¡ç®—
pub fn lcs_parallel(text1: &str, text2: &str) -> usize {
    use rayon::prelude::*;
    
    if text1.len() < 1000 || text2.len() < 1000 {
        return lcs(text1, text2);
    }
    
    let mid = text1.len() / 2;
    let (left, right) = text1.split_at(mid);
    
    // å¹¶è¡Œè®¡ç®—ä¸¤éƒ¨åˆ†
    let (lcs_left, lcs_right) = rayon::join(
        || lcs(left, text2),
        || lcs(right, text2)
    );
    
    lcs_left.max(lcs_right)
}

/// 0-1 èƒŒåŒ…é—®é¢˜
pub fn knapsack_01(weights: &[i32], values: &[i32], capacity: i32) -> i32 {
    let n = weights.len();
    let cap = capacity as usize;
    let mut dp = vec![vec![0; cap + 1]; n + 1];
    
    for i in 1..=n {
        for w in 0..=cap {
            if weights[i - 1] as usize <= w {
                dp[i][w] = dp[i - 1][w].max(
                    dp[i - 1][w - weights[i - 1] as usize] + values[i - 1]
                );
            } else {
                dp[i][w] = dp[i - 1][w];
            }
        }
    }
    
    dp[n][cap]
}

/// 0-1 èƒŒåŒ… - æ»šåŠ¨æ•°ç»„ä¼˜åŒ–
pub fn knapsack_01_optimized(weights: &[i32], values: &[i32], capacity: i32) -> i32 {
    let cap = capacity as usize;
    let mut dp = vec![0; cap + 1];
    
    for i in 0..weights.len() {
        // å€’åºéå†é¿å…é‡å¤ä½¿ç”¨
        for w in (weights[i] as usize..=cap).rev() {
            dp[w] = dp[w].max(dp[w - weights[i] as usize] + values[i]);
        }
    }
    
    dp[cap]
}

/// å®Œå…¨èƒŒåŒ…é—®é¢˜
pub fn knapsack_complete(weights: &[i32], values: &[i32], capacity: i32) -> i32 {
    let cap = capacity as usize;
    let mut dp = vec![0; cap + 1];
    
    for i in 0..weights.len() {
        // æ­£åºéå†å…è®¸é‡å¤ä½¿ç”¨
        for w in weights[i] as usize..=cap {
            dp[w] = dp[w].max(dp[w - weights[i] as usize] + values[i]);
        }
    }
    
    dp[cap]
}

/// å¼‚æ­¥ 0-1 èƒŒåŒ… - å±•ç¤º async/await (é€‚ç”¨äºå¤§è§„æ¨¡æˆ–è¿œç¨‹æ•°æ®)
pub async fn knapsack_01_async(
    weights: Vec<i32>,
    values: Vec<i32>,
    capacity: i32,
) -> Result<i32, Box<dyn std::error::Error + Send + Sync>> {
    // æ¨¡æ‹Ÿå¼‚æ­¥æ•°æ®åŠ è½½
    tokio::time::sleep(tokio::time::Duration::from_micros(1)).await;
    
    let result = tokio::task::spawn_blocking(move || {
        knapsack_01_optimized(&weights, &values, capacity)
    }).await?;
    
    Ok(result)
}

/// ç¼–è¾‘è·ç¦» (Levenshtein Distance)
pub fn edit_distance(word1: &str, word2: &str) -> usize {
    let m = word1.len();
    let n = word2.len();
    let word1: Vec<char> = word1.chars().collect();
    let word2: Vec<char> = word2.chars().collect();
    
    let mut dp = vec![vec![0; n + 1]; m + 1];
    
    // åˆå§‹åŒ–
    for i in 0..=m {
        dp[i][0] = i;
    }
    for j in 0..=n {
        dp[0][j] = j;
    }
    
    // åŠ¨æ€è§„åˆ’
    for i in 1..=m {
        for j in 1..=n {
            if word1[i - 1] == word2[j - 1] {
                dp[i][j] = dp[i - 1][j - 1];
            } else {
                dp[i][j] = 1 + dp[i - 1][j]     // åˆ é™¤
                    .min(dp[i][j - 1])           // æ’å…¥
                    .min(dp[i - 1][j - 1]);      // æ›¿æ¢
            }
        }
    }
    
    dp[m][n]
}

/// æœ€é•¿é€’å¢å­åºåˆ— (LIS) - O(n log n)
pub fn lis(nums: &[i32]) -> usize {
    let mut tails = Vec::new();
    
    for &num in nums {
        match tails.binary_search(&num) {
            Ok(_) => {} // å·²å­˜åœ¨
            Err(pos) => {
                if pos < tails.len() {
                    tails[pos] = num;
                } else {
                    tails.push(num);
                }
            }
        }
    }
    
    tails.len()
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_lcs() {
        assert_eq!(lcs("ABCBDAB", "BDCABA"), 4); // "BCBA" or "BDAB"
        assert_eq!(lcs_optimized("ABCBDAB", "BDCABA"), 4);
    }
    
    #[test]
    fn test_knapsack() {
        let weights = vec![2, 2, 6, 5, 4];
        let values = vec![6, 3, 5, 4, 6];
        assert_eq!(knapsack_01(&weights, &values, 10), 15);
        assert_eq!(knapsack_01_optimized(&weights, &values, 10), 15);
    }
    
    #[tokio::test]
    async fn test_knapsack_async() {
        let weights = vec![2, 2, 6, 5, 4];
        let values = vec![6, 3, 5, 4, 6];
        let result = knapsack_01_async(weights, values, 10).await.unwrap();
        assert_eq!(result, 15);
    }
    
    #[test]
    fn test_edit_distance() {
        assert_eq!(edit_distance("horse", "ros"), 3);
        assert_eq!(edit_distance("intention", "execution"), 5);
    }
    
    #[test]
    fn test_lis() {
        assert_eq!(lis(&[10, 9, 2, 5, 3, 7, 101, 18]), 4);
        assert_eq!(lis(&[0, 1, 0, 3, 2, 3]), 4);
    }
}
```

---

## ğŸ”„ ç®—æ³•æ¼”åŒ–ä¸å…³ç³»

### æ’åºç®—æ³•æ¼”åŒ–å›¾

```mermaid
timeline
    title æ’åºç®—æ³•æ¼”åŒ–å²
    
    1950s : å†’æ³¡æ’åº
          : æ’å…¥æ’åº
          : é€‰æ‹©æ’åº
    
    1960s : å¿«é€Ÿæ’åº (Hoare)
          : å †æ’åº (Williams)
    
    1970s : å½’å¹¶æ’åºä¼˜åŒ–
    
    1980s : æ¡¶æ’åº
          : è®¡æ•°æ’åº
    
    1990s : åŸºæ•°æ’åº
          : Tim Sort (Python)
    
    2000s : å¹¶è¡Œæ’åºç®—æ³•
    
    2020s : Rust std::sort (Pattern-defeating Quicksort)
          : å¼‚æ­¥æ’åº
```

### å›¾ç®—æ³•ä¾èµ–å…³ç³»

```mermaid
graph LR
    subgraph åŸºç¡€
    A[BFS/DFS]
    B[å¹¶æŸ¥é›†]
    C[ä¼˜å…ˆé˜Ÿåˆ—]
    end
    
    subgraph ä¸­çº§
    D[Dijkstra]
    E[Kruskal]
    F[Prim]
    G[æ‹“æ‰‘æ’åº]
    end
    
    subgraph é«˜çº§
    H[Floyd-Warshall]
    I[Bellman-Ford]
    J[ç½‘ç»œæµ]
    K[äºŒåˆ†å›¾åŒ¹é…]
    end
    
    A --> D
    A --> G
    C --> D
    C --> F
    B --> E
    D --> I
    A --> H
    G --> J
    A --> K
```

---

## ğŸ“Š ç®—æ³•åº”ç”¨åœºæ™¯æ˜ å°„

| ç®—æ³•ç±»åˆ« | æ ¸å¿ƒç®—æ³• | åº”ç”¨åœºæ™¯ | Rust 1.90 ç‰¹æ€§ | æ—¶é—´å¤æ‚åº¦ |
|---------|---------|---------|---------------|-----------|
| **æ’åº** | å¿«é€Ÿæ’åº | é€šç”¨æ’åºã€Top-K | å¹¶è¡ŒåŒ– `rayon::join` | O(n log n) |
| | å½’å¹¶æ’åº | ç¨³å®šæ’åºã€å¤–éƒ¨æ’åº | `async fn in trait` | O(n log n) |
| | å †æ’åº | ä¼˜å…ˆçº§é˜Ÿåˆ— | `const generics` | O(n log n) |
| **æœç´¢** | äºŒåˆ†æœç´¢ | æœ‰åºæ•°æ®æŸ¥æ‰¾ | `Option::is_some_and` | O(log n) |
| | BFS | æœ€çŸ­è·¯å¾„ã€å±‚æ¬¡éå† | å¹¶è¡Œå±‚å¤„ç† | O(V + E) |
| | DFS | æ‹“æ‰‘æ’åºã€è¿é€šæ€§ | æ ˆä¼˜åŒ– | O(V + E) |
| **å›¾è®º** | Dijkstra | å•æºæœ€çŸ­è·¯å¾„ | `async fn in trait` | O(E + V log V) |
| | Floyd-Warshall | å…¨æºæœ€çŸ­è·¯å¾„ | å¹¶è¡ŒåŒ– | O(VÂ³) |
| | Kruskal | æœ€å°ç”Ÿæˆæ ‘ | å¹¶æŸ¥é›†ä¼˜åŒ– | O(E log E) |
| **åŠ¨æ€è§„åˆ’** | LCS | æ–‡æœ¬ç›¸ä¼¼åº¦ã€diff | æ»šåŠ¨æ•°ç»„ | O(mn) |
| | 0-1èƒŒåŒ… | èµ„æºåˆ†é… | `async task` | O(nW) |
| | ç¼–è¾‘è·ç¦» | æ‹¼å†™æ£€æŸ¥ | SIMD åŠ é€Ÿ | O(mn) |
| **å­—ç¬¦ä¸²** | KMP | æ¨¡å¼åŒ¹é… | `const generics` | O(m + n) |
| | Aho-Corasick | å¤šæ¨¡å¼åŒ¹é… | Trie + çŠ¶æ€æœº | O(n + m + z) |

---

## ğŸ§  è®¤çŸ¥ç»´åº¦æ˜ å°„

### ç®—æ³•ç†è§£çš„äº”ä¸ªå±‚æ¬¡

```mermaid
graph TB
    L1[å±‚æ¬¡1: ä½¿ç”¨ Use] --> L2[å±‚æ¬¡2: ç†è§£ Understand]
    L2 --> L3[å±‚æ¬¡3: åˆ†æ Analyze]
    L3 --> L4[å±‚æ¬¡4: ä¼˜åŒ– Optimize]
    L4 --> L5[å±‚æ¬¡5: åˆ›æ–° Innovate]
    
    L1 -.ç¤ºä¾‹.-> U1[ä¼šè°ƒç”¨ sort å‡½æ•°]
    L2 -.ç¤ºä¾‹.-> U2[ç†è§£å¿«æ’åŸç†]
    L3 -.ç¤ºä¾‹.-> U3[åˆ†ææ—¶é—´å¤æ‚åº¦]
    L4 -.ç¤ºä¾‹.-> U4[ä¸‰è·¯å¿«æ’ä¼˜åŒ–]
    L5 -.ç¤ºä¾‹.-> U5[å‘æ˜æ–°ç®—æ³•]
    
    style L1 fill:#e8f5e9
    style L2 fill:#c8e6c9
    style L3 fill:#a5d6a7
    style L4 fill:#81c784
    style L5 fill:#66bb6a
```

---

## ğŸ¯ å­¦ä¹ è·¯å¾„çŸ¥è¯†å›¾è°±

```mermaid
graph TD
    Start[å¼€å§‹å­¦ä¹ ç®—æ³•] --> Foundation[åŸºç¡€æ•°æ®ç»“æ„]
    
    Foundation --> Array[æ•°ç»„ä¸é“¾è¡¨]
    Foundation --> StackQueue[æ ˆä¸é˜Ÿåˆ—]
    Foundation --> TreeBasic[äºŒå‰æ ‘]
    
    Array --> Sorting[æ’åºç®—æ³•]
    StackQueue --> Recursion[é€’å½’ä¸å›æº¯]
    TreeBasic --> TreeAdvanced[é«˜çº§æ ‘ç»“æ„]
    
    Sorting --> BasicAlgo[åŸºç¡€ç®—æ³•]
    Recursion --> DivideConquer[åˆ†æ²»ç®—æ³•]
    TreeAdvanced --> GraphBasic[å›¾åŸºç¡€]
    
    BasicAlgo --> Search[æœç´¢ç®—æ³•]
    DivideConquer --> DP[åŠ¨æ€è§„åˆ’]
    GraphBasic --> GraphAdvanced[é«˜çº§å›¾ç®—æ³•]
    
    Search --> String[å­—ç¬¦ä¸²ç®—æ³•]
    DP --> Greedy[è´ªå¿ƒç®—æ³•]
    GraphAdvanced --> NetworkFlow[ç½‘ç»œæµ]
    
    String --> Advanced[é«˜çº§ä¸“é¢˜]
    Greedy --> Advanced
    NetworkFlow --> Advanced
    
    Advanced --> Parallel[å¹¶è¡Œç®—æ³•]
    Advanced --> Async[å¼‚æ­¥ç®—æ³•]
    Advanced --> Optimization[æ€§èƒ½ä¼˜åŒ–]
    
    Parallel --> Master[ç®—æ³•å¤§å¸ˆ]
    Async --> Master
    Optimization --> Master
    
    style Start fill:#ff6b6b
    style Foundation fill:#4ecdc4
    style BasicAlgo fill:#45b7d1
    style Advanced fill:#96ceb4
    style Master fill:#ffd93d
```

---

## ğŸ“š å‚è€ƒèµ„æº

- [Rust Algorithm Club](https://rust-algo.club/)
- [The Algorithm Design Manual](https://www.algorist.com/)
- [Introduction to Algorithms (CLRS)](https://mitpress.mit.edu/books/introduction-algorithms-fourth-edition)
- [Rust Performance Book](https://nnethercote.github.io/perf-book/)

---

**æœ€åæ›´æ–°**: 2025å¹´10æœˆ19æ—¥  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**ç»´æŠ¤è€…**: c08_algorithms å›¢é˜Ÿ

