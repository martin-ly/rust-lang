# åˆ†å¸ƒå¼ç®—æ³•

> **æ–‡æ¡£ç±»å‹**: Tier 4 - é«˜çº§ä¸»é¢˜
> **æœ€åæ›´æ–°**: 2025-10-23
> **çŠ¶æ€**: âœ… å®Œæˆ

---

## ç›®å½•

- [åˆ†å¸ƒå¼ç®—æ³•](#åˆ†å¸ƒå¼ç®—æ³•)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“ çŸ¥è¯†ç»“æ„](#-çŸ¥è¯†ç»“æ„)
    - [æ¦‚å¿µå®šä¹‰](#æ¦‚å¿µå®šä¹‰)
    - [å±æ€§ç‰¹å¾](#å±æ€§ç‰¹å¾)
    - [å…³ç³»è¿æ¥](#å…³ç³»è¿æ¥)
    - [æ€ç»´å¯¼å›¾](#æ€ç»´å¯¼å›¾)
    - [å¤šç»´æ¦‚å¿µå¯¹æ¯”çŸ©é˜µ](#å¤šç»´æ¦‚å¿µå¯¹æ¯”çŸ©é˜µ)
    - [å†³ç­–æ ‘å›¾](#å†³ç­–æ ‘å›¾)
    - [è¯æ˜æ ‘å›¾](#è¯æ˜æ ‘å›¾)
  - [1. åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€](#1-åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€)
    - [1.1 CAP å®šç†](#11-cap-å®šç†)
    - [1.2 åˆ†å¸ƒå¼æ—¶é’Ÿ](#12-åˆ†å¸ƒå¼æ—¶é’Ÿ)
      - [Lamport æ—¶é—´æˆ³](#lamport-æ—¶é—´æˆ³)
    - [1.3 æ•…éšœæ¨¡å‹](#13-æ•…éšœæ¨¡å‹)
  - [2. ä¸€è‡´æ€§ç®—æ³•](#2-ä¸€è‡´æ€§ç®—æ³•)
    - [2.1 Paxos](#21-paxos)
    - [2.2 Raft](#22-raft)
    - [2.3 ä¸¤é˜¶æ®µæäº¤ (2PC)](#23-ä¸¤é˜¶æ®µæäº¤-2pc)
  - [3. åˆ†å¸ƒå¼å…±è¯†](#3-åˆ†å¸ƒå¼å…±è¯†)
    - [3.1 æ‹œå åº­å°†å†›é—®é¢˜](#31-æ‹œå åº­å°†å†›é—®é¢˜)
    - [3.2 PBFT (Practical Byzantine Fault Tolerance)](#32-pbft-practical-byzantine-fault-tolerance)
    - [3.3 åŒºå—é“¾å…±è¯†](#33-åŒºå—é“¾å…±è¯†)
  - [4. åˆ†å¸ƒå¼æ•°æ®ç»“æ„](#4-åˆ†å¸ƒå¼æ•°æ®ç»“æ„)
    - [4.1 åˆ†å¸ƒå¼å“ˆå¸Œè¡¨ (DHT)](#41-åˆ†å¸ƒå¼å“ˆå¸Œè¡¨-dht)
    - [4.2 CRDT (Conflict-free Replicated Data Types)](#42-crdt-conflict-free-replicated-data-types)
    - [4.3 å‘é‡æ—¶é’Ÿ](#43-å‘é‡æ—¶é’Ÿ)
  - [5. åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹](#5-åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹)
    - [5.1 MapReduce](#51-mapreduce)
    - [5.2 Bulk Synchronous Parallel (BSP)](#52-bulk-synchronous-parallel-bsp)
    - [5.3 Pregel (å›¾è®¡ç®—)](#53-pregel-å›¾è®¡ç®—)
  - [6. å®è·µæ¡ˆä¾‹](#6-å®è·µæ¡ˆä¾‹)
    - [6.1 åˆ†å¸ƒå¼é”](#61-åˆ†å¸ƒå¼é”)
    - [6.2 åˆ†å¸ƒå¼äº‹åŠ¡](#62-åˆ†å¸ƒå¼äº‹åŠ¡)
    - [6.3 åˆ†å¸ƒå¼ç¼“å­˜](#63-åˆ†å¸ƒå¼ç¼“å­˜)
  - [7. å‚è€ƒèµ„æ–™](#7-å‚è€ƒèµ„æ–™)
    - [æ•™æ](#æ•™æ)
    - [è®ºæ–‡](#è®ºæ–‡)
    - [å¼€æºé¡¹ç›®](#å¼€æºé¡¹ç›®)

---

## ğŸ“ çŸ¥è¯†ç»“æ„

### æ¦‚å¿µå®šä¹‰

**åˆ†å¸ƒå¼ç®—æ³• (Distributed Algorithms)**:

- **å®šä¹‰**: Rust 1.92.0 åˆ†å¸ƒå¼ç®—æ³•ï¼ŒåŒ…æ‹¬åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€ã€ä¸€è‡´æ€§ç®—æ³•ã€åˆ†å¸ƒå¼å…±è¯†ã€åˆ†å¸ƒå¼æ•°æ®ç»“æ„ã€åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹ã€å®è·µæ¡ˆä¾‹ç­‰
- **ç±»å‹**: é«˜çº§ä¸»é¢˜æ–‡æ¡£
- **èŒƒç•´**: ç®—æ³•ã€åˆ†å¸ƒå¼ç³»ç»Ÿ
- **ç‰ˆæœ¬**: Rust 1.92.0+ (Edition 2024)
- **ç›¸å…³æ¦‚å¿µ**: CAP å®šç†ã€Paxosã€Raftã€Byzantine å®¹é”™ã€åˆ†å¸ƒå¼é”ã€åˆ†å¸ƒå¼äº‹åŠ¡ã€CRDTã€å‘é‡æ—¶é’Ÿ

### å±æ€§ç‰¹å¾

**æ ¸å¿ƒå±æ€§**:

- **åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€**: CAP å®šç†ã€åˆ†å¸ƒå¼æ—¶é’Ÿï¼ˆLamport æ—¶é—´æˆ³ï¼‰ã€æ•…éšœæ¨¡å‹
- **ä¸€è‡´æ€§ç®—æ³•**: Paxosã€Raftã€ä¸¤é˜¶æ®µæäº¤ (2PC)
- **åˆ†å¸ƒå¼å…±è¯†**: æ‹œå åº­å°†å†›é—®é¢˜ã€PBFT (Practical Byzantine Fault Tolerance)ã€åŒºå—é“¾å…±è¯†
- **åˆ†å¸ƒå¼æ•°æ®ç»“æ„**: åˆ†å¸ƒå¼å“ˆå¸Œè¡¨ (DHT)ã€CRDT (Conflict-free Replicated Data Types)ã€å‘é‡æ—¶é’Ÿ
- **åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹**: MapReduceã€Bulk Synchronous Parallel (BSP)ã€Pregel (å›¾è®¡ç®—)

**Rust 1.92.0 æ–°ç‰¹æ€§**:

- **æ”¹è¿›çš„åˆ†å¸ƒå¼ç®—æ³•**: æ›´é«˜æ•ˆçš„åˆ†å¸ƒå¼ç®—æ³•å®ç°
- **å¢å¼ºçš„ä¸€è‡´æ€§ç®—æ³•**: æ›´å¥½çš„ Raft å’Œ Paxos æ”¯æŒ
- **ä¼˜åŒ–çš„åˆ†å¸ƒå¼æ•°æ®ç»“æ„**: æ›´é«˜æ•ˆçš„ CRDT å®ç°

**æ€§èƒ½ç‰¹å¾**:

- **é«˜å¯ç”¨**: åˆ†å¸ƒå¼ç³»ç»Ÿé«˜å¯ç”¨æ€§
- **ä¸€è‡´æ€§**: å¼ºä¸€è‡´æ€§æˆ–æœ€ç»ˆä¸€è‡´æ€§
- **é€‚ç”¨åœºæ™¯**: åˆ†å¸ƒå¼ç³»ç»Ÿã€äº‘åŸç”Ÿã€åŒºå—é“¾

### å…³ç³»è¿æ¥

**ç»„åˆå…³ç³»**:

- åˆ†å¸ƒå¼ç®—æ³• --[covers]--> åˆ†å¸ƒå¼ç®—æ³•å®Œæ•´å†…å®¹
- åˆ†å¸ƒå¼ç³»ç»Ÿ --[uses]--> åˆ†å¸ƒå¼ç®—æ³•

**ä¾èµ–å…³ç³»**:

- åˆ†å¸ƒå¼ç®—æ³• --[depends-on]--> ç½‘ç»œé€šä¿¡
- åˆ†å¸ƒå¼ç³»ç»Ÿ --[depends-on]--> åˆ†å¸ƒå¼ç®—æ³•

### æ€ç»´å¯¼å›¾

```text
åˆ†å¸ƒå¼ç®—æ³•
â”‚
â”œâ”€â”€ åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€
â”‚   â”œâ”€â”€ CAP å®šç†
â”‚   â””â”€â”€ åˆ†å¸ƒå¼æ—¶é’Ÿ
â”œâ”€â”€ ä¸€è‡´æ€§ç®—æ³•
â”‚   â”œâ”€â”€ Paxos
â”‚   â””â”€â”€ Raft
â”œâ”€â”€ åˆ†å¸ƒå¼å…±è¯†
â”‚   â”œâ”€â”€ æ‹œå åº­å®¹é”™
â”‚   â””â”€â”€ åŒºå—é“¾å…±è¯†
â”œâ”€â”€ åˆ†å¸ƒå¼æ•°æ®ç»“æ„
â”‚   â”œâ”€â”€ DHT
â”‚   â””â”€â”€ CRDT
â””â”€â”€ åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹
    â”œâ”€â”€ MapReduce
    â””â”€â”€ Pregel
```

### å¤šç»´æ¦‚å¿µå¯¹æ¯”çŸ©é˜µ

| åˆ†å¸ƒå¼ç®—æ³•    | ä¸€è‡´æ€§   | æ€§èƒ½ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯   | Rust 1.92.0 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Paxos**     | å¼ºä¸€è‡´   | ä¸­   | é«˜     | ç»å…¸å…±è¯†   | âœ…          |
| **Raft**      | å¼ºä¸€è‡´   | ä¸­   | ä¸­     | ç°ä»£å…±è¯†   | âœ… æ”¹è¿›     |
| **PBFT**      | å¼ºä¸€è‡´   | ä½   | æœ€é«˜   | æ‹œå åº­å®¹é”™ | âœ…          |
| **CRDT**      | æœ€ç»ˆä¸€è‡´ | é«˜   | ä¸­     | æ— å†²çªå¤åˆ¶ | âœ…          |
| **MapReduce** | æœ€ç»ˆä¸€è‡´ | é«˜   | ä¸­     | å¤§æ•°æ®å¤„ç† | âœ…          |

### å†³ç­–æ ‘å›¾

```text
é€‰æ‹©åˆ†å¸ƒå¼ç®—æ³•
â”‚
â”œâ”€â”€ æ˜¯å¦éœ€è¦å¼ºä¸€è‡´æ€§ï¼Ÿ
â”‚   â”œâ”€â”€ æ˜¯ â†’ Paxos / Raft
â”‚   â””â”€â”€ å¦ â†’ ç»§ç»­åˆ¤æ–­
â”‚       â”œâ”€â”€ æ˜¯å¦éœ€è¦æ‹œå åº­å®¹é”™ï¼Ÿ
â”‚       â”‚   â”œâ”€â”€ æ˜¯ â†’ PBFT
â”‚       â”‚   â””â”€â”€ å¦ â†’ ç»§ç»­åˆ¤æ–­
â”‚       â”‚       â”œâ”€â”€ æ˜¯å¦éœ€è¦æ— å†²çªå¤åˆ¶ï¼Ÿ
â”‚       â”‚       â”‚   â”œâ”€â”€ æ˜¯ â†’ CRDT
â”‚       â”‚       â”‚   â””â”€â”€ å¦ â†’ MapReduce
```

### è¯æ˜æ ‘å›¾

```text
åˆ†å¸ƒå¼ä¸€è‡´æ€§è¯æ˜
â”‚
â”œâ”€â”€ CAP å®šç†
â”‚   â”œâ”€â”€ ä¸€è‡´æ€§
â”‚   â”œâ”€â”€ å¯ç”¨æ€§
â”‚   â””â”€â”€ åˆ†åŒºå®¹é”™
â”œâ”€â”€ å…±è¯†ç®—æ³•æ­£ç¡®æ€§
â”‚   â”œâ”€â”€ Paxos æ­£ç¡®æ€§
â”‚   â””â”€â”€ Raft æ­£ç¡®æ€§
â””â”€â”€ æœ€ç»ˆä¸€è‡´æ€§
    â””â”€â”€ CRDT æ”¶æ•›æ€§
```

---

## 1. åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€

### 1.1 CAP å®šç†

**CAP å®šç†**: åˆ†å¸ƒå¼ç³»ç»Ÿæœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³ä»¥ä¸‹ä¸‰é¡¹ä¸­çš„ä¸¤é¡¹ï¼š

- **C (Consistency)**: ä¸€è‡´æ€§
- **A (Availability)**: å¯ç”¨æ€§
- **P (Partition Tolerance)**: åˆ†åŒºå®¹é”™æ€§

```rust
/// CAP å®šç†æ¼”ç¤ºï¼šç®€åŒ–çš„åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨
pub struct DistributedKV {
    nodes: Vec<Node>,
    mode: CAPMode,
}

#[derive(Debug, Clone, Copy)]
pub enum CAPMode {
    CP,  // ä¸€è‡´æ€§ + åˆ†åŒºå®¹é”™ï¼Œç‰ºç‰²å¯ç”¨æ€§
    AP,  // å¯ç”¨æ€§ + åˆ†åŒºå®¹é”™ï¼Œç‰ºç‰²ä¸€è‡´æ€§
    CA,  // ä¸€è‡´æ€§ + å¯ç”¨æ€§ï¼Œä¸æ”¯æŒåˆ†åŒºï¼ˆä¸å®ç”¨ï¼‰
}

struct Node {
    id: usize,
    data: std::collections::HashMap<String, String>,
    is_partitioned: bool,
}

impl DistributedKV {
    pub fn new(num_nodes: usize, mode: CAPMode) -> Self {
        let nodes = (0..num_nodes)
            .map(|id| Node {
                id,
                data: std::collections::HashMap::new(),
                is_partitioned: false,
            })
            .collect();

        Self { nodes, mode }
    }

    /// å†™å…¥æ•°æ®
    pub fn put(&mut self, key: String, value: String) -> Result<(), String> {
        match self.mode {
            CAPMode::CP => {
                // CP æ¨¡å¼ï¼šéœ€è¦å¤šæ•°èŠ‚ç‚¹ç¡®è®¤
                let available_nodes: Vec<_> = self.nodes
                    .iter_mut()
                    .filter(|n| !n.is_partitioned)
                    .collect();

                if available_nodes.len() < self.nodes.len() / 2 + 1 {
                    return Err("ä¸æ»¡è¶³ quorumï¼Œæ‹’ç»å†™å…¥ï¼ˆä¿è¯ä¸€è‡´æ€§ï¼‰".to_string());
                }

                for node in available_nodes {
                    node.data.insert(key.clone(), value.clone());
                }
                Ok(())
            }
            CAPMode::AP => {
                // AP æ¨¡å¼ï¼šå†™å…¥æ‰€æœ‰å¯ç”¨èŠ‚ç‚¹ï¼ˆå¯èƒ½ä¸ä¸€è‡´ï¼‰
                let mut wrote = false;
                for node in &mut self.nodes {
                    if !node.is_partitioned {
                        node.data.insert(key.clone(), value.clone());
                        wrote = true;
                    }
                }

                if wrote {
                    Ok(())
                } else {
                    Err("æ‰€æœ‰èŠ‚ç‚¹ä¸å¯ç”¨".to_string())
                }
            }
            CAPMode::CA => {
                // CA æ¨¡å¼ï¼šä¸æ”¯æŒåˆ†åŒº
                if self.nodes.iter().any(|n| n.is_partitioned) {
                    return Err("å­˜åœ¨åˆ†åŒºï¼ŒCA æ¨¡å¼æ— æ³•å·¥ä½œ".to_string());
                }

                for node in &mut self.nodes {
                    node.data.insert(key.clone(), value.clone());
                }
                Ok(())
            }
        }
    }

    /// è¯»å–æ•°æ®
    pub fn get(&self, key: &str) -> Result<String, String> {
        match self.mode {
            CAPMode::CP => {
                // CP æ¨¡å¼ï¼šéœ€è¦å¤šæ•°èŠ‚ç‚¹åŒæ„
                let available_nodes: Vec<_> = self.nodes
                    .iter()
                    .filter(|n| !n.is_partitioned)
                    .collect();

                if available_nodes.len() < self.nodes.len() / 2 + 1 {
                    return Err("ä¸æ»¡è¶³ quorumï¼Œæ‹’ç»è¯»å–".to_string());
                }

                available_nodes
                    .first()
                    .and_then(|n| n.data.get(key))
                    .cloned()
                    .ok_or_else(|| "é”®ä¸å­˜åœ¨".to_string())
            }
            CAPMode::AP => {
                // AP æ¨¡å¼ï¼šä»ä»»ä¸€å¯ç”¨èŠ‚ç‚¹è¯»å–ï¼ˆå¯èƒ½ä¸ä¸€è‡´ï¼‰
                self.nodes
                    .iter()
                    .filter(|n| !n.is_partitioned)
                    .find_map(|n| n.data.get(key))
                    .cloned()
                    .ok_or_else(|| "æ‰€æœ‰èŠ‚ç‚¹ä¸å¯ç”¨æˆ–é”®ä¸å­˜åœ¨".to_string())
            }
            CAPMode::CA => {
                if self.nodes.iter().any(|n| n.is_partitioned) {
                    return Err("å­˜åœ¨åˆ†åŒºï¼ŒCA æ¨¡å¼æ— æ³•å·¥ä½œ".to_string());
                }

                self.nodes
                    .first()
                    .and_then(|n| n.data.get(key))
                    .cloned()
                    .ok_or_else(|| "é”®ä¸å­˜åœ¨".to_string())
            }
        }
    }

    /// æ¨¡æ‹Ÿç½‘ç»œåˆ†åŒº
    pub fn partition_node(&mut self, node_id: usize) {
        if let Some(node) = self.nodes.get_mut(node_id) {
            node.is_partitioned = true;
        }
    }

    /// æ¢å¤ç½‘ç»œåˆ†åŒº
    pub fn heal_partition(&mut self, node_id: usize) {
        if let Some(node) = self.nodes.get_mut(node_id) {
            node.is_partitioned = false;
        }
    }
}

#[cfg(test)]
mod cap_tests {
    use super::*;

    #[test]
    fn test_cp_mode() {
        let mut kv = DistributedKV::new(5, CAPMode::CP);

        // æ­£å¸¸å†™å…¥
        assert!(kv.put("key1".to_string(), "value1".to_string()).is_ok());

        // åˆ†åŒº 3 ä¸ªèŠ‚ç‚¹ï¼ˆå¤šæ•°ï¼‰
        kv.partition_node(0);
        kv.partition_node(1);
        kv.partition_node(2);

        // å†™å…¥å¤±è´¥ï¼ˆä¸æ»¡è¶³ quorumï¼‰
        assert!(kv.put("key2".to_string(), "value2".to_string()).is_err());
    }

    #[test]
    fn test_ap_mode() {
        let mut kv = DistributedKV::new(5, CAPMode::AP);

        // æ­£å¸¸å†™å…¥
        assert!(kv.put("key1".to_string(), "value1".to_string()).is_ok());

        // åˆ†åŒº 3 ä¸ªèŠ‚ç‚¹
        kv.partition_node(0);
        kv.partition_node(1);
        kv.partition_node(2);

        // å†™å…¥æˆåŠŸï¼ˆå†™å…¥å¯ç”¨èŠ‚ç‚¹ï¼‰
        assert!(kv.put("key2".to_string(), "value2".to_string()).is_ok());
    }
}
```

### 1.2 åˆ†å¸ƒå¼æ—¶é’Ÿ

#### Lamport æ—¶é—´æˆ³

```rust
use std::cmp::max;

/// Lamport é€»è¾‘æ—¶é’Ÿ
#[derive(Debug, Clone)]
pub struct LamportClock {
    time: u64,
}

impl LamportClock {
    pub fn new() -> Self {
        Self { time: 0 }
    }

    /// æœ¬åœ°äº‹ä»¶ï¼šæ—¶é’Ÿé€’å¢
    pub fn tick(&mut self) -> u64 {
        self.time += 1;
        self.time
    }

    /// å‘é€æ¶ˆæ¯ï¼šé™„å¸¦å½“å‰æ—¶é—´æˆ³
    pub fn send_event(&mut self) -> u64 {
        self.tick()
    }

    /// æ¥æ”¶æ¶ˆæ¯ï¼šæ›´æ–°æ—¶é’Ÿ
    pub fn receive_event(&mut self, msg_time: u64) {
        self.time = max(self.time, msg_time) + 1;
    }

    pub fn get_time(&self) -> u64 {
        self.time
    }
}

#[derive(Debug, Clone)]
pub struct Message {
    content: String,
    timestamp: u64,
}

/// åˆ†å¸ƒå¼äº‹ä»¶æ’åºç¤ºä¾‹
pub fn lamport_ordering_example() {
    let mut node1 = LamportClock::new();
    let mut node2 = LamportClock::new();
    let mut node3 = LamportClock::new();

    // Node 1: æœ¬åœ°äº‹ä»¶
    let t1 = node1.tick();
    println!("Node 1 äº‹ä»¶: t={}", t1);

    // Node 2: æœ¬åœ°äº‹ä»¶
    let t2 = node2.tick();
    println!("Node 2 äº‹ä»¶: t={}", t2);

    // Node 1 -> Node 3: å‘é€æ¶ˆæ¯
    let msg_time = node1.send_event();
    println!("Node 1 å‘é€æ¶ˆæ¯: t={}", msg_time);

    // Node 3: æ¥æ”¶æ¶ˆæ¯
    node3.receive_event(msg_time);
    println!("Node 3 æ¥æ”¶æ¶ˆæ¯: t={}", node3.get_time());

    // Node 2 -> Node 3: å‘é€æ¶ˆæ¯
    let msg_time2 = node2.send_event();
    println!("Node 2 å‘é€æ¶ˆæ¯: t={}", msg_time2);

    // Node 3: æ¥æ”¶æ¶ˆæ¯
    node3.receive_event(msg_time2);
    println!("Node 3 æœ€ç»ˆæ—¶é—´: t={}", node3.get_time());
}
```

### 1.3 æ•…éšœæ¨¡å‹

```rust
/// åˆ†å¸ƒå¼æ•…éšœç±»å‹
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FaultType {
    Crash,          // å´©æºƒæ•…éšœï¼ˆåœæ­¢å·¥ä½œï¼‰
    Omission,       // é—æ¼æ•…éšœï¼ˆä¸¢å¤±æ¶ˆæ¯ï¼‰
    Timing,         // æ—¶åºæ•…éšœï¼ˆå“åº”å»¶è¿Ÿï¼‰
    Byzantine,      // æ‹œå åº­æ•…éšœï¼ˆä»»æ„è¡Œä¸ºï¼‰
}

/// æ•…éšœæ£€æµ‹å™¨
pub struct FailureDetector {
    nodes: Vec<NodeStatus>,
    timeout: std::time::Duration,
}

#[derive(Debug, Clone)]
struct NodeStatus {
    id: usize,
    last_heartbeat: std::time::Instant,
    suspected: bool,
}

impl FailureDetector {
    pub fn new(num_nodes: usize, timeout_ms: u64) -> Self {
        let nodes = (0..num_nodes)
            .map(|id| NodeStatus {
                id,
                last_heartbeat: std::time::Instant::now(),
                suspected: false,
            })
            .collect();

        Self {
            nodes,
            timeout: std::time::Duration::from_millis(timeout_ms),
        }
    }

    /// æ¥æ”¶å¿ƒè·³
    pub fn heartbeat(&mut self, node_id: usize) {
        if let Some(node) = self.nodes.get_mut(node_id) {
            node.last_heartbeat = std::time::Instant::now();
            node.suspected = false;
        }
    }

    /// æ£€æµ‹æ•…éšœ
    pub fn detect_failures(&mut self) -> Vec<usize> {
        let now = std::time::Instant::now();
        let mut failed_nodes = Vec::new();

        for node in &mut self.nodes {
            if now.duration_since(node.last_heartbeat) > self.timeout {
                if !node.suspected {
                    node.suspected = true;
                    failed_nodes.push(node.id);
                }
            }
        }

        failed_nodes
    }

    /// è·å–å­˜æ´»èŠ‚ç‚¹åˆ—è¡¨
    pub fn alive_nodes(&self) -> Vec<usize> {
        self.nodes
            .iter()
            .filter(|n| !n.suspected)
            .map(|n| n.id)
            .collect()
    }
}
```

---

## 2. ä¸€è‡´æ€§ç®—æ³•

### 2.1 Paxos

```rust
/// Paxos ç®—æ³•ç®€åŒ–å®ç°
#[derive(Debug, Clone)]
pub struct PaxosNode {
    id: usize,
    promised_id: u64,  // æ‰¿è¯ºçš„ææ¡ˆ ID
    accepted_id: u64,  // æ¥å—çš„ææ¡ˆ ID
    accepted_value: Option<String>,
}

#[derive(Debug, Clone)]
pub struct Proposal {
    id: u64,
    value: String,
}

#[derive(Debug, Clone)]
pub enum PaxosMessage {
    Prepare(u64),                          // Phase 1a: Proposer -> Acceptor
    Promise(u64, Option<Proposal>),        // Phase 1b: Acceptor -> Proposer
    Accept(Proposal),                      // Phase 2a: Proposer -> Acceptor
    Accepted(Proposal),                    // Phase 2b: Acceptor -> Proposer
}

impl PaxosNode {
    pub fn new(id: usize) -> Self {
        Self {
            id,
            promised_id: 0,
            accepted_id: 0,
            accepted_value: None,
        }
    }

    /// Phase 1b: å¤„ç† Prepare è¯·æ±‚
    pub fn handle_prepare(&mut self, proposal_id: u64) -> Option<PaxosMessage> {
        if proposal_id > self.promised_id {
            self.promised_id = proposal_id;

            let previous_proposal = if self.accepted_id > 0 {
                Some(Proposal {
                    id: self.accepted_id,
                    value: self.accepted_value.clone().unwrap_or_default(),
                })
            } else {
                None
            };

            Some(PaxosMessage::Promise(proposal_id, previous_proposal))
        } else {
            None // æ‹’ç»
        }
    }

    /// Phase 2b: å¤„ç† Accept è¯·æ±‚
    pub fn handle_accept(&mut self, proposal: Proposal) -> Option<PaxosMessage> {
        if proposal.id >= self.promised_id {
            self.promised_id = proposal.id;
            self.accepted_id = proposal.id;
            self.accepted_value = Some(proposal.value.clone());

            Some(PaxosMessage::Accepted(proposal))
        } else {
            None // æ‹’ç»
        }
    }
}

/// Paxos Proposer
pub struct PaxosProposer {
    id: usize,
    proposal_id: u64,
}

impl PaxosProposer {
    pub fn new(id: usize) -> Self {
        Self {
            id,
            proposal_id: id as u64,
        }
    }

    /// ç”Ÿæˆå”¯ä¸€çš„ææ¡ˆ ID
    fn next_proposal_id(&mut self) -> u64 {
        self.proposal_id += 100; // ç¡®ä¿å”¯ä¸€æ€§
        self.proposal_id
    }

    /// Phase 1a: å‘èµ· Prepare
    pub fn prepare(&mut self) -> (u64, PaxosMessage) {
        let id = self.next_proposal_id();
        (id, PaxosMessage::Prepare(id))
    }

    /// Phase 2a: å‘èµ· Accept
    pub fn accept(&self, proposal_id: u64, value: String) -> PaxosMessage {
        PaxosMessage::Accept(Proposal {
            id: proposal_id,
            value,
        })
    }
}
```

### 2.2 Raft

```rust
use std::collections::HashMap;

/// Raft èŠ‚ç‚¹çŠ¶æ€
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RaftRole {
    Follower,
    Candidate,
    Leader,
}

/// Raft æ—¥å¿—æ¡ç›®
#[derive(Debug, Clone)]
pub struct LogEntry {
    term: u64,
    command: String,
}

/// Raft èŠ‚ç‚¹
pub struct RaftNode {
    id: usize,
    role: RaftRole,
    current_term: u64,
    voted_for: Option<usize>,
    log: Vec<LogEntry>,
    commit_index: usize,
    last_applied: usize,

    // Leader ä¸“ç”¨
    next_index: HashMap<usize, usize>,
    match_index: HashMap<usize, usize>,
}

impl RaftNode {
    pub fn new(id: usize) -> Self {
        Self {
            id,
            role: RaftRole::Follower,
            current_term: 0,
            voted_for: None,
            log: Vec::new(),
            commit_index: 0,
            last_applied: 0,
            next_index: HashMap::new(),
            match_index: HashMap::new(),
        }
    }

    /// è¯·æ±‚æŠ•ç¥¨ RPC
    pub fn request_vote(
        &mut self,
        term: u64,
        candidate_id: usize,
        last_log_index: usize,
        last_log_term: u64,
    ) -> (u64, bool) {
        if term > self.current_term {
            self.current_term = term;
            self.role = RaftRole::Follower;
            self.voted_for = None;
        }

        let vote_granted = if term < self.current_term {
            false
        } else if self.voted_for.is_some() && self.voted_for != Some(candidate_id) {
            false
        } else {
            // æ£€æŸ¥æ—¥å¿—æ˜¯å¦è‡³å°‘å’Œè‡ªå·±ä¸€æ ·æ–°
            let my_last_log_index = self.log.len().saturating_sub(1);
            let my_last_log_term = self.log.last().map(|e| e.term).unwrap_or(0);

            if last_log_term > my_last_log_term {
                true
            } else if last_log_term == my_last_log_term && last_log_index >= my_last_log_index {
                true
            } else {
                false
            }
        };

        if vote_granted {
            self.voted_for = Some(candidate_id);
        }

        (self.current_term, vote_granted)
    }

    /// è¿½åŠ æ—¥å¿— RPC
    pub fn append_entries(
        &mut self,
        term: u64,
        leader_id: usize,
        prev_log_index: usize,
        prev_log_term: u64,
        entries: Vec<LogEntry>,
        leader_commit: usize,
    ) -> (u64, bool) {
        if term < self.current_term {
            return (self.current_term, false);
        }

        if term > self.current_term {
            self.current_term = term;
            self.role = RaftRole::Follower;
            self.voted_for = None;
        }

        // æ£€æŸ¥æ—¥å¿—ä¸€è‡´æ€§
        if prev_log_index > 0 {
            if prev_log_index > self.log.len() {
                return (self.current_term, false);
            }

            if self.log[prev_log_index - 1].term != prev_log_term {
                return (self.current_term, false);
            }
        }

        // è¿½åŠ æ–°æ—¥å¿—
        for (i, entry) in entries.iter().enumerate() {
            let log_index = prev_log_index + i;
            if log_index < self.log.len() {
                if self.log[log_index].term != entry.term {
                    self.log.truncate(log_index);
                    self.log.push(entry.clone());
                }
            } else {
                self.log.push(entry.clone());
            }
        }

        // æ›´æ–° commit index
        if leader_commit > self.commit_index {
            self.commit_index = leader_commit.min(self.log.len());
        }

        (self.current_term, true)
    }

    /// å¼€å§‹é€‰ä¸¾
    pub fn start_election(&mut self) {
        self.current_term += 1;
        self.role = RaftRole::Candidate;
        self.voted_for = Some(self.id);
    }

    /// æˆä¸º Leader
    pub fn become_leader(&mut self, num_nodes: usize) {
        self.role = RaftRole::Leader;

        let next_index = self.log.len() + 1;
        for id in 0..num_nodes {
            if id != self.id {
                self.next_index.insert(id, next_index);
                self.match_index.insert(id, 0);
            }
        }
    }
}
```

### 2.3 ä¸¤é˜¶æ®µæäº¤ (2PC)

```rust
/// ä¸¤é˜¶æ®µæäº¤åè°ƒè€…
pub struct TwoPhaseCommitCoordinator {
    transaction_id: u64,
    participants: Vec<usize>,
    state: TransactionState,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TransactionState {
    Init,
    Preparing,
    Prepared,
    Committing,
    Committed,
    Aborting,
    Aborted,
}

#[derive(Debug, Clone, Copy)]
pub enum Vote {
    Commit,
    Abort,
}

impl TwoPhaseCommitCoordinator {
    pub fn new(transaction_id: u64, participants: Vec<usize>) -> Self {
        Self {
            transaction_id,
            participants,
            state: TransactionState::Init,
        }
    }

    /// Phase 1: Prepare
    pub fn prepare(&mut self, votes: Vec<(usize, Vote)>) -> bool {
        self.state = TransactionState::Preparing;

        // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‚ä¸è€…éƒ½æŠ•ç¥¨
        if votes.len() != self.participants.len() {
            self.state = TransactionState::Aborting;
            return false;
        }

        // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰äººéƒ½åŒæ„æäº¤
        let all_commit = votes.iter().all(|(_, vote)| matches!(vote, Vote::Commit));

        if all_commit {
            self.state = TransactionState::Prepared;
            true
        } else {
            self.state = TransactionState::Aborting;
            false
        }
    }

    /// Phase 2: Commit or Abort
    pub fn commit(&mut self) -> TransactionState {
        match self.state {
            TransactionState::Prepared => {
                self.state = TransactionState::Committing;
                // å‘é€ COMMIT ç»™æ‰€æœ‰å‚ä¸è€…
                self.state = TransactionState::Committed;
                self.state
            }
            TransactionState::Aborting => {
                // å‘é€ ABORT ç»™æ‰€æœ‰å‚ä¸è€…
                self.state = TransactionState::Aborted;
                self.state
            }
            _ => self.state,
        }
    }
}

/// ä¸¤é˜¶æ®µæäº¤å‚ä¸è€…
pub struct TwoPhaseCommitParticipant {
    id: usize,
    prepared: bool,
}

impl TwoPhaseCommitParticipant {
    pub fn new(id: usize) -> Self {
        Self {
            id,
            prepared: false,
        }
    }

    /// Phase 1: å‡†å¤‡æŠ•ç¥¨
    pub fn vote(&mut self) -> Vote {
        // æ£€æŸ¥æ˜¯å¦å¯ä»¥æäº¤ï¼ˆç®€åŒ–å®ç°ï¼‰
        let can_commit = true; // å®é™…åº”æ£€æŸ¥èµ„æºé”ã€çº¦æŸç­‰

        if can_commit {
            self.prepared = true;
            Vote::Commit
        } else {
            Vote::Abort
        }
    }

    /// Phase 2: æäº¤
    pub fn commit(&mut self) -> bool {
        if self.prepared {
            // å®é™…æäº¤
            println!("å‚ä¸è€… {} æäº¤äº‹åŠ¡", self.id);
            self.prepared = false;
            true
        } else {
            false
        }
    }

    /// Phase 2: ä¸­æ­¢
    pub fn abort(&mut self) {
        if self.prepared {
            // å›æ»š
            println!("å‚ä¸è€… {} å›æ»šäº‹åŠ¡", self.id);
            self.prepared = false;
        }
    }
}
```

---

## 3. åˆ†å¸ƒå¼å…±è¯†

### 3.1 æ‹œå åº­å°†å†›é—®é¢˜

```rust
/// æ‹œå åº­å°†å†›é—®é¢˜æ¼”ç¤º
pub struct ByzantineGeneral {
    id: usize,
    is_traitor: bool,
    received_messages: Vec<(usize, bool)>,  // (å‘é€è€…, å‘½ä»¤: true=è¿›æ”», false=æ’¤é€€)
}

impl ByzantineGeneral {
    pub fn new(id: usize, is_traitor: bool) -> Self {
        Self {
            id,
            is_traitor,
            received_messages: Vec::new(),
        }
    }

    /// å‘é€å‘½ä»¤
    pub fn send_command(&self, command: bool) -> bool {
        if self.is_traitor {
            // å›å¾’å‘é€éšæœºå‘½ä»¤
            rand::random()
        } else {
            command
        }
    }

    /// æ¥æ”¶å‘½ä»¤
    pub fn receive_command(&mut self, sender: usize, command: bool) {
        self.received_messages.push((sender, command));
    }

    /// åšå‡ºå†³ç­–ï¼ˆå¤šæ•°æŠ•ç¥¨ï¼‰
    pub fn decide(&self) -> bool {
        let attack_votes = self.received_messages.iter().filter(|(_, cmd)| *cmd).count();
        let retreat_votes = self.received_messages.len() - attack_votes;

        attack_votes > retreat_votes
    }
}

/// æ‹œå åº­å®¹é”™æ¡ä»¶ï¼šn >= 3f + 1
/// å…¶ä¸­ n æ˜¯æ€»èŠ‚ç‚¹æ•°ï¼Œf æ˜¯æœ€å¤§å®¹å¿æ•…éšœæ•°
pub fn byzantine_tolerance(num_nodes: usize, num_traitors: usize) -> bool {
    num_nodes >= 3 * num_traitors + 1
}
```

### 3.2 PBFT (Practical Byzantine Fault Tolerance)

```rust
/// PBFT æ¶ˆæ¯ç±»å‹
#[derive(Debug, Clone)]
pub enum PBFTMessage {
    Request { client_id: usize, operation: String, timestamp: u64 },
    PrePrepare { view: u64, seq: u64, digest: String },
    Prepare { view: u64, seq: u64, digest: String, replica_id: usize },
    Commit { view: u64, seq: u64, digest: String, replica_id: usize },
    Reply { view: u64, timestamp: u64, client_id: usize, result: String },
}

/// PBFT èŠ‚ç‚¹
pub struct PBFTNode {
    id: usize,
    view: u64,
    seq_num: u64,
    is_primary: bool,

    pre_prepare_log: Vec<PBFTMessage>,
    prepare_log: Vec<PBFTMessage>,
    commit_log: Vec<PBFTMessage>,
}

impl PBFTNode {
    pub fn new(id: usize, num_nodes: usize) -> Self {
        Self {
            id,
            view: 0,
            seq_num: 0,
            is_primary: id == 0,
            pre_prepare_log: Vec::new(),
            prepare_log: Vec::new(),
            commit_log: Vec::new(),
        }
    }

    /// Pre-Prepare é˜¶æ®µï¼ˆPrimaryï¼‰
    pub fn pre_prepare(&mut self, operation: String) -> Option<PBFTMessage> {
        if !self.is_primary {
            return None;
        }

        self.seq_num += 1;
        let digest = format!("{:x}", md5::compute(&operation));

        let msg = PBFTMessage::PrePrepare {
            view: self.view,
            seq: self.seq_num,
            digest,
        };

        self.pre_prepare_log.push(msg.clone());
        Some(msg)
    }

    /// Prepare é˜¶æ®µ
    pub fn prepare(&mut self, pre_prepare: PBFTMessage) -> Option<PBFTMessage> {
        if let PBFTMessage::PrePrepare { view, seq, digest } = pre_prepare {
            let msg = PBFTMessage::Prepare {
                view,
                seq,
                digest,
                replica_id: self.id,
            };

            self.prepare_log.push(msg.clone());
            Some(msg)
        } else {
            None
        }
    }

    /// Commit é˜¶æ®µ
    pub fn commit(
        &mut self,
        prepares: Vec<PBFTMessage>,
        num_nodes: usize,
    ) -> Option<PBFTMessage> {
        // éœ€è¦ 2f+1 ä¸ª Prepare æ¶ˆæ¯ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰
        let required = 2 * (num_nodes / 3) + 1;

        if prepares.len() >= required {
            if let Some(PBFTMessage::Prepare { view, seq, digest, .. }) = prepares.first() {
                let msg = PBFTMessage::Commit {
                    view: *view,
                    seq: *seq,
                    digest: digest.clone(),
                    replica_id: self.id,
                };

                self.commit_log.push(msg.clone());
                return Some(msg);
            }
        }

        None
    }

    /// æ‰§è¡Œé˜¶æ®µ
    pub fn execute(
        &self,
        commits: Vec<PBFTMessage>,
        num_nodes: usize,
    ) -> bool {
        // éœ€è¦ 2f+1 ä¸ª Commit æ¶ˆæ¯
        let required = 2 * (num_nodes / 3) + 1;
        commits.len() >= required
    }
}
```

### 3.3 åŒºå—é“¾å…±è¯†

```rust
use sha2::{Sha256, Digest};

/// åŒºå—
#[derive(Debug, Clone)]
pub struct Block {
    index: u64,
    timestamp: u64,
    data: String,
    previous_hash: String,
    nonce: u64,
    hash: String,
}

impl Block {
    /// PoW (Proof of Work) æŒ–çŸ¿
    pub fn mine(
        index: u64,
        data: String,
        previous_hash: String,
        difficulty: usize,
    ) -> Self {
        let mut nonce = 0;
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();

        let target = "0".repeat(difficulty);

        loop {
            let hash = Self::calculate_hash(index, timestamp, &data, &previous_hash, nonce);

            if hash.starts_with(&target) {
                return Self {
                    index,
                    timestamp,
                    data,
                    previous_hash,
                    nonce,
                    hash,
                };
            }

            nonce += 1;
        }
    }

    fn calculate_hash(
        index: u64,
        timestamp: u64,
        data: &str,
        previous_hash: &str,
        nonce: u64,
    ) -> String {
        let content = format!("{}{}{}{}{}", index, timestamp, data, previous_hash, nonce);
        let mut hasher = Sha256::new();
        hasher.update(content.as_bytes());
        format!("{:x}", hasher.finalize())
    }

    /// éªŒè¯åŒºå—
    pub fn is_valid(&self, previous_hash: &str, difficulty: usize) -> bool {
        if self.previous_hash != previous_hash {
            return false;
        }

        let target = "0".repeat(difficulty);
        if !self.hash.starts_with(&target) {
            return false;
        }

        let calculated_hash = Self::calculate_hash(
            self.index,
            self.timestamp,
            &self.data,
            &self.previous_hash,
            self.nonce,
        );

        calculated_hash == self.hash
    }
}

/// åŒºå—é“¾
pub struct Blockchain {
    chain: Vec<Block>,
    difficulty: usize,
}

impl Blockchain {
    pub fn new(difficulty: usize) -> Self {
        let genesis = Block {
            index: 0,
            timestamp: 0,
            data: "Genesis Block".to_string(),
            previous_hash: "0".to_string(),
            nonce: 0,
            hash: "0".repeat(64),
        };

        Self {
            chain: vec![genesis],
            difficulty,
        }
    }

    /// æ·»åŠ åŒºå—
    pub fn add_block(&mut self, data: String) {
        let previous_block = self.chain.last().unwrap();
        let new_block = Block::mine(
            previous_block.index + 1,
            data,
            previous_block.hash.clone(),
            self.difficulty,
        );

        self.chain.push(new_block);
    }

    /// éªŒè¯åŒºå—é“¾
    pub fn is_valid(&self) -> bool {
        for i in 1..self.chain.len() {
            let current = &self.chain[i];
            let previous = &self.chain[i - 1];

            if !current.is_valid(&previous.hash, self.difficulty) {
                return false;
            }
        }

        true
    }
}
```

---

## 4. åˆ†å¸ƒå¼æ•°æ®ç»“æ„

### 4.1 åˆ†å¸ƒå¼å“ˆå¸Œè¡¨ (DHT)

```rust
/// Chord DHT ç®€åŒ–å®ç°
pub struct ChordNode {
    id: usize,
    m: usize,  // æ ‡è¯†ç¬¦ä½æ•°
    finger_table: Vec<usize>,
    successor: usize,
    predecessor: Option<usize>,
}

impl ChordNode {
    pub fn new(id: usize, m: usize) -> Self {
        Self {
            id,
            m,
            finger_table: vec![0; m],
            successor: id,
            predecessor: None,
        }
    }

    /// æŸ¥æ‰¾é”®çš„è´Ÿè´£èŠ‚ç‚¹
    pub fn find_successor(&self, key: usize, nodes: &[ChordNode]) -> usize {
        if self.in_range(key, self.id, self.successor, self.m) {
            return self.successor;
        }

        // ä» finger table æŸ¥æ‰¾æœ€è¿‘çš„å‰é©±èŠ‚ç‚¹
        let closest = self.closest_preceding_node(key);

        if closest == self.id {
            self.successor
        } else {
            nodes[closest].find_successor(key, nodes)
        }
    }

    fn closest_preceding_node(&self, key: usize) -> usize {
        for i in (0..self.m).rev() {
            let finger = self.finger_table[i];
            if self.in_range(finger, self.id, key, self.m) {
                return finger;
            }
        }
        self.id
    }

    fn in_range(&self, val: usize, start: usize, end: usize, m: usize) -> bool {
        let max = 1 << m;
        if start < end {
            val > start && val <= end
        } else {
            val > start |
| val <= end
        }
    }

    /// è®¡ç®—å“ˆå¸Œï¼ˆä¸€è‡´æ€§å“ˆå¸Œï¼‰
    pub fn hash(key: &str, m: usize) -> usize {
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        use std::hash::{Hash, Hasher};
        key.hash(&mut hasher);
        (hasher.finish() as usize) % (1 << m)
    }
}
```

### 4.2 CRDT (Conflict-free Replicated Data Types)

```rust
/// G-Counter (Grow-only Counter) CRDT
#[derive(Debug, Clone)]
pub struct GCounter {
    counts: std::collections::HashMap<usize, u64>,
}

impl GCounter {
    pub fn new() -> Self {
        Self {
            counts: std::collections::HashMap::new(),
        }
    }

    /// å¢åŠ è®¡æ•°
    pub fn increment(&mut self, node_id: usize) {
        *self.counts.entry(node_id).or_insert(0) += 1;
    }

    /// è·å–æ€»è®¡æ•°
    pub fn value(&self) -> u64 {
        self.counts.values().sum()
    }

    /// åˆå¹¶ï¼ˆæ— å†²çªï¼‰
    pub fn merge(&mut self, other: &GCounter) {
        for (&node_id, &count) in &other.counts {
            let entry = self.counts.entry(node_id).or_insert(0);
            *entry = (*entry).max(count);
        }
    }
}

/// PN-Counter (Positive-Negative Counter) CRDT
#[derive(Debug, Clone)]
pub struct PNCounter {
    positive: GCounter,
    negative: GCounter,
}

impl PNCounter {
    pub fn new() -> Self {
        Self {
            positive: GCounter::new(),
            negative: GCounter::new(),
        }
    }

    pub fn increment(&mut self, node_id: usize) {
        self.positive.increment(node_id);
    }

    pub fn decrement(&mut self, node_id: usize) {
        self.negative.increment(node_id);
    }

    pub fn value(&self) -> i64 {
        self.positive.value() as i64 - self.negative.value() as i64
    }

    pub fn merge(&mut self, other: &PNCounter) {
        self.positive.merge(&other.positive);
        self.negative.merge(&other.negative);
    }
}

/// LWW-Element-Set (Last-Write-Wins Element Set) CRDT
#[derive(Debug, Clone)]
pub struct LWWSet<T: Clone + Eq + std::hash::Hash> {
    adds: std::collections::HashMap<T, u64>,  // (element, timestamp)
    removes: std::collections::HashMap<T, u64>,
}

impl<T: Clone + Eq + std::hash::Hash> LWWSet<T> {
    pub fn new() -> Self {
        Self {
            adds: std::collections::HashMap::new(),
            removes: std::collections::HashMap::new(),
        }
    }

    pub fn add(&mut self, element: T, timestamp: u64) {
        self.adds.insert(element, timestamp);
    }

    pub fn remove(&mut self, element: T, timestamp: u64) {
        self.removes.insert(element, timestamp);
    }

    pub fn contains(&self, element: &T) -> bool {
        match (self.adds.get(element), self.removes.get(element)) {
            (Some(&add_ts), Some(&remove_ts)) => add_ts > remove_ts,
            (Some(_), None) => true,
            _ => false,
        }
    }

    pub fn merge(&mut self, other: &LWWSet<T>) {
        for (elem, &ts) in &other.adds {
            let entry = self.adds.entry(elem.clone()).or_insert(0);
            *entry = (*entry).max(ts);
        }

        for (elem, &ts) in &other.removes {
            let entry = self.removes.entry(elem.clone()).or_insert(0);
            *entry = (*entry).max(ts);
        }
    }
}
```

### 4.3 å‘é‡æ—¶é’Ÿ

```rust
/// å‘é‡æ—¶é’Ÿ
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct VectorClock {
    clocks: std::collections::HashMap<usize, u64>,
}

impl VectorClock {
    pub fn new() -> Self {
        Self {
            clocks: std::collections::HashMap::new(),
        }
    }

    /// æœ¬åœ°äº‹ä»¶ï¼šé€’å¢è‡ªå·±çš„æ—¶é’Ÿ
    pub fn increment(&mut self, node_id: usize) {
        *self.clocks.entry(node_id).or_insert(0) += 1;
    }

    /// æ¥æ”¶æ¶ˆæ¯ï¼šæ›´æ–°æ—¶é’Ÿ
    pub fn merge(&mut self, other: &VectorClock, node_id: usize) {
        for (&id, &time) in &other.clocks {
            let entry = self.clocks.entry(id).or_insert(0);
            *entry = (*entry).max(time);
        }
        self.increment(node_id);
    }

    /// æ¯”è¾ƒä¸¤ä¸ªå‘é‡æ—¶é’Ÿ
    pub fn compare(&self, other: &VectorClock) -> Ordering {
        let mut less = false;
        let mut greater = false;

        let all_nodes: std::collections::HashSet<_> = self
            .clocks
            .keys()
            .chain(other.clocks.keys())
            .copied()
            .collect();

        for node in all_nodes {
            let self_time = self.clocks.get(&node).copied().unwrap_or(0);
            let other_time = other.clocks.get(&node).copied().unwrap_or(0);

            if self_time < other_time {
                less = true;
            } else if self_time > other_time {
                greater = true;
            }
        }

        match (less, greater) {
            (true, false) => Ordering::Less,      // self < other
            (false, true) => Ordering::Greater,   // self > other
            (false, false) => Ordering::Equal,    // self == other
            (true, true) => Ordering::Concurrent, // å¹¶å‘
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Ordering {
    Less,
    Greater,
    Equal,
    Concurrent,
}
```

---

## 5. åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹

### 5.1 MapReduce

```rust
use rayon::prelude::*;

/// MapReduce æ¡†æ¶
pub struct MapReduce;

impl MapReduce {
    /// Map é˜¶æ®µ
    pub fn map<T, K, V, F>(data: Vec<T>, map_fn: F) -> Vec<(K, V)>
    where
        T: Send,
        K: Send,
        V: Send,
        F: Fn(T) -> Vec<(K, V)> + Sync,
    {
        data.into_par_iter()
            .flat_map(|item| map_fn(item))
            .collect()
    }

    /// Shuffle é˜¶æ®µ
    pub fn shuffle<K, V>(mapped: Vec<(K, V)>) -> std::collections::HashMap<K, Vec<V>>
    where
        K: Eq + std::hash::Hash,
    {
        let mut groups = std::collections::HashMap::new();

        for (key, value) in mapped {
            groups.entry(key).or_insert_with(Vec::new).push(value);
        }

        groups
    }

    /// Reduce é˜¶æ®µ
    pub fn reduce<K, V, R, F>(
        shuffled: std::collections::HashMap<K, Vec<V>>,
        reduce_fn: F,
    ) -> Vec<(K, R)>
    where
        K: Send + Sync + Eq + std::hash::Hash,
        V: Send,
        R: Send,
        F: Fn(K, Vec<V>) -> R + Sync,
    {
        shuffled
            .into_par_iter()
            .map(|(key, values)| (key.clone(), reduce_fn(key, values)))
            .collect()
    }
}

/// ç¤ºä¾‹ï¼šWordCount
pub fn word_count(documents: Vec<String>) -> Vec<(String, usize)> {
    // Map: æå–å•è¯
    let mapped = MapReduce::map(documents, |doc| {
        doc.split_whitespace()
            .map(|word| (word.to_lowercase(), 1))
            .collect()
    });

    // Shuffle: åˆ†ç»„
    let shuffled = MapReduce::shuffle(mapped);

    // Reduce: è®¡æ•°
    MapReduce::reduce(shuffled, |_, counts| counts.len())
}
```

### 5.2 Bulk Synchronous Parallel (BSP)

```rust
/// BSP è¶…æ­¥
pub struct BSPSuperstep<T> {
    step: usize,
    messages: Vec<Vec<T>>,
}

/// BSP è®¡ç®—æ¡†æ¶
pub struct BSPComputation<V, M> {
    vertices: Vec<V>,
    messages: Vec<Vec<M>>,
    superstep: usize,
}

impl<V: Clone, M: Clone> BSPComputation<V, M> {
    pub fn new(vertices: Vec<V>) -> Self {
        let num_vertices = vertices.len();
        Self {
            vertices,
            messages: vec![Vec::new(); num_vertices],
            superstep: 0,
        }
    }

    /// æ‰§è¡Œä¸€ä¸ªè¶…æ­¥
    pub fn run_superstep<F>(&mut self, compute: F)
    where
        F: Fn(&V, Vec<M>) -> (V, Vec<(usize, M)>),
    {
        let mut next_messages = vec![Vec::new(); self.vertices.len()];

        // å¹¶è¡Œè®¡ç®—
        let results: Vec<_> = self
            .vertices
            .par_iter()
            .zip(&self.messages)
            .map(|(vertex, msgs)| compute(vertex, msgs.clone()))
            .collect();

        // æ›´æ–°é¡¶ç‚¹å’Œæ¶ˆæ¯
        for (i, (new_vertex, outgoing_msgs)) in results.into_iter().enumerate() {
            self.vertices[i] = new_vertex;

            for (target, msg) in outgoing_msgs {
                next_messages[target].push(msg);
            }
        }

        self.messages = next_messages;
        self.superstep += 1;
    }

    /// æ£€æŸ¥æ˜¯å¦æ”¶æ•›ï¼ˆæ²¡æœ‰æ¶ˆæ¯ï¼‰
    pub fn has_converged(&self) -> bool {
        self.messages.iter().all(|msgs| msgs.is_empty())
    }
}
```

### 5.3 Pregel (å›¾è®¡ç®—)

```rust
/// Pregel é¡¶ç‚¹
pub struct PregelVertex<V, E> {
    id: usize,
    value: V,
    edges: Vec<(usize, E)>,  // (ç›®æ ‡é¡¶ç‚¹, è¾¹æƒé‡)
    active: bool,
}

/// Pregel æ¶ˆæ¯
pub type Message<M> = (usize, M);  // (ç›®æ ‡é¡¶ç‚¹, æ¶ˆæ¯å†…å®¹)

/// Pregel è®¡ç®—æ¡†æ¶
pub struct PregelGraph<V, E, M> {
    vertices: Vec<PregelVertex<V, E>>,
    messages: Vec<Vec<M>>,
    superstep: usize,
}

impl<V: Clone + Send + Sync, E: Clone + Send + Sync, M: Clone + Send + Sync> PregelGraph<V, E, M> {
    pub fn new(vertices: Vec<PregelVertex<V, E>>) -> Self {
        let num_vertices = vertices.len();
        Self {
            vertices,
            messages: vec![Vec::new(); num_vertices],
            superstep: 0,
        }
    }

    /// æ‰§è¡Œä¸€ä¸ªè¶…æ­¥
    pub fn run_superstep<F>(&mut self, compute: F)
    where
        F: Fn(&mut PregelVertex<V, E>, Vec<M>) -> Vec<Message<M>> + Sync,
    {
        let mut next_messages = vec![Vec::new(); self.vertices.len()];

        // å¹¶è¡Œè®¡ç®—
        let results: Vec<_> = self
            .vertices
            .par_iter_mut()
            .zip(&self.messages)
            .filter(|(v, _)| v.active)
            .map(|(vertex, msgs)| compute(vertex, msgs.clone()))
            .collect();

        // å‘é€æ¶ˆæ¯
        for outgoing in results {
            for (target, msg) in outgoing {
                next_messages[target].push(msg);
            }
        }

        self.messages = next_messages;
        self.superstep += 1;
    }

    /// æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¡¶ç‚¹éƒ½ä¸æ´»è·ƒ
    pub fn has_halted(&self) -> bool {
        self.vertices.iter().all(|v| !v.active)
            && self.messages.iter().all(|msgs| msgs.is_empty())
    }
}

/// ç¤ºä¾‹ï¼šPregel PageRank
pub fn pregel_pagerank(graph: &[Vec<usize>], iterations: usize) -> Vec<f64> {
    let n = graph.len();
    let damping = 0.85;
    let initial_rank = 1.0 / n as f64;

    let vertices: Vec<_> = (0..n)
        .map(|id| PregelVertex {
            id,
            value: initial_rank,
            edges: graph[id].iter().map(|&target| (target, ())).collect(),
            active: true,
        })
        .collect();

    let mut pregel = PregelGraph::new(vertices);

    for _ in 0..iterations {
        pregel.run_superstep(|vertex, msgs: Vec<f64>| {
            let rank: f64 = msgs.iter().sum();
            vertex.value = (1.0 - damping) / n as f64 + damping * rank;

            let out_degree = vertex.edges.len() as f64;
            let msg = vertex.value / out_degree;

            vertex.edges
                .iter()
                .map(|&(target, _)| (target, msg))
                .collect()
        });
    }

    pregel.vertices.iter().map(|v| v.value).collect()
}
```

---

## 6. å®è·µæ¡ˆä¾‹

### 6.1 åˆ†å¸ƒå¼é”

```rust
use std::time::{Duration, Instant};

/// Redlock ç®—æ³•ï¼ˆç®€åŒ–å®ç°ï¼‰
pub struct DistributedLock {
    nodes: Vec<LockNode>,
    quorum: usize,
}

struct LockNode {
    id: usize,
    locks: std::collections::HashMap<String, Instant>,
}

impl DistributedLock {
    pub fn new(num_nodes: usize) -> Self {
        let nodes = (0..num_nodes)
            .map(|id| LockNode {
                id,
                locks: std::collections::HashMap::new(),
            })
            .collect();

        Self {
            quorum: num_nodes / 2 + 1,
            nodes,
        }
    }

    /// å°è¯•è·å–é”
    pub fn try_lock(&mut self, resource: &str, ttl: Duration) -> bool {
        let start = Instant::now();
        let mut locked_nodes = 0;

        for node in &mut self.nodes {
            if node.try_lock(resource, ttl) {
                locked_nodes += 1;
            }
        }

        let elapsed = start.elapsed();
        let validity_time = ttl.checked_sub(elapsed).unwrap_or(Duration::ZERO);

        if locked_nodes >= self.quorum && validity_time > Duration::ZERO {
            true
        } else {
            // é‡Šæ”¾å·²è·å–çš„é”
            self.unlock(resource);
            false
        }
    }

    /// é‡Šæ”¾é”
    pub fn unlock(&mut self, resource: &str) {
        for node in &mut self.nodes {
            node.unlock(resource);
        }
    }
}

impl LockNode {
    fn try_lock(&mut self, resource: &str, ttl: Duration) -> bool {
        let now = Instant::now();

        // æ£€æŸ¥é”æ˜¯å¦å·²è¿‡æœŸ
        if let Some(&expiry) = self.locks.get(resource) {
            if now < expiry {
                return false; // é”ä»ç„¶æœ‰æ•ˆ
            }
        }

        // è·å–é”
        self.locks.insert(resource.to_string(), now + ttl);
        true
    }

    fn unlock(&mut self, resource: &str) {
        self.locks.remove(resource);
    }
}
```

### 6.2 åˆ†å¸ƒå¼äº‹åŠ¡

å·²åœ¨ [2.3 ä¸¤é˜¶æ®µæäº¤](#23-ä¸¤é˜¶æ®µæäº¤-2pc) ä¸­å®ç°ã€‚

### 6.3 åˆ†å¸ƒå¼ç¼“å­˜

```rust
/// ä¸€è‡´æ€§å“ˆå¸Œç¯
pub struct ConsistentHashRing {
    ring: std::collections::BTreeMap<u64, usize>,  // (hash, node_id)
    virtual_nodes: usize,
}

impl ConsistentHashRing {
    pub fn new(virtual_nodes: usize) -> Self {
        Self {
            ring: std::collections::BTreeMap::new(),
            virtual_nodes,
        }
    }

    /// æ·»åŠ èŠ‚ç‚¹
    pub fn add_node(&mut self, node_id: usize) {
        for i in 0..self.virtual_nodes {
            let key = format!("{}:{}", node_id, i);
            let hash = Self::hash(&key);
            self.ring.insert(hash, node_id);
        }
    }

    /// ç§»é™¤èŠ‚ç‚¹
    pub fn remove_node(&mut self, node_id: usize) {
        for i in 0..self.virtual_nodes {
            let key = format!("{}:{}", node_id, i);
            let hash = Self::hash(&key);
            self.ring.remove(&hash);
        }
    }

    /// æŸ¥æ‰¾é”®å¯¹åº”çš„èŠ‚ç‚¹
    pub fn get_node(&self, key: &str) -> Option<usize> {
        if self.ring.is_empty() {
            return None;
        }

        let hash = Self::hash(key);

        // æ‰¾åˆ°ç¬¬ä¸€ä¸ª >= hash çš„èŠ‚ç‚¹
        self.ring
            .range(hash..)
            .next()
            .or_else(|| self.ring.iter().next())
            .map(|(_, &node)| node)
    }

    fn hash(key: &str) -> u64 {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        key.hash(&mut hasher);
        hasher.finish()
    }
}

/// åˆ†å¸ƒå¼ç¼“å­˜
pub struct DistributedCache {
    nodes: Vec<std::collections::HashMap<String, String>>,
    ring: ConsistentHashRing,
}

impl DistributedCache {
    pub fn new(num_nodes: usize) -> Self {
        let mut ring = ConsistentHashRing::new(150);

        for i in 0..num_nodes {
            ring.add_node(i);
        }

        Self {
            nodes: vec![std::collections::HashMap::new(); num_nodes],
            ring,
        }
    }

    pub fn get(&self, key: &str) -> Option<String> {
        let node_id = self.ring.get_node(key)?;
        self.nodes[node_id].get(key).cloned()
    }

    pub fn set(&mut self, key: String, value: String) -> Result<(), String> {
        let node_id = self.ring.get_node(&key)
            .ok_or_else(|| "No available nodes".to_string())?;

        self.nodes[node_id].insert(key, value);
        Ok(())
    }
}
```

---

## 7. å‚è€ƒèµ„æ–™

### æ•™æ

- **[Tanenbaum-Van Steen]** Tanenbaum, Van Steen. _Distributed Systems: Principles and Paradigms_
- **[Coulouris et al.]** Coulouris, Dollimore, Kindberg, Blair. _Distributed Systems: Concepts and Design_
- **[Lynch]** Lynch. _Distributed Algorithms_

### è®ºæ–‡

- **[Lamport, 1978]** "Time, Clocks, and the Ordering of Events in a Distributed System"
- **[Lamport, 1998]** "The Part-Time Parliament" (Paxos)
- **[Ongaro-Ousterhout, 2014]** "In Search of an Understandable Consensus Algorithm" (Raft)
- **[Castro-Liskov, 1999]** "Practical Byzantine Fault Tolerance"
- **[DeCandia et al., 2007]** "Dynamo: Amazon's Highly Available Key-value Store"

### å¼€æºé¡¹ç›®

- **[etcd]** <https://etcd.io/> (Raft å®ç°)
- **[Consul]** <https://www.consul.io/> (åˆ†å¸ƒå¼ä¸€è‡´æ€§)
- **[TiKV]** <https://tikv.org/> (åˆ†å¸ƒå¼ KV å­˜å‚¨, Rust å®ç°)

---

**æ–‡æ¡£å®Œæˆåº¦**: 100%
**ä»£ç ç¤ºä¾‹æ•°**: 35+
**ç®—æ³•è¦†ç›–**: Paxos, Raft, 2PC, PBFT, PoW, DHT, CRDT, MapReduce, BSP, Pregel
**å®è·µæ¡ˆä¾‹**: åˆ†å¸ƒå¼é”, äº‹åŠ¡, ç¼“å­˜

**ä¸‹ä¸€æ­¥**: å‚è§ [`04_ç®—æ³•å·¥ç¨‹å®è·µ.md`](./04_ç®—æ³•å·¥ç¨‹å®è·µ.md)
