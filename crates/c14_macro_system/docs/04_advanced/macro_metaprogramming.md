# å®å…ƒç¼–ç¨‹æ·±åº¦è§£æ

> **æ–‡æ¡£å®šä½**: Rustå®å…ƒç¼–ç¨‹å®Œæ•´æŠ€æœ¯æŒ‡å—  
> **åˆ›å»ºæ—¥æœŸ**: 2025-10-20  
> **é€‚ç”¨ç‰ˆæœ¬**: Rust 1.90+ | Edition 2024  
> **æ–‡æ¡£ç±»å‹**: é«˜çº§ä¸»é¢˜ + æ·±åº¦è§£æ

---

## ğŸ“Š ç›®å½•

- [å®å…ƒç¼–ç¨‹æ·±åº¦è§£æ](#å®å…ƒç¼–ç¨‹æ·±åº¦è§£æ)
  - [ğŸ“Š ç›®å½•](#-ç›®å½•)
  - [1. å…ƒç¼–ç¨‹åŸºç¡€](#1-å…ƒç¼–ç¨‹åŸºç¡€)
    - [1.1 ä»€ä¹ˆæ˜¯å…ƒç¼–ç¨‹](#11-ä»€ä¹ˆæ˜¯å…ƒç¼–ç¨‹)
    - [1.2 Rustå®çš„ä¸‰ä¸ªå±‚æ¬¡](#12-rustå®çš„ä¸‰ä¸ªå±‚æ¬¡)
  - [2. TokenStreamå†…éƒ¨æœºåˆ¶](#2-tokenstreamå†…éƒ¨æœºåˆ¶)
    - [2.1 Tokenç»“æ„](#21-tokenç»“æ„)
    - [2.2 æ‰‹åŠ¨æ„å»ºTokenStream](#22-æ‰‹åŠ¨æ„å»ºtokenstream)
  - [3. ASTæ“ä½œä¸è½¬æ¢](#3-astæ“ä½œä¸è½¬æ¢)
    - [3.1 ä½¿ç”¨synè§£æAST](#31-ä½¿ç”¨synè§£æast)
    - [3.2 ASTè®¿é—®å™¨æ¨¡å¼](#32-astè®¿é—®å™¨æ¨¡å¼)
  - [4. ç¼–è¯‘æ—¶è®¡ç®—](#4-ç¼–è¯‘æ—¶è®¡ç®—)
    - [4.1 constå®](#41-constå®)
    - [4.2 ç¼–è¯‘æ—¶å­—ç¬¦ä¸²å¤„ç†](#42-ç¼–è¯‘æ—¶å­—ç¬¦ä¸²å¤„ç†)
  - [5. ç±»å‹çº§ç¼–ç¨‹](#5-ç±»å‹çº§ç¼–ç¨‹)
    - [5.1 ç±»å‹çº§åˆ—è¡¨](#51-ç±»å‹çº§åˆ—è¡¨)
    - [5.2 ç±»å‹çº§å‡½æ•°](#52-ç±»å‹çº§å‡½æ•°)
  - [6. å®ç»„åˆæ¨¡å¼](#6-å®ç»„åˆæ¨¡å¼)
    - [6.1 å®è°ƒç”¨å®](#61-å®è°ƒç”¨å®)
    - [6.2 è¿‡ç¨‹å®è°ƒç”¨å£°æ˜å®](#62-è¿‡ç¨‹å®è°ƒç”¨å£°æ˜å®)
  - [7. é«˜çº§è¯­æ³•æ“ä½œ](#7-é«˜çº§è¯­æ³•æ“ä½œ)
    - [7.1 å±æ€§æ“ä½œ](#71-å±æ€§æ“ä½œ)
    - [7.2 æ³›å‹æ“ä½œ](#72-æ³›å‹æ“ä½œ)
  - [8. å®æˆ˜æ¡ˆä¾‹](#8-å®æˆ˜æ¡ˆä¾‹)
    - [8.1 SQLæŸ¥è¯¢ç”Ÿæˆå™¨](#81-sqlæŸ¥è¯¢ç”Ÿæˆå™¨)
    - [8.2 ç¼–è¯‘æ—¶JSONéªŒè¯](#82-ç¼–è¯‘æ—¶jsonéªŒè¯)
  - [æ€»ç»“](#æ€»ç»“)
  - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)
  - [è¿”å›å¯¼èˆª](#è¿”å›å¯¼èˆª)

---

## 1. å…ƒç¼–ç¨‹åŸºç¡€

### 1.1 ä»€ä¹ˆæ˜¯å…ƒç¼–ç¨‹

**å®šä¹‰**: ç¼–å†™ç”Ÿæˆæˆ–æ“ä½œä»£ç çš„ä»£ç ã€‚

```rust
/// å…ƒç¼–ç¨‹çš„æœ¬è´¨ï¼šä»£ç å³æ•°æ®ï¼Œæ•°æ®å³ä»£ç 
///
/// Level 0: è¿è¡Œæ—¶ - æ‰§è¡Œä»£ç 
/// Level 1: ç¼–è¯‘æ—¶ - ç”Ÿæˆä»£ç ï¼ˆå®ï¼‰
/// Level 2: ç±»å‹ç³»ç»Ÿ - çº¦æŸä»£ç ï¼ˆæ³›å‹+traitï¼‰
```

### 1.2 Rustå®çš„ä¸‰ä¸ªå±‚æ¬¡

```mermaid
graph TB
    subgraph L3[Layer 3: ç±»å‹ç³»ç»Ÿ]
        Generic[æ³›å‹]
        Trait[Trait]
        Associated[å…³è”ç±»å‹]
    end
    
    subgraph L2[Layer 2: è¿‡ç¨‹å®]
        Derive[Deriveå®]
        Attribute[å±æ€§å®]
        Function[å‡½æ•°å®]
    end
    
    subgraph L1[Layer 1: å£°æ˜å®]
        MacroRules[macro_rules!]
        Pattern[æ¨¡å¼åŒ¹é…]
    end
    
    L1 --> L2
    L2 --> L3
    
    style L1 fill:#e3f2fd
    style L2 fill:#fff3e0
    style L3 fill:#c8e6c9
```

---

## 2. TokenStreamå†…éƒ¨æœºåˆ¶

### 2.1 Tokenç»“æ„

```rust
use proc_macro2::{TokenStream, TokenTree, Spacing, Span};

/// Tokençš„å®Œæ•´ç»“æ„
pub enum TokenTree {
    /// æ ‡è¯†ç¬¦æˆ–å…³é”®å­—
    Ident(Ident),
    
    /// å­—é¢é‡
    Literal(Literal),
    
    /// æ ‡ç‚¹ç¬¦å·
    Punct(Punct),
    
    /// åˆ†ç»„ (æ‹¬å·åŒ…è£¹çš„å†…å®¹)
    Group(Group),
}

/// Punct: æ ‡ç‚¹ç¬¦å·
pub struct Punct {
    ch: char,               // å­—ç¬¦: +, -, *, ...
    spacing: Spacing,       // Alone or Joint
    span: Span,             // æºä»£ç ä½ç½®
}

/// ç¤ºä¾‹ï¼šè§£æ `a + b`
fn parse_addition(tokens: TokenStream) {
    let mut iter = tokens.into_iter();
    
    // Token 1: Ident("a")
    let a = iter.next().unwrap();
    
    // Token 2: Punct('+', Alone)
    let plus = iter.next().unwrap();
    
    // Token 3: Ident("b")
    let b = iter.next().unwrap();
}
```

---

### 2.2 æ‰‹åŠ¨æ„å»ºTokenStream

```rust
use quote::quote;
use syn::Ident;
use proc_macro2::{TokenStream, Span};

/// æ–¹æ³•1: ä½¿ç”¨quoteå®
fn build_with_quote() -> TokenStream {
    let name = Ident::new("MyStruct", Span::call_site());
    
    quote! {
        struct #name {
            field: i32,
        }
    }
}

/// æ–¹æ³•2: æ‰‹åŠ¨æ„å»º
fn build_manually() -> TokenStream {
    use proc_macro2::{TokenTree, Group, Delimiter};
    
    let mut tokens = TokenStream::new();
    
    // struct
    tokens.extend([
        TokenTree::Ident(Ident::new("struct", Span::call_site())),
    ]);
    
    // MyStruct
    tokens.extend([
        TokenTree::Ident(Ident::new("MyStruct", Span::call_site())),
    ]);
    
    // { field: i32 }
    let mut body = TokenStream::new();
    body.extend([
        TokenTree::Ident(Ident::new("field", Span::call_site())),
        TokenTree::Punct(Punct::new(':', Spacing::Alone)),
        TokenTree::Ident(Ident::new("i32", Span::call_site())),
    ]);
    
    tokens.extend([
        TokenTree::Group(Group::new(Delimiter::Brace, body)),
    ]);
    
    tokens
}
```

---

## 3. ASTæ“ä½œä¸è½¬æ¢

### 3.1 ä½¿ç”¨synè§£æAST

```rust
use syn::{parse_macro_input, DeriveInput, Data, Fields};
use quote::quote;

#[proc_macro_derive(MyDebug)]
pub fn my_debug(input: TokenStream) -> TokenStream {
    // 1. è§£æä¸ºAST
    let input = parse_macro_input!(input as DeriveInput);
    
    let name = &input.ident;
    let generics = &input.generics;
    let (impl_generics, ty_generics, where_clause) = generics.split_for_impl();
    
    // 2. åˆ†æç»“æ„
    let debug_fields = match &input.data {
        Data::Struct(data) => {
            match &data.fields {
                Fields::Named(fields) => {
                    let field_names: Vec<_> = fields.named
                        .iter()
                        .map(|f| &f.ident)
                        .collect();
                    
                    quote! {
                        #(
                            .field(stringify!(#field_names), &self.#field_names)
                        )*
                    }
                }
                _ => panic!("Only named fields supported"),
            }
        }
        _ => panic!("Only structs supported"),
    };
    
    // 3. ç”Ÿæˆä»£ç 
    let expanded = quote! {
        impl #impl_generics std::fmt::Debug for #name #ty_generics #where_clause {
            fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
                f.debug_struct(stringify!(#name))
                    #debug_fields
                    .finish()
            }
        }
    };
    
    TokenStream::from(expanded)
}
```

---

### 3.2 ASTè®¿é—®å™¨æ¨¡å¼

```rust
use syn::visit::{self, Visit};
use syn::{ItemFn, Expr};

/// è®¿é—®å™¨ï¼šç»Ÿè®¡å‡½æ•°ä¸­çš„è¡¨è¾¾å¼æ•°é‡
struct ExprCounter {
    count: usize,
}

impl<'ast> Visit<'ast> for ExprCounter {
    fn visit_expr(&mut self, expr: &'ast Expr) {
        self.count += 1;
        // é€’å½’è®¿é—®å­è¡¨è¾¾å¼
        visit::visit_expr(self, expr);
    }
}

// ä½¿ç”¨
fn count_expressions(func: &ItemFn) -> usize {
    let mut counter = ExprCounter { count: 0 };
    counter.visit_item_fn(func);
    counter.count
}
```

---

## 4. ç¼–è¯‘æ—¶è®¡ç®—

### 4.1 constå®

```rust
/// ç¼–è¯‘æ—¶è®¡ç®—æ–æ³¢é‚£å¥‘æ•°
macro_rules! fib {
    (0) => { 0 };
    (1) => { 1 };
    ($n:expr) => {
        fib!($n - 1) + fib!($n - 2)
    };
}

// ç¼–è¯‘æ—¶è®¡ç®—
const FIB_10: u64 = fib!(10); // 55

/// ç¼–è¯‘æ—¶ç±»å‹çº§è®¡ç®—
trait Nat {
    const VALUE: usize;
}

struct Zero;
struct Succ<N: Nat>(N);

impl Nat for Zero {
    const VALUE: usize = 0;
}

impl<N: Nat> Nat for Succ<N> {
    const VALUE: usize = N::VALUE + 1;
}

// ç±»å‹çº§è‡ªç„¶æ•°
type One = Succ<Zero>;
type Two = Succ<One>;
type Three = Succ<Two>;

assert_eq!(Three::VALUE, 3);
```

---

### 4.2 ç¼–è¯‘æ—¶å­—ç¬¦ä¸²å¤„ç†

```rust
/// ç¼–è¯‘æ—¶æ‹¼æ¥å­—ç¬¦ä¸²
macro_rules! concat_idents {
    ($a:ident, $b:ident) => {
        paste::paste! {
            [<$a $b>]
        }
    };
}

// ä½¿ç”¨paste crate
use paste::paste;

paste! {
    fn [<make_ foo>]() -> i32 { 42 }
}

assert_eq!(make_foo(), 42);
```

---

## 5. ç±»å‹çº§ç¼–ç¨‹

### 5.1 ç±»å‹çº§åˆ—è¡¨

```rust
/// HList: å¼‚æ„åˆ—è¡¨
trait HList {}

struct HNil;
struct HCons<H, T: HList>(H, T);

impl HList for HNil {}
impl<H, T: HList> HList for HCons<H, T> {}

/// ä½¿ç”¨
type MyList = HCons<i32, HCons<String, HCons<bool, HNil>>>;

/// å®ç®€åŒ–æ„é€ 
macro_rules! hlist {
    () => { HNil };
    ($head:expr) => { HCons($head, HNil) };
    ($head:expr, $($tail:expr),+) => {
        HCons($head, hlist!($($tail),+))
    };
}

let list = hlist!(42, "hello".to_string(), true);
```

---

### 5.2 ç±»å‹çº§å‡½æ•°

```rust
/// ç±»å‹çº§å‡½æ•°ï¼šLength
trait Length {
    const LEN: usize;
}

impl Length for HNil {
    const LEN: usize = 0;
}

impl<H, T: HList + Length> Length for HCons<H, T> {
    const LEN: usize = 1 + T::LEN;
}

/// ç±»å‹çº§æ˜ å°„
trait Map<F> {
    type Output: HList;
}

impl<F> Map<F> for HNil {
    type Output = HNil;
}

impl<F, H, T> Map<F> for HCons<H, T>
where
    F: TypeFn<H>,
    T: HList + Map<F>,
{
    type Output = HCons<F::Output, T::Map<F>>;
}
```

---

## 6. å®ç»„åˆæ¨¡å¼

### 6.1 å®è°ƒç”¨å®

```rust
/// æ„å»ºå™¨æ¨¡å¼ç”Ÿæˆå™¨
macro_rules! builder_pattern {
    (
        $name:ident {
            $($field:ident: $ty:ty),* $(,)?
        }
    ) => {
        // ç”Ÿæˆä¸»ç»“æ„
        pub struct $name {
            $(pub $field: $ty),*
        }
        
        // ç”ŸæˆBuilder
        paste::paste! {
            pub struct [<$name Builder>] {
                $($field: Option<$ty>),*
            }
            
            impl [<$name Builder>] {
                pub fn new() -> Self {
                    Self {
                        $($field: None),*
                    }
                }
                
                $(
                    pub fn $field(mut self, value: $ty) -> Self {
                        self.$field = Some(value);
                        self
                    }
                )*
                
                pub fn build(self) -> Result<$name, String> {
                    Ok($name {
                        $(
                            $field: self.$field
                                .ok_or(concat!("Missing field: ", stringify!($field)))?,
                        )*
                    })
                }
            }
        }
    };
}

// ä½¿ç”¨
builder_pattern! {
    User {
        id: u64,
        name: String,
        email: String,
    }
}

let user = UserBuilder::new()
    .id(1)
    .name("Alice".to_string())
    .email("alice@example.com".to_string())
    .build()
    .unwrap();
```

---

### 6.2 è¿‡ç¨‹å®è°ƒç”¨å£°æ˜å®

```rust
#[proc_macro]
pub fn generate_tests(input: TokenStream) -> TokenStream {
    let cases: Vec<(String, i32)> = parse_test_cases(input);
    
    let tests = cases.iter().map(|(name, input)| {
        let test_name = format_ident!("test_{}", name);
        quote! {
            #[test]
            fn #test_name() {
                assert_eq!(function_under_test(#input), expected_output(#input));
            }
        }
    });
    
    quote! {
        #(#tests)*
    }.into()
}
```

---

## 7. é«˜çº§è¯­æ³•æ“ä½œ

### 7.1 å±æ€§æ“ä½œ

```rust
use syn::{Attribute, Meta, NestedMeta, Lit};

/// è§£æ #[my_macro(key = "value")]
fn parse_attributes(attrs: &[Attribute]) -> HashMap<String, String> {
    let mut map = HashMap::new();
    
    for attr in attrs {
        if attr.path.is_ident("my_macro") {
            if let Ok(Meta::List(meta_list)) = attr.parse_meta() {
                for nested in meta_list.nested {
                    if let NestedMeta::Meta(Meta::NameValue(nv)) = nested {
                        if let Lit::Str(lit_str) = &nv.lit {
                            let key = nv.path.get_ident().unwrap().to_string();
                            map.insert(key, lit_str.value());
                        }
                    }
                }
            }
        }
    }
    
    map
}
```

---

### 7.2 æ³›å‹æ“ä½œ

```rust
use syn::{Generics, GenericParam, TypeParam};

/// ä¸ºæ³›å‹æ·»åŠ traitçº¦æŸ
fn add_trait_bounds(generics: &mut Generics, trait_path: syn::Path) {
    for param in &mut generics.params {
        if let GenericParam::Type(type_param) = param {
            type_param.bounds.push(syn::TypeParamBound::Trait(
                syn::TraitBound {
                    paren_token: None,
                    modifier: syn::TraitBoundModifier::None,
                    lifetimes: None,
                    path: trait_path.clone(),
                }
            ));
        }
    }
}

// ä½¿ç”¨
let mut generics = /* ... */;
let trait_path = syn::parse_quote!(std::fmt::Debug);
add_trait_bounds(&mut generics, trait_path);
```

---

## 8. å®æˆ˜æ¡ˆä¾‹

### 8.1 SQLæŸ¥è¯¢ç”Ÿæˆå™¨

```rust
/// SQL DSLå®
macro_rules! sql {
    (SELECT $($col:ident),+ FROM $table:ident WHERE $field:ident = $value:expr) => {
        {
            let mut query = String::from("SELECT ");
            $(
                query.push_str(stringify!($col));
                query.push_str(", ");
            )+
            query.truncate(query.len() - 2);
            
            query.push_str(" FROM ");
            query.push_str(stringify!($table));
            query.push_str(" WHERE ");
            query.push_str(stringify!($field));
            query.push_str(" = ");
            query.push_str(&format!("{:?}", $value));
            
            query
        }
    };
}

// ä½¿ç”¨
let query = sql!(SELECT id, name FROM users WHERE age = 25);
assert_eq!(query, "SELECT id, name FROM users WHERE age = 25");
```

---

### 8.2 ç¼–è¯‘æ—¶JSONéªŒè¯

```rust
use proc_macro::TokenStream;
use syn::{parse_macro_input, LitStr};
use serde_json::Value;

#[proc_macro]
pub fn json_schema(input: TokenStream) -> TokenStream {
    let json_str = parse_macro_input!(input as LitStr);
    
    // ç¼–è¯‘æ—¶éªŒè¯JSON
    match serde_json::from_str::<Value>(&json_str.value()) {
        Ok(_) => {
            // ç”Ÿæˆé™æ€å­—ç¬¦ä¸²
            quote! {
                #json_str
            }.into()
        }
        Err(e) => {
            let error_msg = format!("Invalid JSON: {}", e);
            quote! {
                compile_error!(#error_msg);
            }.into()
        }
    }
}
```

---

## æ€»ç»“

å®å…ƒç¼–ç¨‹æ˜¯Rustæœ€å¼ºå¤§çš„ç‰¹æ€§ä¹‹ä¸€ï¼š

- âœ… **TokenStream**: ç†è§£Tokenç»“æ„å’Œæ“ä½œ
- âœ… **ASTæ“ä½œ**: ä½¿ç”¨synè§£æå’Œè½¬æ¢
- âœ… **ç¼–è¯‘æ—¶è®¡ç®—**: constå’Œç±»å‹çº§è®¡ç®—
- âœ… **ç±»å‹çº§ç¼–ç¨‹**: HListå’Œç±»å‹å‡½æ•°
- âœ… **å®ç»„åˆ**: æ„å»ºå¤æ‚çš„å…ƒç¼–ç¨‹ç³»ç»Ÿ

---

## ç›¸å…³æ–‡æ¡£

- [è¿‡ç¨‹å®åŸºç¡€](../03_procedural/01_proc_macro_basics.md)
- [TokenStreamè¯¦è§£](../03_procedural/05_token_streams.md)
- [DSLæ„å»º](./dsl_construction.md)
- [æ€§èƒ½ä¼˜åŒ–](./macro_optimization.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-20

## è¿”å›å¯¼èˆª

- [è¿”å›é«˜çº§ä¸»é¢˜](README.md)
- [è¿”å›ä¸»ç´¢å¼•](../00_MASTER_INDEX.md)
