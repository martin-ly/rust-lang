# æ¶ˆæ¯é˜Ÿåˆ—

> **æ ¸å¿ƒåº“**: rdkafka, lapin, async-nats, pulsar-rs  
> **é€‚ç”¨åœºæ™¯**: åˆ†å¸ƒå¼æ¶ˆæ¯ã€äº‹ä»¶é©±åŠ¨ã€å¼‚æ­¥é€šä¿¡ã€æµå¤„ç†ã€å¾®æœåŠ¡è§£è€¦

---

## ğŸ“‹ ç›®å½•

- [æ¶ˆæ¯é˜Ÿåˆ—](#æ¶ˆæ¯é˜Ÿåˆ—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
    - [æ¶ˆæ¯é˜Ÿåˆ—æ¦‚å¿µ](#æ¶ˆæ¯é˜Ÿåˆ—æ¦‚å¿µ)
    - [ä¸ºä»€ä¹ˆéœ€è¦æ¶ˆæ¯é˜Ÿåˆ—](#ä¸ºä»€ä¹ˆéœ€è¦æ¶ˆæ¯é˜Ÿåˆ—)
    - [æ¶ˆæ¯æ¨¡å¼å¯¹æ¯”](#æ¶ˆæ¯æ¨¡å¼å¯¹æ¯”)
  - [æ ¸å¿ƒåº“å¯¹æ¯”](#æ ¸å¿ƒåº“å¯¹æ¯”)
    - [åŠŸèƒ½çŸ©é˜µ](#åŠŸèƒ½çŸ©é˜µ)
    - [é€‰æ‹©æŒ‡å—](#é€‰æ‹©æŒ‡å—)
    - [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
  - [rdkafka - Kafka å®¢æˆ·ç«¯](#rdkafka---kafka-å®¢æˆ·ç«¯)
    - [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
    - [ç”Ÿäº§è€…](#ç”Ÿäº§è€…)
      - [åŸºç¡€ç”¨æ³•ï¼šå¼‚æ­¥ç”Ÿäº§è€…](#åŸºç¡€ç”¨æ³•å¼‚æ­¥ç”Ÿäº§è€…)
      - [é«˜çº§ç”¨æ³•ï¼šæ‰¹é‡å‘é€](#é«˜çº§ç”¨æ³•æ‰¹é‡å‘é€)
    - [æ¶ˆè´¹è€…](#æ¶ˆè´¹è€…)
      - [åŸºç¡€ç”¨æ³•ï¼šæ¶ˆè´¹è€…ç»„](#åŸºç¡€ç”¨æ³•æ¶ˆè´¹è€…ç»„)
      - [é«˜çº§ç”¨æ³•ï¼šæ‰‹åŠ¨æäº¤ offset](#é«˜çº§ç”¨æ³•æ‰‹åŠ¨æäº¤-offset)
    - [æµå¤„ç†](#æµå¤„ç†)
      - [çª—å£èšåˆç¤ºä¾‹](#çª—å£èšåˆç¤ºä¾‹)
  - [lapin - RabbitMQ å®¢æˆ·ç«¯](#lapin---rabbitmq-å®¢æˆ·ç«¯)
    - [æ ¸å¿ƒç‰¹æ€§1](#æ ¸å¿ƒç‰¹æ€§1)
    - [åŸºç¡€ç”¨æ³•](#åŸºç¡€ç”¨æ³•)
      - [ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…](#ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…)
      - [æ¶ˆè´¹è€…ï¼ˆå·¥ä½œé˜Ÿåˆ—ï¼‰](#æ¶ˆè´¹è€…å·¥ä½œé˜Ÿåˆ—)
    - [å·¥ä½œé˜Ÿåˆ—æ¨¡å¼](#å·¥ä½œé˜Ÿåˆ—æ¨¡å¼)
    - [å‘å¸ƒè®¢é˜…æ¨¡å¼](#å‘å¸ƒè®¢é˜…æ¨¡å¼)
  - [async-nats - NATS å®¢æˆ·ç«¯](#async-nats---nats-å®¢æˆ·ç«¯)
    - [æ ¸å¿ƒç‰¹æ€§2](#æ ¸å¿ƒç‰¹æ€§2)
    - [å‘å¸ƒè®¢é˜…](#å‘å¸ƒè®¢é˜…)
      - [åŸºç¡€ç”¨æ³•1](#åŸºç¡€ç”¨æ³•1)
      - [è®¢é˜…æ¶ˆæ¯](#è®¢é˜…æ¶ˆæ¯)
    - [è¯·æ±‚å“åº”](#è¯·æ±‚å“åº”)
    - [JetStream æŒä¹…åŒ–](#jetstream-æŒä¹…åŒ–)
  - [å®æˆ˜åœºæ™¯](#å®æˆ˜åœºæ™¯)
    - [åœºæ™¯1: è®¢å•å¤„ç†ç³»ç»Ÿ](#åœºæ™¯1-è®¢å•å¤„ç†ç³»ç»Ÿ)
    - [åœºæ™¯2: å®æ—¶æ—¥å¿—èšåˆ](#åœºæ™¯2-å®æ—¶æ—¥å¿—èšåˆ)
    - [åœºæ™¯3: å¾®æœåŠ¡äº‹ä»¶æ€»çº¿](#åœºæ™¯3-å¾®æœåŠ¡äº‹ä»¶æ€»çº¿)
  - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
    - [1. æ¶ˆæ¯å¹‚ç­‰æ€§å¤„ç†](#1-æ¶ˆæ¯å¹‚ç­‰æ€§å¤„ç†)
    - [2. é”™è¯¯å¤„ç†å’Œé‡è¯•](#2-é”™è¯¯å¤„ç†å’Œé‡è¯•)
    - [3. æ¶ˆè´¹è€…ç»„é…ç½®](#3-æ¶ˆè´¹è€…ç»„é…ç½®)
    - [4. æ¶ˆæ¯å‹ç¼©](#4-æ¶ˆæ¯å‹ç¼©)
    - [5. ç›‘æ§å’Œå¯è§‚æµ‹æ€§](#5-ç›‘æ§å’Œå¯è§‚æµ‹æ€§)
  - [å¸¸è§é™·é˜±](#å¸¸è§é™·é˜±)
    - [âš ï¸ é™·é˜±1: Kafka offset æäº¤é”™è¯¯](#ï¸-é™·é˜±1-kafka-offset-æäº¤é”™è¯¯)
    - [âš ï¸ é™·é˜±2: RabbitMQ ä¸ç¡®è®¤æ¶ˆæ¯å¯¼è‡´å†…å­˜æ³„æ¼](#ï¸-é™·é˜±2-rabbitmq-ä¸ç¡®è®¤æ¶ˆæ¯å¯¼è‡´å†…å­˜æ³„æ¼)
    - [âš ï¸ é™·é˜±3: æ¶ˆæ¯é¡ºåºæ€§è¯¯è§£](#ï¸-é™·é˜±3-æ¶ˆæ¯é¡ºåºæ€§è¯¯è§£)
    - [âš ï¸ é™·é˜±4: æ¶ˆæ¯å †ç§¯æœªç›‘æ§](#ï¸-é™·é˜±4-æ¶ˆæ¯å †ç§¯æœªç›‘æ§)
  - [å‚è€ƒèµ„æº](#å‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [æ•™ç¨‹ä¸æ–‡ç« ](#æ•™ç¨‹ä¸æ–‡ç« )
    - [ç¤ºä¾‹é¡¹ç›®](#ç¤ºä¾‹é¡¹ç›®)
    - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)

---

## æ¦‚è¿°

### æ¶ˆæ¯é˜Ÿåˆ—æ¦‚å¿µ

æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆMessage Queue, MQï¼‰æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å¼‚æ­¥é€šä¿¡çš„æ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºè§£è€¦æœåŠ¡ã€ç¼“å†²æµé‡ã€ä¿è¯æ¶ˆæ¯å¯é æ€§ã€‚

**æ ¸å¿ƒæ¦‚å¿µ**:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    å‘é€æ¶ˆæ¯    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    æ¶ˆè´¹æ¶ˆæ¯    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”Ÿäº§è€…     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  æ¶ˆæ¯é˜Ÿåˆ—    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚  æ¶ˆè´¹è€…     â”‚
â”‚ (Producer)  â”‚                â”‚   (Broker)   â”‚                â”‚ (Consumer)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                              â”‚                              â”‚
      â”‚                              â”‚                              â”‚
      â–¼                              â–¼                              â–¼
  å‘é€ç¡®è®¤ (ACK)              æŒä¹…åŒ–å­˜å‚¨                      æ¶ˆæ¯ç¡®è®¤ (ACK)
```

**å…³é”®æœ¯è¯­**:

- **Topic/Queue**: æ¶ˆæ¯ä¸»é¢˜æˆ–é˜Ÿåˆ—ï¼Œæ¶ˆæ¯çš„é€»è¾‘åˆ†ç±»
- **Producer**: ç”Ÿäº§è€…ï¼Œå‘é€æ¶ˆæ¯çš„åº”ç”¨
- **Consumer**: æ¶ˆè´¹è€…ï¼Œæ¥æ”¶æ¶ˆæ¯çš„åº”ç”¨
- **Broker**: æ¶ˆæ¯ä»£ç†ï¼Œå­˜å‚¨å’Œè½¬å‘æ¶ˆæ¯çš„æœåŠ¡å™¨
- **Partition**: åˆ†åŒºï¼Œç”¨äºæ°´å¹³æ‰©å±•çš„æ¶ˆæ¯å­é›†ï¼ˆKafkaï¼‰
- **Consumer Group**: æ¶ˆè´¹è€…ç»„ï¼Œå®ç°è´Ÿè½½å‡è¡¡å’Œå®¹é”™

### ä¸ºä»€ä¹ˆéœ€è¦æ¶ˆæ¯é˜Ÿåˆ—

1. **å¼‚æ­¥è§£è€¦**: ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ç‹¬ç«‹æ¼”è¿›ï¼Œä¸éœ€è¦åŒæ­¥ç­‰å¾…
2. **å‰Šå³°å¡«è°·**: ç¼“å†²çªå‘æµé‡ï¼Œä¿æŠ¤ä¸‹æ¸¸æœåŠ¡
3. **å¯é æ€§**: æ¶ˆæ¯æŒä¹…åŒ–ï¼Œç¡®ä¿ä¸ä¸¢å¤±
4. **æ‰©å±•æ€§**: é€šè¿‡åˆ†åŒºå’Œæ¶ˆè´¹è€…ç»„å®ç°æ°´å¹³æ‰©å±•
5. **é¡ºåºä¿è¯**: åœ¨åˆ†åŒºå†…ä¿è¯æ¶ˆæ¯é¡ºåºï¼ˆKafkaï¼‰

**ä½¿ç”¨åœºæ™¯**:

- è®¢å•å¤„ç†ã€æ”¯ä»˜é€šçŸ¥
- æ—¥å¿—èšåˆã€æŒ‡æ ‡æ”¶é›†
- äº‹ä»¶æº¯æºã€CQRS
- æ•°æ®ç®¡é“ã€ETL
- å¾®æœåŠ¡è§£è€¦ã€äº‹ä»¶é©±åŠ¨æ¶æ„

### æ¶ˆæ¯æ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | æè¿° | é€‚ç”¨åœºæ™¯ | å®ç° |
|------|------|---------|------|
| **ç‚¹å¯¹ç‚¹ (P2P)** | ä¸€æ¡æ¶ˆæ¯åªè¢«ä¸€ä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹ | ä»»åŠ¡åˆ†å‘ã€å·¥ä½œé˜Ÿåˆ— | RabbitMQ Queue, Kafka Consumer Group |
| **å‘å¸ƒè®¢é˜… (Pub/Sub)** | ä¸€æ¡æ¶ˆæ¯è¢«å¤šä¸ªè®¢é˜…è€…æ¶ˆè´¹ | äº‹ä»¶å¹¿æ’­ã€é€šçŸ¥ç³»ç»Ÿ | RabbitMQ Exchange, Kafka Topic, NATS |
| **è¯·æ±‚å“åº” (Req/Reply)** | åŒæ­¥æˆ–å¼‚æ­¥çš„RPCæ¨¡å¼ | APIç½‘å…³ã€å¾®æœåŠ¡è°ƒç”¨ | RabbitMQ RPC, NATS Request |
| **æµå¤„ç† (Streaming)** | è¿ç»­å¤„ç†æ¶ˆæ¯æµ | å®æ—¶åˆ†æã€çª—å£èšåˆ | Kafka Streams |

---

## æ ¸å¿ƒåº“å¯¹æ¯”

### åŠŸèƒ½çŸ©é˜µ

| ç‰¹æ€§ | rdkafka | lapin | async-nats | pulsar-rs | è¯´æ˜ |
|------|---------|-------|------------|-----------|------|
| **åè®®** | Kafka | AMQP 0.9.1 | NATS | Pulsar | åº•å±‚åè®® |
| **å¼‚æ­¥æ”¯æŒ** | âœ… Tokio | âœ… Tokio | âœ… Tokio | âœ… Tokio | å…¨å¼‚æ­¥ |
| **æŒä¹…åŒ–** | âœ… å¼º | âœ… | å¯é€‰ (JetStream) | âœ… | Kafka æœ€å¼º |
| **é¡ºåºä¿è¯** | âœ… åˆ†åŒºå†… | æœ‰é™ | âŒ | âœ… | Kafka ä¸¥æ ¼é¡ºåº |
| **åˆ†åŒº** | âœ… | âŒ | âŒ | âœ… | æ°´å¹³æ‰©å±• |
| **æ¶ˆè´¹è€…ç»„** | âœ… | âŒ | âœ… Queue Group | âœ… | è´Ÿè½½å‡è¡¡ |
| **æµå¤„ç†** | âœ… | âŒ | âŒ | éƒ¨åˆ† | Kafka æœ€ä½³ |
| **æ¶ˆæ¯è·¯ç”±** | ç®€å• | âœ… Exchange | âœ… Subject | âœ… | RabbitMQ æœ€çµæ´» |
| **ååé‡** | æé«˜ | ä¸­ç­‰ | é«˜ | é«˜ | Kafka >100MB/s |
| **å»¶è¿Ÿ** | ä¸­ç­‰ (ms) | ä½ (Î¼s) | æä½ (Î¼s) | ä¸­ç­‰ | NATS æœ€å¿« |
| **è·¨å¹³å°** | âœ… | âœ… | âœ… | âœ… | éƒ½æ”¯æŒ |

### é€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èåº“ | ç†ç”± |
|------|--------|------|
| **å¤§è§„æ¨¡æ—¥å¿—/äº‹ä»¶æµ** | rdkafka (Kafka) | é«˜ååã€æŒä¹…åŒ–ã€é¡ºåºä¿è¯ |
| **å®æ—¶åˆ†æ/æµå¤„ç†** | rdkafka (Kafka) | Kafka Streamsã€çª—å£èšåˆ |
| **å¾®æœåŠ¡è§£è€¦** | async-nats (NATS) | è½»é‡ã€ä½å»¶è¿Ÿã€æ˜“éƒ¨ç½² |
| **å¤æ‚æ¶ˆæ¯è·¯ç”±** | lapin (RabbitMQ) | Exchangeã€Bindingã€çµæ´»è·¯ç”± |
| **ä»»åŠ¡é˜Ÿåˆ—/å·¥ä½œåˆ†å‘** | lapin (RabbitMQ) | å·¥ä½œé˜Ÿåˆ—ã€ä¼˜å…ˆçº§ã€æ­»ä¿¡é˜Ÿåˆ— |
| **è¯·æ±‚å“åº”æ¨¡å¼** | async-nats (NATS) | å†…ç½® Request/Reply |
| **è·¨æ•°æ®ä¸­å¿ƒåŒæ­¥** | pulsar-rs (Pulsar) | åœ°ç†å¤åˆ¶ã€å¤šç§Ÿæˆ· |
| **é«˜æ€§èƒ½ + æŒä¹…åŒ–** | rdkafka (Kafka) | ä¸¤è€…å…¼é¡¾ |

### æ€§èƒ½å¯¹æ¯”

**åŸºå‡†æµ‹è¯•ç¯å¢ƒ**:

- CPU: 8æ ¸ Intel Xeon
- å†…å­˜: 32GB
- ç½‘ç»œ: 1Gbps
- æ¶ˆæ¯å¤§å°: 1KB

| æ“ä½œ | rdkafka | lapin | async-nats | è¯´æ˜ |
|------|---------|-------|------------|------|
| **ç”Ÿäº§åå** | 500K msg/s | 50K msg/s | 300K msg/s | Kafka æœ€é«˜ |
| **æ¶ˆè´¹åå** | 800K msg/s | 80K msg/s | 500K msg/s | Kafka æ‰¹é‡è¯»å– |
| **ç«¯åˆ°ç«¯å»¶è¿Ÿ** | 5-10ms | 1-2ms | <1ms | NATS æœ€ä½ |
| **å­˜å‚¨æ•ˆç‡** | æé«˜ (å‹ç¼©) | ä¸­ç­‰ | å†…å­˜ (å¯é€‰æŒä¹…) | Kafka æ—¥å¿—æ®µå‹ç¼© |

---

## rdkafka - Kafka å®¢æˆ·ç«¯

### æ ¸å¿ƒç‰¹æ€§

- âœ… **é«˜åå**: >100MB/s å•èŠ‚ç‚¹ï¼Œå¯æ°´å¹³æ‰©å±•
- âœ… **æŒä¹…åŒ–**: æ—¥å¿—æ®µå­˜å‚¨ï¼Œå¯é…ç½®ä¿ç•™ç­–ç•¥
- âœ… **é¡ºåºä¿è¯**: åˆ†åŒºå†…ä¸¥æ ¼é¡ºåº
- âœ… **exactly-once**: äº‹åŠ¡æ”¯æŒï¼Œå¹‚ç­‰ç”Ÿäº§è€…
- âœ… **æµå¤„ç†**: Kafka Streams API

**å®‰è£…**:

```toml
[dependencies]
rdkafka = { version = "0.36", features = ["tokio"] }
tokio = { version = "1", features = ["full"] }
```

### ç”Ÿäº§è€…

#### åŸºç¡€ç”¨æ³•ï¼šå¼‚æ­¥ç”Ÿäº§è€…

```rust
use rdkafka::producer::{FutureProducer, FutureRecord};
use rdkafka::config::ClientConfig;
use rdkafka::util::Timeout;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ›å»ºç”Ÿäº§è€…
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("message.timeout.ms", "5000")
        .set("compression.type", "lz4")  // å¯ç”¨å‹ç¼©
        .create()?;
    
    // å‘é€å•æ¡æ¶ˆæ¯
    let topic = "orders";
    let key = "order-123";
    let payload = r#"{"orderId": "123", "amount": 100.0}"#;
    
    let delivery_status = producer
        .send(
            FutureRecord::to(topic)
                .payload(payload)
                .key(key),
            Timeout::After(std::time::Duration::from_secs(5)),
        )
        .await;
    
    match delivery_status {
        Ok((partition, offset)) => {
            println!("æ¶ˆæ¯å·²å‘é€: partition={}, offset={}", partition, offset);
        }
        Err((e, _)) => {
            eprintln!("å‘é€å¤±è´¥: {:?}", e);
        }
    }
    
    Ok(())
}
```

**è¦ç‚¹**:

1. `bootstrap.servers` æŒ‡å®š Kafka é›†ç¾¤åœ°å€
2. `FutureRecord` æ”¯æŒ key å’Œ payload
3. key å†³å®šæ¶ˆæ¯åˆ†åŒºï¼ˆç›¸åŒ key è·¯ç”±åˆ°åŒä¸€åˆ†åŒºï¼‰
4. è¿”å› `(partition, offset)` ç¡®è®¤æ¶ˆæ¯ä½ç½®

#### é«˜çº§ç”¨æ³•ï¼šæ‰¹é‡å‘é€

```rust
use rdkafka::producer::{FutureProducer, FutureRecord};
use rdkafka::config::ClientConfig;
use futures::stream::{self, StreamExt};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("linger.ms", "10")  // æ‰¹é‡å»¶è¿Ÿ10ms
        .set("batch.size", "16384")  // 16KBæ‰¹æ¬¡
        .create()?;
    
    // ç”Ÿæˆ1000æ¡æ¶ˆæ¯
    let messages: Vec<_> = (0..1000)
        .map(|i| format!("message-{}", i))
        .collect();
    
    // å¹¶å‘å‘é€ï¼ˆé™åˆ¶å¹¶å‘åº¦ä¸º100ï¼‰
    let results = stream::iter(messages)
        .map(|payload| {
            let producer = producer.clone();
            async move {
                producer
                    .send(
                        FutureRecord::to("test-topic")
                            .payload(&payload)
                            .key(&format!("key-{}", payload)),
                        std::time::Duration::from_secs(0).into(),
                    )
                    .await
            }
        })
        .buffer_unordered(100)  // å¹¶å‘100ä¸ªè¯·æ±‚
        .collect::<Vec<_>>()
        .await;
    
    let success_count = results.iter().filter(|r| r.is_ok()).count();
    println!("å‘é€æˆåŠŸ: {}/{}", success_count, results.len());
    
    Ok(())
}
```

**æ€§èƒ½ä¼˜åŒ–**:

- `linger.ms`: æ‰¹é‡å»¶è¿Ÿæ—¶é—´ï¼ˆåå vs å»¶è¿Ÿæƒè¡¡ï¼‰
- `batch.size`: æ‰¹æ¬¡å¤§å°
- `compression.type`: å‹ç¼©ç®—æ³•ï¼ˆlz4, snappy, gzipï¼‰
- `buffer_unordered`: å¹¶å‘å‘é€

### æ¶ˆè´¹è€…

#### åŸºç¡€ç”¨æ³•ï¼šæ¶ˆè´¹è€…ç»„

```rust
use rdkafka::consumer::{Consumer, StreamConsumer};
use rdkafka::config::ClientConfig;
use rdkafka::message::Message;
use futures::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ›å»ºæ¶ˆè´¹è€…
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("group.id", "order-processor-group")
        .set("enable.auto.commit", "true")
        .set("auto.offset.reset", "earliest")  // ä»æœ€æ—©çš„æ¶ˆæ¯å¼€å§‹
        .create()?;
    
    // è®¢é˜…ä¸»é¢˜
    consumer.subscribe(&["orders"])?;
    
    println!("å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯...");
    
    // æ¶ˆè´¹æ¶ˆæ¯æµ
    let mut message_stream = consumer.stream();
    
    while let Some(message) = message_stream.next().await {
        match message {
            Ok(msg) => {
                let payload = msg.payload_view::<str>().unwrap_or(Ok(""))?;
                let key = msg.key_view::<str>().unwrap_or(Ok(""))?;
                
                println!(
                    "æ”¶åˆ°æ¶ˆæ¯: topic={}, partition={}, offset={}, key={}, payload={}",
                    msg.topic(),
                    msg.partition(),
                    msg.offset(),
                    key,
                    payload
                );
                
                // å¤„ç†æ¶ˆæ¯
                process_order(payload).await?;
            }
            Err(e) => {
                eprintln!("æ¶ˆè´¹é”™è¯¯: {:?}", e);
            }
        }
    }
    
    Ok(())
}

async fn process_order(payload: &str) -> Result<(), Box<dyn std::error::Error>> {
    // ä¸šåŠ¡é€»è¾‘
    println!("å¤„ç†è®¢å•: {}", payload);
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    Ok(())
}
```

**è¦ç‚¹**:

1. `group.id` å®šä¹‰æ¶ˆè´¹è€…ç»„ï¼ˆç»„å†…è´Ÿè½½å‡è¡¡ï¼‰
2. `auto.offset.reset` æ§åˆ¶åˆå§‹æ¶ˆè´¹ä½ç½®ï¼ˆearliest/latestï¼‰
3. `enable.auto.commit` è‡ªåŠ¨æäº¤ offsetï¼ˆç®€åŒ–ä½†ä¸ä¿è¯ exactly-onceï¼‰
4. åŒç»„æ¶ˆè´¹è€…å…±äº«åˆ†åŒºï¼ˆå®ç°æ°´å¹³æ‰©å±•ï¼‰

#### é«˜çº§ç”¨æ³•ï¼šæ‰‹åŠ¨æäº¤ offset

```rust
use rdkafka::consumer::{Consumer, StreamConsumer, CommitMode};
use rdkafka::message::Message;
use futures::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("group.id", "reliable-processor")
        .set("enable.auto.commit", "false")  // ç¦ç”¨è‡ªåŠ¨æäº¤
        .create()?;
    
    consumer.subscribe(&["orders"])?;
    
    let mut message_stream = consumer.stream();
    
    while let Some(message) = message_stream.next().await {
        match message {
            Ok(msg) => {
                let payload = msg.payload_view::<str>().unwrap_or(Ok(""))?;
                
                // å¤„ç†æ¶ˆæ¯
                match process_order_safely(payload).await {
                    Ok(_) => {
                        // å¤„ç†æˆåŠŸï¼Œæ‰‹åŠ¨æäº¤ offset
                        consumer.commit_message(&msg, CommitMode::Async)?;
                        println!("offset å·²æäº¤: {}", msg.offset());
                    }
                    Err(e) => {
                        eprintln!("å¤„ç†å¤±è´¥: {:?}, ä¸æäº¤ offset", e);
                        // offset ä¸æäº¤ï¼Œé‡å¯åä¼šé‡æ–°æ¶ˆè´¹
                    }
                }
            }
            Err(e) => {
                eprintln!("æ¶ˆè´¹é”™è¯¯: {:?}", e);
            }
        }
    }
    
    Ok(())
}

async fn process_order_safely(payload: &str) -> Result<(), Box<dyn std::error::Error>> {
    // ä¸šåŠ¡é€»è¾‘ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
    if payload.contains("invalid") {
        return Err("æ— æ•ˆè®¢å•".into());
    }
    
    // å†™å…¥æ•°æ®åº“ã€è°ƒç”¨å¤–éƒ¨APIç­‰
    println!("å¤„ç†è®¢å•: {}", payload);
    Ok(())
}
```

**å¯é æ€§ä¿è¯**:

- æ‰‹åŠ¨æäº¤ç¡®ä¿æ¶ˆæ¯å¤„ç†æˆåŠŸåæ‰æäº¤ offset
- å¤±è´¥æ—¶ä¸æäº¤ï¼Œé‡å¯åé‡æ–°æ¶ˆè´¹ï¼ˆat-least-onceï¼‰
- é…åˆå¹‚ç­‰å¤„ç†å®ç° exactly-once

### æµå¤„ç†

#### çª—å£èšåˆç¤ºä¾‹

```rust
use rdkafka::consumer::{Consumer, StreamConsumer};
use rdkafka::message::Message;
use futures::StreamExt;
use std::collections::HashMap;
use tokio::time::{interval, Duration};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("group.id", "analytics")
        .create()?;
    
    consumer.subscribe(&["page-views"])?;
    
    // æ»‘åŠ¨çª—å£ï¼šæ¯5ç§’ç»Ÿè®¡ä¸€æ¬¡
    let mut window = HashMap::new();
    let mut tick = interval(Duration::from_secs(5));
    let mut message_stream = consumer.stream();
    
    loop {
        tokio::select! {
            Some(message) = message_stream.next() => {
                if let Ok(msg) = message {
                    let page = msg.key_view::<str>().unwrap_or(Ok("unknown"))?;
                    *window.entry(page.to_string()).or_insert(0) += 1;
                }
            }
            _ = tick.tick() => {
                println!("çª—å£ç»Ÿè®¡:");
                for (page, count) in &window {
                    println!("  {} : {} views", page, count);
                }
                window.clear();
            }
        }
    }
}
```

---

## lapin - RabbitMQ å®¢æˆ·ç«¯

### æ ¸å¿ƒç‰¹æ€§1

- âœ… **çµæ´»è·¯ç”±**: Exchange + Binding æ¨¡å¼
- âœ… **å¤šç§ Exchange**: Direct, Fanout, Topic, Headers
- âœ… **å¯é æ€§**: æ¶ˆæ¯ç¡®è®¤ã€æŒä¹…åŒ–ã€é•œåƒé˜Ÿåˆ—
- âœ… **ä¼˜å…ˆçº§é˜Ÿåˆ—**: æ¶ˆæ¯ä¼˜å…ˆçº§ã€æ­»ä¿¡é˜Ÿåˆ—

**å®‰è£…**:

```toml
[dependencies]
lapin = "2.3"
tokio = { version = "1", features = ["full"] }
```

### åŸºç¡€ç”¨æ³•

#### ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…

```rust
use lapin::{
    Connection, ConnectionProperties,
    options::*, types::FieldTable,
    BasicProperties,
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // è¿æ¥ RabbitMQ
    let conn = Connection::connect(
        "amqp://guest:guest@localhost:5672/%2f",
        ConnectionProperties::default(),
    ).await?;
    
    let channel = conn.create_channel().await?;
    
    // å£°æ˜é˜Ÿåˆ—
    let queue = channel
        .queue_declare(
            "tasks",
            QueueDeclareOptions {
                durable: true,  // æŒä¹…åŒ–
                ..Default::default()
            },
            FieldTable::default(),
        )
        .await?;
    
    println!("é˜Ÿåˆ—å·²å£°æ˜: {:?}", queue);
    
    // å‘é€æ¶ˆæ¯
    channel
        .basic_publish(
            "",
            "tasks",
            BasicPublishOptions::default(),
            b"Task: Process order #123",
            BasicProperties::default()
                .with_delivery_mode(2),  // æŒä¹…åŒ–æ¶ˆæ¯
        )
        .await?;
    
    println!("æ¶ˆæ¯å·²å‘é€");
    
    Ok(())
}
```

#### æ¶ˆè´¹è€…ï¼ˆå·¥ä½œé˜Ÿåˆ—ï¼‰

```rust
use lapin::{
    Connection, ConnectionProperties,
    options::*, types::FieldTable,
    message::Delivery,
};
use futures::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let conn = Connection::connect(
        "amqp://guest:guest@localhost:5672/%2f",
        ConnectionProperties::default(),
    ).await?;
    
    let channel = conn.create_channel().await?;
    
    // å£°æ˜é˜Ÿåˆ—ï¼ˆä¸ç”Ÿäº§è€…ç›¸åŒï¼‰
    channel
        .queue_declare(
            "tasks",
            QueueDeclareOptions {
                durable: true,
                ..Default::default()
            },
            FieldTable::default(),
        )
        .await?;
    
    // è®¾ç½® QoSï¼ˆé¢„å–1æ¡æ¶ˆæ¯ï¼‰
    channel
        .basic_qos(1, BasicQosOptions::default())
        .await?;
    
    // å¼€å§‹æ¶ˆè´¹
    let mut consumer = channel
        .basic_consume(
            "tasks",
            "worker-1",
            BasicConsumeOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    println!("ç­‰å¾…æ¶ˆæ¯...");
    
    while let Some(delivery) = consumer.next().await {
        if let Ok(delivery) = delivery {
            let payload = std::str::from_utf8(&delivery.data)?;
            println!("æ”¶åˆ°ä»»åŠ¡: {}", payload);
            
            // å¤„ç†ä»»åŠ¡
            tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
            
            // æ‰‹åŠ¨ç¡®è®¤
            delivery.ack(BasicAckOptions::default()).await?;
            println!("ä»»åŠ¡å®Œæˆ");
        }
    }
    
    Ok(())
}
```

### å·¥ä½œé˜Ÿåˆ—æ¨¡å¼

**ç‰¹ç‚¹**: å¤šä¸ªæ¶ˆè´¹è€…ç«äº‰æ¶ˆè´¹ï¼Œå®ç°è´Ÿè½½å‡è¡¡ã€‚

```rust
use lapin::{Connection, ConnectionProperties, options::*, types::FieldTable};
use futures::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let conn = Connection::connect(
        "amqp://localhost:5672",
        ConnectionProperties::default(),
    ).await?;
    
    let channel = conn.create_channel().await?;
    
    // å£°æ˜å·¥ä½œé˜Ÿåˆ—
    channel
        .queue_declare(
            "work-queue",
            QueueDeclareOptions {
                durable: true,
                ..Default::default()
            },
            FieldTable::default(),
        )
        .await?;
    
    // æ¨¡æ‹Ÿå¤šä¸ªå·¥ä½œè€…
    for worker_id in 1..=3 {
        let channel = channel.clone();
        
        tokio::spawn(async move {
            worker(worker_id, channel).await.unwrap();
        });
    }
    
    // ä¿æŒè¿è¡Œ
    tokio::signal::ctrl_c().await?;
    Ok(())
}

async fn worker(
    id: u32,
    channel: lapin::Channel,
) -> Result<(), Box<dyn std::error::Error>> {
    let mut consumer = channel
        .basic_consume(
            "work-queue",
            &format!("worker-{}", id),
            BasicConsumeOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    println!("Worker {} å¯åŠ¨", id);
    
    while let Some(delivery) = consumer.next().await {
        if let Ok(delivery) = delivery {
            let payload = std::str::from_utf8(&delivery.data)?;
            println!("Worker {} å¤„ç†: {}", id, payload);
            
            // æ¨¡æ‹Ÿå·¥ä½œ
            let work_time = payload.matches('.').count() as u64;
            tokio::time::sleep(tokio::time::Duration::from_secs(work_time)).await;
            
            delivery.ack(BasicAckOptions::default()).await?;
            println!("Worker {} å®Œæˆ", id);
        }
    }
    
    Ok(())
}
```

### å‘å¸ƒè®¢é˜…æ¨¡å¼

**ç‰¹ç‚¹**: ä¸€æ¡æ¶ˆæ¯å¹¿æ’­ç»™æ‰€æœ‰è®¢é˜…è€…ã€‚

```rust
use lapin::{
    Connection, ConnectionProperties,
    options::*, types::FieldTable,
    ExchangeKind, BasicProperties,
};
use futures::StreamExt;

// å‘å¸ƒè€…
async fn publisher() -> Result<(), Box<dyn std::error::Error>> {
    let conn = Connection::connect(
        "amqp://localhost:5672",
        ConnectionProperties::default(),
    ).await?;
    
    let channel = conn.create_channel().await?;
    
    // å£°æ˜ fanout exchangeï¼ˆå¹¿æ’­ï¼‰
    channel
        .exchange_declare(
            "logs",
            ExchangeKind::Fanout,
            ExchangeDeclareOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    // å‘å¸ƒæ—¥å¿—
    let log_messages = vec!["INFO: Server started", "WARN: High memory", "ERROR: Connection lost"];
    
    for msg in log_messages {
        channel
            .basic_publish(
                "logs",
                "",  // routing_key ä¸ºç©ºï¼ˆfanout ä¸éœ€è¦ï¼‰
                BasicPublishOptions::default(),
                msg.as_bytes(),
                BasicProperties::default(),
            )
            .await?;
        
        println!("å‘å¸ƒæ—¥å¿—: {}", msg);
    }
    
    Ok(())
}

// è®¢é˜…è€…
async fn subscriber(name: &str) -> Result<(), Box<dyn std::error::Error>> {
    let conn = Connection::connect(
        "amqp://localhost:5672",
        ConnectionProperties::default(),
    ).await?;
    
    let channel = conn.create_channel().await?;
    
    // å£°æ˜ exchange
    channel
        .exchange_declare(
            "logs",
            ExchangeKind::Fanout,
            ExchangeDeclareOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    // å£°æ˜ä¸´æ—¶é˜Ÿåˆ—ï¼ˆexclusive: è¿æ¥æ–­å¼€è‡ªåŠ¨åˆ é™¤ï¼‰
    let queue = channel
        .queue_declare(
            "",
            QueueDeclareOptions {
                exclusive: true,
                ..Default::default()
            },
            FieldTable::default(),
        )
        .await?;
    
    // ç»‘å®šåˆ° exchange
    channel
        .queue_bind(
            queue.name().as_str(),
            "logs",
            "",
            QueueBindOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    // æ¶ˆè´¹æ¶ˆæ¯
    let mut consumer = channel
        .basic_consume(
            queue.name().as_str(),
            name,
            BasicConsumeOptions::default(),
            FieldTable::default(),
        )
        .await?;
    
    println!("{} ç­‰å¾…æ—¥å¿—...", name);
    
    while let Some(delivery) = consumer.next().await {
        if let Ok(delivery) = delivery {
            let log = std::str::from_utf8(&delivery.data)?;
            println!("{} æ”¶åˆ°: {}", name, log);
            delivery.ack(BasicAckOptions::default()).await?;
        }
    }
    
    Ok(())
}
```

---

## async-nats - NATS å®¢æˆ·ç«¯

### æ ¸å¿ƒç‰¹æ€§2

- âœ… **æä½å»¶è¿Ÿ**: <1ms ç«¯åˆ°ç«¯
- âœ… **è½»é‡çº§**: å•äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ— ä¾èµ–
- âœ… **è¯·æ±‚å“åº”**: å†…ç½® Request/Reply æ¨¡å¼
- âœ… **JetStream**: å¯é€‰æŒä¹…åŒ–å’Œé‡æ”¾

**å®‰è£…**:

```toml
[dependencies]
async-nats = "0.33"
tokio = { version = "1", features = ["full"] }
```

### å‘å¸ƒè®¢é˜…

#### åŸºç¡€ç”¨æ³•1

```rust
use async_nats;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // è¿æ¥ NATS
    let client = async_nats::connect("localhost:4222").await?;
    
    // å‘å¸ƒæ¶ˆæ¯
    client.publish("events.user.created", "User ID: 123".into()).await?;
    client.publish("events.user.updated", "User ID: 123".into()).await?;
    
    println!("æ¶ˆæ¯å·²å‘å¸ƒ");
    
    // åˆ·æ–°ç¡®ä¿å‘é€
    client.flush().await?;
    
    Ok(())
}
```

#### è®¢é˜…æ¶ˆæ¯

```rust
use async_nats;
use futures::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = async_nats::connect("localhost:4222").await?;
    
    // è®¢é˜…ä¸»é¢˜ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
    let mut subscriber = client.subscribe("events.user.*").await?;
    
    println!("è®¢é˜… events.user.*");
    
    // æ¶ˆè´¹æ¶ˆæ¯
    while let Some(message) = subscriber.next().await {
        let payload = String::from_utf8_lossy(&message.payload);
        println!("æ”¶åˆ°æ¶ˆæ¯: subject={}, payload={}", message.subject, payload);
    }
    
    Ok(())
}
```

**é€šé…ç¬¦æ”¯æŒ**:

- `*`: åŒ¹é…ä¸€ä¸ªå•è¯ï¼ˆ`events.*.created`ï¼‰
- `>`: åŒ¹é…å¤šä¸ªå•è¯ï¼ˆ`events.>`ï¼‰

### è¯·æ±‚å“åº”

**ç‰¹ç‚¹**: å†…ç½® RPC æ¨¡å¼ï¼Œè¶…ä½å»¶è¿Ÿã€‚

```rust
use async_nats;
use futures::StreamExt;

// æœåŠ¡ç«¯ï¼ˆå“åº”è€…ï¼‰
async fn responder() -> Result<(), Box<dyn std::error::Error>> {
    let client = async_nats::connect("localhost:4222").await?;
    
    let mut subscriber = client.subscribe("rpc.add").await?;
    
    println!("RPC æœåŠ¡å¯åŠ¨");
    
    while let Some(message) = subscriber.next().await {
        let payload = String::from_utf8_lossy(&message.payload);
        let numbers: Vec<i32> = payload
            .split(',')
            .filter_map(|s| s.trim().parse().ok())
            .collect();
        
        let sum: i32 = numbers.iter().sum();
        let response = format!("{}", sum);
        
        // å›å¤è¯·æ±‚
        if let Some(reply) = message.reply {
            client.publish(reply, response.into()).await?;
        }
    }
    
    Ok(())
}

// å®¢æˆ·ç«¯ï¼ˆè¯·æ±‚è€…ï¼‰
async fn requester() -> Result<(), Box<dyn std::error::Error>> {
    let client = async_nats::connect("localhost:4222").await?;
    
    // å‘é€è¯·æ±‚
    let response = client
        .request("rpc.add", "10, 20, 30".into())
        .await?;
    
    let result = String::from_utf8_lossy(&response.payload);
    println!("RPC ç»“æœ: {}", result);
    
    Ok(())
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // å¯åŠ¨å“åº”è€…
    tokio::spawn(async {
        responder().await.unwrap();
    });
    
    // ç­‰å¾…æœåŠ¡å¯åŠ¨
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    
    // å‘é€è¯·æ±‚
    requester().await?;
    
    Ok(())
}
```

### JetStream æŒä¹…åŒ–

**ç‰¹ç‚¹**: NATS çš„æŒä¹…åŒ–æ‰©å±•ï¼Œæ”¯æŒæ¶ˆæ¯é‡æ”¾å’Œè‡³å°‘ä¸€æ¬¡è¯­ä¹‰ã€‚

```rust
use async_nats;
use async_nats::jetstream;
use futures::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = async_nats::connect("localhost:4222").await?;
    
    // åˆ›å»º JetStream ä¸Šä¸‹æ–‡
    let jetstream = jetstream::new(client);
    
    // åˆ›å»ºæµï¼ˆStreamï¼‰
    let _stream = jetstream
        .create_stream(jetstream::stream::Config {
            name: "ORDERS".to_string(),
            subjects: vec!["orders.*".to_string()],
            max_messages: 1000,
            ..Default::default()
        })
        .await?;
    
    // å‘å¸ƒæ¶ˆæ¯åˆ° JetStream
    let ack = jetstream
        .publish("orders.new", "Order #123".into())
        .await?;
    
    println!("æ¶ˆæ¯å·²å­˜å‚¨: stream={}, sequence={}", ack.stream, ack.sequence);
    
    // åˆ›å»ºæŒä¹…æ¶ˆè´¹è€…
    let consumer = jetstream
        .create_consumer_on_stream(
            jetstream::consumer::pull::Config {
                durable_name: Some("order-processor".to_string()),
                ..Default::default()
            },
            "ORDERS",
        )
        .await?;
    
    // æ¶ˆè´¹æ¶ˆæ¯
    let mut messages = consumer.messages().await?;
    
    while let Some(message) = messages.next().await {
        let message = message?;
        let payload = String::from_utf8_lossy(&message.payload);
        
        println!("æ¶ˆè´¹æ¶ˆæ¯: {}", payload);
        
        // ç¡®è®¤æ¶ˆæ¯
        message.ack().await?;
    }
    
    Ok(())
}
```

---

## å®æˆ˜åœºæ™¯

### åœºæ™¯1: è®¢å•å¤„ç†ç³»ç»Ÿ

**éœ€æ±‚æè¿°**: ç”µå•†è®¢å•éœ€è¦ç»è¿‡å¤šä¸ªå¤„ç†é˜¶æ®µï¼šåˆ›å»ºè®¢å• â†’ æ‰£åº“å­˜ â†’ æ”¯ä»˜ â†’ å‘è´§ã€‚ä½¿ç”¨ Kafka ä¿è¯é¡ºåºå’Œå¯é æ€§ã€‚

**å®Œæ•´å®ç°**:

```rust
use rdkafka::producer::{FutureProducer, FutureRecord};
use rdkafka::consumer::{Consumer, StreamConsumer};
use rdkafka::config::ClientConfig;
use rdkafka::message::Message;
use futures::StreamExt;
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize)]
struct Order {
    order_id: String,
    user_id: String,
    amount: f64,
    status: String,
}

// è®¢å•æœåŠ¡ï¼šåˆ›å»ºè®¢å•
async fn create_order_service(producer: FutureProducer) -> Result<(), Box<dyn std::error::Error>> {
    let order = Order {
        order_id: "ORD-001".to_string(),
        user_id: "USR-123".to_string(),
        amount: 299.99,
        status: "created".to_string(),
    };
    
    let payload = serde_json::to_string(&order)?;
    
    // ä½¿ç”¨ user_id ä½œä¸º key ç¡®ä¿åŒä¸€ç”¨æˆ·çš„è®¢å•é¡ºåº
    producer
        .send(
            FutureRecord::to("orders")
                .payload(&payload)
                .key(&order.user_id),
            std::time::Duration::from_secs(0).into(),
        )
        .await
        .map_err(|(e, _)| e)?;
    
    println!("è®¢å•å·²åˆ›å»º: {:?}", order);
    Ok(())
}

// åº“å­˜æœåŠ¡ï¼šæ‰£åº“å­˜
async fn inventory_service() -> Result<(), Box<dyn std::error::Error>> {
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("group.id", "inventory-service")
        .create()?;
    
    consumer.subscribe(&["orders"])?;
    
    let mut message_stream = consumer.stream();
    
    while let Some(message) = message_stream.next().await {
        if let Ok(msg) = message {
            let payload = msg.payload_view::<str>().unwrap_or(Ok(""))?;
            let mut order: Order = serde_json::from_str(payload)?;
            
            if order.status == "created" {
                // æ‰£åº“å­˜é€»è¾‘
                println!("æ‰£åº“å­˜: order_id={}", order.order_id);
                tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
                
                order.status = "inventory_reserved".to_string();
                
                // å‘å¸ƒåˆ°ä¸‹ä¸€é˜¶æ®µ
                let producer: FutureProducer = ClientConfig::new()
                    .set("bootstrap.servers", "localhost:9092")
                    .create()?;
                
                producer
                    .send(
                        FutureRecord::to("orders")
                            .payload(&serde_json::to_string(&order)?)
                            .key(&order.user_id),
                        std::time::Duration::from_secs(0).into(),
                    )
                    .await
                    .map_err(|(e, _)| e)?;
            }
        }
    }
    
    Ok(())
}
```

**è¦ç‚¹è¯´æ˜**:

1. ä½¿ç”¨ `user_id` ä½œä¸º key ç¡®ä¿é¡ºåº
2. è®¢å•çŠ¶æ€æœºï¼šcreated â†’ inventory_reserved â†’ paid â†’ shipped
3. æ¯ä¸ªæœåŠ¡ç‹¬ç«‹æ¶ˆè´¹å’Œç”Ÿäº§
4. æ•…éšœæ—¶å¯é‡æ–°æ¶ˆè´¹ï¼ˆå¹‚ç­‰æ€§ä¿è¯ï¼‰

### åœºæ™¯2: å®æ—¶æ—¥å¿—èšåˆ

**éœ€æ±‚æè¿°**: æ”¶é›†å¤šä¸ªæœåŠ¡çš„æ—¥å¿—ï¼Œä½¿ç”¨ Kafka èšåˆåˆ° Elasticsearchã€‚

**å®Œæ•´å®ç°**:

```rust
use rdkafka::producer::{FutureProducer, FutureRecord};
use rdkafka::consumer::{Consumer, StreamConsumer};
use rdkafka::config::ClientConfig;
use rdkafka::message::Message;
use futures::StreamExt;
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize)]
struct LogEntry {
    timestamp: i64,
    service: String,
    level: String,
    message: String,
}

// æ—¥å¿—ç”Ÿäº§è€…ï¼ˆå„æœåŠ¡è°ƒç”¨ï¼‰
async fn log_producer(service_name: &str) -> Result<(), Box<dyn std::error::Error>> {
    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .create()?;
    
    // æ¨¡æ‹Ÿæ—¥å¿—ç”Ÿæˆ
    for i in 0..10 {
        let log = LogEntry {
            timestamp: chrono::Utc::now().timestamp(),
            service: service_name.to_string(),
            level: if i % 5 == 0 { "ERROR" } else { "INFO" }.to_string(),
            message: format!("Log message #{} from {}", i, service_name),
        };
        
        producer
            .send(
                FutureRecord::to("logs")
                    .payload(&serde_json::to_string(&log)?)
                    .key(service_name),
                std::time::Duration::from_secs(0).into(),
            )
            .await
            .map_err(|(e, _)| e)?;
        
        tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    }
    
    Ok(())
}

// æ—¥å¿—èšåˆå™¨ï¼ˆå†™å…¥ Elasticsearchï¼‰
async fn log_aggregator() -> Result<(), Box<dyn std::error::Error>> {
    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", "localhost:9092")
        .set("group.id", "log-aggregator")
        .create()?;
    
    consumer.subscribe(&["logs"])?;
    
    let mut message_stream = consumer.stream();
    let mut batch = Vec::new();
    
    while let Some(message) = message_stream.next().await {
        if let Ok(msg) = message {
            let payload = msg.payload_view::<str>().unwrap_or(Ok(""))?;
            let log: LogEntry = serde_json::from_str(payload)?;
            
            batch.push(log);
            
            // æ‰¹é‡å†™å…¥ï¼ˆ100æ¡æˆ–1ç§’ï¼‰
            if batch.len() >= 100 {
                write_to_elasticsearch(&batch).await?;
                batch.clear();
            }
        }
    }
    
    Ok(())
}

async fn write_to_elasticsearch(logs: &[LogEntry]) -> Result<(), Box<dyn std::error::Error>> {
    // æ¨¡æ‹Ÿæ‰¹é‡å†™å…¥ ES
    println!("å†™å…¥ {} æ¡æ—¥å¿—åˆ° Elasticsearch", logs.len());
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    Ok(())
}
```

### åœºæ™¯3: å¾®æœåŠ¡äº‹ä»¶æ€»çº¿

**éœ€æ±‚æè¿°**: ä½¿ç”¨ NATS å®ç°å¾®æœåŠ¡é—´çš„äº‹ä»¶é©±åŠ¨é€šä¿¡ã€‚

**å®Œæ•´å®ç°**:

```rust
use async_nats;
use futures::StreamExt;
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize)]
struct UserCreatedEvent {
    user_id: String,
    email: String,
    timestamp: i64,
}

// ç”¨æˆ·æœåŠ¡ï¼šå‘å¸ƒäº‹ä»¶
async fn user_service() -> Result<(), Box<dyn std::error::Error>> {
    let client = async_nats::connect("localhost:4222").await?;
    
    let event = UserCreatedEvent {
        user_id: "USR-123".to_string(),
        email: "user@example.com".to_string(),
        timestamp: chrono::Utc::now().timestamp(),
    };
    
    let payload = serde_json::to_string(&event)?;
    
    client.publish("events.user.created", payload.into()).await?;
    
    println!("äº‹ä»¶å·²å‘å¸ƒ: UserCreated");
    
    Ok(())
}

// é‚®ä»¶æœåŠ¡ï¼šè®¢é˜…äº‹ä»¶
async fn email_service() -> Result<(), Box<dyn std::error::Error>> {
    let client = async_nats::connect("localhost:4222").await?;
    
    let mut subscriber = client.subscribe("events.user.created").await?;
    
    println!("é‚®ä»¶æœåŠ¡å¯åŠ¨ï¼Œç›‘å¬ç”¨æˆ·åˆ›å»ºäº‹ä»¶");
    
    while let Some(message) = subscriber.next().await {
        let payload = String::from_utf8_lossy(&message.payload);
        let event: UserCreatedEvent = serde_json::from_str(&payload)?;
        
        println!("å‘é€æ¬¢è¿é‚®ä»¶: email={}", event.email);
        
        // å‘é€é‚®ä»¶é€»è¾‘
        send_welcome_email(&event.email).await?;
    }
    
    Ok(())
}

// é€šçŸ¥æœåŠ¡ï¼šè®¢é˜…äº‹ä»¶
async fn notification_service() -> Result<(), Box<dyn std::error::Error>> {
    let client = async_nats::connect("localhost:4222").await?;
    
    let mut subscriber = client.subscribe("events.user.>").await?;  // è®¢é˜…æ‰€æœ‰ç”¨æˆ·äº‹ä»¶
    
    println!("é€šçŸ¥æœåŠ¡å¯åŠ¨ï¼Œç›‘å¬æ‰€æœ‰ç”¨æˆ·äº‹ä»¶");
    
    while let Some(message) = subscriber.next().await {
        println!("æ”¶åˆ°äº‹ä»¶: subject={}", message.subject);
        
        // æ¨é€é€šçŸ¥é€»è¾‘
    }
    
    Ok(())
}

async fn send_welcome_email(email: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“§ å‘é€æ¬¢è¿é‚®ä»¶åˆ°: {}", email);
    Ok(())
}
```

---

## æœ€ä½³å®è·µ

### 1. æ¶ˆæ¯å¹‚ç­‰æ€§å¤„ç†

**æè¿°**: at-least-once è¯­ä¹‰ä¸‹ï¼Œæ¶ˆæ¯å¯èƒ½é‡å¤æ¶ˆè´¹ï¼Œå¿…é¡»ä¿è¯å¹‚ç­‰ã€‚

```rust
use std::collections::HashSet;
use std::sync::Arc;
use tokio::sync::Mutex;

struct MessageDeduplicator {
    processed_ids: Arc<Mutex<HashSet<String>>>,
}

impl MessageDeduplicator {
    async fn is_processed(&self, msg_id: &str) -> bool {
        let ids = self.processed_ids.lock().await;
        ids.contains(msg_id)
    }
    
    async fn mark_processed(&self, msg_id: String) {
        let mut ids = self.processed_ids.lock().await;
        ids.insert(msg_id);
    }
}

// ä½¿ç”¨æ–¹å¼
async fn process_message(dedup: &MessageDeduplicator, msg_id: &str) {
    if dedup.is_processed(msg_id).await {
        println!("æ¶ˆæ¯å·²å¤„ç†ï¼Œè·³è¿‡: {}", msg_id);
        return;
    }
    
    // å¤„ç†ä¸šåŠ¡é€»è¾‘
    // ...
    
    dedup.mark_processed(msg_id.to_string()).await;
}
```

### 2. é”™è¯¯å¤„ç†å’Œé‡è¯•

**æè¿°**: æ¶ˆæ¯å¤„ç†å¤±è´¥æ—¶ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿é‡è¯•ã€‚

```rust
use tokio::time::{sleep, Duration};

async fn process_with_retry<F, Fut>(f: F, max_retries: u32) -> Result<(), Box<dyn std::error::Error>>
where
    F: Fn() -> Fut,
    Fut: std::future::Future<Output = Result<(), Box<dyn std::error::Error>>>,
{
    let mut attempts = 0;
    
    loop {
        match f().await {
            Ok(_) => return Ok(()),
            Err(e) if attempts < max_retries => {
                attempts += 1;
                let wait_time = Duration::from_millis(100 * 2u64.pow(attempts));
                println!("å¤„ç†å¤±è´¥ï¼Œ{}ms åé‡è¯• ({}/{}): {:?}", 
                    wait_time.as_millis(), attempts, max_retries, e);
                sleep(wait_time).await;
            }
            Err(e) => {
                eprintln!("å¤„ç†å¤±è´¥ï¼Œè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°: {:?}", e);
                return Err(e);
            }
        }
    }
}
```

### 3. æ¶ˆè´¹è€…ç»„é…ç½®

**æè¿°**: åˆç†é…ç½®æ¶ˆè´¹è€…ç»„ï¼Œé¿å…æ¶ˆæ¯å †ç§¯å’Œä¸å‡è¡¡ã€‚

```rust
// Kafka æ¶ˆè´¹è€…æœ€ä½³é…ç½®
let consumer: StreamConsumer = ClientConfig::new()
    .set("bootstrap.servers", "localhost:9092")
    .set("group.id", "my-service")
    .set("enable.auto.commit", "false")  // æ‰‹åŠ¨æäº¤
    .set("auto.offset.reset", "earliest")  // ä»å¤´å¼€å§‹
    .set("session.timeout.ms", "10000")  // ä¼šè¯è¶…æ—¶
    .set("max.poll.interval.ms", "300000")  // æœ€å¤§æ‹‰å–é—´éš”ï¼ˆ5åˆ†é’Ÿï¼‰
    .set("fetch.min.bytes", "1024")  // æœ€å°æ‹‰å–å­—èŠ‚æ•°
    .set("fetch.max.wait.ms", "500")  // æœ€å¤§ç­‰å¾…æ—¶é—´
    .create()?;
```

### 4. æ¶ˆæ¯å‹ç¼©

**æè¿°**: å¯ç”¨å‹ç¼©èŠ‚çœå¸¦å®½å’Œå­˜å‚¨ã€‚

```rust
// Kafka ç”Ÿäº§è€…å‹ç¼©
let producer: FutureProducer = ClientConfig::new()
    .set("bootstrap.servers", "localhost:9092")
    .set("compression.type", "lz4")  // æˆ– snappy, gzip, zstd
    .set("compression.level", "3")  // å‹ç¼©çº§åˆ«
    .create()?;
```

### 5. ç›‘æ§å’Œå¯è§‚æµ‹æ€§

**æè¿°**: è®°å½•å…³é”®æŒ‡æ ‡å’Œé“¾è·¯è¿½è¸ªã€‚

```rust
use tracing::{info, warn, error};

async fn consume_message(msg: &str) -> Result<(), Box<dyn std::error::Error>> {
    let start = std::time::Instant::now();
    
    // å¤„ç†æ¶ˆæ¯
    process(msg).await?;
    
    let duration = start.elapsed();
    info!("æ¶ˆæ¯å¤„ç†å®Œæˆï¼Œè€—æ—¶: {:?}", duration);
    
    // è®°å½•æŒ‡æ ‡
    if duration.as_millis() > 1000 {
        warn!("æ¶ˆæ¯å¤„ç†è¶…æ—¶: {}ms", duration.as_millis());
    }
    
    Ok(())
}

async fn process(msg: &str) -> Result<(), Box<dyn std::error::Error>> {
    // ä¸šåŠ¡é€»è¾‘
    Ok(())
}
```

---

## å¸¸è§é™·é˜±

### âš ï¸ é™·é˜±1: Kafka offset æäº¤é”™è¯¯

**é—®é¢˜æè¿°**: è‡ªåŠ¨æäº¤ offset å¯èƒ½å¯¼è‡´æ¶ˆæ¯ä¸¢å¤±æˆ–é‡å¤æ¶ˆè´¹ã€‚

âŒ **é”™è¯¯ç¤ºä¾‹**:

```rust
let consumer: StreamConsumer = ClientConfig::new()
    .set("enable.auto.commit", "true")  // âŒ è‡ªåŠ¨æäº¤
    .create()?;

while let Some(message) = stream.next().await {
    // å¤„ç†æ¶ˆæ¯
    process(message).await?;  // å¦‚æœå¤±è´¥ï¼Œoffset å¯èƒ½å·²æäº¤
}
```

âœ… **æ­£ç¡®åšæ³•**:

```rust
let consumer: StreamConsumer = ClientConfig::new()
    .set("enable.auto.commit", "false")  // âœ… ç¦ç”¨è‡ªåŠ¨æäº¤
    .create()?;

while let Some(message) = stream.next().await {
    if let Ok(msg) = message {
        match process(&msg).await {
            Ok(_) => {
                consumer.commit_message(&msg, CommitMode::Async)?;  // âœ… å¤„ç†æˆåŠŸåæäº¤
            }
            Err(e) => {
                eprintln!("å¤„ç†å¤±è´¥: {:?}", e);
                // offset ä¸æäº¤ï¼Œä¸‹æ¬¡é‡æ–°æ¶ˆè´¹
            }
        }
    }
}
```

### âš ï¸ é™·é˜±2: RabbitMQ ä¸ç¡®è®¤æ¶ˆæ¯å¯¼è‡´å†…å­˜æ³„æ¼

**é—®é¢˜æè¿°**: æ¶ˆè´¹æ¶ˆæ¯åå¿˜è®° ack/nack ä¼šå¯¼è‡´æ¶ˆæ¯å †ç§¯ã€‚

âŒ **é”™è¯¯ç¤ºä¾‹**:

```rust
while let Some(delivery) = consumer.next().await {
    if let Ok(delivery) = delivery {
        process(&delivery.data).await;
        // âŒ å¿˜è®°ç¡®è®¤
    }
}
```

âœ… **æ­£ç¡®åšæ³•**:

```rust
while let Some(delivery) = consumer.next().await {
    if let Ok(delivery) = delivery {
        match process(&delivery.data).await {
            Ok(_) => {
                delivery.ack(BasicAckOptions::default()).await?;  // âœ… ç¡®è®¤
            }
            Err(_) => {
                delivery.nack(BasicNackOptions {
                    requeue: true,  // é‡æ–°å…¥é˜Ÿ
                    ..Default::default()
                }).await?;
            }
        }
    }
}
```

### âš ï¸ é™·é˜±3: æ¶ˆæ¯é¡ºåºæ€§è¯¯è§£

**é—®é¢˜æè¿°**: Kafka åªä¿è¯åˆ†åŒºå†…é¡ºåºï¼Œå…¨å±€æ— åºã€‚

âŒ **é”™è¯¯ç¤ºä¾‹**:

```rust
// âŒ æ²¡æœ‰æŒ‡å®š keyï¼Œæ¶ˆæ¯è½®è¯¢åˆ†åŒºï¼Œå…¨å±€æ— åº
producer.send(
    FutureRecord::to("orders")
        .payload("order-1"),
    timeout,
).await?;
```

âœ… **æ­£ç¡®åšæ³•**:

```rust
// âœ… ä½¿ç”¨ user_id ä½œä¸º keyï¼ŒåŒä¸€ç”¨æˆ·çš„æ¶ˆæ¯åœ¨åŒä¸€åˆ†åŒº
producer.send(
    FutureRecord::to("orders")
        .payload("order-1")
        .key(&user_id),  // âœ… æŒ‡å®š key
    timeout,
).await?;
```

### âš ï¸ é™·é˜±4: æ¶ˆæ¯å †ç§¯æœªç›‘æ§

**é—®é¢˜æè¿°**: æ¶ˆè´¹é€Ÿåº¦æ…¢äºç”Ÿäº§é€Ÿåº¦å¯¼è‡´å †ç§¯ï¼Œä½†æœªåŠæ—¶å‘ç°ã€‚

âœ… **æ­£ç¡®åšæ³•**:

```rust
use sysinfo::{System, SystemExt};

async fn monitor_lag() {
    // ç›‘æ§ Kafka lagï¼ˆä½¿ç”¨ rdkafka admin APIï¼‰
    // ç›‘æ§ RabbitMQ é˜Ÿåˆ—æ·±åº¦ï¼ˆä½¿ç”¨ HTTP APIï¼‰
    
    loop {
        let lag = get_consumer_lag().await;
        
        if lag > 10000 {
            eprintln!("è­¦å‘Šï¼šæ¶ˆæ¯å †ç§¯ {} æ¡", lag);
            // å‘Šè­¦é€šçŸ¥
        }
        
        tokio::time::sleep(tokio::time::Duration::from_secs(60)).await;
    }
}

async fn get_consumer_lag() -> u64 {
    // å®ç°ç›‘æ§é€»è¾‘
    0
}
```

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- ğŸ“š [rdkafka æ–‡æ¡£](https://docs.rs/rdkafka/latest/rdkafka/)
- ğŸ“š [lapin æ–‡æ¡£](https://docs.rs/lapin/latest/lapin/)
- ğŸ“š [async-nats æ–‡æ¡£](https://docs.rs/async-nats/latest/async_nats/)
- ğŸ“š [Apache Kafka å®˜æ–¹æ–‡æ¡£](https://kafka.apache.org/documentation/)
- ğŸ“š [RabbitMQ å®˜æ–¹æ–‡æ¡£](https://www.rabbitmq.com/documentation.html)
- ğŸ“š [NATS å®˜æ–¹æ–‡æ¡£](https://docs.nats.io/)

### æ•™ç¨‹ä¸æ–‡ç« 

- ğŸ“– [Kafka æƒå¨æŒ‡å—](https://www.confluent.io/resources/kafka-the-definitive-guide/)
- ğŸ“– [RabbitMQ å®æˆ˜](https://www.manning.com/books/rabbitmq-in-action)
- ğŸ“– [æ¶ˆæ¯é˜Ÿåˆ—è®¾è®¡æ¨¡å¼](https://www.enterpriseintegrationpatterns.com/)

### ç¤ºä¾‹é¡¹ç›®

- ğŸ’» [Kafka Rust Examples](https://github.com/fede1024/rust-rdkafka/tree/master/examples)
- ğŸ’» [RabbitMQ Tutorials (Rust)](https://github.com/rabbitmq/rabbitmq-tutorials/tree/main/rust)
- ğŸ’» [NATS by Example](https://natsbyexample.com/)

### ç›¸å…³æ–‡æ¡£

- ğŸ”— [å¼‚æ­¥è¿è¡Œæ—¶](../../02_system_programming/async_runtime/README.md)
- ğŸ”— [æ•°æ®åº“è¿æ¥æ± ](../database/README.md)
- ğŸ”— [æ—¥å¿—ç³»ç»Ÿ](../../05_toolchain/logging/README.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0  
**æœ€åæ›´æ–°**: 2025-10-20  
**ç»´æŠ¤è€…**: Rust å­¦ä¹ ç¤¾åŒº
