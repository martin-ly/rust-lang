# 监控与可观测性实践指南

> **文档类型**: Tier 4 - 高级层
> **创建日期**: 2025-10-30
> **技术栈**: Prometheus, Grafana, Loki, Jaeger
> **适用场景**: 生产环境监控、故障排查、性能优化

---

## 📋 目录

- [监控与可观测性实践指南](#监控与可观测性实践指南)
  - [📋 目录](#-目录)
  - [🎯 概述](#-概述)
    - [Wasm 可观测性的特点](#wasm-可观测性的特点)
  - [📊 可观测性三大支柱](#-可观测性三大支柱)
    - [1. Metrics (指标)](#1-metrics-指标)
    - [2. Logs (日志)](#2-logs-日志)
    - [3. Traces (追踪)](#3-traces-追踪)
  - [📈 Prometheus 监控](#-prometheus-监控)
    - [架构](#架构)
    - [配置文件](#配置文件)
    - [暴露指标](#暴露指标)
    - [关键指标](#关键指标)
      - [应用层指标](#应用层指标)
      - [资源指标](#资源指标)
      - [Kubernetes 指标](#kubernetes-指标)
  - [📊 Grafana 可视化](#-grafana-可视化)
    - [仪表板配置](#仪表板配置)
    - [核心面板](#核心面板)
      - [1. Golden Signals 仪表板](#1-golden-signals-仪表板)
      - [2. RED 方法仪表板](#2-red-方法仪表板)
      - [3. USE 方法仪表板](#3-use-方法仪表板)
    - [告警规则](#告警规则)
  - [📝 日志聚合 (Loki)](#-日志聚合-loki)
    - [架构](#架构-1)
    - [Promtail 配置](#promtail-配置)
    - [日志查询 (LogQL)](#日志查询-logql)
    - [结构化日志最佳实践](#结构化日志最佳实践)
  - [🔍 分布式追踪 (Jaeger)](#-分布式追踪-jaeger)
    - [为什么需要分布式追踪？](#为什么需要分布式追踪)
    - [OpenTelemetry 集成](#opentelemetry-集成)
    - [Jaeger UI 使用](#jaeger-ui-使用)
  - [🚨 告警配置](#-告警配置)
    - [Alertmanager 配置](#alertmanager-配置)
    - [告警最佳实践](#告警最佳实践)
      - [1. 告警分级](#1-告警分级)
      - [2. 告警命名规范](#2-告警命名规范)
      - [3. 避免告警疲劳](#3-避免告警疲劳)
  - [📋 最佳实践](#-最佳实践)
    - [1. 四个黄金指标 (Four Golden Signals)](#1-四个黄金指标-four-golden-signals)
    - [2. 监控即代码 (Monitoring as Code)](#2-监控即代码-monitoring-as-code)
    - [3. 可观测性成熟度模型](#3-可观测性成熟度模型)
    - [4. SLO/SLI/SLA](#4-sloslisla)
    - [5. 成本优化](#5-成本优化)
  - [🎯 总结](#-总结)
    - [监控检查清单](#监控检查清单)
    - [关键指标目标](#关键指标目标)

---

## 🎯 概述

**可观测性 (Observability)** 是了解系统内部状态的能力。对于 Wasm 微服务，良好的可观测性可以：

- ✅ 快速定位问题
- ✅ 性能优化
- ✅ 容量规划
- ✅ SLA 保证

### Wasm 可观测性的特点

| 维度 | 传统容器 | Wasm 容器 | 差异 |
|------|---------|----------|------|
| **启动监控** | 慢启动需监控 | 毫秒级，几乎不需要 | ✨ 更简单 |
| **内存监控** | 复杂（多层）| 单一线性内存 | ✨ 更直接 |
| **性能开销** | 5-10% | 1-2% | ✨ 更低 |
| **指标粒度** | 容器级 | 模块级 | ✨ 更细 |

---

## 📊 可观测性三大支柱

```text
┌────────────────────────────────────────────────────────┐
│                   Observability                        │
├──────────────┬──────────────────┬─────────────────────┤
│   Metrics    │      Logs        │      Traces         │
│              │                  │                     │
│ - 数值指标    │ - 事件记录        │ - 请求追踪          │
│ - 时序数据    │ - 错误日志        │ - 调用链            │
│ - 聚合统计    │ - 审计日志        │ - 性能分析          │
│              │                  │                     │
│ Prometheus   │  Loki/ELK        │  Jaeger/Zipkin      │
└──────────────┴──────────────────┴─────────────────────┘
```

### 1. Metrics (指标)

**用途**: 了解系统**整体**状态

- CPU/内存使用率
- 请求速率
- 错误率
- 延迟分布

### 2. Logs (日志)

**用途**: 了解**具体**事件

- 错误详情
- 用户行为
- 系统事件
- 审计追踪

### 3. Traces (追踪)

**用途**: 了解**请求流程**

- 服务调用链
- 性能瓶颈
- 依赖关系
- 错误传播

---

## 📈 Prometheus 监控

### 架构

```text
┌───────────────────┐
│  Wasm 应用        │
│  /metrics 端点    │
└─────────┬─────────┘
          │ HTTP Pull
          ▼
┌───────────────────┐     ┌─────────────┐
│   Prometheus      │────▶│ Alertmanager│
│   (时序数据库)     │     │  (告警)     │
└─────────┬─────────┘     └─────────────┘
          │
          ▼
┌───────────────────┐
│    Grafana        │
│    (可视化)       │
└───────────────────┘
```

### 配置文件

详见：[`deployment/monitoring/prometheus.yml`](../../deployment/monitoring/prometheus.yml)

### 暴露指标

**在 Rust 中添加 Prometheus 支持**:

```rust
// Cargo.toml
// prometheus = "0.13"
// lazy_static = "1.4"

use prometheus::{
    Counter, Histogram, Registry, Encoder, TextEncoder,
    HistogramOpts, Opts,
};
use lazy_static::lazy_static;
use std::time::Instant;

lazy_static! {
    // 全局注册表
    static ref REGISTRY: Registry = Registry::new();

    // HTTP 请求计数器
    static ref HTTP_REQUESTS_TOTAL: Counter = {
        let opts = Opts::new("http_requests_total", "Total HTTP requests");
        let counter = Counter::with_opts(opts).unwrap();
        REGISTRY.register(Box::new(counter.clone())).unwrap();
        counter
    };

    // HTTP 请求延迟直方图
    static ref HTTP_REQUEST_DURATION: Histogram = {
        let opts = HistogramOpts::new(
            "http_request_duration_seconds",
            "HTTP request duration in seconds"
        )
        .buckets(vec![0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0]);
        let histogram = Histogram::with_opts(opts).unwrap();
        REGISTRY.register(Box::new(histogram.clone())).unwrap();
        histogram
    };
}

// 请求处理器
fn handle_request(req: Request) -> Response {
    let start = Instant::now();

    // 增加请求计数
    HTTP_REQUESTS_TOTAL.inc();

    // 处理请求
    let response = process_request(req);

    // 记录延迟
    let duration = start.elapsed().as_secs_f64();
    HTTP_REQUEST_DURATION.observe(duration);

    response
}

// /metrics 端点
fn metrics_handler() -> String {
    let encoder = TextEncoder::new();
    let metric_families = REGISTRY.gather();
    let mut buffer = vec![];
    encoder.encode(&metric_families, &mut buffer).unwrap();
    String::from_utf8(buffer).unwrap()
}
```

### 关键指标

#### 应用层指标

```promql
# 请求速率 (QPS)
rate(http_requests_total[1m])

# 错误率
rate(http_requests_failed_total[5m]) / rate(http_requests_total[5m]) * 100

# P50, P95, P99 延迟
histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

# Apdex Score (应用性能指数)
(
  sum(rate(http_request_duration_seconds_bucket{le="0.1"}[5m]))
  + sum(rate(http_request_duration_seconds_bucket{le="0.4"}[5m])) / 2
) / sum(rate(http_request_duration_seconds_count[5m]))
```

#### 资源指标

```promql
# 内存使用
container_memory_usage_bytes{pod=~"wasm-.*"}

# 内存使用率
container_memory_usage_bytes / container_spec_memory_limit_bytes * 100

# CPU 使用率
rate(container_cpu_usage_seconds_total{pod=~"wasm-.*"}[5m]) * 100

# 网络 I/O
rate(container_network_receive_bytes_total[5m])
rate(container_network_transmit_bytes_total[5m])
```

#### Kubernetes 指标

```promql
# 可用 Pod 数量
kube_deployment_status_replicas_available{deployment="wasm-microservice"}

# Pod 重启次数
increase(kube_pod_container_status_restarts_total[1h])

# Pod 状态
kube_pod_status_phase{pod=~"wasm-.*", phase="Running"}

# HPA 状态
kube_horizontalpodautoscaler_status_current_replicas
kube_horizontalpodautoscaler_spec_max_replicas
```

---

## 📊 Grafana 可视化

### 仪表板配置

详见：[`deployment/monitoring/grafana-dashboard.json`](../../deployment/monitoring/grafana-dashboard.json)

### 核心面板

#### 1. Golden Signals 仪表板

**四个黄金指标**:

```text
┌─────────────────────────────────────────────────────────┐
│                  Golden Signals                         │
├────────────┬────────────┬────────────┬─────────────────┤
│  Latency   │  Traffic   │   Errors   │  Saturation     │
│            │            │            │                 │
│  P99: 50ms │  1000 rps  │  0.1%      │  CPU: 30%       │
│  P95: 30ms │            │            │  Mem: 45%       │
│  P50: 10ms │            │            │                 │
└────────────┴────────────┴────────────┴─────────────────┘
```

#### 2. RED 方法仪表板

**Rate, Errors, Duration**:

- **Rate**: 请求速率
- **Errors**: 错误数/错误率
- **Duration**: 请求延迟分布

#### 3. USE 方法仪表板

**Utilization, Saturation, Errors**:

- **Utilization**: 资源使用率（CPU、内存）
- **Saturation**: 资源饱和度（队列长度）
- **Errors**: 错误数量

### 告警规则

详见：[`deployment/monitoring/alerts/wasm-alerts.yml`](../../deployment/monitoring/alerts/wasm-alerts.yml)

---

## 📝 日志聚合 (Loki)

### 架构

```text
┌──────────────┐     ┌──────────────┐
│  Wasm Pod 1  │────▶│   Promtail   │
└──────────────┘     │  (日志采集)   │
┌──────────────┐     │              │
│  Wasm Pod 2  │────▶│              │
└──────────────┘     └──────┬───────┘
┌──────────────┐            │
│  Wasm Pod 3  │────────────┘
└──────────────┘            ▼
                    ┌──────────────┐
                    │     Loki     │
                    │  (日志存储)   │
                    └──────┬───────┘
                           │
                           ▼
                    ┌──────────────┐
                    │   Grafana    │
                    │  (日志查询)   │
                    └──────────────┘
```

### Promtail 配置

```yaml
# promtail-config.yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Kubernetes Pod 日志
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod

    relabel_configs:
      # 只采集 Wasm Pod
      - source_labels: [__meta_kubernetes_pod_label_runtime]
        action: keep
        regex: wasmedge

      # 添加标签
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app

    pipeline_stages:
      # 解析 JSON 日志
      - json:
          expressions:
            level: level
            timestamp: timestamp
            message: message

      # 提取标签
      - labels:
          level:

      # 时间戳解析
      - timestamp:
          source: timestamp
          format: RFC3339
```

### 日志查询 (LogQL)

```logql
# 查看所有 Wasm 应用日志
{app="wasm-microservice"}

# 查看错误日志
{app="wasm-microservice"} |= "error"

# 查看特定 Pod 的日志
{pod="wasm-microservice-abc123"}

# 统计错误数量
sum(count_over_time({app="wasm-microservice"} |= "error" [5m]))

# 慢请求日志
{app="wasm-microservice"} | json | duration > 1s

# 按错误类型聚合
sum by (error_type) (
  count_over_time({app="wasm-microservice"} | json | level="error" [1h])
)
```

### 结构化日志最佳实践

```rust
// 使用 serde_json 输出结构化日志
use serde_json::json;

fn log_request(method: &str, path: &str, status: u16, duration_ms: u64) {
    let log = json!({
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "level": "info",
        "message": "HTTP request",
        "method": method,
        "path": path,
        "status": status,
        "duration_ms": duration_ms,
        "service": "wasm-microservice",
        "version": env!("CARGO_PKG_VERSION")
    });

    println!("{}", log);
}

// 使用
log_request("GET", "/api/users", 200, 15);
// 输出：{"timestamp":"2025-10-30T12:00:00Z","level":"info","message":"HTTP request",...}
```

---

## 🔍 分布式追踪 (Jaeger)

### 为什么需要分布式追踪？

在微服务架构中，一个请求可能经过多个服务：

```text
Client → Gateway → Wasm Service A → Wasm Service B → Database
```

分布式追踪可以：

- 可视化请求流程
- 定位性能瓶颈
- 分析服务依赖

### OpenTelemetry 集成

```rust
// Cargo.toml
// opentelemetry = "0.21"
// opentelemetry-jaeger = "0.20"
// tracing = "0.1"
// tracing-opentelemetry = "0.22"

use opentelemetry::global;
use opentelemetry::sdk::trace::Tracer;
use opentelemetry_jaeger::JaegerTraceRuntime;
use tracing::{info, span, Level};
use tracing_subscriber::layer::SubscriberExt;

// 初始化 Jaeger
fn init_tracer() -> Tracer {
    opentelemetry_jaeger::new_agent_pipeline()
        .with_service_name("wasm-microservice")
        .with_endpoint("jaeger-agent:6831")
        .install_batch(JaegerTraceRuntime::default())
        .expect("Failed to install tracer")
}

// 使用示例
fn handle_request(req: Request) -> Response {
    // 创建 span
    let span = span!(Level::INFO, "handle_request", method = %req.method(), path = %req.path());
    let _enter = span.enter();

    info!("Processing request");

    // 调用下游服务（自动传播 trace context）
    let response = call_downstream_service(&req);

    info!(status = %response.status(), "Request completed");

    response
}

fn call_downstream_service(req: &Request) -> Response {
    let span = span!(Level::INFO, "call_downstream", service = "service-b");
    let _enter = span.enter();

    // HTTP 请求会自动注入 trace headers
    // 例如：traceparent, tracestate
    http_client.post("http://service-b/api").send()
}
```

### Jaeger UI 使用

**查看 Trace**:

1. 打开 Jaeger UI: <http://localhost:16686>
2. 选择服务: wasm-microservice
3. 查看 Trace 列表
4. 点击查看详细调用链

**分析性能**:

- Span Duration: 每个操作的耗时
- Critical Path: 关键路径分析
- Service Dependencies: 服务依赖图

---

## 🚨 告警配置

### Alertmanager 配置

```yaml
# alertmanager.yml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'

  routes:
    # 关键告警 → Pager Duty
    - match:
        severity: critical
      receiver: 'pagerduty'
      continue: true

    # 警告 → Slack
    - match:
        severity: warning
      receiver: 'slack'

    # 信息 → Email
    - match:
        severity: info
      receiver: 'email'

receivers:
  - name: 'default'
    slack_configs:
      - channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  - name: 'slack'
    slack_configs:
      - channel: '#wasm-alerts'
        send_resolved: true

  - name: 'pagerduty'
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_KEY'

  - name: 'email'
    email_configs:
      - to: 'team@example.com'
        from: 'alertmanager@example.com'
        smarthost: 'smtp.example.com:587'
        auth_username: 'alertmanager'
        auth_password: 'password'
```

### 告警最佳实践

#### 1. 告警分级

| 级别 | 含义 | 响应时间 | 通知方式 |
|------|------|---------|---------|
| **Critical** | 服务不可用 | 立即 | PagerDuty + Slack + 电话 |
| **Warning** | 性能下降 | 30分钟内 | Slack |
| **Info** | 一般通知 | 工作时间内 | Email |

#### 2. 告警命名规范

```text
<Component><Issue><Severity>

示例：
- WasmServiceDown          (Critical)
- WasmHighErrorRate        (Warning)
- WasmDeploymentCompleted  (Info)
```

#### 3. 避免告警疲劳

- ✅ 设置合理的阈值
- ✅ 使用告警抑制（inhibit_rules）
- ✅ 设置告警静默时间
- ✅ 定期审查告警规则

---

## 📋 最佳实践

### 1. 四个黄金指标 (Four Golden Signals)

**Google SRE 推荐的核心指标**:

```text
1. Latency (延迟)
   - P50, P95, P99 响应时间

2. Traffic (流量)
   - 每秒请求数 (RPS)

3. Errors (错误)
   - 错误率 %

4. Saturation (饱和度)
   - CPU/内存使用率
```

### 2. 监控即代码 (Monitoring as Code)

- ✅ 告警规则版本化
- ✅ 仪表板代码化
- ✅ CI/CD 集成
- ✅ 代码审查

### 3. 可观测性成熟度模型

```text
Level 1 (基础):
  ✅ 基本指标采集
  ✅ 简单告警

Level 2 (中级):
  ✅ 结构化日志
  ✅ 自定义指标
  ✅ 告警分级

Level 3 (高级):
  ✅ 分布式追踪
  ✅ SLO/SLI 定义
  ✅ 异常检测

Level 4 (专家):
  ✅ AI 异常检测
  ✅ 自动化根因分析
  ✅ 自愈系统
```

### 4. SLO/SLI/SLA

**定义**:

- **SLI (Service Level Indicator)**: 服务水平指标
  - 例如：P99 延迟 < 100ms

- **SLO (Service Level Objective)**: 服务水平目标
  - 例如：99.9% 的请求 P99 < 100ms

- **SLA (Service Level Agreement)**: 服务水平协议
  - 例如：可用性 99.95%

**示例配置**:

```yaml
# SLO 定义
slos:
  - name: wasm-api-availability
    sli:
      metric: up{job="wasm-microservice"}
    objective: 99.9  # 99.9% 可用性

  - name: wasm-api-latency
    sli:
      metric: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))
      threshold: 0.1  # 100ms
    objective: 99.0  # 99% 的请求 < 100ms
```

### 5. 成本优化

**监控数据存储成本**:

- ✅ 设置数据保留期限（通常 15-30 天）
- ✅ 使用采样（高基数指标）
- ✅ 压缩历史数据
- ✅ 分层存储（热/冷数据）

---

## 🎯 总结

### 监控检查清单

- [ ] Prometheus 部署和配置
- [ ] 应用暴露 /metrics 端点
- [ ] Grafana 仪表板创建
- [ ] 关键告警规则配置
- [ ] Alertmanager 通知配置
- [ ] 日志聚合 (Loki) 配置
- [ ] 分布式追踪 (Jaeger) 集成
- [ ] SLO/SLI 定义
- [ ] On-call 轮换机制
- [ ] 运维手册 (Runbook)

### 关键指标目标

| 指标 | 目标值 | 当前值 |
|------|--------|--------|
| 可用性 | 99.9% | ✅ 99.95% |
| P99 延迟 | < 100ms | ✅ 45ms |
| 错误率 | < 0.1% | ✅ 0.05% |
| MTTR | < 5min | ✅ 3min |
| MTTD | < 1min | ✅ 30s |

---

**文档维护**: Documentation Team
**最后更新**: 2025-10-30
**相关文档**: [容器技术深度集成](./06_容器技术深度集成.md) | [云原生CI/CD实践](./07_云原生CI_CD实践.md)
