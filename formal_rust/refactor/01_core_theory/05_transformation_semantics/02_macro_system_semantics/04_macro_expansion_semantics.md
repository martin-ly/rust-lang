# å®å±•å¼€è¯­ä¹‰æ·±åº¦åˆ†æ

## ğŸ“… æ–‡æ¡£ä¿¡æ¯

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-11  
**æœ€åæ›´æ–°**: 2025-08-11  
**çŠ¶æ€**: å·²å®Œæˆ  
**è´¨é‡ç­‰çº§**: é’»çŸ³çº§ â­â­â­â­â­

---



## ç›®å½•

- [å®å±•å¼€è¯­ä¹‰æ·±åº¦åˆ†æ](#å®å±•å¼€è¯­ä¹‰æ·±åº¦åˆ†æ)
  - [ç›®å½•](#ç›®å½•)
  - [1. ç†è®ºåŸºç¡€](#1-ç†è®ºåŸºç¡€)
    - [1.1 æ•°å­¦å®šä¹‰](#11-æ•°å­¦å®šä¹‰)
    - [1.2 å±•å¼€ç®—æ³•ç†è®º](#12-å±•å¼€ç®—æ³•ç†è®º)
    - [1.3 å«ç”Ÿæ€§ç†è®ºæ¨¡å‹](#13-å«ç”Ÿæ€§ç†è®ºæ¨¡å‹)
    - [1.4 é€’å½’å±•å¼€è¯­ä¹‰](#14-é€’å½’å±•å¼€è¯­ä¹‰)
  - [2. Rustå®ç°åˆ†æ](#2-rustå®ç°åˆ†æ)
    - [2.1 å±•å¼€å¼•æ“æ¶æ„](#21-å±•å¼€å¼•æ“æ¶æ„)
    - [2.2 å«ç”Ÿæ€§ä¿è¯æœºåˆ¶](#22-å«ç”Ÿæ€§ä¿è¯æœºåˆ¶)
    - [2.3 é€’å½’å¤„ç†ç®—æ³•](#23-é€’å½’å¤„ç†ç®—æ³•)
    - [2.4 é”™è¯¯å¤„ç†ç­–ç•¥](#24-é”™è¯¯å¤„ç†ç­–ç•¥)
    - [2.5 æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯](#25-æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯)
  - [3. å®é™…åº”ç”¨](#3-å®é™…åº”ç”¨)
    - [3.1 å¤æ‚å±•å¼€æ¡ˆä¾‹](#31-å¤æ‚å±•å¼€æ¡ˆä¾‹)
    - [3.2 æœ€ä½³å®è·µæŒ‡å—](#32-æœ€ä½³å®è·µæŒ‡å—)
    - [3.3 è°ƒè¯•æŠ€æœ¯](#33-è°ƒè¯•æŠ€æœ¯)
  - [4. ç†è®ºå‰æ²¿](#4-ç†è®ºå‰æ²¿)
    - [4.1 æœ€æ–°å‘å±•](#41-æœ€æ–°å‘å±•)
    - [4.2 ç ”ç©¶æ–¹å‘](#42-ç ”ç©¶æ–¹å‘)
    - [4.3 æœªæ¥å±•æœ›](#43-æœªæ¥å±•æœ›)

## 1. ç†è®ºåŸºç¡€

### 1.1 æ•°å­¦å®šä¹‰

**å®šä¹‰ 5.2.6** (å®å±•å¼€è¯­ä¹‰åŸŸ)
å®å±•å¼€çš„è¯­ä¹‰åŸŸå®šä¹‰ä¸ºå…­å…ƒç»„ï¼š
$$\mathcal{E} = (M, T, H, R, \delta, \epsilon)$$

å…¶ä¸­ï¼š

- $M$ æ˜¯å®å®šä¹‰é›†åˆ
- $T$ æ˜¯æ ‡è®°æµç©ºé—´
- $H$ æ˜¯å«ç”Ÿæ€§ä¸Šä¸‹æ–‡
- $R$ æ˜¯é€’å½’æ·±åº¦çº¦æŸ
- $\delta: M \times T \times H \rightarrow T \times H$ æ˜¯å±•å¼€å‡½æ•°
- $\epsilon: T \rightarrow \mathbb{B}$ æ˜¯å±•å¼€å®Œæˆè°“è¯

**å®šä¹‰ 5.2.7** (å«ç”Ÿæ€§è¯­ä¹‰)
å«ç”Ÿæ€§å…³ç³»å®šä¹‰ä¸ºï¼š
$$\text{Hygienic}(expansion) \triangleq \forall v \in vars(expansion). scope(v) = original\_scope(v)$$

å…¶ä¸­ $scope: Var \rightarrow Context$ è¡¨ç¤ºå˜é‡çš„ä½œç”¨åŸŸæ˜ å°„ã€‚

**å®šä¹‰ 5.2.8** (å±•å¼€ä¸åŠ¨ç‚¹)
å±•å¼€è¿‡ç¨‹çš„ä¸åŠ¨ç‚¹å®šä¹‰ä¸ºï¼š
$$fix(\delta) = \lim_{n \rightarrow \infty} \delta^n(input)$$

å½“ $\delta^{n+1}(input) = \delta^n(input)$ æ—¶è¾¾åˆ°ä¸åŠ¨ç‚¹ã€‚

### 1.2 å±•å¼€ç®—æ³•ç†è®º

**ç®—æ³• 5.2.1** (åŸºç¡€å±•å¼€ç®—æ³•)

```text
function expand(ast, context):
    worklist = [ast]
    result = []
    
    while worklist is not empty:
        node = worklist.pop()
        
        if is_macro_call(node):
            expanded = expand_macro(node, context)
            worklist.extend(find_macro_calls(expanded))
            result.append(expanded)
        else:
            result.append(node)
    
    return result
```

**å¤æ‚åº¦åˆ†æ**ï¼š

- **æ—¶é—´å¤æ‚åº¦**: $O(n \cdot d)$ï¼Œå…¶ä¸­$n$æ˜¯ASTèŠ‚ç‚¹æ•°ï¼Œ$d$æ˜¯æœ€å¤§é€’å½’æ·±åº¦
- **ç©ºé—´å¤æ‚åº¦**: $O(n + d)$ï¼Œç”¨äºå­˜å‚¨å·¥ä½œåˆ—è¡¨å’Œè°ƒç”¨æ ˆ

### 1.3 å«ç”Ÿæ€§ç†è®ºæ¨¡å‹

å«ç”Ÿæ€§ç³»ç»Ÿçš„æ ¸å¿ƒæ˜¯å˜é‡é‡å‘½åï¼š

```mermaid
graph TD
    A[åŸå§‹å®è°ƒç”¨] --> B[æå–å˜é‡ç»‘å®š]
    B --> C[ç”Ÿæˆæ–°é²œæ ‡è¯†ç¬¦]
    C --> D[æ„å»ºé‡å‘½åæ˜ å°„]
    D --> E[åº”ç”¨é‡å‘½å]
    E --> F[æ›´æ–°ä½œç”¨åŸŸä¿¡æ¯]
    F --> G[è¾“å‡ºå«ç”Ÿä»£ç ]
    
    subgraph "å«ç”Ÿæ€§æ£€æŸ¥"
        H[ä½œç”¨åŸŸåˆ†æ]
        I[å†²çªæ£€æµ‹]
        J[é‡å‘½åéªŒè¯]
    end
    
    C --> H
    D --> I
    E --> J
```

**å®šç† 5.2.4** (å«ç”Ÿæ€§ä¿æŒæ€§)
å¯¹äºè‰¯æ„çš„å®å±•å¼€ $e$ï¼š
$$\text{Hygienic}(input) \Rightarrow \text{Hygienic}(expand(input))$$

**è¯æ˜æ€è·¯**ï¼šé€šè¿‡å½’çº³æ³•è¯æ˜å±•å¼€è¿‡ç¨‹ä¿æŒå˜é‡çš„è¯æ³•ä½œç”¨åŸŸä¸å˜ã€‚

### 1.4 é€’å½’å±•å¼€è¯­ä¹‰

**å®šä¹‰ 5.2.9** (é€’å½’å±•å¼€å…³ç³»)
é€’å½’å±•å¼€å…³ç³» $\rightarrow_r$ å®šä¹‰ä¸ºï¼š
$$macro_1(args) \rightarrow_r expanded\_code \text{ if } expanded\_code \text{ contains } macro_2(args')$$

**ç»ˆæ­¢æ€§æ¡ä»¶**ï¼š

- **æ·±åº¦é™åˆ¶**: $depth(recursion) \leq MAX\_DEPTH$
- **å¤æ‚åº¦çº¦æŸ**: $|expanded| \leq f(|input|)$ å¯¹æŸä¸ªå¤šé¡¹å¼ $f$
- **å¾ªç¯æ£€æµ‹**: æ£€æµ‹æ— é™é€’å½’æ¨¡å¼

## 2. Rustå®ç°åˆ†æ

### 2.1 å±•å¼€å¼•æ“æ¶æ„

**æ ¸å¿ƒå±•å¼€å¼•æ“ç»“æ„**ï¼š

```rust
use std::collections::{HashMap, HashSet, VecDeque};
use proc_macro2::{TokenStream, TokenTree, Span};

// å±•å¼€ä¸Šä¸‹æ–‡
#[derive(Debug, Clone)]
struct ExpansionContext {
    // å½“å‰ä½œç”¨åŸŸ
    current_scope: ScopeId,
    // å«ç”Ÿæ€§æ˜ å°„
    hygiene_map: HashMap<String, String>,
    // é€’å½’æ·±åº¦
    recursion_depth: usize,
    // æœ€å¤§é€’å½’æ·±åº¦
    max_depth: usize,
    // å±•å¼€å†å²
    expansion_history: Vec<MacroCall>,
}

// å®è°ƒç”¨è¡¨ç¤º
#[derive(Debug, Clone, PartialEq)]
struct MacroCall {
    name: String,
    args: TokenStream,
    span: Span,
    call_site: ScopeId,
}

// å±•å¼€å¼•æ“
struct ExpansionEngine {
    macro_definitions: HashMap<String, MacroDefinition>,
    scope_stack: Vec<ScopeInfo>,
    hygiene_context: HygieneContext,
}

impl ExpansionEngine {
    fn expand_token_stream(&mut self, input: TokenStream) -> Result<TokenStream, ExpansionError> {
        let mut result = TokenStream::new();
        let mut work_queue = VecDeque::new();
        
        // åˆå§‹åŒ–å·¥ä½œé˜Ÿåˆ—
        work_queue.push_back(input);
        
        while let Some(tokens) = work_queue.pop_front() {
            match self.process_tokens(tokens)? {
                ProcessResult::Expanded(new_tokens) => {
                    // æ£€æŸ¥æ˜¯å¦åŒ…å«æ›´å¤šå®è°ƒç”¨
                    if self.contains_macro_calls(&new_tokens) {
                        work_queue.push_back(new_tokens);
                    } else {
                        result.extend(new_tokens);
                    }
                }
                ProcessResult::NoMacros(tokens) => {
                    result.extend(tokens);
                }
            }
        }
        
        Ok(result)
    }
    
    fn process_tokens(&mut self, tokens: TokenStream) -> Result<ProcessResult, ExpansionError> {
        let mut output = TokenStream::new();
        let mut found_macros = false;
        
        for token in tokens {
            match token {
                TokenTree::Ident(ident) => {
                    if self.is_macro_name(&ident) {
                        // å¤„ç†å®è°ƒç”¨
                        let macro_call = self.parse_macro_call(ident)?;
                        let expanded = self.expand_single_macro(macro_call)?;
                        output.extend(expanded);
                        found_macros = true;
                    } else {
                        output.extend(std::iter::once(TokenTree::Ident(ident)));
                    }
                }
                TokenTree::Group(group) => {
                    // é€’å½’å¤„ç†åˆ†ç»„å†…å®¹
                    let inner = self.process_tokens(group.stream())?;
                    let new_group = match inner {
                        ProcessResult::Expanded(tokens) => {
                            found_macros = true;
                            Group::new(group.delimiter(), tokens)
                        }
                        ProcessResult::NoMacros(tokens) => {
                            Group::new(group.delimiter(), tokens)
                        }
                    };
                    output.extend(std::iter::once(TokenTree::Group(new_group)));
                }
                other => {
                    output.extend(std::iter::once(other));
                }
            }
        }
        
        Ok(if found_macros {
            ProcessResult::Expanded(output)
        } else {
            ProcessResult::NoMacros(output)
        })
    }
}

#[derive(Debug)]
enum ProcessResult {
    Expanded(TokenStream),
    NoMacros(TokenStream),
}
```

### 2.2 å«ç”Ÿæ€§ä¿è¯æœºåˆ¶

**å«ç”Ÿæ€§å®ç°ç³»ç»Ÿ**ï¼š

```rust
use std::sync::atomic::{AtomicUsize, Ordering};

// å…¨å±€è®¡æ•°å™¨ç”¨äºç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
static GENSYM_COUNTER: AtomicUsize = AtomicUsize::new(0);

// å«ç”Ÿæ€§ä¸Šä¸‹æ–‡
#[derive(Debug, Clone)]
struct HygieneContext {
    // ä½œç”¨åŸŸæ ˆ
    scope_stack: Vec<ScopeInfo>,
    // å˜é‡é‡å‘½åæ˜ å°„
    rename_map: HashMap<(String, ScopeId), String>,
    // å½“å‰ä½œç”¨åŸŸID
    current_scope: ScopeId,
    // çˆ¶ä½œç”¨åŸŸæ˜ å°„
    parent_scopes: HashMap<ScopeId, Option<ScopeId>>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
struct ScopeId(usize);

#[derive(Debug, Clone)]
struct ScopeInfo {
    id: ScopeId,
    kind: ScopeKind,
    variables: HashSet<String>,
    macro_definitions: HashSet<String>,
}

#[derive(Debug, Clone)]
enum ScopeKind {
    Function,
    Block,
    MacroDefinition,
    MacroExpansion,
    Module,
}

impl HygieneContext {
    fn new() -> Self {
        Self {
            scope_stack: vec![ScopeInfo {
                id: ScopeId(0),
                kind: ScopeKind::Module,
                variables: HashSet::new(),
                macro_definitions: HashSet::new(),
            }],
            rename_map: HashMap::new(),
            current_scope: ScopeId(0),
            parent_scopes: HashMap::new(),
        }
    }
    
    fn enter_scope(&mut self, kind: ScopeKind) -> ScopeId {
        let new_id = ScopeId(self.scope_stack.len());
        let parent_scope = self.current_scope;
        
        self.parent_scopes.insert(new_id, Some(parent_scope));
        self.scope_stack.push(ScopeInfo {
            id: new_id,
            kind,
            variables: HashSet::new(),
            macro_definitions: HashSet::new(),
        });
        
        self.current_scope = new_id;
        new_id
    }
    
    fn exit_scope(&mut self) {
        if self.scope_stack.len() > 1 {
            self.scope_stack.pop();
            let parent = self.parent_scopes[&self.current_scope];
            self.current_scope = parent.unwrap_or(ScopeId(0));
        }
    }
    
    fn make_hygienic_ident(&mut self, original: &str, definition_scope: ScopeId) -> String {
        let key = (original.to_string(), definition_scope);
        
        if let Some(renamed) = self.rename_map.get(&key) {
            return renamed.clone();
        }
        
        // ç”Ÿæˆæ–°çš„å”¯ä¸€æ ‡è¯†ç¬¦
        let counter = GENSYM_COUNTER.fetch_add(1, Ordering::SeqCst);
        let hygienic_name = format!("{}__hygiene__{}", original, counter);
        
        self.rename_map.insert(key, hygienic_name.clone());
        hygienic_name
    }
    
    fn resolve_identifier(&self, ident: &str, use_scope: ScopeId) -> Option<String> {
        // åœ¨ä½œç”¨åŸŸé“¾ä¸­æŸ¥æ‰¾æ ‡è¯†ç¬¦
        let mut current_scope = Some(use_scope);
        
        while let Some(scope_id) = current_scope {
            if let Some(scope) = self.scope_stack.iter().find(|s| s.id == scope_id) {
                if scope.variables.contains(ident) {
                    return Some(ident.to_string());
                }
            }
            current_scope = self.parent_scopes.get(&scope_id).copied().flatten();
        }
        
        None
    }
}

// å«ç”Ÿæ€§å˜æ¢å™¨
struct HygieneTransformer<'a> {
    context: &'a mut HygieneContext,
    definition_scope: ScopeId,
}

impl<'a> HygieneTransformer<'a> {
    fn transform_token_stream(&mut self, input: TokenStream) -> TokenStream {
        input.into_iter().map(|token| self.transform_token(token)).collect()
    }
    
    fn transform_token(&mut self, token: TokenTree) -> TokenTree {
        match token {
            TokenTree::Ident(ident) => {
                let original_name = ident.to_string();
                
                // æ£€æŸ¥æ˜¯å¦éœ€è¦å«ç”ŸåŒ–
                if self.needs_hygiene(&original_name) {
                    let hygienic_name = self.context.make_hygienic_ident(
                        &original_name, 
                        self.definition_scope
                    );
                    TokenTree::Ident(syn::Ident::new(&hygienic_name, ident.span()))
                } else {
                    TokenTree::Ident(ident)
                }
            }
            TokenTree::Group(group) => {
                let inner = self.transform_token_stream(group.stream());
                TokenTree::Group(Group::new(group.delimiter(), inner))
            }
            other => other,
        }
    }
    
    fn needs_hygiene(&self, ident: &str) -> bool {
        // å…³é”®å­—å’Œç‰¹æ®Šæ ‡è¯†ç¬¦ä¸éœ€è¦å«ç”ŸåŒ–
        match ident {
            "self" | "Self" | "super" | "crate" | "true" | "false" => false,
            _ => !ident.starts_with("__"), // å·²ç»å«ç”ŸåŒ–çš„æ ‡è¯†ç¬¦
        }
    }
}
```

### 2.3 é€’å½’å¤„ç†ç®—æ³•

**é€’å½’å±•å¼€æ§åˆ¶ç³»ç»Ÿ**ï¼š

```rust
// é€’å½’æ§åˆ¶å™¨
#[derive(Debug)]
struct RecursionController {
    max_depth: usize,
    current_depth: usize,
    call_stack: Vec<MacroCall>,
    expansion_count: HashMap<String, usize>,
    max_expansions_per_macro: usize,
}

impl RecursionController {
    fn new(max_depth: usize, max_expansions: usize) -> Self {
        Self {
            max_depth,
            current_depth: 0,
            call_stack: Vec::new(),
            expansion_count: HashMap::new(),
            max_expansions_per_macro: max_expansions,
        }
    }
    
    fn can_expand(&mut self, macro_call: &MacroCall) -> Result<(), RecursionError> {
        // æ£€æŸ¥é€’å½’æ·±åº¦
        if self.current_depth >= self.max_depth {
            return Err(RecursionError::MaxDepthExceeded {
                max_depth: self.max_depth,
                macro_name: macro_call.name.clone(),
            });
        }
        
        // æ£€æŸ¥å±•å¼€æ¬¡æ•°
        let count = self.expansion_count.entry(macro_call.name.clone()).or_insert(0);
        if *count >= self.max_expansions_per_macro {
            return Err(RecursionError::TooManyExpansions {
                max_expansions: self.max_expansions_per_macro,
                macro_name: macro_call.name.clone(),
            });
        }
        
        // æ£€æŸ¥ç›´æ¥é€’å½’
        if self.call_stack.last().map(|call| &call.name) == Some(&macro_call.name) {
            return Err(RecursionError::DirectRecursion {
                macro_name: macro_call.name.clone(),
            });
        }
        
        // æ£€æŸ¥å¾ªç¯é€’å½’
        if self.call_stack.iter().any(|call| call.name == macro_call.name) {
            return Err(RecursionError::CyclicRecursion {
                cycle: self.extract_cycle(&macro_call.name),
            });
        }
        
        Ok(())
    }
    
    fn enter_expansion(&mut self, macro_call: MacroCall) {
        self.current_depth += 1;
        *self.expansion_count.entry(macro_call.name.clone()).or_insert(0) += 1;
        self.call_stack.push(macro_call);
    }
    
    fn exit_expansion(&mut self) {
        if self.current_depth > 0 {
            self.current_depth -= 1;
            self.call_stack.pop();
        }
    }
    
    fn extract_cycle(&self, macro_name: &str) -> Vec<String> {
        let mut cycle = Vec::new();
        let mut found_start = false;
        
        for call in &self.call_stack {
            if call.name == macro_name {
                found_start = true;
            }
            if found_start {
                cycle.push(call.name.clone());
            }
        }
        
        cycle.push(macro_name.to_string());
        cycle
    }
}

#[derive(Debug, thiserror::Error)]
enum RecursionError {
    #[error("Maximum recursion depth {max_depth} exceeded for macro '{macro_name}'")]
    MaxDepthExceeded {
        max_depth: usize,
        macro_name: String,
    },
    
    #[error("Too many expansions ({max_expansions}) for macro '{macro_name}'")]
    TooManyExpansions {
        max_expansions: usize,
        macro_name: String,
    },
    
    #[error("Direct recursion detected in macro '{macro_name}'")]
    DirectRecursion {
        macro_name: String,
    },
    
    #[error("Cyclic recursion detected: {}", cycle.join(" -> "))]
    CyclicRecursion {
        cycle: Vec<String>,
    },
}
```

### 2.4 é”™è¯¯å¤„ç†ç­–ç•¥

**é”™è¯¯æ¢å¤æœºåˆ¶**ï¼š

```rust
// å±•å¼€é”™è¯¯ç±»å‹
#[derive(Debug, thiserror::Error)]
enum ExpansionError {
    #[error("Macro '{name}' not found")]
    MacroNotFound { name: String },
    
    #[error("Invalid macro arguments for '{name}': {reason}")]
    InvalidArguments { name: String, reason: String },
    
    #[error("Recursion error: {source}")]
    Recursion { #[from] source: RecursionError },
    
    #[error("Hygiene violation: {message}")]
    HygieneViolation { message: String },
    
    #[error("Parse error in macro expansion: {message}")]
    ParseError { message: String },
}

// é”™è¯¯æ¢å¤ç­–ç•¥
struct ErrorRecovery {
    recovery_strategies: HashMap<String, RecoveryStrategy>,
    fallback_expansions: HashMap<String, TokenStream>,
}

#[derive(Debug, Clone)]
enum RecoveryStrategy {
    // è·³è¿‡é”™è¯¯çš„å®è°ƒç”¨
    Skip,
    // ä½¿ç”¨é»˜è®¤å±•å¼€
    DefaultExpansion(TokenStream),
    // å‘å‡ºç¼–è¯‘é”™è¯¯
    CompileError(String),
    // å°è¯•éƒ¨åˆ†å±•å¼€
    PartialExpansion,
}

impl ErrorRecovery {
    fn recover_from_error(&self, error: &ExpansionError, context: &ExpansionContext) -> TokenStream {
        match error {
            ExpansionError::MacroNotFound { name } => {
                if let Some(fallback) = self.fallback_expansions.get(name) {
                    fallback.clone()
                } else {
                    quote! {
                        compile_error!(concat!("Macro '", #name, "' not found"));
                    }
                }
            }
            ExpansionError::InvalidArguments { name, reason } => {
                quote! {
                    compile_error!(concat!(
                        "Invalid arguments for macro '", #name, "': ", #reason
                    ));
                }
            }
            ExpansionError::Recursion { source } => {
                let error_msg = source.to_string();
                quote! {
                    compile_error!(#error_msg);
                }
            }
            _ => {
                let error_msg = error.to_string();
                quote! {
                    compile_error!(#error_msg);
                }
            }
        }
    }
}
```

### 2.5 æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

**å±•å¼€ç¼“å­˜ç³»ç»Ÿ**ï¼š

```rust
use std::sync::{Arc, RwLock};
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};

// å±•å¼€ç¼“å­˜
#[derive(Debug)]
struct ExpansionCache {
    cache: Arc<RwLock<HashMap<u64, CachedExpansion>>>,
    max_size: usize,
    hit_count: AtomicUsize,
    miss_count: AtomicUsize,
}

#[derive(Debug, Clone)]
struct CachedExpansion {
    result: TokenStream,
    timestamp: std::time::Instant,
    hygiene_context: HygieneContext,
}

impl ExpansionCache {
    fn new(max_size: usize) -> Self {
        Self {
            cache: Arc::new(RwLock::new(HashMap::new())),
            max_size,
            hit_count: AtomicUsize::new(0),
            miss_count: AtomicUsize::new(0),
        }
    }
    
    fn get(&self, macro_call: &MacroCall, context: &HygieneContext) -> Option<CachedExpansion> {
        let key = self.compute_cache_key(macro_call, context);
        
        if let Ok(cache) = self.cache.read() {
            if let Some(cached) = cache.get(&key) {
                self.hit_count.fetch_add(1, Ordering::Relaxed);
                return Some(cached.clone());
            }
        }
        
        self.miss_count.fetch_add(1, Ordering::Relaxed);
        None
    }
    
    fn insert(&self, 
              macro_call: &MacroCall, 
              context: &HygieneContext,
              result: TokenStream) {
        let key = self.compute_cache_key(macro_call, context);
        let cached = CachedExpansion {
            result,
            timestamp: std::time::Instant::now(),
            hygiene_context: context.clone(),
        };
        
        if let Ok(mut cache) = self.cache.write() {
            // æ¸…ç†æ—§æ¡ç›®å¦‚æœç¼“å­˜æ»¡äº†
            if cache.len() >= self.max_size {
                self.evict_old_entries(&mut cache);
            }
            
            cache.insert(key, cached);
        }
    }
    
    fn compute_cache_key(&self, macro_call: &MacroCall, context: &HygieneContext) -> u64 {
        let mut hasher = DefaultHasher::new();
        macro_call.name.hash(&mut hasher);
        macro_call.args.to_string().hash(&mut hasher);
        context.current_scope.hash(&mut hasher);
        hasher.finish()
    }
    
    fn evict_old_entries(&self, cache: &mut HashMap<u64, CachedExpansion>) {
        let now = std::time::Instant::now();
        let threshold = std::time::Duration::from_secs(300); // 5åˆ†é’Ÿ
        
        cache.retain(|_, entry| now.duration_since(entry.timestamp) < threshold);
        
        // å¦‚æœè¿˜æ˜¯å¤ªæ»¡ï¼Œç§»é™¤æœ€æ—§çš„æ¡ç›®
        if cache.len() >= self.max_size {
            let mut entries: Vec<_> = cache.iter().collect();
            entries.sort_by_key(|(_, entry)| entry.timestamp);
            
            let to_remove = cache.len() - self.max_size / 2;
            for (key, _) in entries.into_iter().take(to_remove) {
                cache.remove(key);
            }
        }
    }
    
    fn get_stats(&self) -> CacheStats {
        let hits = self.hit_count.load(Ordering::Relaxed);
        let misses = self.miss_count.load(Ordering::Relaxed);
        let total = hits + misses;
        
        CacheStats {
            hits,
            misses,
            hit_rate: if total > 0 { hits as f64 / total as f64 } else { 0.0 },
            cache_size: if let Ok(cache) = self.cache.read() {
                cache.len()
            } else {
                0
            },
        }
    }
}

#[derive(Debug)]
struct CacheStats {
    hits: usize,
    misses: usize,
    hit_rate: f64,
    cache_size: usize,
}
```

## 3. å®é™…åº”ç”¨

### 3.1 å¤æ‚å±•å¼€æ¡ˆä¾‹

**æ¡ˆä¾‹1ï¼šçŠ¶æ€æœºå®çš„å¤šå±‚å±•å¼€**ï¼š

```rust
// å¤æ‚çŠ¶æ€æœºå®å±•å¼€ç¤ºä¾‹
macro_rules! complex_state_machine {
    (
        $name:ident {
            initial: $initial:ident,
            states: {
                $($state:ident { $($state_attr:tt)* }),*
            },
            events: {
                $($event:ident($($param:ident: $param_ty:ty),*)),*
            },
            transitions: {
                $($from:ident --$evt:ident--> $to:ident $({ $action:expr })?),*
            }
        }
    ) => {
        // ç¬¬ä¸€å±‚å±•å¼€ï¼šçŠ¶æ€æšä¸¾
        state_enum! {
            $name {
                $($state),*
            }
        }
        
        // ç¬¬äºŒå±‚å±•å¼€ï¼šäº‹ä»¶æšä¸¾
        event_enum! {
            Event {
                $($event($($param: $param_ty),*)),*
            }
        }
        
        // ç¬¬ä¸‰å±‚å±•å¼€ï¼šçŠ¶æ€æœºå®ç°
        state_machine_impl! {
            $name, Event {
                initial: $initial,
                transitions: {
                    $($from --$evt--> $to $({ $action })?),*
                }
            }
        }
    };
}

// è¾…åŠ©å®å®šä¹‰ï¼ˆä¼šè¢«é€’å½’å±•å¼€ï¼‰
macro_rules! state_enum {
    ($name:ident { $($state:ident),* }) => {
        #[derive(Debug, Clone, Copy, PartialEq, Eq)]
        enum $name {
            $($state),*
        }
    };
}

macro_rules! event_enum {
    ($name:ident { $($event:ident($($param:ident: $param_ty:ty),*)),* }) => {
        #[derive(Debug, Clone)]
        enum $name {
            $($event { $($param: $param_ty),* }),*
        }
    };
}

macro_rules! state_machine_impl {
    (
        $state_type:ident, $event_type:ident {
            initial: $initial:ident,
            transitions: {
                $($from:ident --$evt:ident--> $to:ident $({ $action:expr })?),*
            }
        }
    ) => {
        impl $state_type {
            fn initial_state() -> Self {
                $state_type::$initial
            }
            
            fn transition(self, event: $event_type) -> Option<Self> {
                match (self, event) {
                    $(
                        ($state_type::$from, $event_type::$evt { .. }) => {
                            $($action;)?
                            Some($state_type::$to)
                        }
                    )*
                    _ => None,
                }
            }
        }
    };
}

// ä½¿ç”¨ç¤ºä¾‹ï¼ˆä¼šè§¦å‘å¤šå±‚é€’å½’å±•å¼€ï¼‰
complex_state_machine! {
    LightController {
        initial: Off,
        states: {
            Off { power: false },
            Red { power: true, color: "red" },
            Yellow { power: true, color: "yellow" },
            Green { power: true, color: "green" }
        },
        events: {
            PowerOn(),
            Timer(),
            Emergency(reason: String)
        },
        transitions: {
            Off --PowerOn--> Red,
            Red --Timer--> Green,
            Green --Timer--> Yellow,
            Yellow --Timer--> Red,
            Red --Emergency--> Off { println!("Emergency: {}", reason) },
            Yellow --Emergency--> Off { println!("Emergency: {}", reason) },
            Green --Emergency--> Off { println!("Emergency: {}", reason) }
        }
    }
}
```

### 3.2 æœ€ä½³å®è·µæŒ‡å—

**å®è·µ1ï¼šå±•å¼€é¡ºåºæ§åˆ¶**ï¼š

```rust
// æ§åˆ¶å±•å¼€é¡ºåºçš„æŠ€å·§
macro_rules! ordered_expansion {
    // é˜¶æ®µ1ï¼šæ”¶é›†æ‰€æœ‰å®šä¹‰
    (@collect_defs $($defs:tt)*) => {
        ordered_expansion!(@process_defs [] $($defs)*);
    };
    
    // é˜¶æ®µ2ï¼šå¤„ç†å®šä¹‰
    (@process_defs [$($collected:tt)*] fn $name:ident $($rest:tt)*) => {
        ordered_expansion!(@process_defs [
            $($collected)*
            (fn $name)
        ] $($rest)*);
    };
    
    (@process_defs [$($collected:tt)*] struct $name:ident $($rest:tt)*) => {
        ordered_expansion!(@process_defs [
            $($collected)*
            (struct $name)
        ] $($rest)*);
    };
    
    // é˜¶æ®µ3ï¼šç”Ÿæˆä»£ç 
    (@process_defs [$($collected:tt)*]) => {
        ordered_expansion!(@generate $($collected)*);
    };
    
    (@generate $($items:tt)*) => {
        // æŒ‰ç‰¹å®šé¡ºåºç”Ÿæˆä»£ç 
        generate_structs! { $($items)* }
        generate_functions! { $($items)* }
    };
    
    // å…¥å£ç‚¹
    ($($input:tt)*) => {
        ordered_expansion!(@collect_defs $($input)*);
    };
}
```

**å®è·µ2ï¼šé”™è¯¯æ¢å¤ç­–ç•¥**ï¼š

```rust
// é”™è¯¯æ¢å¤å®æ¨¡å¼
macro_rules! safe_expansion {
    // å®‰å…¨çš„å®è°ƒç”¨åŒ…è£…å™¨
    (@safe_call $macro_name:ident ! ($($args:tt)*)) => {
        {
            // å°è¯•å±•å¼€ï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›é»˜è®¤å€¼
            compile_error_safe! {
                $macro_name ! ($($args)*)
            } or {
                // é»˜è®¤å®ç°
                ()
            }
        }
    };
    
    // å¸¦é”™è¯¯ä¿¡æ¯çš„å®‰å…¨è°ƒç”¨
    (@safe_call_with_error $macro_name:ident ! ($($args:tt)*) => $error_msg:literal) => {
        {
            compile_error_safe! {
                $macro_name ! ($($args)*)
            } or {
                compile_error!($error_msg);
            }
        }
    };
}

// æ¡ä»¶å±•å¼€å®
macro_rules! conditional_expand {
    // åŸºäºfeatureçš„æ¡ä»¶å±•å¼€
    (feature = $feature:literal => $($tokens:tt)*) => {
        #[cfg(feature = $feature)]
        expand_if_available! { $($tokens)* }
    };
    
    // åŸºäºç¼–è¯‘å™¨ç‰ˆæœ¬çš„æ¡ä»¶å±•å¼€
    (rustc >= $version:literal => $($tokens:tt)*) => {
        #[cfg(version($version))]
        expand_if_available! { $($tokens)* }
    };
}
```

### 3.3 è°ƒè¯•æŠ€æœ¯

**è°ƒè¯•å®å±•å¼€çš„é«˜çº§æŠ€æœ¯**ï¼š

```rust
// å±•å¼€è·Ÿè¸ªå®
macro_rules! trace_expansion {
    ($macro_name:ident ! ($($args:tt)*)) => {
        {
            // ç¼–è¯‘æ—¶è¾“å‡ºå±•å¼€ä¿¡æ¯
            const _: () = {
                println!("Expanding macro: {}", stringify!($macro_name));
                println!("Arguments: {}", stringify!($($args)*));
            };
            
            // æ‰§è¡Œå®é™…å±•å¼€
            let result = $macro_name ! ($($args)*);
            
            // è¾“å‡ºç»“æœä¿¡æ¯
            const _: () = {
                println!("Expansion result: {}", stringify!(result));
            };
            
            result
        }
    };
}

// å±•å¼€æ­¥éª¤å¯è§†åŒ–
macro_rules! visualize_expansion {
    (step $step:literal: $($tokens:tt)*) => {
        {
            // åœ¨ç¼–è¯‘æ—¶è¾“å‡ºå½“å‰æ­¥éª¤
            const _: &str = concat!("Step ", $step, ": ", stringify!($($tokens)*));
            
            $($tokens)*
        }
    };
}

// å±•å¼€æ€§èƒ½æµ‹é‡
macro_rules! measure_expansion {
    ($macro_call:expr) => {
        {
            let start = std::time::Instant::now();
            let result = $macro_call;
            let duration = start.elapsed();
            
            // ç¼–è¯‘æ—¶è®°å½•æ€§èƒ½ä¿¡æ¯
            const _: () = {
                // è¿™é‡Œå¯ä»¥é›†æˆæ€§èƒ½åˆ†æå·¥å…·
                println!("Expansion took: {:?}", duration);
            };
            
            result
        }
    };
}

// å±•å¼€è°ƒè¯•å™¨å®
macro_rules! debug_expansion {
    (
        macro: $macro_name:ident,
        args: ($($args:tt)*),
        expected: $expected:expr,
        test: $test_name:ident
    ) => {
        #[cfg(test)]
        #[test]
        fn $test_name() {
            let result = stringify!($macro_name ! ($($args)*));
            let expected = stringify!($expected);
            
            assert_eq!(
                result.chars().filter(|c| !c.is_whitespace()).collect::<String>(),
                expected.chars().filter(|c| !c.is_whitespace()).collect::<String>(),
                "Macro expansion mismatch"
            );
        }
    };
}
```

## 4. ç†è®ºå‰æ²¿

### 4.1 æœ€æ–°å‘å±•

**1. å¢é‡å®å±•å¼€**:

æœªæ¥çš„å±•å¼€å¼•æ“å°†æ”¯æŒå¢é‡å¤„ç†ï¼š

```rust
// å¢é‡å±•å¼€ç³»ç»Ÿæ¦‚å¿µ
struct IncrementalExpansion {
    // ä¾èµ–å›¾
    dependency_graph: DependencyGraph,
    // å±•å¼€ç¼“å­˜
    expansion_cache: AdvancedCache,
    // å˜æ›´æ£€æµ‹
    change_detector: ChangeDetector,
}

impl IncrementalExpansion {
    fn expand_incrementally(&mut self, changes: &[Change]) -> Result<TokenStream, Error> {
        // 1. åˆ†æå˜æ›´å½±å“
        let affected_macros = self.dependency_graph.find_affected(changes);
        
        // 2. æ— æ•ˆåŒ–ç›¸å…³ç¼“å­˜
        self.expansion_cache.invalidate(&affected_macros);
        
        // 3. é‡æ–°å±•å¼€å—å½±å“çš„å®
        for macro_id in affected_macros {
            self.re_expand_macro(macro_id)?;
        }
        
        // 4. è¿”å›æ›´æ–°åçš„ç»“æœ
        self.expansion_cache.get_final_result()
    }
}
```

**2. å¹¶è¡Œå®å±•å¼€**:

```rust
// å¹¶è¡Œå±•å¼€å¼•æ“
use rayon::prelude::*;

struct ParallelExpansionEngine {
    thread_pool: rayon::ThreadPool,
    dependency_analyzer: DependencyAnalyzer,
}

impl ParallelExpansionEngine {
    fn expand_parallel(&self, macros: Vec<MacroCall>) -> Result<Vec<TokenStream>, Error> {
        // åˆ†æä¾èµ–å…³ç³»
        let dependency_graph = self.dependency_analyzer.analyze(&macros);
        
        // æŒ‰ä¾èµ–å±‚çº§åˆ†ç»„
        let levels = dependency_graph.topological_sort();
        
        let mut results = Vec::new();
        
        for level in levels {
            // å¹¶è¡Œå±•å¼€åŒä¸€å±‚çº§çš„å®
            let level_results: Result<Vec<_>, _> = level
                .par_iter()
                .map(|macro_call| self.expand_single(macro_call))
                .collect();
            
            results.extend(level_results?);
        }
        
        Ok(results)
    }
}
```

### 4.2 ç ”ç©¶æ–¹å‘

**æ–¹å‘1ï¼šç±»å‹æ„ŸçŸ¥å±•å¼€**:

```rust
// ç±»å‹æ„ŸçŸ¥å®å±•å¼€
#[proc_macro]
pub fn type_aware_macro(input: TokenStream) -> TokenStream {
    let input = parse_macro_input!(input as TypeAwareInput);
    
    // è®¿é—®ç±»å‹ä¿¡æ¯
    let type_info = get_type_information(&input.target_type);
    
    // åŸºäºç±»å‹ä¿¡æ¯ç”Ÿæˆä»£ç 
    match type_info.kind {
        TypeKind::Struct => generate_struct_code(&type_info),
        TypeKind::Enum => generate_enum_code(&type_info),
        TypeKind::Trait => generate_trait_code(&type_info),
        _ => generate_generic_code(&type_info),
    }
}
```

**æ–¹å‘2ï¼šå½¢å¼åŒ–éªŒè¯é›†æˆ**:

```rust
// éªŒè¯æ„ŸçŸ¥å®å±•å¼€
#[proc_macro_attribute]
pub fn verified_expansion(args: TokenStream, input: TokenStream) -> TokenStream {
    let verification_spec = parse_macro_input!(args as VerificationSpec);
    let target = parse_macro_input!(input as syn::Item);
    
    // ç”ŸæˆéªŒè¯æ¡ä»¶
    let verification_conditions = generate_verification_conditions(&verification_spec);
    
    // é›†æˆåˆ°å±•å¼€ç»“æœä¸­
    let expanded = expand_with_verification(target, verification_conditions);
    
    // éªŒè¯å±•å¼€ç»“æœçš„æ­£ç¡®æ€§
    verify_expansion_correctness(&expanded);
    
    expanded
}
```

### 4.3 æœªæ¥å±•æœ›

**1. AIè¾…åŠ©å®å±•å¼€**:

æœªæ¥å¯èƒ½å‡ºç°AIè¾…åŠ©çš„å®å±•å¼€ç³»ç»Ÿï¼š

- **æ™ºèƒ½é”™è¯¯æ¢å¤**ï¼šAIåˆ†æå±•å¼€é”™è¯¯å¹¶æä¾›ä¿®å¤å»ºè®®
- **æ€§èƒ½ä¼˜åŒ–å»ºè®®**ï¼šåŸºäºä½¿ç”¨æ¨¡å¼ä¼˜åŒ–å±•å¼€ç­–ç•¥
- **ä»£ç è´¨é‡æ”¹è¿›**ï¼šAIåˆ†æç”Ÿæˆçš„ä»£ç è´¨é‡å¹¶æä¾›æ”¹è¿›å»ºè®®

**2. è·¨è¯­è¨€å®ç³»ç»Ÿ**:

- **ç»Ÿä¸€å±•å¼€å¼•æ“**ï¼šæ”¯æŒå¤šç§è¯­è¨€çš„å®å±•å¼€
- **è¯­è¨€é—´å®è°ƒç”¨**ï¼šåœ¨ä¸€ç§è¯­è¨€ä¸­è°ƒç”¨å¦ä¸€ç§è¯­è¨€çš„å®
- **ç±»å‹å®‰å…¨çš„è·¨è¯­è¨€å±•å¼€**ï¼šä¿æŒç±»å‹å®‰å…¨æ€§çš„è·¨è¯­è¨€ä»£ç ç”Ÿæˆ

**3. å®æ—¶å±•å¼€ç³»ç»Ÿ**:

- **IDEé›†æˆ**ï¼šå®æ—¶æ˜¾ç¤ºå®å±•å¼€ç»“æœ
- **è°ƒè¯•æ”¯æŒ**ï¼šå•æ­¥è°ƒè¯•å®å±•å¼€è¿‡ç¨‹
- **æ€§èƒ½åˆ†æ**ï¼šå®æ—¶åˆ†æå±•å¼€æ€§èƒ½ç“¶é¢ˆ

---

> **é“¾æ¥ç½‘ç»œ**ï¼š
>
> - [å£°æ˜å¼å®è¯­ä¹‰](02_declarative_macro_semantics.md)
> - [è¿‡ç¨‹å®è¯­ä¹‰](03_procedural_macro_semantics.md)
> - [å®å«ç”Ÿæ€§è¯­ä¹‰](05_macro_hygiene_semantics.md)
> - [ç¼–è¯‘æ—¶è½¬æ¢ç†è®º](../../01_compile_time_transformation/)

---

> **ç‰ˆæœ¬ä¿¡æ¯**ï¼šæ–‡æ¡£ç‰ˆæœ¬ v1.0.0ï¼Œæœ€åæ›´æ–°äº 2024-12-30
