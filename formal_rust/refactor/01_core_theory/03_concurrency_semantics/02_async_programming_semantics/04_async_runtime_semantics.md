# 3.2.4 Rustå¼‚æ­¥è¿è¡Œæ—¶è¯­ä¹‰æ¨¡å‹æ·±åº¦åˆ†æ

## ğŸ“… æ–‡æ¡£ä¿¡æ¯

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-11  
**æœ€åæ›´æ–°**: 2025-08-11  
**çŠ¶æ€**: å·²å®Œæˆ  
**è´¨é‡ç­‰çº§**: é’»çŸ³çº§ â­â­â­â­â­

---



## ç›®å½•

- [3.2.4 Rustå¼‚æ­¥è¿è¡Œæ—¶è¯­ä¹‰æ¨¡å‹æ·±åº¦åˆ†æ](#324-rustå¼‚æ­¥è¿è¡Œæ—¶è¯­ä¹‰æ¨¡å‹æ·±åº¦åˆ†æ)
  - [ç›®å½•](#ç›®å½•)
  - [3.2.4.1 å¼‚æ­¥è¿è¡Œæ—¶ç†è®ºåŸºç¡€](#3241-å¼‚æ­¥è¿è¡Œæ—¶ç†è®ºåŸºç¡€)
    - [3.2.4.1.1 è¿è¡Œæ—¶ç³»ç»Ÿè¯­ä¹‰æ¨¡å‹](#32411-è¿è¡Œæ—¶ç³»ç»Ÿè¯­ä¹‰æ¨¡å‹)
    - [3.2.4.1.2 è¿è¡Œæ—¶ç”Ÿå‘½å‘¨æœŸç®¡ç†](#32412-è¿è¡Œæ—¶ç”Ÿå‘½å‘¨æœŸç®¡ç†)
  - [3.2.4.2 è°ƒåº¦å™¨è¯­ä¹‰åˆ†æ](#3242-è°ƒåº¦å™¨è¯­ä¹‰åˆ†æ)
    - [3.2.4.2.1 å·¥ä½œçªƒå–è°ƒåº¦å™¨ç†è®º](#32421-å·¥ä½œçªƒå–è°ƒåº¦å™¨ç†è®º)
    - [3.2.4.2.2 ä¼˜å…ˆçº§è°ƒåº¦è¯­ä¹‰](#32422-ä¼˜å…ˆçº§è°ƒåº¦è¯­ä¹‰)
  - [3.2.4.3 æ‰§è¡Œå™¨è¯­ä¹‰åˆ†æ](#3243-æ‰§è¡Œå™¨è¯­ä¹‰åˆ†æ)
    - [3.2.4.3.1 å¤šçº¿ç¨‹æ‰§è¡Œå™¨æ¶æ„](#32431-å¤šçº¿ç¨‹æ‰§è¡Œå™¨æ¶æ„)
    - [3.2.4.3.2 å•çº¿ç¨‹æ‰§è¡Œå™¨ä¼˜åŒ–](#32432-å•çº¿ç¨‹æ‰§è¡Œå™¨ä¼˜åŒ–)
  - [3.2.4.4 I/Oäº‹ä»¶å¤„ç†è¯­ä¹‰](#3244-ioäº‹ä»¶å¤„ç†è¯­ä¹‰)
    - [3.2.4.4.1 äº‹ä»¶å¾ªç¯ç†è®ºæ¨¡å‹](#32441-äº‹ä»¶å¾ªç¯ç†è®ºæ¨¡å‹)
    - [3.2.4.4.2 å®šæ—¶å™¨ç³»ç»Ÿè¯­ä¹‰](#32442-å®šæ—¶å™¨ç³»ç»Ÿè¯­ä¹‰)
  - [3.2.4.5 å†…å­˜ç®¡ç†è¯­ä¹‰](#3245-å†…å­˜ç®¡ç†è¯­ä¹‰)
    - [3.2.4.5.1 å¼‚æ­¥ä»»åŠ¡å†…å­˜æ¨¡å‹](#32451-å¼‚æ­¥ä»»åŠ¡å†…å­˜æ¨¡å‹)
    - [3.2.4.5.2 åƒåœ¾å›æ”¶ä¸æ¸…ç†](#32452-åƒåœ¾å›æ”¶ä¸æ¸…ç†)
  - [3.2.4.6 æ€§èƒ½ä¼˜åŒ–è¯­ä¹‰](#3246-æ€§èƒ½ä¼˜åŒ–è¯­ä¹‰)
    - [3.2.4.6.1 è¿è¡Œæ—¶æ€§èƒ½è°ƒä¼˜](#32461-è¿è¡Œæ—¶æ€§èƒ½è°ƒä¼˜)
    - [3.2.4.6.2 ç¼“å­˜ä¼˜åŒ–ç­–ç•¥](#32462-ç¼“å­˜ä¼˜åŒ–ç­–ç•¥)
  - [3.2.4.7 è·¨å¼•ç”¨ç½‘ç»œ](#3247-è·¨å¼•ç”¨ç½‘ç»œ)
    - [3.2.4.7.1 å†…éƒ¨å¼•ç”¨](#32471-å†…éƒ¨å¼•ç”¨)
    - [3.2.4.7.2 å¤–éƒ¨å¼•ç”¨](#32472-å¤–éƒ¨å¼•ç”¨)
  - [3.2.4.8 æ‰¹åˆ¤æ€§åˆ†æ](#3248-æ‰¹åˆ¤æ€§åˆ†æ)
    - [3.2.4.8.1 è¿è¡Œæ—¶ç³»ç»Ÿä¼˜åŠ¿ä¸å±€é™](#32481-è¿è¡Œæ—¶ç³»ç»Ÿä¼˜åŠ¿ä¸å±€é™)
    - [3.2.4.8.2 ç†è®ºåˆ›æ–°ç‚¹](#32482-ç†è®ºåˆ›æ–°ç‚¹)
  - [3.2.4.9 è§„èŒƒåŒ–è¿›åº¦ä¸åç»­å»ºè®®](#3249-è§„èŒƒåŒ–è¿›åº¦ä¸åç»­å»ºè®®)
    - [3.2.4.9.1 å½“å‰å®Œæˆåº¦](#32491-å½“å‰å®Œæˆåº¦)
    - [3.2.4.9.2 åç»­æ‰©å±•å»ºè®®](#32492-åç»­æ‰©å±•å»ºè®®)

## 3. 2.4.1 å¼‚æ­¥è¿è¡Œæ—¶ç†è®ºåŸºç¡€

### 3.2.4.1.1 è¿è¡Œæ—¶ç³»ç»Ÿè¯­ä¹‰æ¨¡å‹

**å®šä¹‰ 3.2.4.1** (å¼‚æ­¥è¿è¡Œæ—¶ç³»ç»Ÿ)
å¼‚æ­¥è¿è¡Œæ—¶æ˜¯ä¸€ä¸ªå…­å…ƒç»„ $ARS = (E, S, Q, W, T, R)$ï¼Œå…¶ä¸­ï¼š

- $E$ æ˜¯æ‰§è¡Œå™¨é›†åˆ (Executors)
- $S$ æ˜¯è°ƒåº¦å™¨é›†åˆ (Schedulers)  
- $Q$ æ˜¯ä»»åŠ¡é˜Ÿåˆ—é›†åˆ (Task Queues)
- $W$ æ˜¯å·¥ä½œçº¿ç¨‹é›†åˆ (Worker Threads)
- $T$ æ˜¯å®šæ—¶å™¨ç³»ç»Ÿ (Timer System)
- $R: E Ã— S Ã— Q Ã— W Ã— T â†’ Execution$ æ˜¯è¿è¡Œæ—¶å‡½æ•°

**è¿è¡Œæ—¶çŠ¶æ€è½¬æ¢å›¾**ï¼š

```mermaid
graph TB
    subgraph "è¿è¡Œæ—¶æ¶æ„"
        A[ä»»åŠ¡æäº¤] --> B[è°ƒåº¦å™¨]
        B --> C{è´Ÿè½½å‡è¡¡}
        C --> D[æœ¬åœ°é˜Ÿåˆ—]
        C --> E[å…¨å±€é˜Ÿåˆ—]
        D --> F[å·¥ä½œçº¿ç¨‹1]
        E --> G[å·¥ä½œçº¿ç¨‹2]
        F --> H[æ‰§è¡ŒFuture]
        G --> H
        H --> I{Pollç»“æœ}
        I -->|Ready| J[ä»»åŠ¡å®Œæˆ]
        I -->|Pending| K[æ³¨å†ŒWaker]
        K --> L[æŒ‚èµ·ä»»åŠ¡]
        L --> M[äº‹ä»¶è§¦å‘]
        M --> N[å”¤é†’ä»»åŠ¡]
        N --> B
    end
```

**å®šç† 3.2.4.1** (è¿è¡Œæ—¶æ­£ç¡®æ€§ä¿è¯)
å¼‚æ­¥è¿è¡Œæ—¶ç³»ç»Ÿæ»¡è¶³ä»¥ä¸‹æ€§è´¨ï¼š

1. **è¿›åº¦ä¿è¯** (Progress): $\forall f \in Ready(F), \exists t \in \mathbb{N}, \text{executed}(f, t)$
2. **å…¬å¹³æ€§** (Fairness): $\forall f_1, f_2 \in Ready(F), \text{priority}(f_1) = \text{priority}(f_2) \Rightarrow \text{fair\_schedule}(f_1, f_2)$
3. **èµ„æºç•Œé™** (Resource Bounds): $\text{memory\_usage}(ARS) \leq \text{bound}(\text{active\_tasks})$

### 3.2.4.1.2 è¿è¡Œæ—¶ç”Ÿå‘½å‘¨æœŸç®¡ç†

```rust
// è¿è¡Œæ—¶ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æœº
#[derive(Debug, Clone, PartialEq)]
enum RuntimeState {
    Uninitialized,
    Initializing,
    Running,
    Shutting Down,
    Terminated,
}

struct RuntimeLifecycle {
    state: RuntimeState,
    start_time: Instant,
    active_tasks: AtomicUsize,
    shutdown_signal: Option<oneshot::Receiver<()>>,
}

impl RuntimeLifecycle {
    fn transition(&mut self, new_state: RuntimeState) -> Result<(), RuntimeError> {
        use RuntimeState::*;
        
        let valid_transition = match (&self.state, &new_state) {
            (Uninitialized, Initializing) => true,
            (Initializing, Running) => true,
            (Running, Shutting Down) => true,
            (Shutting Down, Terminated) => true,
            _ => false,
        };
        
        if valid_transition {
            self.state = new_state;
            Ok(())
        } else {
            Err(RuntimeError::InvalidStateTransition)
        }
    }
}
```

---

## 3. 2.4.2 è°ƒåº¦å™¨è¯­ä¹‰åˆ†æ

### 3.2.4.2.1 å·¥ä½œçªƒå–è°ƒåº¦å™¨ç†è®º

**å®šä¹‰ 3.2.4.2** (å·¥ä½œçªƒå–è°ƒåº¦ç®—æ³•)
å·¥ä½œçªƒå–è°ƒåº¦å™¨æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ $WSS = (LQ, GQ, ST)$ï¼Œå…¶ä¸­ï¼š

- $LQ$ æ˜¯æœ¬åœ°ä»»åŠ¡é˜Ÿåˆ—é›†åˆï¼Œæ¯ä¸ªå·¥ä½œçº¿ç¨‹ä¸€ä¸ª
- $GQ$ æ˜¯å…¨å±€ä»»åŠ¡é˜Ÿåˆ—
- $ST: Worker \times Queue \rightarrow Task$ æ˜¯çªƒå–ç­–ç•¥å‡½æ•°

**å·¥ä½œçªƒå–ç®—æ³•æµç¨‹**ï¼š

```mermaid
graph LR
    subgraph "ä»»åŠ¡è·å–ç­–ç•¥"
        A[å·¥ä½œçº¿ç¨‹] --> B{æœ¬åœ°é˜Ÿåˆ—ç©º?}
        B -->|å¦| C[ä»æœ¬åœ°é˜Ÿåˆ—å–ä»»åŠ¡]
        B -->|æ˜¯| D{å…¨å±€é˜Ÿåˆ—ç©º?}
        D -->|å¦| E[ä»å…¨å±€é˜Ÿåˆ—å–ä»»åŠ¡]
        D -->|æ˜¯| F[éšæœºé€‰æ‹©å…¶ä»–çº¿ç¨‹]
        F --> G[å°è¯•çªƒå–ä»»åŠ¡]
        G --> H{çªƒå–æˆåŠŸ?}
        H -->|æ˜¯| I[æ‰§è¡Œçªƒå–çš„ä»»åŠ¡]
        H -->|å¦| J[ç­‰å¾…æˆ–è‡ªæ—‹]
        C --> K[æ‰§è¡Œä»»åŠ¡]
        E --> K
        I --> K
        J --> B
        K --> L[ä»»åŠ¡å®Œæˆ]
        L --> B
    end
```

**é«˜çº§å·¥ä½œçªƒå–å®ç°**ï¼š

```rust
use crossbeam::deque::{Injector, Stealer, Worker};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::thread;
use std::time::{Duration, Instant};

struct AdvancedWorkStealingScheduler {
    // å…¨å±€ä»»åŠ¡æ³¨å…¥å™¨
    global_queue: Arc<Injector<Task>>,
    
    // æ¯ä¸ªå·¥ä½œçº¿ç¨‹çš„æœ¬åœ°é˜Ÿåˆ—
    workers: Vec<Worker<Task>>,
    
    // ç”¨äºçªƒå–çš„å¥æŸ„
    stealers: Vec<Stealer<Task>>,
    
    // æ€§èƒ½ç»Ÿè®¡
    steal_attempts: AtomicUsize,
    successful_steals: AtomicUsize,
    local_executions: AtomicUsize,
    
    // è‡ªé€‚åº”å‚æ•°
    steal_backoff: Duration,
    max_steal_attempts: usize,
}

impl AdvancedWorkStealingScheduler {
    fn new(num_workers: usize) -> Self {
        let mut workers = Vec::with_capacity(num_workers);
        let mut stealers = Vec::with_capacity(num_workers);
        
        for _ in 0..num_workers {
            let (worker, stealer) = crossbeam::deque::deque();
            workers.push(worker);
            stealers.push(stealer);
        }
        
        Self {
            global_queue: Arc::new(Injector::new()),
            workers,
            stealers,
            steal_attempts: AtomicUsize::new(0),
            successful_steals: AtomicUsize::new(0),
            local_executions: AtomicUsize::new(0),
            steal_backoff: Duration::from_millis(1),
            max_steal_attempts: 3,
        }
    }
    
    fn find_task(&self, worker_id: usize) -> Option<Task> {
        // 1. ä¼˜å…ˆä»æœ¬åœ°é˜Ÿåˆ—è·å–ä»»åŠ¡
        if let Some(task) = self.workers[worker_id].pop() {
            self.local_executions.fetch_add(1, Ordering::Relaxed);
            return Some(task);
        }
        
        // 2. ä»å…¨å±€é˜Ÿåˆ—è·å–ä»»åŠ¡
        if let crossbeam::deque::Steal::Success(task) = self.global_queue.steal() {
            return Some(task);
        }
        
        // 3. å°è¯•ä»å…¶ä»–å·¥ä½œçº¿ç¨‹çªƒå–ä»»åŠ¡
        self.steal_from_others(worker_id)
    }
    
    fn steal_from_others(&self, worker_id: usize) -> Option<Task> {
        let mut attempts = 0;
        
        // éšæœºåŒ–çªƒå–é¡ºåºä»¥é¿å…çƒ­ç‚¹
        let mut steal_order: Vec<usize> = (0..self.stealers.len())
            .filter(|&i| i != worker_id)
            .collect();
        
        use rand::seq::SliceRandom;
        steal_order.shuffle(&mut rand::thread_rng());
        
        while attempts < self.max_steal_attempts {
            for &target_worker in &steal_order {
                self.steal_attempts.fetch_add(1, Ordering::Relaxed);
                
                match self.stealers[target_worker].steal() {
                    crossbeam::deque::Steal::Success(task) => {
                        self.successful_steals.fetch_add(1, Ordering::Relaxed);
                        return Some(task);
                    }
                    crossbeam::deque::Steal::Empty => continue,
                    crossbeam::deque::Steal::Retry => {
                        // çŸ­æš‚é€€é¿åé‡è¯•
                        thread::sleep(self.steal_backoff);
                        continue;
                    }
                }
            }
            
            attempts += 1;
            
            // æŒ‡æ•°é€€é¿
            thread::sleep(self.steal_backoff * (1 << attempts));
        }
        
        None
    }
}
```

**å®šç† 3.2.4.2** (å·¥ä½œçªƒå–ç®—æ³•å¤æ‚åº¦)
å·¥ä½œçªƒå–è°ƒåº¦å™¨çš„æ€§èƒ½ç‰¹å¾ï¼š

1. **æ—¶é—´å¤æ‚åº¦**: æœ¬åœ°æ“ä½œ $O(1)$ï¼Œçªƒå–æ“ä½œ $O(n)$ å…¶ä¸­ $n$ æ˜¯å·¥ä½œçº¿ç¨‹æ•°
2. **ç©ºé—´å¤æ‚åº¦**: $O(n \cdot k)$ å…¶ä¸­ $k$ æ˜¯å¹³å‡é˜Ÿåˆ—é•¿åº¦
3. **è´Ÿè½½å‡è¡¡**: æœŸæœ›è´Ÿè½½åå·® $\leq \frac{1}{\sqrt{n}}$

### 3.2.4.2.2 ä¼˜å…ˆçº§è°ƒåº¦è¯­ä¹‰

```rust
use std::cmp::Ordering;
use std::collections::BinaryHeap;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum TaskPriority {
    Critical = 0,
    High = 1,
    Normal = 2,
    Low = 3,
    Background = 4,
}

struct PriorityTask {
    task: Task,
    priority: TaskPriority,
    creation_time: Instant,
    deadline: Option<Instant>,
}

impl PartialOrd for PriorityTask {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for PriorityTask {
    fn cmp(&self, other: &Self) -> Ordering {
        // é¦–å…ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        match self.priority.cmp(&other.priority) {
            Ordering::Equal => {
                // ä¼˜å…ˆçº§ç›¸åŒæ—¶ï¼ŒæŒ‰æˆªæ­¢æ—¶é—´æ’åº
                match (self.deadline, other.deadline) {
                    (Some(d1), Some(d2)) => d1.cmp(&d2),
                    (Some(_), None) => Ordering::Less, // æœ‰æˆªæ­¢æ—¶é—´çš„ä¼˜å…ˆ
                    (None, Some(_)) => Ordering::Greater,
                    (None, None) => {
                        // éƒ½æ²¡æœ‰æˆªæ­¢æ—¶é—´ï¼ŒæŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆFIFOï¼‰
                        self.creation_time.cmp(&other.creation_time)
                    }
                }
            }
            other => other.reverse(), // åè½¬æ’åºï¼Œå› ä¸ºBinaryHeapæ˜¯æœ€å¤§å †
        }
    }
}

struct PriorityScheduler {
    task_queue: BinaryHeap<PriorityTask>,
    starvation_threshold: Duration,
}

impl PriorityScheduler {
    fn prevent_starvation(&mut self) {
        let now = Instant::now();
        let mut tasks_to_boost = Vec::new();
        
        // ä¸´æ—¶å–å‡ºæ‰€æœ‰ä»»åŠ¡æ£€æŸ¥é¥¥é¥¿æƒ…å†µ
        let mut temp_tasks = Vec::new();
        while let Some(task) = self.task_queue.pop() {
            if now.duration_since(task.creation_time) > self.starvation_threshold {
                // æå‡ä¼˜å…ˆçº§
                let boosted_priority = match task.priority {
                    TaskPriority::Background => TaskPriority::Low,
                    TaskPriority::Low => TaskPriority::Normal,
                    TaskPriority::Normal => TaskPriority::High,
                    TaskPriority::High => TaskPriority::Critical,
                    TaskPriority::Critical => TaskPriority::Critical,
                };
                
                tasks_to_boost.push(PriorityTask {
                    priority: boosted_priority,
                    ..task
                });
            } else {
                temp_tasks.push(task);
            }
        }
        
        // é‡æ–°æ’å…¥æ‰€æœ‰ä»»åŠ¡
        for task in temp_tasks.into_iter().chain(tasks_to_boost.into_iter()) {
            self.task_queue.push(task);
        }
    }
}
```

---

## 3. 2.4.3 æ‰§è¡Œå™¨è¯­ä¹‰åˆ†æ

### 3.2.4.3.1 å¤šçº¿ç¨‹æ‰§è¡Œå™¨æ¶æ„

**å®šä¹‰ 3.2.4.3** (å¤šçº¿ç¨‹æ‰§è¡Œå™¨)
å¤šçº¿ç¨‹æ‰§è¡Œå™¨æ˜¯ä¸€ä¸ªäº”å…ƒç»„ $MTE = (W, Q, S, M, C)$ï¼Œå…¶ä¸­ï¼š

- $W$ æ˜¯å·¥ä½œçº¿ç¨‹æ± 
- $Q$ æ˜¯ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ
- $S$ æ˜¯è°ƒåº¦ç­–ç•¥
- $M$ æ˜¯å†…å­˜ç®¡ç†å™¨
- $C$ æ˜¯é€šä¿¡æœºåˆ¶

```rust
use std::sync::{Arc, Mutex};
use std::thread::{self, JoinHandle};
use crossbeam::channel::{unbounded, Receiver, Sender};
use futures::task::{Context, Poll, Waker};
use std::collections::HashMap;
use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};

struct MultiThreadedExecutor {
    // æ ¸å¿ƒç»„ä»¶
    worker_threads: Vec<JoinHandle<()>>,
    task_sender: Sender<ExecutorTask>,
    shutdown_signal: Arc<AtomicBool>,
    
    // æ€§èƒ½ç›‘æ§
    active_tasks: Arc<AtomicUsize>,
    completed_tasks: Arc<AtomicUsize>,
    thread_utilization: Arc<Mutex<HashMap<usize, f64>>>,
    
    // é…ç½®å‚æ•°
    config: ExecutorConfig,
}

#[derive(Debug, Clone)]
struct ExecutorConfig {
    num_threads: usize,
    max_queue_size: Option<usize>,
    thread_stack_size: Option<usize>,
    thread_name_prefix: String,
    enable_work_stealing: bool,
    enable_priority_scheduling: bool,
}

struct ExecutorTask {
    future: Pin<Box<dyn Future<Output = ()> + Send>>,
    priority: TaskPriority,
    created_at: Instant,
    task_id: u64,
    waker: Option<Waker>,
}

impl MultiThreadedExecutor {
    fn worker_loop(
        thread_id: usize,
        receiver: Receiver<ExecutorTask>,
        shutdown: Arc<AtomicBool>,
        active_tasks: Arc<AtomicUsize>,
        completed_tasks: Arc<AtomicUsize>,
        utilization: Arc<Mutex<HashMap<usize, f64>>>,
    ) {
        let mut local_completed = 0u64;
        let mut idle_time = Duration::new(0, 0);
        let mut work_time = Duration::new(0, 0);
        
        while !shutdown.load(Ordering::Relaxed) {
            match receiver.try_recv() {
                Ok(mut task) => {
                    let work_start = Instant::now();
                    
                    // åˆ›å»ºWaker
                    let waker = Self::create_task_waker(task.task_id);
                    let mut context = Context::from_waker(&waker);
                    
                    // æ‰§è¡ŒFuture
                    match task.future.as_mut().poll(&mut context) {
                        Poll::Ready(()) => {
                            // ä»»åŠ¡å®Œæˆ
                            active_tasks.fetch_sub(1, Ordering::Relaxed);
                            completed_tasks.fetch_add(1, Ordering::Relaxed);
                            local_completed += 1;
                        }
                        Poll::Pending => {
                            // ä»»åŠ¡æœªå®Œæˆï¼Œéœ€è¦é‡æ–°è°ƒåº¦
                            task.waker = Some(waker);
                            // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šå°†ä»»åŠ¡æ”¾å›è°ƒåº¦é˜Ÿåˆ—
                        }
                    }
                    
                    work_time += work_start.elapsed();
                }
                Err(_) => {
                    // é˜Ÿåˆ—ä¸ºç©ºï¼ŒçŸ­æš‚ä¼‘çœ 
                    thread::sleep(Duration::from_micros(10));
                    idle_time += Duration::from_micros(10);
                }
            }
        }
    }
    
    fn create_task_waker(task_id: u64) -> Waker {
        // åˆ›å»ºè‡ªå®šä¹‰Wakerå®ç°
        use std::task::{RawWaker, RawWakerVTable};
        
        unsafe fn clone_waker(data: *const ()) -> RawWaker {
            RawWaker::new(data, &WAKER_VTABLE)
        }
        
        unsafe fn wake_waker(data: *const ()) {
            let task_id = data as u64;
            // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šé‡æ–°è°ƒåº¦å¯¹åº”çš„ä»»åŠ¡
            println!("Waking task {}", task_id);
        }
        
        unsafe fn wake_by_ref_waker(data: *const ()) {
            wake_waker(data);
        }
        
        unsafe fn drop_waker(_data: *const ()) {
            // æ¸…ç†èµ„æº
        }
        
        static WAKER_VTABLE: RawWakerVTable = RawWakerVTable::new(
            clone_waker,
            wake_waker,
            wake_by_ref_waker,
            drop_waker,
        );
        
        let raw_waker = RawWaker::new(task_id as *const (), &WAKER_VTABLE);
        unsafe { Waker::from_raw(raw_waker) }
    }
}
```

### 3.2.4.3.2 å•çº¿ç¨‹æ‰§è¡Œå™¨ä¼˜åŒ–

```rust
struct SingleThreadedExecutor {
    task_queue: VecDeque<ExecutorTask>,
    waker_registry: HashMap<u64, Waker>,
    is_running: bool,
    current_task: Option<u64>,
}

impl SingleThreadedExecutor {
    fn block_on<F>(&mut self, future: F) -> F::Output
    where
        F: Future,
    {
        let mut future = Box::pin(future);
        let waker = self.create_main_waker();
        let mut context = Context::from_waker(&waker);
        
        loop {
            match future.as_mut().poll(&mut context) {
                Poll::Ready(output) => return output,
                Poll::Pending => {
                    // æ‰§è¡Œå…¶ä»–å°±ç»ªçš„ä»»åŠ¡
                    self.run_until_stalled();
                }
            }
        }
    }
    
    fn run_until_stalled(&mut self) {
        self.is_running = true;
        
        while let Some(mut task) = self.task_queue.pop_front() {
            self.current_task = Some(task.task_id);
            
            let waker = self.waker_registry
                .get(&task.task_id)
                .cloned()
                .unwrap_or_else(|| self.create_task_waker(task.task_id));
            
            let mut context = Context::from_waker(&waker);
            
            match task.future.as_mut().poll(&mut context) {
                Poll::Ready(()) => {
                    // ä»»åŠ¡å®Œæˆï¼Œæ¸…ç†
                    self.waker_registry.remove(&task.task_id);
                }
                Poll::Pending => {
                    // ä»»åŠ¡æœªå®Œæˆï¼Œä¿å­˜Waker
                    self.waker_registry.insert(task.task_id, waker);
                    // æ³¨æ„ï¼šåœ¨PendingçŠ¶æ€ä¸‹ä¸é‡æ–°å…¥é˜Ÿï¼Œç­‰å¾…è¢«å”¤é†’
                }
            }
        }
        
        self.current_task = None;
        self.is_running = false;
    }
}
```

---

## 3. 2.4.4 I/Oäº‹ä»¶å¤„ç†è¯­ä¹‰

### 3.2.4.4.1 äº‹ä»¶å¾ªç¯ç†è®ºæ¨¡å‹

**å®šä¹‰ 3.2.4.4** (äº‹ä»¶å¾ªç¯ç³»ç»Ÿ)
äº‹ä»¶å¾ªç¯æ˜¯ä¸€ä¸ªå››å…ƒç»„ $EL = (E, H, Q, P)$ï¼Œå…¶ä¸­ï¼š

- $E$ æ˜¯äº‹ä»¶é›†åˆ
- $H$ æ˜¯äº‹ä»¶å¤„ç†å™¨æ˜ å°„ $H: E \rightarrow Handler$
- $Q$ æ˜¯äº‹ä»¶é˜Ÿåˆ—
- $P$ æ˜¯è½®è¯¢æœºåˆ¶

```mermaid
graph TB
    subgraph "I/Oäº‹ä»¶å¤„ç†æ¶æ„"
        A[ç³»ç»ŸI/Oäº‹ä»¶] --> B[äº‹ä»¶å¤šè·¯å¤ç”¨å™¨]
        B --> C{äº‹ä»¶ç±»å‹}
        C -->|è¯»å°±ç»ª| D[è¯»äº‹ä»¶å¤„ç†]
        C -->|å†™å°±ç»ª| E[å†™äº‹ä»¶å¤„ç†]
        C -->|é”™è¯¯| F[é”™è¯¯å¤„ç†]
        C -->|å®šæ—¶å™¨| G[å®šæ—¶å™¨å¤„ç†]
        D --> H[å”¤é†’ç­‰å¾…çš„Future]
        E --> H
        F --> H
        G --> H
        H --> I[ä»»åŠ¡è°ƒåº¦é˜Ÿåˆ—]
        I --> J[æ‰§è¡Œå™¨å¤„ç†]
    end
```

### 3.2.4.4.2 å®šæ—¶å™¨ç³»ç»Ÿè¯­ä¹‰

```rust
use std::collections::BinaryHeap;
use std::cmp::Reverse;

struct TimerEntry {
    deadline: Instant,
    token: Token,
    interval: Option<Duration>, // ç”¨äºå‘¨æœŸæ€§å®šæ—¶å™¨
}

impl PartialEq for TimerEntry {
    fn eq(&self, other: &Self) -> bool {
        self.deadline == other.deadline
    }
}

impl Eq for TimerEntry {}

impl PartialOrd for TimerEntry {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for TimerEntry {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        // ä½¿ç”¨Reverseä½¿æœ€æ—©çš„æˆªæ­¢æ—¶é—´æ’åœ¨å‰é¢
        Reverse(self.deadline).cmp(&Reverse(other.deadline))
    }
}

struct TimerWheel {
    timers: BinaryHeap<TimerEntry>,
    waker_registry: HashMap<Token, Waker>,
}

impl TimerWheel {
    fn process_timeouts<F>(&mut self, mut callback: F)
    where
        F: FnMut(Token),
    {
        let now = Instant::now();
        
        while let Some(entry) = self.timers.peek() {
            if entry.deadline <= now {
                let entry = self.timers.pop().unwrap();
                
                // å”¤é†’å¯¹åº”çš„Future
                if let Some(waker) = self.waker_registry.remove(&entry.token) {
                    waker.wake();
                }
                
                // è°ƒç”¨å›è°ƒ
                callback(entry.token);
                
                // å¦‚æœæ˜¯å‘¨æœŸæ€§å®šæ—¶å™¨ï¼Œé‡æ–°æ·»åŠ 
                if let Some(interval) = entry.interval {
                    self.timers.push(TimerEntry {
                        deadline: now + interval,
                        token: entry.token,
                        interval: Some(interval),
                    });
                }
            } else {
                break;
            }
        }
    }
}
```

---

## 3. 2.4.5 å†…å­˜ç®¡ç†è¯­ä¹‰

### 3.2.4.5.1 å¼‚æ­¥ä»»åŠ¡å†…å­˜æ¨¡å‹

**å®šä¹‰ 3.2.4.5** (å¼‚æ­¥å†…å­˜æ¨¡å‹)
å¼‚æ­¥ä»»åŠ¡çš„å†…å­˜å¸ƒå±€éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **çŠ¶æ€æœºå†…å­˜**: æ¯ä¸ªasyncå‡½æ•°ç¼–è¯‘ä¸ºçŠ¶æ€æœºï¼Œå ç”¨å›ºå®šå†…å­˜
2. **æ ˆå¸§å¤ç”¨**: å¼‚æ­¥è°ƒç”¨ä¸ä½¿ç”¨ä¼ ç»Ÿæ ˆï¼Œè€Œæ˜¯åœ¨å †ä¸Šåˆ†é…çŠ¶æ€
3. **é›¶æ‹·è´ä¼ è¾“**: æ•°æ®åœ¨å¼‚æ­¥è¾¹ç•Œé—´ä¼ è¾“æ—¶å°½é‡é¿å…æ‹·è´

```rust
use std::alloc::{alloc, dealloc, Layout};
use std::ptr::NonNull;

struct AsyncMemoryPool {
    small_blocks: Vec<NonNull<u8>>,  // å°å¯¹è±¡æ±  (< 1KB)
    medium_blocks: Vec<NonNull<u8>>, // ä¸­ç­‰å¯¹è±¡æ±  (1KB - 64KB)
    large_blocks: Vec<NonNull<u8>>,  // å¤§å¯¹è±¡æ±  (> 64KB)
    
    small_layout: Layout,
    medium_layout: Layout,
    
    allocated_bytes: AtomicUsize,
    peak_usage: AtomicUsize,
}

impl AsyncMemoryPool {
    fn allocate(&mut self, size: usize) -> Option<NonNull<u8>> {
        let ptr = match size {
            0..=1024 => self.allocate_small(),
            1025..=65536 => self.allocate_medium(),
            _ => self.allocate_large(size),
        }?;
        
        let current = self.allocated_bytes.fetch_add(size, Ordering::Relaxed) + size;
        let peak = self.peak_usage.load(Ordering::Relaxed);
        if current > peak {
            self.peak_usage.store(current, Ordering::Relaxed);
        }
        
        Some(ptr)
    }
    
    fn batch_allocate_small(&mut self) {
        const BATCH_SIZE: usize = 64;
        let layout = Layout::array::<u8>(self.small_layout.size() * BATCH_SIZE).unwrap();
        
        unsafe {
            if let Ok(ptr) = std::alloc::alloc(layout).try_into() {
                let base_ptr: NonNull<u8> = ptr;
                
                for i in 0..BATCH_SIZE {
                    let offset = i * self.small_layout.size();
                    let block_ptr = NonNull::new_unchecked(base_ptr.as_ptr().add(offset));
                    self.small_blocks.push(block_ptr);
                }
            }
        }
    }
}
```

### 3.2.4.5.2 åƒåœ¾å›æ”¶ä¸æ¸…ç†

```rust
struct AsyncGarbageCollector {
    cleanup_tasks: VecDeque<CleanupTask>,
    collection_threshold: usize,
    collection_interval: Duration,
    last_collection: Instant,
}

enum CleanupTask {
    DropFuture(Box<dyn Future<Output = ()> + Send>),
    DeallocateMemory { ptr: NonNull<u8>, size: usize },
    CloseResource(Box<dyn AsyncResource>),
}

trait AsyncResource: Send {
    fn cleanup(&mut self) -> Pin<Box<dyn Future<Output = ()> + Send>>;
}

impl AsyncGarbageCollector {
    fn collect(&mut self) {
        let batch_size = std::cmp::min(100, self.cleanup_tasks.len());
        
        for _ in 0..batch_size {
            if let Some(task) = self.cleanup_tasks.pop_front() {
                match task {
                    CleanupTask::DropFuture(future) => {
                        // åœ¨åå°çº¿ç¨‹ä¸­drop Future
                        std::thread::spawn(move || {
                            drop(future);
                        });
                    }
                    CleanupTask::DeallocateMemory { ptr, size } => {
                        unsafe {
                            let layout = Layout::from_size_align_unchecked(size, 8);
                            dealloc(ptr.as_ptr(), layout);
                        }
                    }
                    CleanupTask::CloseResource(mut resource) => {
                        // å¼‚æ­¥æ¸…ç†èµ„æº
                        tokio::spawn(async move {
                            resource.cleanup().await;
                        });
                    }
                }
            }
        }
        
        self.last_collection = Instant::now();
    }
}
```

---

## 3. 2.4.6 æ€§èƒ½ä¼˜åŒ–è¯­ä¹‰

### 3.2.4.6.1 è¿è¡Œæ—¶æ€§èƒ½è°ƒä¼˜

```rust
struct RuntimePerformanceTuner {
    metrics_collector: MetricsCollector,
    optimization_strategies: Vec<Box<dyn OptimizationStrategy>>,
    tuning_interval: Duration,
    last_tuning: Instant,
}

trait OptimizationStrategy: Send + Sync {
    fn analyze(&self, metrics: &RuntimeMetrics) -> OptimizationRecommendation;
    fn apply(&self, runtime: &mut dyn RuntimeTunable) -> Result<(), OptimizationError>;
}

#[derive(Debug, Clone)]
struct RuntimeMetrics {
    task_throughput: f64,
    average_latency: Duration,
    cpu_utilization: f64,
    memory_usage: usize,
    queue_depths: HashMap<String, usize>,
    thread_utilization: Vec<f64>,
    gc_pressure: f64,
}

#[derive(Debug)]
enum OptimizationRecommendation {
    IncreaseThreads(usize),
    DecreaseThreads(usize),
    AdjustQueueSize(usize),
    EnableWorkStealing,
    DisableWorkStealing,
    TuneGcThreshold(usize),
    NoAction,
}

struct ThreadCountOptimizer;

impl OptimizationStrategy for ThreadCountOptimizer {
    fn analyze(&self, metrics: &RuntimeMetrics) -> OptimizationRecommendation {
        let avg_utilization = metrics.thread_utilization.iter().sum::<f64>() 
            / metrics.thread_utilization.len() as f64;
        
        if avg_utilization > 0.9 && metrics.average_latency > Duration::from_millis(100) {
            // é«˜åˆ©ç”¨ç‡ä¸”é«˜å»¶è¿Ÿï¼Œå¢åŠ çº¿ç¨‹
            let current_threads = metrics.thread_utilization.len();
            let recommended_threads = (current_threads as f64 * 1.5) as usize;
            OptimizationRecommendation::IncreaseThreads(recommended_threads)
        } else if avg_utilization < 0.3 && metrics.thread_utilization.len() > 2 {
            // ä½åˆ©ç”¨ç‡ï¼Œå‡å°‘çº¿ç¨‹
            let current_threads = metrics.thread_utilization.len();
            let recommended_threads = std::cmp::max(2, current_threads / 2);
            OptimizationRecommendation::DecreaseThreads(recommended_threads)
        } else {
            OptimizationRecommendation::NoAction
        }
    }
    
    fn apply(&self, runtime: &mut dyn RuntimeTunable) -> Result<(), OptimizationError> {
        // åº”ç”¨çº¿ç¨‹æ•°è°ƒæ•´
        Ok(())
    }
}

trait RuntimeTunable {
    fn set_thread_count(&mut self, count: usize) -> Result<(), RuntimeError>;
    fn set_queue_size(&mut self, size: usize) -> Result<(), RuntimeError>;
    fn enable_work_stealing(&mut self, enabled: bool) -> Result<(), RuntimeError>;
    fn set_gc_threshold(&mut self, threshold: usize) -> Result<(), RuntimeError>;
}
```

### 3.2.4.6.2 ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

```rust
struct CacheOptimizedScheduler {
    cpu_topology: CpuTopology,
    thread_affinity: HashMap<usize, CpuSet>,
    numa_aware_allocation: bool,
    cache_line_size: usize,
}

#[derive(Debug, Clone)]
struct CpuTopology {
    numa_nodes: Vec<NumaNode>,
    cpu_cores: Vec<CpuCore>,
    cache_hierarchy: CacheHierarchy,
}

impl CacheOptimizedScheduler {
    fn schedule_task_with_affinity(&mut self, task: Task, preferred_numa_node: Option<usize>) -> Result<(), SchedulingError> {
        let target_node = preferred_numa_node
            .or_else(|| self.find_optimal_numa_node(&task))
            .unwrap_or(0);
        
        let target_core = self.find_optimal_core_in_node(target_node)?;
        
        // è®¾ç½®çº¿ç¨‹äº²å’Œæ€§
        self.set_thread_affinity(task.thread_id, target_core)?;
        
        // åœ¨å¯¹åº”NUMAèŠ‚ç‚¹ä¸Šåˆ†é…å†…å­˜
        if self.numa_aware_allocation {
            self.allocate_on_numa_node(task.memory_requirements, target_node)?;
        }
        
        Ok(())
    }
}
```

---

## 3. 2.4.7 è·¨å¼•ç”¨ç½‘ç»œ

### 3.2.4.7.1 å†…éƒ¨å¼•ç”¨

- [Futureè¯­ä¹‰](01_future_semantics.md) - Futureçš„åŸºç¡€ç†è®º
- [async/awaitè¯­ä¹‰](02_async_await_semantics.md) - è¯­æ³•ç³–å®ç°
- [æ‰§è¡Œå™¨è¯­ä¹‰](03_executor_semantics.md) - æ‰§è¡Œå™¨è¯¦ç»†å®ç°

### 3.2.4.7.2 å¤–éƒ¨å¼•ç”¨

- [å†…å­˜æ¨¡å‹è¯­ä¹‰](../../01_foundation_semantics/03_memory_model_semantics/) - å†…å­˜å®‰å…¨ä¿è¯
- [çº¿ç¨‹æ¨¡å‹è¯­ä¹‰](../01_concurrency_model_semantics/) - ä¸çº¿ç¨‹ç³»ç»Ÿé›†æˆ
- [é”™è¯¯å¤„ç†è¯­ä¹‰](../../02_control_semantics/04_error_handling_semantics/) - å¼‚æ­¥é”™è¯¯å¤„ç†

---

## 3. 2.4.8 æ‰¹åˆ¤æ€§åˆ†æ

### 3.2.4.8.1 è¿è¡Œæ—¶ç³»ç»Ÿä¼˜åŠ¿ä¸å±€é™

| æ–¹é¢ | ä¼˜åŠ¿ | å±€é™æ€§ | æ”¹è¿›æ–¹å‘ |
|------|------|--------|----------|
| **æ€§èƒ½** | é›¶æˆæœ¬æŠ½è±¡ã€é«˜å¹¶å‘ | çŠ¶æ€æœºå¼€é”€ã€å†…å­˜ç¢ç‰‡ | ç¼–è¯‘æ—¶ä¼˜åŒ–ã€å†…å­˜æ±  |
| **å¯æ‰©å±•æ€§** |:---:|:---:|:---:| å·¥ä½œçªƒå–ã€NUMAæ„ŸçŸ¥ |:---:|:---:|:---:| è°ƒåº¦å¼€é”€ã€ç¼“å­˜å¤±æ•ˆ |:---:|:---:|:---:| è‡ªé€‚åº”è°ƒåº¦ã€å±€éƒ¨æ€§ä¼˜åŒ– |:---:|:---:|:---:|


| **èµ„æºç®¡ç†** | è‡ªåŠ¨æ¸…ç†ã€å¼•ç”¨è®¡æ•° | GCå‹åŠ›ã€å†…å­˜æ³„æ¼é£é™© | å¢é‡GCã€å¼±å¼•ç”¨ |
| **è°ƒè¯•æ€§** |:---:|:---:|:---:| ç»“æ„åŒ–å¹¶å‘ |:---:|:---:|:---:| å¤æ‚çš„è°ƒç”¨æ ˆã€éš¾ä»¥è°ƒè¯• |:---:|:---:|:---:| å¼‚æ­¥è°ƒè¯•å·¥å…·ã€è¿½è¸ª |:---:|:---:|:---:|



### 3.2.4.8.2 ç†è®ºåˆ›æ–°ç‚¹

1. **è‡ªé€‚åº”è°ƒåº¦ç®—æ³•**: æ ¹æ®è¿è¡Œæ—¶æŒ‡æ ‡åŠ¨æ€è°ƒæ•´è°ƒåº¦ç­–ç•¥
2. **NUMAæ„ŸçŸ¥å†…å­˜ç®¡ç†**: åŸºäºCPUæ‹“æ‰‘çš„å†…å­˜åˆ†é…ä¼˜åŒ–
3. **åˆ†å±‚äº‹ä»¶å¤„ç†**: å¤šçº§äº‹ä»¶é˜Ÿåˆ—å‡å°‘å»¶è¿Ÿ
4. **å¢é‡åƒåœ¾å›æ”¶**: é™ä½GCå¯¹å®æ—¶æ€§çš„å½±å“

---

## 3. 2.4.9 è§„èŒƒåŒ–è¿›åº¦ä¸åç»­å»ºè®®

### 3.2.4.9.1 å½“å‰å®Œæˆåº¦

- âœ… **ç†è®ºåŸºç¡€**: è¿è¡Œæ—¶ç³»ç»Ÿæ•°å­¦æ¨¡å‹
- âœ… **è°ƒåº¦å™¨è¯­ä¹‰**: å·¥ä½œçªƒå–ã€ä¼˜å…ˆçº§ã€è‡ªé€‚åº”è°ƒåº¦
- âœ… **æ‰§è¡Œå™¨æ¶æ„**: å¤šçº¿ç¨‹ã€å•çº¿ç¨‹æ‰§è¡Œå™¨å®ç°
- âœ… **I/Oäº‹ä»¶å¤„ç†**: äº‹ä»¶å¾ªç¯ã€å®šæ—¶å™¨ç³»ç»Ÿ
- âœ… **å†…å­˜ç®¡ç†**: å†…å­˜æ± ã€åƒåœ¾å›æ”¶
- âœ… **æ€§èƒ½ä¼˜åŒ–**: ç¼“å­˜ä¼˜åŒ–ã€NUMAæ„ŸçŸ¥
- âœ… **æ‰¹åˆ¤æ€§åˆ†æ**: ä¼˜åŠ¿å±€é™åˆ†æ

### 3.2.4.9.2 åç»­æ‰©å±•å»ºè®®

1. **åˆ†å¸ƒå¼è¿è¡Œæ—¶**: è·¨èŠ‚ç‚¹ä»»åŠ¡è°ƒåº¦
2. **å®æ—¶è°ƒåº¦**: ç¡¬å®æ—¶çº¦æŸæ”¯æŒ
3. **èƒ½è€—ä¼˜åŒ–**: åŠŸè€—æ„ŸçŸ¥çš„è°ƒåº¦ç­–ç•¥
4. **å®‰å…¨éš”ç¦»**: ä»»åŠ¡é—´å®‰å…¨è¾¹ç•Œ

---

*æ–‡æ¡£çŠ¶æ€: å·²å®Œæˆè§„èŒƒåŒ–*  
*ç‰ˆæœ¬: 2.0*  
*å­—æ•°: ~15KB*  
*æœ€åæ›´æ–°: 2025-01-27*
