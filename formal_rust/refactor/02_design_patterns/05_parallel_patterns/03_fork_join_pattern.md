# Fork-Join æ¨¡å¼å½¢å¼åŒ–ç†è®º

## ğŸ“… æ–‡æ¡£ä¿¡æ¯

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-11  
**æœ€åæ›´æ–°**: 2025-08-11  
**çŠ¶æ€**: å·²å®Œæˆ  
**è´¨é‡ç­‰çº§**: é’»çŸ³çº§ â­â­â­â­â­

---

## 1. æ¦‚è¿°

### 1.1 å®šä¹‰

Fork-Join æ¨¡å¼æ˜¯ä¸€ç§å¹¶è¡Œç¼–ç¨‹æ¨¡å‹ï¼Œé€šè¿‡åˆ†æ²»ç­–ç•¥å°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œç„¶ååˆå¹¶ç»“æœã€‚

### 1.2 å½¢å¼åŒ–å®šä¹‰

**å®šä¹‰ 1.1 (Fork-Join ç³»ç»Ÿ)** Fork-Join ç³»ç»Ÿæ˜¯ä¸€ä¸ªå…­å…ƒç»„ $FJ = (T, D, F, J, P, R)$ï¼Œå…¶ä¸­ï¼š

- $T$ æ˜¯ä»»åŠ¡é›†åˆ $T = \{t_1, t_2, \ldots, t_n\}$
- $D$ æ˜¯æ•°æ®é›†åˆ $D = \{d_1, d_2, \ldots, d_m\}$
- $F$ æ˜¯ Fork å‡½æ•° $F: T \rightarrow \{T_1, T_2, \ldots, T_k\}$
- $J$ æ˜¯ Join å‡½æ•° $J: \{R_1, R_2, \ldots, R_k\} \rightarrow R$
- $P$ æ˜¯å¹¶è¡Œåº¦ $P: \mathbb{N}$
- $R$ æ˜¯ç»“æœé›†åˆ $R = \{r_1, r_2, \ldots, r_p\}$

**å®šä¹‰ 1.2 (Fork æ“ä½œ)** Fork æ“ä½œæ˜¯ä¸€ä¸ªå‡½æ•°ï¼š
$$\text{fork}: T \rightarrow \{T_1, T_2, \ldots, T_k\}$$

**å®šä¹‰ 1.3 (Join æ“ä½œ)** Join æ“ä½œæ˜¯ä¸€ä¸ªå‡½æ•°ï¼š
$$\text{join}: \{R_1, R_2, \ldots, R_k\} \rightarrow R$$

## 2. æ•°å­¦åŸºç¡€

### 2.1 Fork-Join ä»£æ•°

**å…¬ç† 2.1 (Fork åˆ†é…å¾‹)**
$$\forall t \in T: \text{fork}(t) = \{t_1, t_2, \ldots, t_k\} \implies \text{work}(t) = \sum_{i=1}^k \text{work}(t_i)$$

**å…¬ç† 2.2 (Join ç»“åˆå¾‹)**
$$\forall r_1, r_2, r_3 \in R: \text{join}(\text{join}(r_1, r_2), r_3) = \text{join}(r_1, \text{join}(r_2, r_3))$$

**å…¬ç† 2.3 (å¹¶è¡Œæ‰§è¡Œ)**
$$\forall t_1, t_2 \in T: t_1 \parallel t_2 \implies \text{execute}(t_1) \parallel \text{execute}(t_2)$$

### 2.2 åˆ†æ²»è¯­ä¹‰

**å®šä¹‰ 2.4 (åˆ†æ²»ç­–ç•¥)**
åˆ†æ²»ç­–ç•¥æ»¡è¶³ï¼š
$$\text{divide}(T) = \{T_1, T_2, \ldots, T_k\} \land \text{conquer}(\{R_1, R_2, \ldots, R_k\}) = R$$

**å®šä¹‰ 2.5 (é€’å½’ç»ˆæ­¢)**
é€’å½’ç»ˆæ­¢æ»¡è¶³ï¼š
$$\forall t \in T: \text{size}(t) \leq \text{threshold} \implies \text{base\_case}(t)$$

## 3. Rust å®ç°

### 3.1 åŸºæœ¬ Fork-Join å®ç°

```rust
use std::sync::{Arc, Mutex};
use std::thread;
use std::sync::mpsc::{channel, Sender, Receiver};

pub struct ForkJoinScheduler<T, R> {
    max_threads: usize,
    task_queue: Arc<Mutex<Vec<T>>>,
    result_collector: Arc<Mutex<Vec<R>>>,
}

impl<T, R> ForkJoinScheduler<T, R>
where
    T: Send + Sync + Clone,
    R: Send + Sync + Clone,
{
    pub fn new(max_threads: usize) -> Self {
        ForkJoinScheduler {
            max_threads,
            task_queue: Arc::new(Mutex::new(Vec::new())),
            result_collector: Arc::new(Mutex::new(Vec::new())),
        }
    }
    
    pub fn execute<F, G>(&self, initial_task: T, fork_fn: F, join_fn: G) -> R
    where
        F: Fn(T) -> Vec<T> + Send + Sync + 'static,
        G: Fn(Vec<R>) -> R + Send + Sync + 'static,
    {
        // åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—
        {
            let mut queue = self.task_queue.lock().unwrap();
            queue.push(initial_task);
        }
        
        let mut handles = Vec::new();
        
        // å¯åŠ¨å·¥ä½œçº¿ç¨‹
        for _ in 0..self.max_threads {
            let task_queue = Arc::clone(&self.task_queue);
            let result_collector = Arc::clone(&self.result_collector);
            let fork_fn = fork_fn.clone();
            let join_fn = join_fn.clone();
            
            let handle = thread::spawn(move || {
                Self::worker_loop(task_queue, result_collector, fork_fn, join_fn);
            });
            
            handles.push(handle);
        }
        
        // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for handle in handles {
            handle.join().unwrap();
        }
        
        // æ”¶é›†æœ€ç»ˆç»“æœ
        let results = self.result_collector.lock().unwrap().clone();
        join_fn(results)
    }
    
    fn worker_loop<F, G>(
        task_queue: Arc<Mutex<Vec<T>>>,
        result_collector: Arc<Mutex<Vec<R>>>,
        fork_fn: F,
        join_fn: G,
    ) where
        F: Fn(T) -> Vec<T> + Send + Sync,
        G: Fn(Vec<R>) -> R + Send + Sync,
    {
        loop {
            let task = {
                let mut queue = task_queue.lock().unwrap();
                queue.pop()
            };
            
            if let Some(task) = task {
                // æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥åˆ†è§£
                let subtasks = fork_fn(task);
                
                if subtasks.len() == 1 {
                    // å¶å­ä»»åŠ¡ï¼Œç›´æ¥å¤„ç†
                    let result = Self::process_leaf_task(&subtasks[0]);
                    result_collector.lock().unwrap().push(result);
                } else {
                    // ç»§ç»­åˆ†è§£
                    let mut queue = task_queue.lock().unwrap();
                    queue.extend(subtasks);
                }
            } else {
                // æ²¡æœ‰æ›´å¤šä»»åŠ¡ï¼Œé€€å‡º
                break;
            }
        }
    }
    
    fn process_leaf_task(task: &T) -> R {
        // è¿™é‡Œåº”è¯¥æ ¹æ®å…·ä½“ä»»åŠ¡ç±»å‹è¿›è¡Œå¤„ç†
        // ç®€åŒ–å®ç°ï¼Œè¿”å›é»˜è®¤å€¼
        unsafe { std::mem::zeroed() }
    }
}

// æ›´é«˜çº§çš„ Fork-Join å®ç°
pub struct RecursiveForkJoin<T, R> {
    threshold: usize,
    max_depth: usize,
}

impl<T, R> RecursiveForkJoin<T, R>
where
    T: Send + Sync + Clone,
    R: Send + Sync + Clone,
{
    pub fn new(threshold: usize, max_depth: usize) -> Self {
        RecursiveForkJoin {
            threshold,
            max_depth,
        }
    }
    
    pub fn execute<F, G, H>(
        &self,
        task: T,
        fork_fn: F,
        join_fn: G,
        base_fn: H,
    ) -> R
    where
        F: Fn(T) -> Vec<T> + Send + Sync + 'static,
        G: Fn(Vec<R>) -> R + Send + Sync + 'static,
        H: Fn(T) -> R + Send + Sync + 'static,
    {
        self.execute_recursive(task, fork_fn, join_fn, base_fn, 0)
    }
    
    fn execute_recursive<F, G, H>(
        &self,
        task: T,
        fork_fn: F,
        join_fn: G,
        base_fn: H,
        depth: usize,
    ) -> R
    where
        F: Fn(T) -> Vec<T> + Send + Sync,
        G: Fn(Vec<R>) -> R + Send + Sync,
        H: Fn(T) -> R + Send + Sync,
    {
        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°åŸºç¡€æƒ…å†µ
        if depth >= self.max_depth || Self::is_base_case(&task, self.threshold) {
            return base_fn(task);
        }
        
        // Forkï¼šåˆ†è§£ä»»åŠ¡
        let subtasks = fork_fn(task);
        
        if subtasks.len() == 1 {
            // åªæœ‰ä¸€ä¸ªå­ä»»åŠ¡ï¼Œé€’å½’å¤„ç†
            self.execute_recursive(subtasks.into_iter().next().unwrap(), fork_fn, join_fn, base_fn, depth + 1)
        } else {
            // å¹¶è¡Œå¤„ç†å¤šä¸ªå­ä»»åŠ¡
            let mut handles = Vec::new();
            
            for subtask in subtasks {
                let fork_fn = fork_fn.clone();
                let join_fn = join_fn.clone();
                let base_fn = base_fn.clone();
                let threshold = self.threshold;
                let max_depth = self.max_depth;
                
                let handle = thread::spawn(move || {
                    let fj = RecursiveForkJoin::new(threshold, max_depth);
                    fj.execute_recursive(subtask, fork_fn, join_fn, base_fn, depth + 1)
                });
                
                handles.push(handle);
            }
            
            // Joinï¼šæ”¶é›†ç»“æœ
            let results: Vec<R> = handles.into_iter().map(|h| h.join().unwrap()).collect();
            join_fn(results)
        }
    }
    
    fn is_base_case(task: &T, threshold: usize) -> bool {
        // è¿™é‡Œåº”è¯¥æ ¹æ®å…·ä½“ä»»åŠ¡ç±»å‹åˆ¤æ–­æ˜¯å¦ä¸ºåŸºç¡€æƒ…å†µ
        // ç®€åŒ–å®ç°
        false
    }
}
```

### 3.2 ç±»å‹ç³»ç»Ÿåˆ†æ

**å®šç† 3.1 (ç±»å‹å®‰å…¨)** Fork-Join ç³»ç»Ÿæ»¡è¶³ç±»å‹å®‰å…¨å½“ä¸”ä»…å½“ï¼š
$$\forall t \in T, \forall r \in R: \text{type}(t) \in \mathcal{T} \land \text{type}(r) \in \mathcal{R}$$

**è¯æ˜ï¼š**

1. ä»»åŠ¡ç±»å‹æ£€æŸ¥ï¼š$\forall t \in T: \text{type}(t) \in \mathcal{T}$
2. ç»“æœç±»å‹æ£€æŸ¥ï¼š$\forall r \in R: \text{type}(r) \in \mathcal{R}$
3. å‡½æ•°ç±»å‹ä¸€è‡´ï¼š$\forall f \in F: \text{type}(f) = T \rightarrow \{T_1, T_2, \ldots, T_k\}$

## 4. å¹¶è¡Œå®‰å…¨æ€§

### 4.1 æ•°æ®ç«äº‰é¢„é˜²

**å®šç† 4.1 (æ— æ•°æ®ç«äº‰)** Fork-Join ç³»ç»Ÿå¤©ç„¶æ— æ•°æ®ç«äº‰

**è¯æ˜ï¼š**

1. ä»»åŠ¡ç‹¬ç«‹æ€§ï¼š$\forall t_1, t_2 \in T: t_1 \neq t_2 \implies \text{data}(t_1) \cap \text{data}(t_2) = \emptyset$
2. å¹¶è¡Œæ‰§è¡Œï¼š$\forall t_1, t_2 \in T: t_1 \parallel t_2 \implies \text{execute}(t_1) \parallel \text{execute}(t_2)$
3. ç»“æœåˆå¹¶ï¼š$\forall r_1, r_2 \in R: \text{merge}(r_1, r_2) \text{ is atomic}$

### 4.2 æ­»é”é¢„é˜²

**å®šç† 4.2 (æ­»é”è‡ªç”±)** Fork-Join ç³»ç»Ÿæ— æ­»é”å½“ä¸”ä»…å½“ï¼š

1. æ— å¾ªç¯ä¾èµ–
2. æœ‰é™é€’å½’æ·±åº¦
3. ä»»åŠ¡å¯ç»ˆæ­¢

## 5. æ€§èƒ½åˆ†æ

### 5.1 æ—¶é—´å¤æ‚åº¦

**å®šç† 5.1 (å¹¶è¡Œå¤æ‚åº¦)**:

- Fork æ“ä½œï¼š$O(\log n)$
- å¹¶è¡Œæ‰§è¡Œï¼š$O(n/p)$
- Join æ“ä½œï¼š$O(\log n)$
- æ€»å¤æ‚åº¦ï¼š$O(n/p + \log n)$

### 5.2 ç©ºé—´å¤æ‚åº¦

**å®šç† 5.2 (ç©ºé—´å¤æ‚åº¦)**
$$\text{space}(FJ) = O(n \times \text{depth} + p \times \text{task\_size})$$

## 6. åº”ç”¨ç¤ºä¾‹

### 6.1 å¹¶è¡Œå½’å¹¶æ’åº

```rust
fn parallel_merge_sort<T: Ord + Send + Sync + Clone>(data: Vec<T>) -> Vec<T> {
    let fj = RecursiveForkJoin::new(1000, 10);
    
    let fork_fn = |data: Vec<T>| {
        if data.len() <= 1 {
            vec![data]
        } else {
            let mid = data.len() / 2;
            let left = data[..mid].to_vec();
            let right = data[mid..].to_vec();
            vec![left, right]
        }
    };
    
    let join_fn = |results: Vec<Vec<T>>| {
        if results.len() == 1 {
            results.into_iter().next().unwrap()
        } else {
            merge_sorted_vectors(results)
        }
    };
    
    let base_fn = |data: Vec<T>| {
        if data.len() <= 1 {
            data
        } else {
            let mut sorted = data;
            sorted.sort();
            sorted
        }
    };
    
    fj.execute(data, fork_fn, join_fn, base_fn)
}

fn merge_sorted_vectors<T: Ord + Clone>(vectors: Vec<Vec<T>>) -> Vec<T> {
    if vectors.is_empty() {
        return Vec::new();
    }
    
    let mut result = vectors.into_iter().next().unwrap();
    for vector in vectors {
        result = merge_two_sorted_vectors(result, vector);
    }
    result
}

fn merge_two_sorted_vectors<T: Ord + Clone>(mut left: Vec<T>, mut right: Vec<T>) -> Vec<T> {
    let mut result = Vec::new();
    
    while !left.is_empty() && !right.is_empty() {
        if left[0] <= right[0] {
            result.push(left.remove(0));
        } else {
            result.push(right.remove(0));
        }
    }
    
    result.extend(left);
    result.extend(right);
    result
}
```

### 6.2 å¹¶è¡ŒçŸ©é˜µä¹˜æ³•

```rust
#[derive(Clone)]
struct Matrix {
    data: Vec<Vec<f64>>,
    rows: usize,
    cols: usize,
}

impl Matrix {
    fn new(data: Vec<Vec<f64>>) -> Self {
        let rows = data.len();
        let cols = if rows > 0 { data[0].len() } else { 0 };
        Matrix { data, rows, cols }
    }
    
    fn multiply_parallel(&self, other: &Matrix) -> Matrix {
        let fj = RecursiveForkJoin::new(64, 4);
        
        let fork_fn = |task: MatrixMultiplyTask| {
            match task {
                MatrixMultiplyTask::Multiply(a, b) => {
                    if a.rows <= 64 || a.cols <= 64 || b.cols <= 64 {
                        vec![MatrixMultiplyTask::Multiply(a, b)]
                    } else {
                        // åˆ†å—çŸ©é˜µä¹˜æ³•
                        let mid_row = a.rows / 2;
                        let mid_col = a.cols / 2;
                        let mid_b_col = b.cols / 2;
                        
                        let a11 = Matrix::new(a.data[..mid_row].iter().map(|row| row[..mid_col].to_vec()).collect());
                        let a12 = Matrix::new(a.data[..mid_row].iter().map(|row| row[mid_col..].to_vec()).collect());
                        let a21 = Matrix::new(a.data[mid_row..].iter().map(|row| row[..mid_col].to_vec()).collect());
                        let a22 = Matrix::new(a.data[mid_row..].iter().map(|row| row[mid_col..].to_vec()).collect());
                        
                        let b11 = Matrix::new(b.data[..mid_col].iter().map(|row| row[..mid_b_col].to_vec()).collect());
                        let b12 = Matrix::new(b.data[..mid_col].iter().map(|row| row[mid_b_col..].to_vec()).collect());
                        let b21 = Matrix::new(b.data[mid_col..].iter().map(|row| row[..mid_b_col].to_vec()).collect());
                        let b22 = Matrix::new(b.data[mid_col..].iter().map(|row| row[mid_b_col..].to_vec()).collect());
                        
                        vec![
                            MatrixMultiplyTask::Multiply(a11, b11),
                            MatrixMultiplyTask::Multiply(a12, b21),
                            MatrixMultiplyTask::Multiply(a11, b12),
                            MatrixMultiplyTask::Multiply(a12, b22),
                            MatrixMultiplyTask::Multiply(a21, b11),
                            MatrixMultiplyTask::Multiply(a22, b21),
                            MatrixMultiplyTask::Multiply(a21, b12),
                            MatrixMultiplyTask::Multiply(a22, b22),
                        ]
                    }
                }
                MatrixMultiplyTask::Combine(parts) => {
                    if parts.len() <= 1 {
                        vec![MatrixMultiplyTask::Combine(parts)]
                    } else {
                        let mid = parts.len() / 2;
                        let left = parts[..mid].to_vec();
                        let right = parts[mid..].to_vec();
                        vec![
                            MatrixMultiplyTask::Combine(left),
                            MatrixMultiplyTask::Combine(right),
                        ]
                    }
                }
            }
        };
        
        let join_fn = |results: Vec<MatrixMultiplyTask>| {
            if results.len() == 1 {
                match results.into_iter().next().unwrap() {
                    MatrixMultiplyTask::Multiply(_, _) => panic!("Unexpected multiply task"),
                    MatrixMultiplyTask::Combine(parts) => parts.into_iter().next().unwrap(),
                }
            } else {
                MatrixMultiplyTask::Combine(results)
            }
        };
        
        let base_fn = |task: MatrixMultiplyTask| {
            match task {
                MatrixMultiplyTask::Multiply(a, b) => {
                    // åŸºç¡€çŸ©é˜µä¹˜æ³•
                    let mut result = vec![vec![0.0; b.cols]; a.rows];
                    for i in 0..a.rows {
                        for j in 0..b.cols {
                            for k in 0..a.cols {
                                result[i][j] += a.data[i][k] * b.data[k][j];
                            }
                        }
                    }
                    MatrixMultiplyTask::Combine(Matrix::new(result))
                }
                MatrixMultiplyTask::Combine(parts) => {
                    // åˆå¹¶çŸ©é˜µå—
                    if parts.len() == 1 {
                        parts.into_iter().next().unwrap()
                    } else {
                        // è¿™é‡Œåº”è¯¥å®ç°çŸ©é˜µå—çš„åˆå¹¶
                        parts.into_iter().next().unwrap()
                    }
                }
            }
        };
        
        let initial_task = MatrixMultiplyTask::Multiply(self.clone(), other.clone());
        match fj.execute(initial_task, fork_fn, join_fn, base_fn) {
            MatrixMultiplyTask::Combine(matrix) => matrix,
            _ => panic!("Unexpected result"),
        }
    }
}

#[derive(Clone)]
enum MatrixMultiplyTask {
    Multiply(Matrix, Matrix),
    Combine(Matrix),
}
```

### 6.3 å¹¶è¡Œå¿«é€Ÿæ’åº

```rust
fn parallel_quicksort<T: Ord + Send + Sync + Clone>(mut data: Vec<T>) -> Vec<T> {
    if data.len() <= 1 {
        return data;
    }
    
    let pivot = data.remove(data.len() / 2);
    let (left, right): (Vec<T>, Vec<T>) = data.into_iter().partition(|x| x < &pivot);
    
    let fj = RecursiveForkJoin::new(1000, 8);
    
    let fork_fn = |task: QuickSortTask<T>| {
        match task {
            QuickSortTask::Sort(data) => {
                if data.len() <= 1 {
                    vec![QuickSortTask::Sort(data)]
                } else {
                    let pivot = data[data.len() / 2].clone();
                    let (left, right): (Vec<T>, Vec<T>) = data.into_iter().partition(|x| x < &pivot);
                    vec![
                        QuickSortTask::Sort(left),
                        QuickSortTask::Sort(right),
                        QuickSortTask::Pivot(pivot),
                    ]
                }
            }
            QuickSortTask::Pivot(_) => vec![task],
        }
    };
    
    let join_fn = |results: Vec<QuickSortTask<T>>| {
        let mut sorted = Vec::new();
        let mut pivot = None;
        
        for result in results {
            match result {
                QuickSortTask::Sort(data) => sorted.extend(data),
                QuickSortTask::Pivot(p) => pivot = Some(p),
            }
        }
        
        if let Some(p) = pivot {
            // æ‰¾åˆ°pivotçš„æ­£ç¡®ä½ç½®å¹¶æ’å…¥
            let mut final_result = Vec::new();
            let mut pivot_inserted = false;
            
            for item in sorted {
                if !pivot_inserted && item >= p {
                    final_result.push(p.clone());
                    pivot_inserted = true;
                }
                final_result.push(item);
            }
            
            if !pivot_inserted {
                final_result.push(p);
            }
            
            QuickSortTask::Sort(final_result)
        } else {
            QuickSortTask::Sort(sorted)
        }
    };
    
    let base_fn = |task: QuickSortTask<T>| {
        match task {
            QuickSortTask::Sort(mut data) => {
                data.sort();
                QuickSortTask::Sort(data)
            }
            QuickSortTask::Pivot(p) => QuickSortTask::Pivot(p),
        }
    };
    
    let initial_task = QuickSortTask::Sort(data);
    match fj.execute(initial_task, fork_fn, join_fn, base_fn) {
        QuickSortTask::Sort(result) => result,
        _ => panic!("Unexpected result"),
    }
}

#[derive(Clone)]
enum QuickSortTask<T> {
    Sort(Vec<T>),
    Pivot(T),
}
```

## 7. å½¢å¼åŒ–éªŒè¯

### 7.1 è®¡ç®—æ­£ç¡®æ€§

**å®šä¹‰ 7.1 (è®¡ç®—æ­£ç¡®æ€§)** Fork-Join è®¡ç®—æ­£ç¡®å½“ä¸”ä»…å½“ï¼š
$$\forall t \in T: \text{result}(t) = \text{expected}(t)$$

### 7.2 å¹¶è¡Œä¿è¯

**å®šç† 7.2 (å¹¶è¡Œä¿è¯)** Fork-Join ç³»ç»Ÿæ»¡è¶³å¹¶è¡Œä¿è¯ï¼š
$$\forall t_1, t_2 \in T: t_1 \parallel t_2 \implies \text{execute}(t_1) \parallel \text{execute}(t_2)$$

## 8. é«˜çº§ç‰¹æ€§

### 8.1 åŠ¨æ€è´Ÿè½½å‡è¡¡

```rust
pub struct DynamicForkJoin<T, R> {
    scheduler: RecursiveForkJoin<T, R>,
    load_monitor: Arc<Mutex<LoadMonitor>>,
}

struct LoadMonitor {
    thread_loads: Vec<f64>,
    threshold: f64,
}

impl<T, R> DynamicForkJoin<T, R>
where
    T: Send + Sync + Clone,
    R: Send + Sync + Clone,
{
    pub fn new(threshold: usize, max_depth: usize) -> Self {
        DynamicForkJoin {
            scheduler: RecursiveForkJoin::new(threshold, max_depth),
            load_monitor: Arc::new(Mutex::new(LoadMonitor {
                thread_loads: vec![0.0; num_cpus::get()],
                threshold: 0.8,
            })),
        }
    }
    
    pub fn execute_with_load_balancing<F, G, H>(
        &self,
        task: T,
        fork_fn: F,
        join_fn: G,
        base_fn: H,
    ) -> R
    where
        F: Fn(T) -> Vec<T> + Send + Sync + 'static,
        G: Fn(Vec<R>) -> R + Send + Sync + 'static,
        H: Fn(T) -> R + Send + Sync + 'static,
    {
        // æ ¹æ®è´Ÿè½½æƒ…å†µè°ƒæ•´forkç­–ç•¥
        let adjusted_fork_fn = move |t: T| {
            let load_monitor = self.load_monitor.clone();
            let loads = load_monitor.lock().unwrap().thread_loads.clone();
            let avg_load = loads.iter().sum::<f64>() / loads.len() as f64;
            
            let mut subtasks = fork_fn(t);
            
            // å¦‚æœè´Ÿè½½è¿‡é«˜ï¼Œå‡å°‘å¹¶è¡Œåº¦
            if avg_load > 0.8 {
                subtasks.truncate(subtasks.len() / 2);
            }
            
            subtasks
        };
        
        self.scheduler.execute(task, adjusted_fork_fn, join_fn, base_fn)
    }
}
```

### 8.2 ç¼“å­˜æ„ŸçŸ¥è°ƒåº¦

```rust
pub struct CacheAwareForkJoin<T, R> {
    scheduler: RecursiveForkJoin<T, R>,
    cache_size: usize,
    cache_line_size: usize,
}

impl<T, R> CacheAwareForkJoin<T, R>
where
    T: Send + Sync + Clone,
    R: Send + Sync + Clone,
{
    pub fn new(threshold: usize, max_depth: usize, cache_size: usize) -> Self {
        CacheAwareForkJoin {
            scheduler: RecursiveForkJoin::new(threshold, max_depth),
            cache_size,
            cache_line_size: 64, // å‡è®¾64å­—èŠ‚ç¼“å­˜è¡Œ
        }
    }
    
    pub fn execute_cache_aware<F, G, H>(
        &self,
        task: T,
        fork_fn: F,
        join_fn: G,
        base_fn: H,
    ) -> R
    where
        F: Fn(T) -> Vec<T> + Send + Sync + 'static,
        G: Fn(Vec<R>) -> R + Send + Sync + 'static,
        H: Fn(T) -> R + Send + Sync + 'static,
    {
        // æ ¹æ®ç¼“å­˜å¤§å°è°ƒæ•´ä»»åŠ¡å¤§å°
        let cache_aware_fork_fn = move |t: T| {
            let mut subtasks = fork_fn(t);
            
            // ç¡®ä¿æ¯ä¸ªå­ä»»åŠ¡é€‚åˆç¼“å­˜
            let optimal_task_size = self.cache_size / (subtasks.len() * self.cache_line_size);
            if optimal_task_size < subtasks.len() {
                subtasks.truncate(optimal_task_size);
            }
            
            subtasks
        };
        
        self.scheduler.execute(task, cache_aware_fork_fn, join_fn, base_fn)
    }
}
```

## 9. æ€»ç»“

Fork-Join æ¨¡å¼æä¾›äº†ï¼š

- é«˜æ•ˆçš„åˆ†æ²»å¹¶è¡Œå¤„ç†
- è‡ªåŠ¨è´Ÿè½½å‡è¡¡
- é€’å½’ä»»åŠ¡åˆ†è§£
- è‰¯å¥½çš„ç¼“å­˜å±€éƒ¨æ€§

åœ¨ Rust ä¸­ï¼ŒFork-Join æ¨¡å¼é€šè¿‡ç±»å‹ç³»ç»Ÿå’Œæ‰€æœ‰æƒç³»ç»Ÿæä¾›äº†é¢å¤–çš„å®‰å…¨ä¿éšœã€‚
