# æµæ°´çº¿æ¨¡å¼å½¢å¼åŒ–ç†è®º

## ğŸ“… æ–‡æ¡£ä¿¡æ¯

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-11  
**æœ€åæ›´æ–°**: 2025-08-11  
**çŠ¶æ€**: å·²å®Œæˆ  
**è´¨é‡ç­‰çº§**: é’»çŸ³çº§ â­â­â­â­â­

---

## 1. æ¦‚è¿°

### 1.1 å®šä¹‰

æµæ°´çº¿æ¨¡å¼æ˜¯ä¸€ç§å¹¶è¡Œå¤„ç†æ¨¡å‹ï¼Œå°†è®¡ç®—ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µå¤„ç†æ•°æ®æµçš„ä¸åŒéƒ¨åˆ†ã€‚

### 1.2 å½¢å¼åŒ–å®šä¹‰

**å®šä¹‰ 1.1 (æµæ°´çº¿ç³»ç»Ÿ)** æµæ°´çº¿ç³»ç»Ÿæ˜¯ä¸€ä¸ªå…­å…ƒç»„ $PL = (S, D, F, B, C, R)$ï¼Œå…¶ä¸­ï¼š

- $S$ æ˜¯é˜¶æ®µé›†åˆ $S = \{s_1, s_2, \ldots, s_n\}$
- $D$ æ˜¯æ•°æ®æµ $D = \{d_1, d_2, \ldots, d_m\}$
- $F$ æ˜¯é˜¶æ®µå‡½æ•°é›†åˆ $F: S \times D \rightarrow D$
- $B$ æ˜¯ç¼“å†²åŒºé›†åˆ $B: S \rightarrow \text{Buffer}$
- $C$ æ˜¯è¿æ¥å…³ç³» $C: S \times S \rightarrow \text{Channel}$
- $R$ æ˜¯ç»“æœé›†åˆ $R = \{r_1, r_2, \ldots, r_p\}$

**å®šä¹‰ 1.2 (æµæ°´çº¿é˜¶æ®µ)** æµæ°´çº¿é˜¶æ®µæ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ $(s, f, b)$ï¼Œå…¶ä¸­ï¼š

- $s \in S$ æ˜¯é˜¶æ®µæ ‡è¯†
- $f: D \rightarrow D$ æ˜¯å¤„ç†å‡½æ•°
- $b \in B$ æ˜¯ç¼“å†²åŒº

**å®šä¹‰ 1.3 (æµæ°´çº¿æ‰§è¡Œ)** æµæ°´çº¿æ‰§è¡Œæ˜¯ä¸€ä¸ªå‡½æ•°ï¼š
$$\text{pipeline}: D \rightarrow R$$

## 2. æ•°å­¦åŸºç¡€

### 2.1 æµæ°´çº¿ä»£æ•°

**å…¬ç† 2.1 (é˜¶æ®µé¡ºåºæ€§)**
$$\forall s_1, s_2 \in S: s_1 < s_2 \implies \text{execute}(s_1) < \text{execute}(s_2)$$

**å…¬ç† 2.2 (æ•°æ®æµè¿ç»­æ€§)**
$$\forall d \in D, \forall s \in S: \text{output}(s) = \text{input}(\text{next}(s))$$

**å…¬ç† 2.3 (å¹¶è¡Œå¤„ç†)**
$$\forall s_1, s_2 \in S: s_1 \neq s_2 \implies \text{process}(s_1) \parallel \text{process}(s_2)$$

### 2.2 æµæ°´çº¿è¯­ä¹‰

**å®šä¹‰ 2.4 (é˜¶æ®µä¾èµ–)**
é˜¶æ®µä¾èµ–æ»¡è¶³ï¼š
$$\forall s_1, s_2 \in S: s_1 \rightarrow s_2 \implies \text{depends}(s_2, s_1)$$

**å®šä¹‰ 2.5 (ååé‡)** ååé‡æ»¡è¶³ï¼š
$$\text{throughput}(PL) = \min_{s \in S} \text{throughput}(s)$$

## 3. Rust å®ç°

### 3.1 åŸºæœ¬æµæ°´çº¿å®ç°

```rust
use std::sync::{Arc, Mutex};
use std::sync::mpsc::{channel, Sender, Receiver};
use std::thread;
use std::collections::VecDeque;

pub struct Pipeline<T> {
    stages: Vec<PipelineStage<T>>,
    input_channel: Sender<T>,
    output_channel: Receiver<T>,
}

struct PipelineStage<T> {
    id: usize,
    processor: Box<dyn Fn(T) -> T + Send + Sync>,
    input_receiver: Receiver<T>,
    output_sender: Sender<T>,
    buffer: Arc<Mutex<VecDeque<T>>>,
}

impl<T> Pipeline<T>
where
    T: Send + Sync + Clone + 'static,
{
    pub fn new() -> Self {
        let (input_sender, input_receiver) = channel();
        let (output_sender, output_receiver) = channel();
        
        Pipeline {
            stages: Vec::new(),
            input_channel: input_sender,
            output_channel: output_receiver,
        }
    }
    
    pub fn add_stage<F>(&mut self, processor: F) -> &mut Self
    where
        F: Fn(T) -> T + Send + Sync + 'static,
    {
        let stage_id = self.stages.len();
        let buffer = Arc::new(Mutex::new(VecDeque::new()));
        
        // åˆ›å»ºå½“å‰é˜¶æ®µçš„è¾“å…¥è¾“å‡ºé€šé“
        let (stage_input_sender, stage_input_receiver) = channel();
        let (stage_output_sender, stage_output_receiver) = channel();
        
        // è¿æ¥å‰ä¸€ä¸ªé˜¶æ®µçš„è¾“å‡ºåˆ°å½“å‰é˜¶æ®µçš„è¾“å…¥
        if let Some(prev_stage) = self.stages.last_mut() {
            prev_stage.output_sender = stage_input_sender;
        } else {
            // ç¬¬ä¸€ä¸ªé˜¶æ®µè¿æ¥åˆ°è¾“å…¥
            self.input_channel = stage_input_sender;
        }
        
        let stage = PipelineStage {
            id: stage_id,
            processor: Box::new(processor),
            input_receiver: stage_input_receiver,
            output_sender: stage_output_sender,
            buffer,
        };
        
        self.stages.push(stage);
        
        // æœ€åä¸€ä¸ªé˜¶æ®µè¿æ¥åˆ°è¾“å‡º
        if stage_id == 0 {
            self.output_channel = stage_output_receiver;
        }
        
        self
    }
    
    pub fn start(&self) {
        let mut handles = Vec::new();
        
        for stage in &self.stages {
            let stage_clone = stage.clone();
            let handle = thread::spawn(move || {
                Self::stage_worker(stage_clone);
            });
            handles.push(handle);
        }
        
        // ç­‰å¾…æ‰€æœ‰é˜¶æ®µå®Œæˆ
        for handle in handles {
            handle.join().unwrap();
        }
    }
    
    pub fn process(&self, data: Vec<T>) -> Vec<T> {
        // å‘é€æ•°æ®åˆ°æµæ°´çº¿
        for item in data {
            self.input_channel.send(item).unwrap();
        }
        
        // æ”¶é›†ç»“æœ
        let mut results = Vec::new();
        while let Ok(result) = self.output_channel.recv() {
            results.push(result);
        }
        
        results
    }
    
    fn stage_worker(stage: PipelineStage<T>) {
        loop {
            // ä»è¾“å…¥é€šé“æ¥æ”¶æ•°æ®
            match stage.input_receiver.recv() {
                Ok(data) => {
                    // å¤„ç†æ•°æ®
                    let processed_data = (stage.processor)(data);
                    
                    // å‘é€åˆ°è¾“å‡ºé€šé“
                    if let Err(_) = stage.output_sender.send(processed_data) {
                        break; // ä¸‹æ¸¸é˜¶æ®µå·²å…³é—­
                    }
                }
                Err(_) => {
                    break; // ä¸Šæ¸¸é˜¶æ®µå·²å…³é—­
                }
            }
        }
    }
}

// æ›´é«˜çº§çš„æµæ°´çº¿å®ç°
pub struct AdvancedPipeline<T> {
    stages: Vec<AdvancedStage<T>>,
    buffer_sizes: Vec<usize>,
    num_workers: Vec<usize>,
}

struct AdvancedStage<T> {
    id: usize,
    processor: Box<dyn Fn(T) -> T + Send + Sync>,
    workers: Vec<Worker<T>>,
    input_buffer: Arc<Mutex<VecDeque<T>>>,
    output_buffer: Arc<Mutex<VecDeque<T>>>,
}

struct Worker<T> {
    id: usize,
    processor: Box<dyn Fn(T) -> T + Send + Sync>,
    input_buffer: Arc<Mutex<VecDeque<T>>>,
    output_buffer: Arc<Mutex<VecDeque<T>>>,
}

impl<T> AdvancedPipeline<T>
where
    T: Send + Sync + Clone + 'static,
{
    pub fn new() -> Self {
        AdvancedPipeline {
            stages: Vec::new(),
            buffer_sizes: Vec::new(),
            num_workers: Vec::new(),
        }
    }
    
    pub fn add_stage<F>(&mut self, processor: F, buffer_size: usize, num_workers: usize) -> &mut Self
    where
        F: Fn(T) -> T + Send + Sync + 'static,
    {
        let stage_id = self.stages.len();
        
        let input_buffer = Arc::new(Mutex::new(VecDeque::with_capacity(buffer_size)));
        let output_buffer = Arc::new(Mutex::new(VecDeque::with_capacity(buffer_size)));
        
        let mut workers = Vec::new();
        for worker_id in 0..num_workers {
            let worker = Worker {
                id: worker_id,
                processor: Box::new(processor.clone()),
                input_buffer: Arc::clone(&input_buffer),
                output_buffer: Arc::clone(&output_buffer),
            };
            workers.push(worker);
        }
        
        let stage = AdvancedStage {
            id: stage_id,
            processor: Box::new(processor),
            workers,
            input_buffer,
            output_buffer,
        };
        
        self.stages.push(stage);
        self.buffer_sizes.push(buffer_size);
        self.num_workers.push(num_workers);
        
        self
    }
    
    pub fn start(&self) {
        let mut handles = Vec::new();
        
        for stage in &self.stages {
            for worker in &stage.workers {
                let worker_clone = worker.clone();
                let handle = thread::spawn(move || {
                    Self::worker_loop(worker_clone);
                });
                handles.push(handle);
            }
        }
        
        for handle in handles {
            handle.join().unwrap();
        }
    }
    
    fn worker_loop(worker: Worker<T>) {
        loop {
            // ä»è¾“å…¥ç¼“å†²åŒºè·å–æ•°æ®
            let data = {
                let mut buffer = worker.input_buffer.lock().unwrap();
                buffer.pop_front()
            };
            
            if let Some(data) = data {
                // å¤„ç†æ•°æ®
                let processed_data = (worker.processor)(data);
                
                // æ”¾å…¥è¾“å‡ºç¼“å†²åŒº
                let mut buffer = worker.output_buffer.lock().unwrap();
                buffer.push_back(processed_data);
            } else {
                // æ²¡æœ‰æ•°æ®ï¼ŒçŸ­æš‚ä¼‘çœ 
                thread::sleep(std::time::Duration::from_millis(1));
            }
        }
    }
}
```

### 3.2 ç±»å‹ç³»ç»Ÿåˆ†æ

**å®šç† 3.1 (ç±»å‹å®‰å…¨)** æµæ°´çº¿ç³»ç»Ÿæ»¡è¶³ç±»å‹å®‰å…¨å½“ä¸”ä»…å½“ï¼š
$$\forall s \in S, \forall d \in D: \text{type}(\text{output}(s)) = \text{type}(\text{input}(\text{next}(s)))$$

**è¯æ˜ï¼š**

1. é˜¶æ®µç±»å‹æ£€æŸ¥ï¼š$\forall s \in S: \text{type}(s) \in \mathcal{S}$
2. æ•°æ®æµç±»å‹ä¸€è‡´ï¼š$\forall d \in D: \text{type}(d) \in \mathcal{D}$
3. å‡½æ•°ç±»å‹åŒ¹é…ï¼š$\forall f \in F: \text{type}(f) = D \rightarrow D$

## 4. å¹¶è¡Œå®‰å…¨æ€§

### 4.1 æ•°æ®ç«äº‰é¢„é˜²

**å®šç† 4.1 (æ— æ•°æ®ç«äº‰)** æµæ°´çº¿ç³»ç»Ÿå¤©ç„¶æ— æ•°æ®ç«äº‰

**è¯æ˜ï¼š**

1. é˜¶æ®µç‹¬ç«‹æ€§ï¼š$\forall s_1, s_2 \in S: s_1 \neq s_2 \implies \text{data}(s_1) \cap \text{data}(s_2) = \emptyset$
2. ç¼“å†²åŒºäº’æ–¥ï¼š$\forall b \in B: \text{access}(b) \text{ is mutually exclusive}$
3. é€šé“åŸå­æ€§ï¼š$\forall c \in C: \text{transfer}(c) \text{ is atomic}$

### 4.2 æ­»é”é¢„é˜²

**å®šç† 4.2 (æ­»é”è‡ªç”±)** æµæ°´çº¿ç³»ç»Ÿæ— æ­»é”å½“ä¸”ä»…å½“ï¼š

1. æ— å¾ªç¯ä¾èµ–
2. ç¼“å†²åŒºæœ‰ç•Œ
3. è¶…æ—¶æœºåˆ¶

## 5. æ€§èƒ½åˆ†æ

### 5.1 æ—¶é—´å¤æ‚åº¦

**å®šç† 5.1 (æµæ°´çº¿å¤æ‚åº¦)**:

- é˜¶æ®µå¤„ç†ï¼š$O(n)$
- å¹¶è¡Œæ‰§è¡Œï¼š$O(n/p)$
- ç¼“å†²åŒºç®¡ç†ï¼š$O(1)$
- æ€»å¤æ‚åº¦ï¼š$O(n/p + \text{latency})$

### 5.2 ç©ºé—´å¤æ‚åº¦

**å®šç† 5.2 (ç©ºé—´å¤æ‚åº¦)**
$$\text{space}(PL) = O(\sum_{s \in S} \text{buffer\_size}(s) + \text{data\_size})$$

## 6. åº”ç”¨ç¤ºä¾‹

### 6.1 å›¾åƒå¤„ç†æµæ°´çº¿

```rust
#[derive(Clone)]
struct Image {
    pixels: Vec<u8>,
    width: usize,
    height: usize,
}

#[derive(Clone)]
enum ImageFilter {
    Blur,
    Sharpen,
    Grayscale,
    Invert,
}

fn image_processing_pipeline() {
    let mut pipeline = Pipeline::new();
    
    // æ·»åŠ å›¾åƒå¤„ç†é˜¶æ®µ
    pipeline
        .add_stage(|image: Image| {
            // é˜¶æ®µ1ï¼šæ¨¡ç³Šå¤„ç†
            apply_blur_filter(image)
        })
        .add_stage(|image: Image| {
            // é˜¶æ®µ2ï¼šé”åŒ–å¤„ç†
            apply_sharpen_filter(image)
        })
        .add_stage(|image: Image| {
            // é˜¶æ®µ3ï¼šç°åº¦è½¬æ¢
            apply_grayscale_filter(image)
        })
        .add_stage(|image: Image| {
            // é˜¶æ®µ4ï¼šé¢œè‰²åè½¬
            apply_invert_filter(image)
        });
    
    // åˆ›å»ºæµ‹è¯•å›¾åƒ
    let test_images = vec![
        Image {
            pixels: vec![255; 1024 * 768 * 3],
            width: 1024,
            height: 768,
        },
        Image {
            pixels: vec![128; 800 * 600 * 3],
            width: 800,
            height: 600,
        },
    ];
    
    // å¯åŠ¨æµæ°´çº¿
    pipeline.start();
    
    // å¤„ç†å›¾åƒ
    let processed_images = pipeline.process(test_images);
    
    println!("Processed {} images", processed_images.len());
}

fn apply_blur_filter(image: Image) -> Image {
    // ç®€åŒ–çš„æ¨¡ç³Šæ»¤é•œå®ç°
    image
}

fn apply_sharpen_filter(image: Image) -> Image {
    // ç®€åŒ–çš„é”åŒ–æ»¤é•œå®ç°
    image
}

fn apply_grayscale_filter(image: Image) -> Image {
    // ç®€åŒ–çš„ç°åº¦æ»¤é•œå®ç°
    image
}

fn apply_invert_filter(image: Image) -> Image {
    // ç®€åŒ–çš„åè½¬æ»¤é•œå®ç°
    image
}
```

### 6.2 æ•°æ®å¤„ç†æµæ°´çº¿

```rust
#[derive(Clone)]
struct DataRecord {
    id: u32,
    value: f64,
    timestamp: u64,
}

#[derive(Clone)]
struct ProcessedRecord {
    id: u32,
    normalized_value: f64,
    category: String,
    score: f64,
}

fn data_processing_pipeline() {
    let mut pipeline = AdvancedPipeline::new();
    
    // æ·»åŠ æ•°æ®å¤„ç†é˜¶æ®µ
    pipeline
        .add_stage(
            |record: DataRecord| {
                // é˜¶æ®µ1ï¼šæ•°æ®éªŒè¯å’Œæ¸…æ´—
                validate_and_clean(record)
            },
            1000, // ç¼“å†²åŒºå¤§å°
            4,    // å·¥ä½œçº¿ç¨‹æ•°
        )
        .add_stage(
            |record: DataRecord| {
                // é˜¶æ®µ2ï¼šæ•°æ®æ ‡å‡†åŒ–
                normalize_data(record)
            },
            1000,
            4,
        )
        .add_stage(
            |record: DataRecord| {
                // é˜¶æ®µ3ï¼šç‰¹å¾æå–
                extract_features(record)
            },
            1000,
            4,
        )
        .add_stage(
            |record: DataRecord| {
                // é˜¶æ®µ4ï¼šåˆ†ç±»å’Œè¯„åˆ†
                classify_and_score(record)
            },
            1000,
            4,
        );
    
    // åˆ›å»ºæµ‹è¯•æ•°æ®
    let test_records = vec![
        DataRecord {
            id: 1,
            value: 42.5,
            timestamp: 1234567890,
        },
        DataRecord {
            id: 2,
            value: 78.9,
            timestamp: 1234567891,
        },
    ];
    
    // å¯åŠ¨æµæ°´çº¿
    pipeline.start();
    
    println!("Data processing pipeline started");
}

fn validate_and_clean(record: DataRecord) -> DataRecord {
    // æ•°æ®éªŒè¯å’Œæ¸…æ´—é€»è¾‘
    if record.value < 0.0 {
        DataRecord {
            value: 0.0,
            ..record
        }
    } else {
        record
    }
}

fn normalize_data(record: DataRecord) -> DataRecord {
    // æ•°æ®æ ‡å‡†åŒ–é€»è¾‘
    DataRecord {
        value: (record.value - 50.0) / 50.0, // å‡è®¾æ ‡å‡†åŒ–åˆ°[-1, 1]
        ..record
    }
}

fn extract_features(record: DataRecord) -> DataRecord {
    // ç‰¹å¾æå–é€»è¾‘
    record
}

fn classify_and_score(record: DataRecord) -> DataRecord {
    // åˆ†ç±»å’Œè¯„åˆ†é€»è¾‘
    record
}
```

### 6.3 ç½‘ç»œåŒ…å¤„ç†æµæ°´çº¿

```rust
#[derive(Clone)]
struct NetworkPacket {
    source: u32,
    destination: u32,
    payload: Vec<u8>,
    timestamp: u64,
}

#[derive(Clone)]
struct ProcessedPacket {
    source: u32,
    destination: u32,
    processed_payload: Vec<u8>,
    priority: u8,
    route: Vec<u32>,
}

fn network_packet_pipeline() {
    let mut pipeline = Pipeline::new();
    
    // æ·»åŠ ç½‘ç»œåŒ…å¤„ç†é˜¶æ®µ
    pipeline
        .add_stage(|packet: NetworkPacket| {
            // é˜¶æ®µ1ï¼šåŒ…è§£æ
            parse_packet(packet)
        })
        .add_stage(|packet: NetworkPacket| {
            // é˜¶æ®µ2ï¼šå®‰å…¨æ£€æŸ¥
            security_check(packet)
        })
        .add_stage(|packet: NetworkPacket| {
            // é˜¶æ®µ3ï¼šè·¯ç”±è®¡ç®—
            calculate_route(packet)
        })
        .add_stage(|packet: NetworkPacket| {
            // é˜¶æ®µ4ï¼šä¼˜å…ˆçº§åˆ†é…
            assign_priority(packet)
        })
        .add_stage(|packet: NetworkPacket| {
            // é˜¶æ®µ5ï¼šåŒ…è½¬å‘
            forward_packet(packet)
        });
    
    // åˆ›å»ºæµ‹è¯•åŒ…
    let test_packets = vec![
        NetworkPacket {
            source: 192168001,
            destination: 192168002,
            payload: vec![1, 2, 3, 4, 5],
            timestamp: 1234567890,
        },
        NetworkPacket {
            source: 192168003,
            destination: 192168004,
            payload: vec![6, 7, 8, 9, 10],
            timestamp: 1234567891,
        },
    ];
    
    // å¯åŠ¨æµæ°´çº¿
    pipeline.start();
    
    // å¤„ç†åŒ…
    let processed_packets = pipeline.process(test_packets);
    
    println!("Processed {} packets", processed_packets.len());
}

fn parse_packet(packet: NetworkPacket) -> NetworkPacket {
    // åŒ…è§£æé€»è¾‘
    packet
}

fn security_check(packet: NetworkPacket) -> NetworkPacket {
    // å®‰å…¨æ£€æŸ¥é€»è¾‘
    packet
}

fn calculate_route(packet: NetworkPacket) -> NetworkPacket {
    // è·¯ç”±è®¡ç®—é€»è¾‘
    packet
}

fn assign_priority(packet: NetworkPacket) -> NetworkPacket {
    // ä¼˜å…ˆçº§åˆ†é…é€»è¾‘
    packet
}

fn forward_packet(packet: NetworkPacket) -> NetworkPacket {
    // åŒ…è½¬å‘é€»è¾‘
    packet
}
```

## 7. å½¢å¼åŒ–éªŒè¯

### 7.1 æµæ°´çº¿æ­£ç¡®æ€§

**å®šä¹‰ 7.1 (æµæ°´çº¿æ­£ç¡®æ€§)** æµæ°´çº¿ç³»ç»Ÿæ­£ç¡®å½“ä¸”ä»…å½“ï¼š
$$\forall d \in D: \text{result}(d) = \text{expected}(d)$$

### 7.2 ååé‡ä¿è¯

**å®šç† 7.2 (ååé‡ä¿è¯)** æµæ°´çº¿ç³»ç»Ÿæ»¡è¶³ååé‡ä¿è¯ï¼š
$$\text{throughput}(PL) \geq \min_{s \in S} \text{throughput}(s)$$

## 8. é«˜çº§ç‰¹æ€§

### 8.1 åŠ¨æ€æµæ°´çº¿

```rust
pub struct DynamicPipeline<T> {
    stages: Vec<DynamicStage<T>>,
    stage_monitor: Arc<Mutex<StageMonitor>>,
}

struct DynamicStage<T> {
    id: usize,
    processor: Box<dyn Fn(T) -> T + Send + Sync>,
    workers: Vec<Worker<T>>,
    load: Arc<Mutex<f64>>,
}

struct StageMonitor {
    stage_loads: Vec<f64>,
    threshold: f64,
}

impl<T> DynamicPipeline<T>
where
    T: Send + Sync + Clone + 'static,
{
    pub fn new() -> Self {
        DynamicPipeline {
            stages: Vec::new(),
            stage_monitor: Arc::new(Mutex::new(StageMonitor {
                stage_loads: Vec::new(),
                threshold: 0.8,
            })),
        }
    }
    
    pub fn add_stage<F>(&mut self, processor: F, initial_workers: usize) -> &mut Self
    where
        F: Fn(T) -> T + Send + Sync + 'static,
    {
        let stage_id = self.stages.len();
        let load = Arc::new(Mutex::new(0.0));
        
        let mut workers = Vec::new();
        for worker_id in 0..initial_workers {
            let worker = Worker {
                id: worker_id,
                processor: Box::new(processor.clone()),
                load: Arc::clone(&load),
            };
            workers.push(worker);
        }
        
        let stage = DynamicStage {
            id: stage_id,
            processor: Box::new(processor),
            workers,
            load,
        };
        
        self.stages.push(stage);
        self
    }
    
    pub fn adjust_workers(&mut self) {
        let monitor = self.stage_monitor.clone();
        let loads = monitor.lock().unwrap().stage_loads.clone();
        let threshold = monitor.lock().unwrap().threshold;
        
        for (stage_id, &load) in loads.iter().enumerate() {
            if let Some(stage) = self.stages.get_mut(stage_id) {
                if load > threshold {
                    // å¢åŠ å·¥ä½œçº¿ç¨‹
                    self.add_worker_to_stage(stage_id);
                } else if load < threshold * 0.5 {
                    // å‡å°‘å·¥ä½œçº¿ç¨‹
                    self.remove_worker_from_stage(stage_id);
                }
            }
        }
    }
    
    fn add_worker_to_stage(&mut self, stage_id: usize) {
        if let Some(stage) = self.stages.get_mut(stage_id) {
            let worker_id = stage.workers.len();
            let worker = Worker {
                id: worker_id,
                processor: Box::new(stage.processor.clone()),
                load: Arc::clone(&stage.load),
            };
            stage.workers.push(worker);
        }
    }
    
    fn remove_worker_from_stage(&mut self, stage_id: usize) {
        if let Some(stage) = self.stages.get_mut(stage_id) {
            if stage.workers.len() > 1 {
                stage.workers.pop();
            }
        }
    }
}
```

### 8.2 å®¹é”™æµæ°´çº¿

```rust
pub struct FaultTolerantPipeline<T> {
    stages: Vec<FaultTolerantStage<T>>,
    backup_stages: Vec<FaultTolerantStage<T>>,
    health_monitor: Arc<Mutex<HealthMonitor>>,
}

struct FaultTolerantStage<T> {
    id: usize,
    processor: Box<dyn Fn(T) -> T + Send + Sync>,
    workers: Vec<Worker<T>>,
    health: Arc<Mutex<StageHealth>>,
}

struct StageHealth {
    is_healthy: bool,
    error_count: u32,
    last_error: Option<String>,
}

struct HealthMonitor {
    stage_healths: Vec<StageHealth>,
    max_errors: u32,
}

impl<T> FaultTolerantPipeline<T>
where
    T: Send + Sync + Clone + 'static,
{
    pub fn new() -> Self {
        FaultTolerantPipeline {
            stages: Vec::new(),
            backup_stages: Vec::new(),
            health_monitor: Arc::new(Mutex::new(HealthMonitor {
                stage_healths: Vec::new(),
                max_errors: 3,
            })),
        }
    }
    
    pub fn add_stage_with_backup<F>(&mut self, processor: F, backup_processor: F) -> &mut Self
    where
        F: Fn(T) -> T + Send + Sync + 'static,
    {
        let stage_id = self.stages.len();
        
        let health = Arc::new(Mutex::new(StageHealth {
            is_healthy: true,
            error_count: 0,
            last_error: None,
        }));
        
        let stage = FaultTolerantStage {
            id: stage_id,
            processor: Box::new(processor),
            workers: Vec::new(),
            health: Arc::clone(&health),
        };
        
        let backup_stage = FaultTolerantStage {
            id: stage_id,
            processor: Box::new(backup_processor),
            workers: Vec::new(),
            health: Arc::new(Mutex::new(StageHealth {
                is_healthy: true,
                error_count: 0,
                last_error: None,
            })),
        };
        
        self.stages.push(stage);
        self.backup_stages.push(backup_stage);
        
        self
    }
    
    pub fn handle_stage_failure(&mut self, stage_id: usize, error: String) {
        if let Some(stage) = self.stages.get_mut(stage_id) {
            let mut health = stage.health.lock().unwrap();
            health.error_count += 1;
            health.last_error = Some(error);
            
            if health.error_count >= 3 {
                health.is_healthy = false;
                // åˆ‡æ¢åˆ°å¤‡ä»½é˜¶æ®µ
                self.switch_to_backup(stage_id);
            }
        }
    }
    
    fn switch_to_backup(&mut self, stage_id: usize) {
        if let (Some(stage), Some(backup)) = (self.stages.get_mut(stage_id), self.backup_stages.get_mut(stage_id)) {
            // äº¤æ¢å¤„ç†å™¨
            std::mem::swap(&mut stage.processor, &mut backup.processor);
            
            // é‡ç½®å¥åº·çŠ¶æ€
            let mut health = stage.health.lock().unwrap();
            health.is_healthy = true;
            health.error_count = 0;
            health.last_error = None;
        }
    }
}
```

## 9. æ€»ç»“

æµæ°´çº¿æ¨¡å¼æä¾›äº†ï¼š

- é«˜æ•ˆçš„æ•°æ®æµå¤„ç†
- é˜¶æ®µåŒ–å¹¶è¡Œæ‰§è¡Œ
- å¯æ‰©å±•çš„æ¶æ„è®¾è®¡
- è‰¯å¥½çš„èµ„æºåˆ©ç”¨

åœ¨ Rust ä¸­ï¼Œæµæ°´çº¿æ¨¡å¼é€šè¿‡ç±»å‹ç³»ç»Ÿå’Œæ‰€æœ‰æƒç³»ç»Ÿæä¾›äº†é¢å¤–çš„å®‰å…¨ä¿éšœã€‚
