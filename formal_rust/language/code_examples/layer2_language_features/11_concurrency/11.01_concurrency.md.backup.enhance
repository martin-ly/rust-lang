# 并发编程

## 元数据

- **概念ID**: 11.01
- **概念名称**: 并发编程 (Concurrency Programming)
- **理论层次**: 第二层：语言特征形式化层
- **相关概念**: 11.02 (线程), 11.03 (消息传递), 11.04 (共享状态)
- **难度级别**: 高级

## 形式化定义

使用统一符号系统(RFUSS)的形式化定义：

```math
\text{Concurrency}(T, S, M) \equiv \forall t \in T. \exists s \in S. \text{Thread}(t) \land \text{State}(s) \land \text{Message}(M)
```

其中：

- $\text{Concurrency}(T, S, M)$ 表示线程集合 $T$、状态集合 $S$ 和消息集合 $M$
- $\forall t \in T$ 表示对所有线程 $t$ 在线程集合 $T$ 中
- $\exists s \in S$ 表示存在状态 $s$ 在状态集合 $S$ 中
- $\text{Thread}(t)$ 表示线程 $t$ 的执行
- $\text{State}(s)$ 表示共享状态 $s$
- $\text{Message}(M)$ 表示消息传递集合 $M$

## 代码映射

形式化表示与代码的对应关系：

| 形式化表示 | Rust代码 | 说明 |
|----------|---------|------|
| `Concurrency(T, S, M)` | `std::thread` | 并发编程基础 |
| `∀t ∈ T` | `thread::spawn` | 创建线程 |
| `∃s ∈ S` | `Arc<Mutex<T>>` | 共享状态 |
| `Thread(t)` | `JoinHandle` | 线程句柄 |
| `State(s)` | `Mutex<T>` | 互斥锁 |
| `Message(M)` | `mpsc::channel` | 消息通道 |

## 基础示例

最小化示例代码，展示并发编程的核心概念：

```rust
use std::thread;
use std::time::Duration;

// 基本线程创建
fn basic_thread() {
    let handle = thread::spawn(|| {
        for i in 1..=5 {
            println!("线程中的数字: {}", i);
            thread::sleep(Duration::from_millis(100));
        }
    });
    
    // 主线程继续执行
    for i in 1..=3 {
        println!("主线程数字: {}", i);
        thread::sleep(Duration::from_millis(200));
    }
    
    // 等待子线程完成
    handle.join().unwrap();
}

// 线程间数据传递
fn thread_with_data() {
    let v = vec![1, 2, 3, 4, 5];
    
    let handle = thread::spawn(move || {
        println!("线程中的向量: {:?}", v);
        let sum: i32 = v.iter().sum();
        println!("向量元素和: {}", sum);
    });
    
    handle.join().unwrap();
}

// 共享状态
use std::sync::{Arc, Mutex};

fn shared_state() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];
    
    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    println!("最终计数: {}", *counter.lock().unwrap());
}

fn main() {
    println!("=== 基本线程创建 ===");
    basic_thread();
    
    println!("\n=== 线程间数据传递 ===");
    thread_with_data();
    
    println!("\n=== 共享状态 ===");
    shared_state();
}
```

**解释**：

- `thread::spawn` 创建新线程
- `move` 关键字移动所有权到线程
- `Arc<Mutex<T>>` 提供线程安全的共享状态
- `join()` 等待线程完成
- `lock()` 获取互斥锁

## 进阶示例

在实际场景中应用并发编程概念：

```rust
use std::sync::{Arc, Mutex, RwLock};
use std::sync::mpsc;
use std::collections::HashMap;
use std::time::{Duration, Instant};

// 消息传递示例
#[derive(Debug, Clone)]
enum Message {
    Add(i32),
    Get,
    Stop,
}

struct Worker {
    id: u32,
    receiver: mpsc::Receiver<Message>,
    sender: mpsc::Sender<i32>,
}

impl Worker {
    fn new(id: u32, receiver: mpsc::Receiver<Message>, sender: mpsc::Sender<i32>) -> Self {
        Worker { id, receiver, sender }
    }
    
    fn run(&self) {
        let mut sum = 0;
        
        while let Ok(msg) = self.receiver.recv() {
            match msg {
                Message::Add(value) => {
                    sum += value;
                    println!("工作线程 {} 添加 {}, 当前和: {}", self.id, value, sum);
                }
                Message::Get => {
                    let _ = self.sender.send(sum);
                }
                Message::Stop => {
                    println!("工作线程 {} 停止", self.id);
                    break;
                }
            }
        }
    }
}

// 线程池实现
struct ThreadPool {
    workers: Vec<Worker>,
    sender: mpsc::Sender<Message>,
}

impl ThreadPool {
    fn new(size: usize) -> Self {
        let (sender, receiver) = mpsc::channel();
        let receiver = Arc::new(Mutex::new(receiver));
        let mut workers = Vec::with_capacity(size);
        
        for id in 0..size {
            let receiver = Arc::clone(&receiver);
            let (worker_sender, worker_receiver) = mpsc::channel();
            
            let worker = Worker::new(id as u32, worker_receiver, worker_sender);
            workers.push(worker);
        }
        
        ThreadPool { workers, sender }
    }
    
    fn execute(&self, message: Message) -> Result<(), mpsc::SendError<Message>> {
        self.sender.send(message)
    }
}

// 读写锁示例
struct Cache {
    data: RwLock<HashMap<String, String>>,
}

impl Cache {
    fn new() -> Self {
        Cache {
            data: RwLock::new(HashMap::new()),
        }
    }
    
    fn set(&self, key: String, value: String) {
        let mut data = self.data.write().unwrap();
        data.insert(key, value);
    }
    
    fn get(&self, key: &str) -> Option<String> {
        let data = self.data.read().unwrap();
        data.get(key).cloned()
    }
}

// 原子操作示例
use std::sync::atomic::{AtomicUsize, Ordering};

struct AtomicCounter {
    count: AtomicUsize,
}

impl AtomicCounter {
    fn new() -> Self {
        AtomicCounter {
            count: AtomicUsize::new(0),
        }
    }
    
    fn increment(&self) {
        self.count.fetch_add(1, Ordering::SeqCst);
    }
    
    fn get(&self) -> usize {
        self.count.load(Ordering::SeqCst)
    }
}

// 条件变量示例
use std::sync::Condvar;

struct ProducerConsumer {
    data: Mutex<Vec<i32>>,
    not_empty: Condvar,
    not_full: Condvar,
    capacity: usize,
}

impl ProducerConsumer {
    fn new(capacity: usize) -> Self {
        ProducerConsumer {
            data: Mutex::new(Vec::new()),
            not_empty: Condvar::new(),
            not_full: Condvar::new(),
            capacity,
        }
    }
    
    fn produce(&self, value: i32) {
        let mut data = self.data.lock().unwrap();
        
        while data.len() >= self.capacity {
            data = self.not_full.wait(data).unwrap();
        }
        
        data.push(value);
        println!("生产: {}", value);
        self.not_empty.notify_one();
    }
    
    fn consume(&self) -> Option<i32> {
        let mut data = self.data.lock().unwrap();
        
        while data.is_empty() {
            data = self.not_empty.wait(data).unwrap();
        }
        
        let value = data.remove(0);
        println!("消费: {}", value);
        self.not_full.notify_one();
        Some(value)
    }
}

fn main() {
    // 消息传递示例
    println!("=== 消息传递示例 ===");
    let (tx, rx) = mpsc::channel();
    let (result_tx, result_rx) = mpsc::channel();
    
    let worker = Worker::new(1, rx, result_tx);
    let worker_handle = thread::spawn(move || worker.run());
    
    // 发送消息
    tx.send(Message::Add(10)).unwrap();
    tx.send(Message::Add(20)).unwrap();
    tx.send(Message::Get).unwrap();
    tx.send(Message::Stop).unwrap();
    
    worker_handle.join().unwrap();
    
    if let Ok(sum) = result_rx.recv() {
        println!("最终结果: {}", sum);
    }
    
    // 线程池示例
    println!("\n=== 线程池示例 ===");
    let pool = ThreadPool::new(4);
    
    for i in 0..10 {
        pool.execute(Message::Add(i)).unwrap();
    }
    
    // 缓存示例
    println!("\n=== 读写锁缓存示例 ===");
    let cache = Arc::new(Cache::new());
    let cache_clone = Arc::clone(&cache);
    
    // 写入线程
    let write_handle = thread::spawn(move || {
        for i in 0..5 {
            cache_clone.set(format!("key{}", i), format!("value{}", i));
            thread::sleep(Duration::from_millis(100));
        }
    });
    
    // 读取线程
    let cache_clone = Arc::clone(&cache);
    let read_handle = thread::spawn(move || {
        for i in 0..5 {
            if let Some(value) = cache_clone.get(&format!("key{}", i)) {
                println!("读取: key{} = {}", i, value);
            }
            thread::sleep(Duration::from_millis(50));
        }
    });
    
    write_handle.join().unwrap();
    read_handle.join().unwrap();
    
    // 原子计数器示例
    println!("\n=== 原子计数器示例 ===");
    let counter = Arc::new(AtomicCounter::new());
    let mut handles = vec![];
    
    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            for _ in 0..1000 {
                counter.increment();
            }
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    println!("原子计数器最终值: {}", counter.get());
    
    // 生产者消费者示例
    println!("\n=== 生产者消费者示例 ===");
    let pc = Arc::new(ProducerConsumer::new(3));
    let pc_clone = Arc::clone(&pc);
    
    // 生产者线程
    let producer_handle = thread::spawn(move || {
        for i in 0..10 {
            pc_clone.produce(i);
            thread::sleep(Duration::from_millis(200));
        }
    });
    
    // 消费者线程
    let pc_clone = Arc::clone(&pc);
    let consumer_handle = thread::spawn(move || {
        for _ in 0..10 {
            pc_clone.consume();
            thread::sleep(Duration::from_millis(300));
        }
    });
    
    producer_handle.join().unwrap();
    consumer_handle.join().unwrap();
}
```

**解释**：

- 消息传递使用 `mpsc::channel` 实现线程间通信
- 线程池管理多个工作线程
- 读写锁 `RwLock` 允许多个读取者或一个写入者
- 原子操作 `AtomicUsize` 提供无锁的线程安全操作
- 条件变量 `Condvar` 实现线程同步

## 边界情况

展示并发编程的边界条件和复杂情况：

```rust
use std::sync::{Arc, Mutex, RwLock, Barrier};
use std::sync::atomic::{AtomicBool, Ordering};
use std::collections::VecDeque;

// 死锁示例和避免
struct Philosopher {
    id: usize,
    left_fork: Arc<Mutex<()>>,
    right_fork: Arc<Mutex<()>>,
}

impl Philosopher {
    fn new(id: usize, left_fork: Arc<Mutex<()>>, right_fork: Arc<Mutex<()>>) -> Self {
        Philosopher { id, left_fork, right_fork }
    }
    
    fn eat(&self) {
        // 避免死锁：总是先拿编号小的叉子
        let (first, second) = if self.id % 2 == 0 {
            (&self.left_fork, &self.right_fork)
        } else {
            (&self.right_fork, &self.left_fork)
        };
        
        let _first = first.lock().unwrap();
        let _second = second.lock().unwrap();
        
        println!("哲学家 {} 正在吃饭", self.id);
        thread::sleep(Duration::from_millis(100));
        println!("哲学家 {} 吃完", self.id);
    }
}

// 饥饿避免
struct FairQueue<T> {
    queue: Mutex<VecDeque<T>>,
    waiting: AtomicUsize,
}

impl<T> FairQueue<T> {
    fn new() -> Self {
        FairQueue {
            queue: Mutex::new(VecDeque::new()),
            waiting: AtomicUsize::new(0),
        }
    }
    
    fn push(&self, item: T) {
        let mut queue = self.queue.lock().unwrap();
        queue.push_back(item);
    }
    
    fn pop(&self) -> Option<T> {
        self.waiting.fetch_add(1, Ordering::SeqCst);
        let result = {
            let mut queue = self.queue.lock().unwrap();
            queue.pop_front()
        };
        self.waiting.fetch_sub(1, Ordering::SeqCst);
        result
    }
}

// 内存屏障和顺序
struct MemoryOrderingExample {
    flag: AtomicBool,
    data: Mutex<String>,
}

impl MemoryOrderingExample {
    fn new() -> Self {
        MemoryOrderingExample {
            flag: AtomicBool::new(false),
            data: Mutex::new(String::new()),
        }
    }
    
    fn set_data(&self, value: String) {
        let mut data = self.data.lock().unwrap();
        *data = value;
        // 使用Release顺序确保数据在标志之前写入
        self.flag.store(true, Ordering::Release);
    }
    
    fn get_data(&self) -> Option<String> {
        // 使用Acquire顺序确保在读取数据之前看到标志
        if self.flag.load(Ordering::Acquire) {
            let data = self.data.lock().unwrap();
            Some(data.clone())
        } else {
            None
        }
    }
}

// 线程本地存储
use std::cell::RefCell;
use std::thread_local;

thread_local! {
    static THREAD_ID: RefCell<Option<u64>> = RefCell::new(None);
}

fn set_thread_id(id: u64) {
    THREAD_ID.with(|thread_id| {
        *thread_id.borrow_mut() = Some(id);
    });
}

fn get_thread_id() -> Option<u64> {
    THREAD_ID.with(|thread_id| {
        thread_id.borrow().clone()
    })
}

// 异步任务调度
struct TaskScheduler {
    tasks: Mutex<Vec<Box<dyn FnOnce() + Send>>>,
    workers: Vec<thread::JoinHandle<()>>,
    shutdown: AtomicBool,
}

impl TaskScheduler {
    fn new(worker_count: usize) -> Self {
        let tasks = Mutex::new(Vec::new());
        let shutdown = AtomicBool::new(false);
        let mut workers = Vec::new();
        
        for _ in 0..worker_count {
            let tasks = Arc::new(tasks.clone());
            let shutdown = Arc::new(shutdown.clone());
            
            let handle = thread::spawn(move || {
                while !shutdown.load(Ordering::Relaxed) {
                    let task = {
                        let mut tasks = tasks.lock().unwrap();
                        tasks.pop()
                    };
                    
                    if let Some(task) = task {
                        task();
                    } else {
                        thread::sleep(Duration::from_millis(10));
                    }
                }
            });
            
            workers.push(handle);
        }
        
        TaskScheduler { tasks, workers, shutdown }
    }
    
    fn submit<F>(&self, task: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let mut tasks = self.tasks.lock().unwrap();
        tasks.push(Box::new(task));
    }
    
    fn shutdown(self) {
        self.shutdown.store(true, Ordering::Relaxed);
        for worker in self.workers {
            worker.join().unwrap();
        }
    }
}

// 并发测试
fn concurrent_test() {
    let counter = Arc::new(AtomicUsize::new(0));
    let barrier = Arc::new(Barrier::new(10));
    let mut handles = vec![];
    
    for i in 0..10 {
        let counter = Arc::clone(&counter);
        let barrier = Arc::clone(&barrier);
        
        let handle = thread::spawn(move || {
            // 等待所有线程准备就绪
            barrier.wait();
            
            // 并发增加计数器
            for _ in 0..1000 {
                counter.fetch_add(1, Ordering::Relaxed);
            }
        });
        
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    println!("并发测试结果: {}", counter.load(Ordering::Relaxed));
}

fn main() {
    // 哲学家进餐问题
    println!("=== 哲学家进餐问题 ===");
    let forks: Vec<Arc<Mutex<()>>> = (0..5).map(|_| Arc::new(Mutex::new(()))).collect();
    let mut philosophers = vec![];
    
    for i in 0..5 {
        let left_fork = Arc::clone(&forks[i]);
        let right_fork = Arc::clone(&forks[(i + 1) % 5]);
        philosophers.push(Philosopher::new(i, left_fork, right_fork));
    }
    
    let mut handles = vec![];
    for philosopher in philosophers {
        let handle = thread::spawn(move || {
            for _ in 0..3 {
                philosopher.eat();
                thread::sleep(Duration::from_millis(100));
            }
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    // 公平队列测试
    println!("\n=== 公平队列测试 ===");
    let queue = Arc::new(FairQueue::new());
    let queue_clone = Arc::clone(&queue);
    
    // 生产者
    let producer_handle = thread::spawn(move || {
        for i in 0..10 {
            queue_clone.push(i);
            thread::sleep(Duration::from_millis(50));
        }
    });
    
    // 消费者
    let queue_clone = Arc::clone(&queue);
    let consumer_handle = thread::spawn(move || {
        for _ in 0..10 {
            if let Some(item) = queue_clone.pop() {
                println!("消费: {}", item);
            }
            thread::sleep(Duration::from_millis(100));
        }
    });
    
    producer_handle.join().unwrap();
    consumer_handle.join().unwrap();
    
    // 内存顺序测试
    println!("\n=== 内存顺序测试 ===");
    let example = Arc::new(MemoryOrderingExample::new());
    let example_clone = Arc::clone(&example);
    
    let writer_handle = thread::spawn(move || {
        example_clone.set_data("重要数据".to_string());
    });
    
    let example_clone = Arc::clone(&example);
    let reader_handle = thread::spawn(move || {
        while let None = example_clone.get_data() {
            thread::sleep(Duration::from_millis(10));
        }
        if let Some(data) = example_clone.get_data() {
            println!("读取到数据: {}", data);
        }
    });
    
    writer_handle.join().unwrap();
    reader_handle.join().unwrap();
    
    // 线程本地存储测试
    println!("\n=== 线程本地存储测试 ===");
    let mut handles = vec![];
    
    for i in 0..5 {
        let handle = thread::spawn(move || {
            set_thread_id(i as u64);
            if let Some(id) = get_thread_id() {
                println!("线程本地ID: {}", id);
            }
        });
        handles.push(handle);
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    // 任务调度器测试
    println!("\n=== 任务调度器测试 ===");
    let scheduler = TaskScheduler::new(4);
    
    for i in 0..10 {
        let scheduler = Arc::new(&scheduler);
        scheduler.submit(move || {
            println!("执行任务 {}", i);
            thread::sleep(Duration::from_millis(100));
        });
    }
    
    thread::sleep(Duration::from_millis(2000));
    
    // 并发测试
    println!("\n=== 并发测试 ===");
    concurrent_test();
}
```

**解释**：

- 哲学家进餐问题展示死锁避免策略
- 公平队列防止饥饿问题
- 内存顺序确保正确的内存可见性
- 线程本地存储提供线程隔离的数据
- 任务调度器实现异步任务处理
- 并发测试验证正确性

## 常见错误

展示与并发编程相关的常见错误及修正：

```rust
fn main() {
    // 错误1: 数据竞争
    // let counter = 0;
    // let handle = thread::spawn(|| {
    //     counter += 1; // 错误：数据竞争
    // });
    
    // 错误2: 死锁
    // let mutex1 = Arc::new(Mutex::new(()));
    // let mutex2 = Arc::new(Mutex::new(()));
    // let handle1 = thread::spawn(move || {
    //     let _lock1 = mutex1.lock().unwrap();
    //     let _lock2 = mutex2.lock().unwrap(); // 可能死锁
    // });
    
    // 错误3: 忘记join
    // thread::spawn(|| {
    //     println!("线程执行");
    // }); // 错误：主线程可能先结束
    
    // 错误4: 错误的共享状态
    // let data = vec![1, 2, 3];
    // let handle = thread::spawn(|| {
    //     println!("{:?}", data); // 错误：没有move
    // });
}
```

**错误原因**：

- 数据竞争：多个线程同时访问可变数据
- 死锁：线程相互等待对方释放锁
- 忘记join：主线程提前结束导致子线程被强制终止
- 错误的共享状态：没有正确移动所有权

**正确版本**：

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // 修正1: 使用原子操作或互斥锁
    let counter = Arc::new(Mutex::new(0));
    let counter_clone = Arc::clone(&counter);
    let handle = thread::spawn(move || {
        let mut count = counter_clone.lock().unwrap();
        *count += 1;
    });
    handle.join().unwrap();
    
    // 修正2: 避免死锁
    let mutex1 = Arc::new(Mutex::new(()));
    let mutex2 = Arc::new(Mutex::new(()));
    let handle1 = thread::spawn(move || {
        let _lock1 = mutex1.lock().unwrap();
        let _lock2 = mutex2.lock().unwrap();
    });
    handle1.join().unwrap();
    
    // 修正3: 总是join线程
    let handle = thread::spawn(|| {
        println!("线程执行");
    });
    handle.join().unwrap();
    
    // 修正4: 正确移动所有权
    let data = vec![1, 2, 3];
    let handle = thread::spawn(move || {
        println!("{:?}", data);
    });
    handle.join().unwrap();
}
```

## 性能考量

讨论并发编程的性能特征：

- **线程创建开销**：线程创建有固定开销，适合长时间运行的任务
- **锁竞争**：频繁的锁竞争会降低性能
- **内存使用**：每个线程需要独立的栈空间
- **上下文切换**：过多的线程会增加上下文切换开销
- **缓存局部性**：线程间数据共享可能影响缓存性能

## 最佳实践

提供使用并发编程的最佳实践建议：

1. **优先使用消息传递**：避免共享可变状态
2. **使用适当的同步原语**：根据需求选择锁、原子操作或通道
3. **避免死锁**：使用一致的锁获取顺序
4. **合理使用线程池**：避免频繁创建和销毁线程
5. **正确处理错误**：在并发环境中妥善处理错误
6. **使用原子操作**：对于简单操作使用原子类型
7. **测试并发代码**：编写专门的并发测试
8. **监控性能**：使用性能分析工具监控并发能

## 相关资源

- [Rust并发编程](https://doc.rust-lang.org/book/ch16-00-concurrency.html)
- [std::thread](https://doc.rust-lang.org/std/thread/)
- [std::sync](https://doc.rust-lang.org/std/sync/)
- [Rayon库](https://docs.rs/rayon/)
- [Tokio异步运行时](https://tokio.rs/)

"

---

<!-- 以下为按标准模板自动补全的占位章节，待后续填充 -->
"
## 概述
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 技术背景
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 核心概念
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 技术实现
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 形式化分析
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 应用案例
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 性能分析
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 常见问题
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n
## 未来值值展望
(待补充，参考 STANDARD_DOCUMENT_TEMPLATE_2025.md)\n




## 未来展望

### 理论发展方向
- **类型系统扩展**: 更强大的类型系统功能
- **形式化验证**: 更完整的数学证明
- **并发模型**: 更安全的并发编程模型

### 工程应用前景
- **高性能计算**: 在HPC领域的应用
- **系统编程**: 操作系统和嵌入式系统
- **Web开发**: WebAssembly和前端开发

### 技术演进趋势
- **编译器优化**: 更智能的编译优化
- **工具链完善**: 更强大的开发工具
- **生态系统**: 更丰富的第三方库

### 社区发展
- **标准化**: 语言特性的标准化
- **教育**: 更好的学习资源
- **企业采用**: 更多企业的采用和支持

