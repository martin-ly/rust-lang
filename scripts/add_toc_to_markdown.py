#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ºMarkdownæ–‡ä»¶è‡ªåŠ¨æ·»åŠ ç›®å½•(Table of Contents)

åŠŸèƒ½ï¼š
1. æ‰«ææ‰€æœ‰.mdæ–‡ä»¶
2. æ£€æµ‹æ˜¯å¦å·²æœ‰ç›®å½•
3. è‡ªåŠ¨ç”Ÿæˆç›®å½•
4. æ’å…¥åˆ°æ–‡ä»¶å¼€å¤´
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Optional

class MarkdownTOCGenerator:
    def __init__(self, root_dir: str):
        self.root_dir = Path(root_dir)
        self.stats = {
            'total': 0,
            'with_toc': 0,
            'without_toc': 0,
            'added_toc': 0,
            'skipped': 0,
            'errors': 0
        }
        
    def has_toc(self, content: str) -> bool:
        """æ£€æµ‹æ–‡æ¡£æ˜¯å¦å·²æœ‰ç›®å½•"""
        # å¸¸è§çš„ç›®å½•æ ‡è¯†
        toc_patterns = [
            r'##?\s*ç›®å½•',
            r'##?\s*ğŸ“Š\s*ç›®å½•',
            r'##?\s*Table of Contents',
            r'##?\s*TOC',
            r'<!-- TOC -->',
            r'\[TOC\]',
        ]
        
        for pattern in toc_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return True
        return False
    
    def extract_headers(self, content: str) -> List[Tuple[int, str, str]]:
        """æå–æ‰€æœ‰æ ‡é¢˜
        è¿”å›: [(level, title, anchor), ...]
        """
        headers = []
        lines = content.split('\n')
        
        for line in lines:
            # åŒ¹é… Markdown æ ‡é¢˜
            match = re.match(r'^(#{1,6})\s+(.+)$', line)
            if match:
                level = len(match.group(1))
                title = match.group(2).strip()
                
                # è·³è¿‡ç¬¬ä¸€çº§æ ‡é¢˜ï¼ˆæ–‡æ¡£æ ‡é¢˜ï¼‰
                if level == 1:
                    continue
                
                # ç”Ÿæˆé”šç‚¹
                anchor = self.generate_anchor(title)
                headers.append((level, title, anchor))
        
        return headers
    
    def generate_anchor(self, title: str) -> str:
        """ç”ŸæˆGitHubé£æ ¼çš„é”šç‚¹"""
        # ç§»é™¤emojiå’Œç‰¹æ®Šå­—ç¬¦
        anchor = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', title)
        # è½¬å°å†™å¹¶æ›¿æ¢ç©ºæ ¼ä¸º-
        anchor = anchor.lower().strip().replace(' ', '-')
        # ç§»é™¤è¿ç»­çš„-
        anchor = re.sub(r'-+', '-', anchor)
        return anchor
    
    def generate_toc(self, headers: List[Tuple[int, str, str]]) -> str:
        """ç”Ÿæˆç›®å½•å†…å®¹"""
        if not headers:
            return ""
        
        toc_lines = ["## ğŸ“Š ç›®å½•\n"]
        
        for level, title, anchor in headers:
            # ç¼©è¿›ï¼ˆä»äºŒçº§æ ‡é¢˜å¼€å§‹ï¼ŒäºŒçº§æ ‡é¢˜ä¸ç¼©è¿›ï¼‰
            indent = "  " * (level - 2)
            toc_lines.append(f"{indent}- [{title}](#{anchor})")
        
        toc_lines.append("")  # ç©ºè¡Œ
        return "\n".join(toc_lines)
    
    def should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡è¯¥æ–‡ä»¶"""
        skip_patterns = [
            'README.md',
            'CHANGELOG.md',
            'LICENSE.md',
            'CONTRIBUTING.md',
            '/target/',
            '/node_modules/',
            '/.git/',
        ]
        
        file_str = str(file_path)
        for pattern in skip_patterns:
            if pattern in file_str:
                return True
        return False
    
    def add_toc_to_file(self, file_path: Path, dry_run: bool = False) -> bool:
        """ä¸ºæ–‡ä»¶æ·»åŠ ç›®å½•
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            dry_run: å¦‚æœä¸ºTrueï¼Œåªæ£€æµ‹ä¸ä¿®æ”¹
            
        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›®å½•
            if self.has_toc(content):
                self.stats['with_toc'] += 1
                return False
            
            self.stats['without_toc'] += 1
            
            # æå–æ ‡é¢˜
            headers = self.extract_headers(content)
            
            # å¦‚æœæ ‡é¢˜å¤ªå°‘ï¼Œè·³è¿‡
            if len(headers) < 3:
                self.stats['skipped'] += 1
                return False
            
            # ç”Ÿæˆç›®å½•
            toc = self.generate_toc(headers)
            
            if not toc:
                self.stats['skipped'] += 1
                return False
            
            # æ‰¾åˆ°æ’å…¥ä½ç½®ï¼ˆåœ¨æ–‡æ¡£å…ƒä¿¡æ¯ä¹‹åï¼‰
            lines = content.split('\n')
            insert_pos = 0
            
            # è·³è¿‡æ–‡æ¡£æ ‡é¢˜å’Œå…ƒä¿¡æ¯
            for i, line in enumerate(lines):
                if i == 0 and line.startswith('#'):
                    insert_pos = i + 1
                    continue
                if line.startswith('>'):
                    insert_pos = i + 1
                    continue
                if line.strip() == '---':
                    insert_pos = i + 1
                    continue
                if line.strip() == '':
                    continue
                break
            
            # è·³è¿‡ç©ºè¡Œ
            while insert_pos < len(lines) and lines[insert_pos].strip() == '':
                insert_pos += 1
            
            if not dry_run:
                # æ’å…¥ç›®å½•
                new_content = '\n'.join(lines[:insert_pos]) + '\n\n' + toc + '\n' + '\n'.join(lines[insert_pos:])
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                self.stats['added_toc'] += 1
                print(f"âœ… Added TOC: {file_path}")
            else:
                print(f"ğŸ” Would add TOC: {file_path}")
            
            return True
            
        except Exception as e:
            self.stats['errors'] += 1
            print(f"âŒ Error processing {file_path}: {e}")
            return False
    
    def process_directory(self, directory: str = None, dry_run: bool = False):
        """å¤„ç†æ•´ä¸ªç›®å½•"""
        if directory is None:
            directory = self.root_dir
        else:
            directory = Path(directory)
        
        print(f"\n{'='*60}")
        print(f"æ‰«æç›®å½•: {directory}")
        print(f"æ¨¡å¼: {'æ£€æµ‹æ¨¡å¼ (ä¸ä¿®æ”¹)' if dry_run else 'ä¿®æ”¹æ¨¡å¼'}")
        print(f"{'='*60}\n")
        
        md_files = list(directory.rglob('*.md'))
        self.stats['total'] = len(md_files)
        
        for md_file in md_files:
            if self.should_skip_file(md_file):
                continue
            
            self.add_toc_to_file(md_file, dry_run)
        
        self.print_stats()
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{'='*60}")
        print("ç»Ÿè®¡ç»“æœ")
        print(f"{'='*60}")
        print(f"æ€»æ–‡ä»¶æ•°:       {self.stats['total']}")
        print(f"å·²æœ‰ç›®å½•:       {self.stats['with_toc']}")
        print(f"ç¼ºå°‘ç›®å½•:       {self.stats['without_toc']}")
        print(f"æ·»åŠ ç›®å½•:       {self.stats['added_toc']}")
        print(f"è·³è¿‡æ–‡ä»¶:       {self.stats['skipped']} (æ ‡é¢˜å¤ªå°‘æˆ–ç‰¹æ®Šæ–‡ä»¶)")
        print(f"å¤„ç†é”™è¯¯:       {self.stats['errors']}")
        print(f"{'='*60}\n")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ä¸ºMarkdownæ–‡ä»¶è‡ªåŠ¨æ·»åŠ ç›®å½•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ£€æµ‹æ¨¡å¼ï¼ˆä¸ä¿®æ”¹æ–‡ä»¶ï¼‰
  python add_toc_to_markdown.py --dry-run
  
  # å®é™…æ·»åŠ ç›®å½•
  python add_toc_to_markdown.py
  
  # æŒ‡å®šç›®å½•
  python add_toc_to_markdown.py --dir crates/c01_ownership_borrow_scope
        """
    )
    
    parser.add_argument(
        '--dir',
        default='.',
        help='è¦å¤„ç†çš„ç›®å½•ï¼ˆé»˜è®¤: å½“å‰ç›®å½•ï¼‰'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='æ£€æµ‹æ¨¡å¼ï¼Œåªæ˜¾ç¤ºä¼šä¿®æ”¹ä»€ä¹ˆï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶'
    )
    
    args = parser.parse_args()
    
    generator = MarkdownTOCGenerator(args.dir)
    generator.process_directory(dry_run=args.dry_run)


if __name__ == '__main__':
    main()

