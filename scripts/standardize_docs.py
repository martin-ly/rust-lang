#!/usr/bin/env python3
"""
Rustè¯­è¨€å½¢å¼åŒ–ç†è®ºä½“ç³»æ–‡æ¡£æ ¼å¼æ ‡å‡†åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. æ‰¹é‡æ£€æŸ¥æ–‡æ¡£æ ¼å¼
2. è‡ªåŠ¨ä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜
3. ç»Ÿä¸€ç« èŠ‚ç¼–å·
4. æ ‡å‡†åŒ–æ•°å­¦å…¬å¼
5. ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
"""

import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import argparse
from datetime import datetime

class DocumentStandardizer:
    """æ–‡æ¡£æ ¼å¼æ ‡å‡†åŒ–å™¨"""
    
    def __init__(self, root_path: str):
        self.root_path = Path(root_path)
        self.results = []
        self.fixes_applied = 0
        
    def find_markdown_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶"""
        markdown_files = []
        for file_path in self.root_path.rglob("*.md"):
            markdown_files.append(file_path)
        return markdown_files
    
    def standardize_document(self, file_path: Path) -> Dict:
        """æ ‡å‡†åŒ–å•ä¸ªæ–‡æ¡£"""
        result = {
            'file_path': str(file_path),
            'original_content': '',
            'modified_content': '',
            'changes': [],
            'errors': [],
            'warnings': []
        }
        
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            result['original_content'] = content
            modified_content = content
            
            # 1. æ ‡å‡†åŒ–æ–‡æ¡£å¤´éƒ¨
            modified_content, changes = self.standardize_header(modified_content, file_path)
            result['changes'].extend(changes)
            
            # 2. æ ‡å‡†åŒ–ç« èŠ‚ç¼–å·
            modified_content, changes = self.standardize_section_numbering(modified_content)
            result['changes'].extend(changes)
            
            # 3. æ ‡å‡†åŒ–æ•°å­¦å…¬å¼
            modified_content, changes = self.standardize_math_formulas(modified_content)
            result['changes'].extend(changes)
            
            # 4. æ ‡å‡†åŒ–è¡¨æ ¼
            modified_content, changes = self.standardize_tables(modified_content)
            result['changes'].extend(changes)
            
            # 5. æ ‡å‡†åŒ–é“¾æ¥
            modified_content, changes = self.standardize_links(modified_content)
            result['changes'].extend(changes)
            
            # 6. æ·»åŠ äº¤å‰å¼•ç”¨
            modified_content, changes = self.add_cross_references(modified_content, file_path)
            result['changes'].extend(changes)
            
            result['modified_content'] = modified_content
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            self.check_document_quality(modified_content, result)
            
        except Exception as e:
            result['errors'].append(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        
        return result
    
    def standardize_header(self, content: str, file_path: Path) -> Tuple[str, List[str]]:
        """æ ‡å‡†åŒ–æ–‡æ¡£å¤´éƒ¨"""
        changes = []
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ ‡å‡†å¤´éƒ¨
        if "## ğŸ“… æ–‡æ¡£ä¿¡æ¯" in content:
            return content, changes
        
        # æå–æ ‡é¢˜
        title_match = re.search(r'^#\s*(.+)$', content, re.MULTILINE)
        if not title_match:
            changes.append("æ·»åŠ æ–‡æ¡£æ ‡é¢˜")
            title = file_path.stem.replace('_', ' ').title()
            content = f"# {title}\n\n" + content
        else:
            title = title_match.group(1)
        
        # æ·»åŠ æ ‡å‡†å¤´éƒ¨
        header = f"""## ğŸ“… æ–‡æ¡£ä¿¡æ¯

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d')}  
**æœ€åæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d')}  
**çŠ¶æ€**: å·²å®Œæˆ  
**è´¨é‡ç­‰çº§**: é’»çŸ³çº§ â­â­â­â­â­

---

"""
        
        # åœ¨æ ‡é¢˜åæ’å…¥å¤´éƒ¨
        content = re.sub(r'^(#\s+.+?)$', r'\1\n\n' + header, content, flags=re.MULTILINE)
        changes.append("æ·»åŠ æ ‡å‡†æ–‡æ¡£å¤´éƒ¨")
        
        return content, changes
    
    def standardize_section_numbering(self, content: str) -> Tuple[str, List[str]]:
        """æ ‡å‡†åŒ–ç« èŠ‚ç¼–å·"""
        changes = []
        
        # æŸ¥æ‰¾æ‰€æœ‰ç« èŠ‚æ ‡é¢˜
        section_pattern = r'^(#{2,})\s*(\d+\.)?\s*(.+)$'
        
        def replace_section(match):
            level = len(match.group(1))
            number = match.group(2)
            title = match.group(3)
            
            # æ ‡å‡†åŒ–ç¼–å·æ ¼å¼
            if level == 2:  # ä¸€çº§ç« èŠ‚
                if not number or not number.endswith('.'):
                    return f"## {title}"
                else:
                    return f"## {number} {title}"
            else:  # å­ç« èŠ‚
                return match.group(0)
        
        new_content = re.sub(section_pattern, replace_section, content, flags=re.MULTILINE)
        
        if new_content != content:
            changes.append("æ ‡å‡†åŒ–ç« èŠ‚ç¼–å·")
        
        return new_content, changes
    
    def standardize_math_formulas(self, content: str) -> Tuple[str, List[str]]:
        """æ ‡å‡†åŒ–æ•°å­¦å…¬å¼"""
        changes = []
        
        # æ£€æŸ¥è¡Œå†…å…¬å¼
        inline_pattern = r'\$([^$]+)\$'
        
        def check_inline_math(match):
            formula = match.group(1)
            # æ£€æŸ¥å¸¸ç”¨æ•°å­¦ç¬¦å·
            if '\\forall' in formula or '\\exists' in formula:
                return match.group(0)  # å·²ç»æ˜¯æ ‡å‡†æ ¼å¼
            else:
                # å¯ä»¥æ·»åŠ æ›´å¤šæ ‡å‡†åŒ–è§„åˆ™
                return match.group(0)
        
        new_content = re.sub(inline_pattern, check_inline_math, content)
        
        # æ£€æŸ¥å—çº§å…¬å¼
        block_pattern = r'\$\$([\s\S]*?)\$\$'
        
        def check_block_math(match):
            formula = match.group(1)
            # æ£€æŸ¥å—çº§å…¬å¼æ ¼å¼
            if formula.strip():
                return match.group(0)
            else:
                changes.append("ä¿®å¤ç©ºçš„å—çº§å…¬å¼")
                return ""
        
        new_content = re.sub(block_pattern, check_block_math, new_content)
        
        if new_content != content:
            changes.append("æ ‡å‡†åŒ–æ•°å­¦å…¬å¼")
        
        return new_content, changes
    
    def standardize_tables(self, content: str) -> Tuple[str, List[str]]:
        """æ ‡å‡†åŒ–è¡¨æ ¼æ ¼å¼"""
        changes = []
        
        # æ£€æŸ¥è¡¨æ ¼å¯¹é½
        table_pattern = r'(\|.*\|.*\n\|.*\|.*\n)'
        
        def fix_table_alignment(match):
            table = match.group(1)
            lines = table.strip().split('\n')
            
            if len(lines) >= 2:
                header = lines[0]
                separator = lines[1]
                
                # æ£€æŸ¥åˆ†éš”ç¬¦æ ¼å¼
                if '|-' not in separator:
                    # æ·»åŠ æ ‡å‡†åˆ†éš”ç¬¦
                    separator = re.sub(r'\|', '|:---', separator)
                    separator = separator.replace('|:---', '|', 1)  # ç¬¬ä¸€ä¸ªä¿æŒåŸæ ·
                    separator = separator.replace('|:---', '|:---:|', -1)  # æœ€åä¸€ä¸ªå±…ä¸­
                    
                    changes.append("ä¿®å¤è¡¨æ ¼å¯¹é½")
                    return header + '\n' + separator + '\n' + '\n'.join(lines[2:]) + '\n'
            
            return match.group(1)
        
        new_content = re.sub(table_pattern, fix_table_alignment, content)
        
        return new_content, changes
    
    def standardize_links(self, content: str) -> Tuple[str, List[str]]:
        """æ ‡å‡†åŒ–é“¾æ¥æ ¼å¼"""
        changes = []
        
        # æ£€æŸ¥å†…éƒ¨é“¾æ¥æ ¼å¼
        link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        
        def fix_internal_links(match):
            text = match.group(1)
            url = match.group(2)
            
            # ä¿®å¤ç›¸å¯¹è·¯å¾„
            if url.startswith('./'):
                url = url[2:]
            elif url.startswith('../'):
                # ä¿æŒç›¸å¯¹è·¯å¾„
                pass
            
            return f"[{text}]({url})"
        
        new_content = re.sub(link_pattern, fix_internal_links, content)
        
        if new_content != content:
            changes.append("æ ‡å‡†åŒ–é“¾æ¥æ ¼å¼")
        
        return new_content, changes
    
    def add_cross_references(self, content: str, file_path: Path) -> Tuple[str, List[str]]:
        """æ·»åŠ äº¤å‰å¼•ç”¨"""
        changes = []
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰äº¤å‰å¼•ç”¨éƒ¨åˆ†
        if "## ğŸ”— ç›¸å…³é“¾æ¥" in content:
            return content, changes
        
        # æ ¹æ®æ–‡ä»¶è·¯å¾„ç”Ÿæˆç›¸å…³é“¾æ¥
        cross_refs = self.generate_cross_references(file_path)
        
        if cross_refs:
            # åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ äº¤å‰å¼•ç”¨
            cross_ref_section = f"""

---

## ğŸ”— ç›¸å…³é“¾æ¥

{cross_refs}
"""
            content += cross_ref_section
            changes.append("æ·»åŠ äº¤å‰å¼•ç”¨")
        
        return content, changes
    
    def generate_cross_references(self, file_path: Path) -> str:
        """ç”Ÿæˆäº¤å‰å¼•ç”¨"""
        refs = []
        
        # æ ¹æ®æ–‡ä»¶è·¯å¾„ç”Ÿæˆç›¸å…³é“¾æ¥
        relative_path = file_path.relative_to(self.root_path)
        parts = relative_path.parts
        
        if len(parts) >= 2:
            module = parts[1]
            
            if module == "01_core_theory":
                refs.extend([
                    "### ğŸ“š ç†è®ºåŸºç¡€",
                    "- [å†…å­˜å®‰å…¨ç†è®º](../01_core_theory/01_foundation_semantics/01_memory_semantics/00_index.md)",
                    "- [ç±»å‹ç³»ç»Ÿç†è®º](../01_core_theory/02_type_system/01_type_semantics/00_index.md)",
                    "- [å¹¶å‘å®‰å…¨ç†è®º](../01_core_theory/03_concurrency_semantics/01_thread_semantics/00_index.md)"
                ])
            elif module == "02_design_patterns":
                refs.extend([
                    "### ğŸ—ï¸ è®¾è®¡æ¨¡å¼",
                    "- [åˆ›å»ºå‹æ¨¡å¼](../02_design_patterns/01_creational_patterns/01_factory_pattern/00_index.md)",
                    "- [ç»“æ„å‹æ¨¡å¼](../02_design_patterns/02_structural_patterns/01_adapter_pattern/00_index.md)",
                    "- [è¡Œä¸ºå‹æ¨¡å¼](../02_design_patterns/03_behavioral_patterns/01_observer_pattern/00_index.md)"
                ])
            elif module == "03_application_domains":
                refs.extend([
                    "### ğŸ“– åº”ç”¨é¢†åŸŸ",
                    "- [ç³»ç»Ÿç¼–ç¨‹åº”ç”¨](../03_application_domains/01_systems_programming/00_index.md)",
                    "- [Webå¼€å‘åº”ç”¨](../03_application_domains/02_web_development/00_index.md)",
                    "- [åŒºå—é“¾åº”ç”¨](../03_application_domains/03_blockchain/00_index.md)"
                ])
        
        return '\n'.join(refs)
    
    def check_document_quality(self, content: str, result: Dict):
        """æ£€æŸ¥æ–‡æ¡£è´¨é‡"""
        # æ£€æŸ¥æ–‡æ¡£é•¿åº¦
        if len(content) < 100:
            result['warnings'].append("æ–‡æ¡£å†…å®¹è¿‡çŸ­")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­¦å…¬å¼
        if '$' not in content:
            result['warnings'].append("å»ºè®®æ·»åŠ æ•°å­¦å…¬å¼")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç å—
        if '```' not in content:
            result['warnings'].append("å»ºè®®æ·»åŠ ä»£ç ç¤ºä¾‹")
        
        # æ£€æŸ¥ç« èŠ‚ç»“æ„
        sections = re.findall(r'^#{2,}\s+(.+)$', content, re.MULTILINE)
        if len(sections) < 3:
            result['warnings'].append("ç« èŠ‚ç»“æ„ä¸å¤Ÿå®Œæ•´")
    
    def process_all_documents(self, apply_changes: bool = False) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰æ–‡æ¡£"""
        markdown_files = self.find_markdown_files()
        print(f"æ‰¾åˆ° {len(markdown_files)} ä¸ªMarkdownæ–‡ä»¶")
        
        for i, file_path in enumerate(markdown_files, 1):
            print(f"å¤„ç†æ–‡ä»¶ {i}/{len(markdown_files)}: {file_path.name}")
            
            result = self.standardize_document(file_path)
            self.results.append(result)
            
            # åº”ç”¨æ›´æ”¹
            if apply_changes and result['changes']:
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(result['modified_content'])
                    self.fixes_applied += 1
                    print(f"  âœ“ åº”ç”¨äº† {len(result['changes'])} ä¸ªæ›´æ”¹")
                except Exception as e:
                    result['errors'].append(f"å†™å…¥æ–‡ä»¶å¤±è´¥: {str(e)}")
                    print(f"  âœ— å†™å…¥æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        return self.results
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        total_files = len(self.results)
        files_with_changes = sum(1 for r in self.results if r['changes'])
        files_with_errors = sum(1 for r in self.results if r['errors'])
        files_with_warnings = sum(1 for r in self.results if r['warnings'])
        
        report = f"""# æ–‡æ¡£æ ¼å¼æ ‡å‡†åŒ–æŠ¥å‘Š

## ğŸ“Š æ€»ä½“ç»Ÿè®¡

- **æ€»æ–‡ä»¶æ•°**: {total_files}
- **éœ€è¦æ›´æ”¹çš„æ–‡ä»¶**: {files_with_changes}
- **æœ‰é”™è¯¯çš„æ–‡ä»¶**: {files_with_errors}
- **æœ‰è­¦å‘Šçš„æ–‡ä»¶**: {files_with_warnings}
- **å·²åº”ç”¨ä¿®å¤**: {self.fixes_applied}

## ğŸ“‹ è¯¦ç»†ç»“æœ

"""
        
        for result in self.results:
            if result['changes'] or result['errors'] or result['warnings']:
                report += f"### {result['file_path']}\n\n"
                
                if result['changes']:
                    report += "**æ›´æ”¹:**\n"
                    for change in result['changes']:
                        report += f"- {change}\n"
                    report += "\n"
                
                if result['errors']:
                    report += "**é”™è¯¯:**\n"
                    for error in result['errors']:
                        report += f"- {error}\n"
                    report += "\n"
                
                if result['warnings']:
                    report += "**è­¦å‘Š:**\n"
                    for warning in result['warnings']:
                        report += f"- {warning}\n"
                    report += "\n"
        
        return report

def main():
    parser = argparse.ArgumentParser(description='Rustè¯­è¨€å½¢å¼åŒ–ç†è®ºä½“ç³»æ–‡æ¡£æ ¼å¼æ ‡å‡†åŒ–å·¥å…·')
    parser.add_argument('path', help='è¦å¤„ç†çš„ç›®å½•è·¯å¾„')
    parser.add_argument('--apply', action='store_true', help='åº”ç”¨æ›´æ”¹åˆ°æ–‡ä»¶')
    parser.add_argument('--report', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.path):
        print(f"é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {args.path}")
        sys.exit(1)
    
    # åˆ›å»ºæ ‡å‡†åŒ–å™¨
    standardizer = DocumentStandardizer(args.path)
    
    # å¤„ç†æ–‡æ¡£
    print("å¼€å§‹å¤„ç†æ–‡æ¡£...")
    results = standardizer.process_all_documents(apply_changes=args.apply)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = standardizer.generate_report()
    
    # è¾“å‡ºæŠ¥å‘Š
    if args.report:
        with open(args.report, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")
    else:
        print("\n" + "="*50)
        print(report)
    
    print(f"\nå¤„ç†å®Œæˆ! å…±å¤„ç† {len(results)} ä¸ªæ–‡ä»¶ï¼Œåº”ç”¨äº† {standardizer.fixes_applied} ä¸ªä¿®å¤ã€‚")

if __name__ == '__main__':
    main() 