// ğŸ” Rust å­¦ä¹ é¡¹ç›® - æ™ºèƒ½æ–‡æ¡£æœç´¢å·¥å…·
// ç‰ˆæœ¬: v1.1
// åˆ›å»ºæ—¥æœŸ: 2025-10-20
// æ›´æ–°æ—¥æœŸ: 2025-10-20

use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};
use serde::{Deserialize, Serialize};

/// æœç´¢ç»“æœé¡¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SearchResult {
    /// æ–‡ä»¶è·¯å¾„
    pub file_path: String,
    /// åŒ¹é…è¡Œå·
    pub line_number: usize,
    /// åŒ¹é…å†…å®¹ï¼ˆä¸Šä¸‹æ–‡ï¼‰
    pub context: String,
    /// ç›¸å…³æ€§åˆ†æ•°
    pub relevance_score: f64,
    /// æ–‡æ¡£ç±»å‹
    pub doc_type: DocumentType,
    /// æ¨¡å—åç§°
    pub module: String,
}

/// æ–‡æ¡£ç±»å‹
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum DocumentType {
    /// ğŸ“Š çŸ¥è¯†å›¾è°±
    KnowledgeGraph,
    /// ğŸ“ å¤šç»´çŸ©é˜µ
    ComparisonMatrix,
    /// ğŸ—ºï¸ æ€ç»´å¯¼å›¾
    MindMap,
    /// ğŸ’» å®æˆ˜ç¤ºä¾‹
    Examples,
    /// ğŸ“‹ å¢å¼ºæŠ¥å‘Š
    Report,
    /// ğŸ“˜ ä¸»æ–‡æ¡£
    MainDoc,
    /// ğŸ“ ç†è®ºæ–‡æ¡£
    Theory,
}

/// æ–‡æ¡£ç´¢å¼•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DocumentIndex {
    /// æ–‡æ¡£è·¯å¾„åˆ°å†…å®¹çš„æ˜ å°„
    pub documents: HashMap<String, DocumentContent>,
    /// å…³é”®è¯ç´¢å¼•
    pub keyword_index: HashMap<String, Vec<String>>,
    /// æ¨¡å—ç´¢å¼•
    pub module_index: HashMap<String, Vec<String>>,
}

/// æ–‡æ¡£å†…å®¹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DocumentContent {
    pub path: String,
    pub doc_type: DocumentType,
    pub module: String,
    pub lines: Vec<String>,
    pub keywords: Vec<String>,
}

/// æ™ºèƒ½æ–‡æ¡£æœç´¢å™¨
pub struct DocSearcher {
    index: DocumentIndex,
    config: Config,
}

impl DocSearcher {
    /// åˆ›å»ºæ–°çš„æœç´¢å™¨å¹¶æ„å»ºç´¢å¼•
    pub fn new(root_path: &Path) -> Result<Self, Box<dyn std::error::Error>> {
        let config = Config::load_or_default();
        Self::new_with_config(root_path, config)
    }
    
    /// ä½¿ç”¨æŒ‡å®šé…ç½®åˆ›å»ºæœç´¢å™¨
    pub fn new_with_config(root_path: &Path, config: Config) -> Result<Self, Box<dyn std::error::Error>> {
        // å°è¯•ä»ç¼“å­˜åŠ è½½ç´¢å¼•
        let index = if config.incremental_index {
            if let Some(cache_path) = &config.cache_path.or_else(|| IndexCache::default_cache_path()) {
                if cache_path.exists() {
                    if let Ok(cache) = IndexCache::load(cache_path) {
                        if cache.is_valid() && cache.metadata.source_path == root_path {
                            println!("âœ… ä»ç¼“å­˜åŠ è½½ç´¢å¼•");
                            cache.index
                        } else {
                            Self::build_and_cache_index(root_path, cache_path)?
                        }
                    } else {
                        Self::build_and_cache_index(root_path, cache_path)?
                    }
                } else {
                    Self::build_and_cache_index(root_path, cache_path)?
                }
            } else {
                Self::build_index(root_path)?
            }
        } else {
            Self::build_index(root_path)?
        };
        
        Ok(Self { index, config })
    }
    
    /// æ„å»ºç´¢å¼•å¹¶ç¼“å­˜
    fn build_and_cache_index(root_path: &Path, cache_path: &Path) -> Result<DocumentIndex, Box<dyn std::error::Error>> {
        let index = Self::build_index(root_path)?;
        
        // ä¿å­˜ç¼“å­˜
        let cache = IndexCache::new(index.clone(), root_path.to_path_buf());
        cache.save(cache_path)?;
        
        Ok(index)
    }

    /// æ„å»ºæ–‡æ¡£ç´¢å¼•
    fn build_index(root_path: &Path) -> Result<DocumentIndex, Box<dyn std::error::Error>> {
        let mut documents = HashMap::new();
        let mut keyword_index = HashMap::new();
        let mut module_index = HashMap::new();

        // éå† crates ç›®å½•
        let crates_path = root_path.join("crates");
        if crates_path.exists() {
            for entry in fs::read_dir(&crates_path)? {
                let entry = entry?;
                let module_path = entry.path();
                
                if module_path.is_dir() {
                    let module_name = module_path
                        .file_name()
                        .unwrap()
                        .to_string_lossy()
                        .to_string();
                    
                    Self::index_module(&module_path, &module_name, &mut documents, &mut keyword_index, &mut module_index)?;
                }
            }
        }

        // ç´¢å¼•æ ¹ç›®å½•æ–‡æ¡£
        Self::index_root_docs(root_path, &mut documents, &mut keyword_index)?;

        Ok(DocumentIndex {
            documents,
            keyword_index,
            module_index,
        })
    }

    /// ç´¢å¼•æ¨¡å—æ–‡æ¡£
    fn index_module(
        module_path: &Path,
        module_name: &str,
        documents: &mut HashMap<String, DocumentContent>,
        keyword_index: &mut HashMap<String, Vec<String>>,
        module_index: &mut HashMap<String, Vec<String>>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        // ç´¢å¼• docs ç›®å½•
        let docs_paths = vec![
            module_path.join("docs"),
            module_path.join("docs/theory"),
            module_path.join("docs/theory_enhanced"),
        ];

        for docs_path in docs_paths {
            if docs_path.exists() {
                Self::index_directory(&docs_path, module_name, documents, keyword_index, module_index)?;
            }
        }

        // ç´¢å¼•æ¨¡å—æ ¹ç›®å½•çš„ README å’ŒæŠ¥å‘Š
        for file_name in &["README.md", format!("{}_COMPREHENSIVE_ENHANCEMENT_REPORT_2025_10_20.md", module_name.to_uppercase())] {
            let file_path = module_path.join(file_name);
            if file_path.exists() {
                Self::index_file(&file_path, module_name, documents, keyword_index, module_index)?;
            }
        }

        Ok(())
    }

    /// ç´¢å¼•æ ¹ç›®å½•æ–‡æ¡£
    fn index_root_docs(
        root_path: &Path,
        documents: &mut HashMap<String, DocumentContent>,
        keyword_index: &mut HashMap<String, Vec<String>>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let root_docs = vec![
            "README.md",
            "GLOBAL_THEORETICAL_FRAMEWORK_2025_10_20.md",
            "COMPREHENSIVE_ENHANCEMENT_FINAL_REPORT_2025_10_20.md",
            "MASTER_DOCUMENTATION_INDEX.md",
            "QUICK_START_GUIDE_2025_10_20.md",
            "PRACTICAL_PROJECTS_ROADMAP_2025_10_20.md",
            "DOCUMENTATION_TOOLCHAIN_DESIGN_2025_10_20.md",
            "FINAL_IMPLEMENTATION_SUMMARY_2025_10_20.md",
        ];

        for doc in root_docs {
            let file_path = root_path.join(doc);
            if file_path.exists() {
                Self::index_file(&file_path, "root", documents, keyword_index, &mut HashMap::new())?;
            }
        }

        Ok(())
    }

    /// ç´¢å¼•ç›®å½•
    fn index_directory(
        dir_path: &Path,
        module_name: &str,
        documents: &mut HashMap<String, DocumentContent>,
        keyword_index: &mut HashMap<String, Vec<String>>,
        module_index: &mut HashMap<String, Vec<String>>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        for entry in fs::read_dir(dir_path)? {
            let entry = entry?;
            let path = entry.path();
            
            if path.is_file() && path.extension().and_then(|s| s.to_str()) == Some("md") {
                Self::index_file(&path, module_name, documents, keyword_index, module_index)?;
            }
        }
        Ok(())
    }

    /// ç´¢å¼•å•ä¸ªæ–‡ä»¶
    fn index_file(
        file_path: &Path,
        module_name: &str,
        documents: &mut HashMap<String, DocumentContent>,
        keyword_index: &mut HashMap<String, Vec<String>>,
        module_index: &mut HashMap<String, Vec<String>>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let content = fs::read_to_string(file_path)?;
        let lines: Vec<String> = content.lines().map(|s| s.to_string()).collect();
        
        let path_str = file_path.to_string_lossy().to_string();
        let doc_type = Self::detect_doc_type(&path_str);
        let keywords = Self::extract_keywords(&content);

        // æ›´æ–°å…³é”®è¯ç´¢å¼•
        for keyword in &keywords {
            keyword_index
                .entry(keyword.clone())
                .or_insert_with(Vec::new)
                .push(path_str.clone());
        }

        // æ›´æ–°æ¨¡å—ç´¢å¼•
        module_index
            .entry(module_name.to_string())
            .or_insert_with(Vec::new)
            .push(path_str.clone());

        // å­˜å‚¨æ–‡æ¡£å†…å®¹
        documents.insert(
            path_str.clone(),
            DocumentContent {
                path: path_str,
                doc_type,
                module: module_name.to_string(),
                lines,
                keywords,
            },
        );

        Ok(())
    }

    /// æ£€æµ‹æ–‡æ¡£ç±»å‹
    fn detect_doc_type(path: &str) -> DocumentType {
        if path.contains("KNOWLEDGE_GRAPH") {
            DocumentType::KnowledgeGraph
        } else if path.contains("MULTI_DIMENSIONAL") || path.contains("COMPARISON_MATRIX") {
            DocumentType::ComparisonMatrix
        } else if path.contains("MINDMAP") {
            DocumentType::MindMap
        } else if path.contains("EXAMPLES") {
            DocumentType::Examples
        } else if path.contains("REPORT") {
            DocumentType::Report
        } else if path.contains("THEORETICAL_FRAMEWORK") {
            DocumentType::Theory
        } else {
            DocumentType::MainDoc
        }
    }

    /// æå–å…³é”®è¯
    fn extract_keywords(content: &str) -> Vec<String> {
        let keywords = vec![
            // æ ¸å¿ƒæ¦‚å¿µ
            "æ‰€æœ‰æƒ", "ownership", "å€Ÿç”¨", "borrow", "ç”Ÿå‘½å‘¨æœŸ", "lifetime",
            "ç±»å‹ç³»ç»Ÿ", "type system", "æ³›å‹", "generic", "trait",
            "å¹¶å‘", "concurrency", "å¼‚æ­¥", "async", "å¤šçº¿ç¨‹", "thread",
            
            // Rust ç‰¹æ€§
            "Send", "Sync", "Arc", "Mutex", "RwLock", "Channel",
            "Future", "Pin", "Box", "Rc", "RefCell",
            
            // è®¾è®¡æ¨¡å¼
            "Builder", "Factory", "Singleton", "Observer", "Strategy",
            "Actor", "Reactor", "CSP",
            
            // ç½‘ç»œç›¸å…³
            "TCP", "UDP", "HTTP", "WebSocket", "gRPC", "MQTT", "QUIC",
            "io_uring", "é›¶æ‹·è´", "zero-copy",
            
            // ç†è®º
            "Hindley-Milner", "çº¿æ€§ç±»å‹", "ä»¿å°„ç±»å‹", "èŒƒç•´è®º",
            "åˆ†ç¦»é€»è¾‘", "å½¢å¼åŒ–", "è¯­ä¹‰",
        ];

        keywords
            .into_iter()
            .filter(|&kw| content.contains(kw))
            .map(|s| s.to_string())
            .collect()
    }

    /// æ‰§è¡Œæœç´¢
    pub fn search(&self, query: &str, options: &SearchOptions) -> Vec<SearchResult> {
        // æ ¹æ®æœç´¢æ¨¡å¼é€‰æ‹©ä¸åŒçš„æœç´¢æ–¹æ³•
        match &options.search_mode {
            SearchMode::Plain => self.search_plain(query, options),
            SearchMode::Regex => self.search_regex(query, options),
            SearchMode::Fuzzy => self.search_fuzzy(query, options),
        }
    }
    
    /// æ™®é€šæœç´¢
    fn search_plain(&self, query: &str, options: &SearchOptions) -> Vec<SearchResult> {
        let mut results = Vec::new();
        let query_lower = query.to_lowercase();
        let query_terms: Vec<&str> = query_lower.split_whitespace().collect();

        for (path, doc_content) in &self.index.documents {
            // è¿‡æ»¤æ¨¡å—
            if let Some(module_filter) = &options.module_filter {
                if &doc_content.module != module_filter {
                    continue;
                }
            }

            // è¿‡æ»¤æ–‡æ¡£ç±»å‹
            if let Some(type_filter) = &options.type_filter {
                if &doc_content.doc_type != type_filter {
                    continue;
                }
            }

            // æœç´¢åŒ¹é…è¡Œ
            for (line_num, line) in doc_content.lines.iter().enumerate() {
                let line_lower = line.to_lowercase();
                
                // è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
                let mut score = 0.0;
                let mut matches = 0;
                
                for term in &query_terms {
                    if line_lower.contains(term) {
                        matches += 1;
                        score += 1.0;
                        
                        // æ ‡é¢˜åŒ¹é…åŠ åˆ†
                        if line.starts_with('#') {
                            score += 2.0;
                        }
                        
                        // ä»£ç å—åŒ¹é…åŠ åˆ†
                        if line.starts_with("```") {
                            score += 0.5;
                        }
                    }
                }

                // å…³é”®è¯åŒ¹é…åŠ åˆ†
                for keyword in &doc_content.keywords {
                    if query_lower.contains(&keyword.to_lowercase()) {
                        score += 1.5;
                    }
                }

                if matches > 0 && score >= options.min_score {
                    // è·å–ä¸Šä¸‹æ–‡
                    let context = Self::get_context(&doc_content.lines, line_num, options.context_lines);
                    
                    results.push(SearchResult {
                        file_path: path.clone(),
                        line_number: line_num + 1,
                        context,
                        relevance_score: score,
                        doc_type: doc_content.doc_type.clone(),
                        module: doc_content.module.clone(),
                    });
                }
            }
        }

        // æ’åºå’Œé™åˆ¶ç»“æœ
        self.finalize_results(results, options)
    }
    
    /// æ­£åˆ™è¡¨è¾¾å¼æœç´¢
    fn search_regex(&self, pattern: &str, options: &SearchOptions) -> Vec<SearchResult> {
        let regex_searcher = match RegexSearcher::new(pattern) {
            Ok(s) => s,
            Err(_) => return Vec::new(),
        };
        
        let mut results = Vec::new();
        
        for (path, doc_content) in &self.index.documents {
            if !self.should_include_document(doc_content, options) {
                continue;
            }
            
            let matches = regex_searcher.find_in_lines(&doc_content.lines);
            
            for (line_num, line_matches) in matches {
                let score = line_matches.len() as f64 * 2.0; // æ­£åˆ™åŒ¹é…ç»™äºˆæ›´é«˜åˆ†æ•°
                
                if score >= options.min_score {
                    let context = Self::get_context(&doc_content.lines, line_num, options.context_lines);
                    
                    results.push(SearchResult {
                        file_path: path.clone(),
                        line_number: line_num + 1,
                        context,
                        relevance_score: score,
                        doc_type: doc_content.doc_type.clone(),
                        module: doc_content.module.clone(),
                    });
                }
            }
        }
        
        self.finalize_results(results, options)
    }
    
    /// æ¨¡ç³Šæœç´¢
    fn search_fuzzy(&self, query: &str, options: &SearchOptions) -> Vec<SearchResult> {
        let fuzzy_searcher = FuzzySearcher::new(self.config.advanced.fuzzy_threshold);
        let mut results = Vec::new();
        
        for (path, doc_content) in &self.index.documents {
            if !self.should_include_document(doc_content, options) {
                continue;
            }
            
            let matches = fuzzy_searcher.fuzzy_match_lines(query, &doc_content.lines);
            
            for (line_num, score) in matches {
                if score >= options.min_score {
                    let context = Self::get_context(&doc_content.lines, line_num, options.context_lines);
                    
                    results.push(SearchResult {
                        file_path: path.clone(),
                        line_number: line_num + 1,
                        context,
                        relevance_score: score * 10.0, // å½’ä¸€åŒ–åˆ†æ•°
                        doc_type: doc_content.doc_type.clone(),
                        module: doc_content.module.clone(),
                    });
                }
            }
        }
        
        self.finalize_results(results, options)
    }
    
    /// æ£€æŸ¥æ˜¯å¦åº”è¯¥åŒ…å«è¯¥æ–‡æ¡£
    fn should_include_document(&self, doc_content: &DocumentContent, options: &SearchOptions) -> bool {
        // è¿‡æ»¤æ¨¡å—
        if let Some(module_filter) = &options.module_filter {
            if &doc_content.module != module_filter {
                return false;
            }
        }
        
        // è¿‡æ»¤æ–‡æ¡£ç±»å‹
        if let Some(type_filter) = &options.type_filter {
            if &doc_content.doc_type != type_filter {
                return false;
            }
        }
        
        true
    }
    
    /// å®Œæˆç»“æœå¤„ç†ï¼ˆæ’åºå’Œé™åˆ¶ï¼‰
    fn finalize_results(&self, mut results: Vec<SearchResult>, options: &SearchOptions) -> Vec<SearchResult> {
        // æ’åºç»“æœ
        results.sort_by(|a, b| {
            b.relevance_score
                .partial_cmp(&a.relevance_score)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        // é™åˆ¶ç»“æœæ•°é‡
        results.truncate(options.max_results);
        results
    }

    /// è·å–ä¸Šä¸‹æ–‡
    fn get_context(lines: &[String], line_num: usize, context_lines: usize) -> String {
        let start = line_num.saturating_sub(context_lines);
        let end = (line_num + context_lines + 1).min(lines.len());
        
        lines[start..end].join("\n")
    }

    /// æŒ‰æ¨¡å—æœç´¢
    pub fn search_by_module(&self, module: &str) -> Vec<String> {
        self.index
            .module_index
            .get(module)
            .cloned()
            .unwrap_or_default()
    }

    /// æŒ‰å…³é”®è¯æœç´¢
    pub fn search_by_keyword(&self, keyword: &str) -> Vec<String> {
        self.index
            .keyword_index
            .get(keyword)
            .cloned()
            .unwrap_or_default()
    }

    /// è·å–æ‰€æœ‰æ¨¡å—
    pub fn get_modules(&self) -> Vec<String> {
        self.index.module_index.keys().cloned().collect()
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn get_stats(&self) -> SearchStats {
        SearchStats {
            total_documents: self.index.documents.len(),
            total_modules: self.index.module_index.len(),
            total_keywords: self.index.keyword_index.len(),
            documents_by_type: self.count_by_type(),
        }
    }

    /// æŒ‰ç±»å‹ç»Ÿè®¡æ–‡æ¡£
    fn count_by_type(&self) -> HashMap<DocumentType, usize> {
        let mut counts = HashMap::new();
        for doc in self.index.documents.values() {
            *counts.entry(doc.doc_type.clone()).or_insert(0) += 1;
        }
        counts
    }
}

/// æœç´¢æ¨¡å¼
#[derive(Debug, Clone)]
pub enum SearchMode {
    /// æ™®é€šæœç´¢
    Plain,
    /// æ­£åˆ™è¡¨è¾¾å¼æœç´¢
    Regex,
    /// æ¨¡ç³Šæœç´¢
    Fuzzy,
}

/// æœç´¢é€‰é¡¹
#[derive(Debug, Clone)]
pub struct SearchOptions {
    /// æ¨¡å—è¿‡æ»¤
    pub module_filter: Option<String>,
    /// æ–‡æ¡£ç±»å‹è¿‡æ»¤
    pub type_filter: Option<DocumentType>,
    /// æœ€å°ç›¸å…³æ€§åˆ†æ•°
    pub min_score: f64,
    /// æœ€å¤§ç»“æœæ•°é‡
    pub max_results: usize,
    /// æœç´¢æ¨¡å¼
    pub search_mode: SearchMode,
    /// ä¸Šä¸‹æ–‡è¡Œæ•°
    pub context_lines: usize,
}

impl Default for SearchOptions {
    fn default() -> Self {
        Self {
            module_filter: None,
            type_filter: None,
            min_score: 1.0,
            max_results: 50,
            search_mode: SearchMode::Plain,
            context_lines: 2,
        }
    }
}

/// æœç´¢ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SearchStats {
    pub total_documents: usize,
    pub total_modules: usize,
    pub total_keywords: usize,
    pub documents_by_type: HashMap<DocumentType, usize>,
}

mod cli;
mod config;
mod export;
mod cache;
mod fuzzy;

pub use config::{Config, ExportFormat};
pub use export::export_results;
pub use cache::{IndexCache, CacheMetadata};
pub use fuzzy::{FuzzySearcher, RegexSearcher, SearchPattern};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    cli::run()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_doc_type_detection() {
        assert_eq!(
            DocSearcher::detect_doc_type("docs/theory/KNOWLEDGE_GRAPH_AND_CONCEPT_RELATIONS.md"),
            DocumentType::KnowledgeGraph
        );
        assert_eq!(
            DocSearcher::detect_doc_type("docs/MULTI_DIMENSIONAL_COMPARISON_MATRIX.md"),
            DocumentType::ComparisonMatrix
        );
    }

    #[test]
    fn test_keyword_extraction() {
        let content = "Rust æ‰€æœ‰æƒç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºå€Ÿç”¨æ£€æŸ¥çš„å†…å­˜å®‰å…¨æœºåˆ¶";
        let keywords = DocSearcher::extract_keywords(content);
        assert!(keywords.contains(&"æ‰€æœ‰æƒ".to_string()));
        assert!(keywords.contains(&"å€Ÿç”¨".to_string()));
    }
}

