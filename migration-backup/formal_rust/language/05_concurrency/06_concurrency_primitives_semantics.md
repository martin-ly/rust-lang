# å¹¶å‘åŸè¯­æ·±åº¦è¯­ä¹‰åˆ†æ

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

| å±æ€§ | å€¼ |
|------|-----|
| æ–‡æ¡£ç¼–å· | 05-06 |
| ä¸»é¢˜ | å¹¶å‘åŸè¯­æ·±åº¦è¯­ä¹‰ (Concurrency Primitives Deep Semantics) |
| ç‰ˆæœ¬ | 1.0.0 |
| åˆ›å»ºæ—¥æœŸ | 2025-01-01 |
| ä½œè€… | Rustè¯­è¨€è®¾è®¡è¯­ä¹‰æ¨¡å‹åˆ†ææ¡†æ¶ |
| çŠ¶æ€ | ä¸“å®¶çº§æ·±åº¦åˆ†æ â­â­â­â­â­ |

## ğŸ¯ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£å»ºç«‹Rustå¹¶å‘åŸè¯­çš„æ·±å±‚è¯­ä¹‰ç†è®ºæ¨¡å‹ï¼ŒåŸºäºè¿›ç¨‹ä»£æ•°ã€æ¨¡æ€é€»è¾‘å’Œåˆ†ç¦»é€»è¾‘ï¼Œæä¾›å¹¶å‘åŒæ­¥æœºåˆ¶çš„å®Œæ•´æ•°å­¦å½¢å¼åŒ–åˆ†æã€‚

### æ ¸å¿ƒè®®é¢˜

1. **äº’æ–¥é”è¯­ä¹‰** - Mutexçš„å…¬å¹³æ€§å’Œæ´»æ€§ä¿è¯
2. **è¯»å†™é”è¯­ä¹‰** - RwLockçš„å¹¶å‘è¯»å’Œç‹¬å å†™è¯­ä¹‰
3. **åŸå­æ“ä½œè¯­ä¹‰** - å†…å­˜åºå’ŒåŒæ­¥ä¿è¯
4. **æ¡ä»¶å˜é‡è¯­ä¹‰** - ç­‰å¾…å”¤é†’æœºåˆ¶çš„æ­£ç¡®æ€§
5. **é€šé“è¯­ä¹‰** - æ¶ˆæ¯ä¼ é€’çš„çº¿æ€§ç±»å‹ç†è®º
6. **å±éšœè¯­ä¹‰** - é›†ä½“åŒæ­¥çš„æ—¶åºæ¨¡å‹

## ğŸ§® ç†è®ºåŸºç¡€

### 1. å¹¶å‘è¯­ä¹‰çš„æ•°å­¦åŸºç¡€

#### 1.1 è¿›ç¨‹ä»£æ•°å»ºæ¨¡

**å®šä¹‰ 1.1**: **å¹¶å‘è¿›ç¨‹è¯­æ³•**

è®¾å¹¶å‘ç³»ç»Ÿçš„è¿›ç¨‹è¯­æ³•ä¸ºï¼š

$$P ::= \mathbf{0} \mid a.P \mid P + Q \mid P \parallel Q \mid \nu x.P \mid !P$$

å…¶ä¸­ï¼š

- $\mathbf{0}$ - ç©ºè¿›ç¨‹
- $a.P$ - åŠ¨ä½œå‰ç¼€
- $P + Q$ - é€‰æ‹©
- $P \parallel Q$ - å¹¶è¡Œç»„åˆ
- $\nu x.P$ - é™åˆ¶ï¼ˆç§æœ‰é€šé“ï¼‰
- $!P$ - å¤åˆ¶

**å®šä¹‰ 1.2**: **æ ‡å·è½¬æ¢ç³»ç»Ÿ (LTS)**

å¹¶å‘è¯­ä¹‰ç”±æ ‡å·è½¬æ¢ç³»ç»Ÿ $(S, L, \to)$ ç»™å‡ºï¼š

- $S$ - çŠ¶æ€é›†åˆ
- $L$ - æ ‡å·é›†åˆï¼ˆåŠ¨ä½œï¼‰
- $\to \subseteq S \times L \times S$ - è½¬æ¢å…³ç³»

### 2. åŒæ­¥åŸè¯­çš„æ¨¡æ€é€»è¾‘

#### 2.1 æ—¶åºé€»è¾‘è§„èŒƒ

**å®šä¹‰ 2.1**: **çº¿æ€§æ—¶åºé€»è¾‘ (LTL)**

å¯¹äºå¹¶å‘å±æ€§éªŒè¯ï¼Œä½¿ç”¨LTLå…¬å¼ï¼š

$$\phi ::= p \mid \neg\phi \mid \phi_1 \land \phi_2 \mid X\phi \mid \phi_1 U \phi_2$$

å…¶ä¸­ï¼š

- $p$ - åŸå­å‘½é¢˜
- $X\phi$ - "ä¸‹ä¸€ä¸ªçŠ¶æ€Ï†æˆç«‹"
- $\phi_1 U \phi_2$ - "Ï†â‚æŒç»­ç›´åˆ°Ï†â‚‚æˆç«‹"

**é‡è¦æ¨¡æ€**ï¼š

- $F\phi \equiv \mathbf{true} U \phi$ - "æœ€ç»ˆÏ†æˆç«‹"
- $G\phi \equiv \neg F\neg\phi$ - "æ€»æ˜¯Ï†æˆç«‹"

## ğŸ”’ äº’æ–¥é”è¯­ä¹‰

### 1. Mutexçš„å½¢å¼åŒ–æ¨¡å‹

#### 1.1 çŠ¶æ€æœºè¯­ä¹‰

```rust
// MutexçŠ¶æ€å®šä¹‰
#[derive(Clone, Copy, Debug, PartialEq)]
enum MutexState {
    Unlocked,
    Locked(ThreadId),
    Poisoned,
}

// æ“ä½œè¯­ä¹‰
impl MutexSemantics {
    fn lock_transition(state: MutexState, thread: ThreadId) 
        -> Result<MutexState, LockError> {
        match state {
            MutexState::Unlocked => Ok(MutexState::Locked(thread)),
            MutexState::Locked(_) => Err(LockError::WouldBlock),
            MutexState::Poisoned => Err(LockError::Poisoned),
        }
    }
    
    fn unlock_transition(state: MutexState, thread: ThreadId) 
        -> Result<MutexState, UnlockError> {
        match state {
            MutexState::Locked(owner) if owner == thread => {
                Ok(MutexState::Unlocked)
            }
            MutexState::Locked(_) => Err(UnlockError::NotOwner),
            _ => Err(UnlockError::NotLocked),
        }
    }
}
```

#### 1.2 ä¸å˜é‡å’Œæ€§è´¨

**å®šç† 1.1**: **äº’æ–¥æ€§ (Mutual Exclusion)**

$$G(\neg(\text{in\_cs}_i \land \text{in\_cs}_j)) \quad \forall i \neq j$$

è¯æ˜ï¼šMutexçš„çŠ¶æ€æœºä¿è¯æœ€å¤šä¸€ä¸ªçº¿ç¨‹æŒæœ‰é”ã€‚

**å®šç† 1.2**: **æ— é¥¥é¥¿æ€§ (Starvation Freedom)**

$$G(F(\text{want\_lock}_i \to F(\text{has\_lock}_i))) \quad \forall i$$

### 2. å…¬å¹³æ€§è¯­ä¹‰

```rust
// å…¬å¹³è°ƒåº¦çš„Mutexå®ç°
pub struct FairMutex<T> {
    data: UnsafeCell<T>,
    state: AtomicU64, // çŠ¶æ€ + ç­‰å¾…è®¡æ•°
    waiters: Mutex<VecDeque<ThreadId>>,
}

impl<T> FairMutex<T> {
    pub fn lock(&self) -> FairMutexGuard<T> {
        let current = thread::current().id();
        
        // FIFOé˜Ÿåˆ—ä¿è¯å…¬å¹³æ€§
        {
            let mut waiters = self.waiters.lock().unwrap();
            waiters.push_back(current);
        }
        
        // ç­‰å¾…è½®åˆ°è‡ªå·±
        loop {
            let waiters = self.waiters.lock().unwrap();
            if waiters.front() == Some(&current) {
                if self.try_acquire() {
                    drop(waiters);
                    let mut waiters = self.waiters.lock().unwrap();
                    waiters.pop_front();
                    break;
                }
            }
            drop(waiters);
            thread::yield_now();
        }
        
        FairMutexGuard { mutex: self }
    }
}
```

## ğŸ“š è¯»å†™é”è¯­ä¹‰

### 1. RwLockçš„å¹¶å‘è¯­ä¹‰

#### 1.1 è¯»è€…-å†™è€…é—®é¢˜å»ºæ¨¡

**å®šä¹‰ 3.1**: **RwLockçŠ¶æ€**

$$\text{RwLockState} = \text{Free} \mid \text{Reading}(n) \mid \text{Writing}(\text{tid})$$

å…¶ä¸­ $n \in \mathbb{N}$ æ˜¯å¹¶å‘è¯»è€…æ•°é‡ã€‚

```rust
// RwLockçŠ¶æ€è½¬æ¢
impl RwLockSemantics {
    fn read_lock(state: &RwLockState) -> Result<RwLockState, ReadError> {
        match state {
            RwLockState::Free => Ok(RwLockState::Reading(1)),
            RwLockState::Reading(n) => Ok(RwLockState::Reading(n + 1)),
            RwLockState::Writing(_) => Err(ReadError::WriterActive),
        }
    }
    
    fn write_lock(state: &RwLockState, tid: ThreadId) 
        -> Result<RwLockState, WriteError> {
        match state {
            RwLockState::Free => Ok(RwLockState::Writing(tid)),
            RwLockState::Reading(_) => Err(WriteError::ReadersActive),
            RwLockState::Writing(_) => Err(WriteError::WriterActive),
        }
    }
}
```

#### 1.2 è¯»å†™ä¼˜å…ˆçº§ç­–ç•¥

```rust
// å†™è€…ä¼˜å…ˆçš„RwLock
pub struct WriterPreferredRwLock<T> {
    data: UnsafeCell<T>,
    reader_count: AtomicUsize,
    writer_waiting: AtomicBool,
    writer_active: AtomicBool,
    read_waiters: Condvar,
    write_waiters: Condvar,
    mutex: Mutex<()>,
}

impl<T> WriterPreferredRwLock<T> {
    pub fn read(&self) -> ReadGuard<T> {
        let _lock = self.mutex.lock().unwrap();
        
        // ç­‰å¾…ç›´åˆ°æ²¡æœ‰å†™è€…ç­‰å¾…æˆ–æ´»è·ƒ
        while self.writer_waiting.load(Ordering::Acquire) 
            || self.writer_active.load(Ordering::Acquire) {
            self.read_waiters.wait(_lock).unwrap();
        }
        
        self.reader_count.fetch_add(1, Ordering::AcqRel);
        ReadGuard { lock: self }
    }
    
    pub fn write(&self) -> WriteGuard<T> {
        let _lock = self.mutex.lock().unwrap();
        
        // æ ‡è®°å†™è€…ç­‰å¾…
        self.writer_waiting.store(true, Ordering::Release);
        
        // ç­‰å¾…æ‰€æœ‰è¯»è€…å®Œæˆ
        while self.reader_count.load(Ordering::Acquire) > 0 {
            self.write_waiters.wait(_lock).unwrap();
        }
        
        self.writer_active.store(true, Ordering::Release);
        self.writer_waiting.store(false, Ordering::Release);
        
        WriteGuard { lock: self }
    }
}
```

## âš›ï¸ åŸå­æ“ä½œè¯­ä¹‰

### 1. å†…å­˜åºè¯­ä¹‰æ¨¡å‹

#### 1.1 Happens-Beforeå…³ç³»

**å®šä¹‰ 4.1**: **Happens-Beforeååº**

è®¾ $\prec$ ä¸ºhappens-beforeå…³ç³»ï¼Œæ»¡è¶³ï¼š

1. **ç¨‹åºåº**: åŒä¸€çº¿ç¨‹å†…çš„æ“ä½œæœ‰åº
2. **åŒæ­¥è¾¹**: åŒæ­¥æ“ä½œå»ºç«‹è·¨çº¿ç¨‹åºå…³ç³»
3. **ä¼ é€’æ€§**: $a \prec b \land b \prec c \Rightarrow a \prec c$

```rust
use std::sync::atomic::{AtomicBool, AtomicI32, Ordering};

// å†…å­˜åºç¤ºä¾‹
static FLAG: AtomicBool = AtomicBool::new(false);
static DATA: AtomicI32 = AtomicI32::new(0);

// ç”Ÿäº§è€…
fn producer() {
    DATA.store(42, Ordering::Relaxed);     // (1)
    FLAG.store(true, Ordering::Release);   // (2) - é‡Šæ”¾è¯­ä¹‰
}

// æ¶ˆè´¹è€…  
fn consumer() {
    while !FLAG.load(Ordering::Acquire) { // (3) - è·å–è¯­ä¹‰
        thread::yield_now();
    }
    let value = DATA.load(Ordering::Relaxed); // (4)
    assert_eq!(value, 42); // ä¿è¯æˆç«‹ï¼Œå› ä¸º (2) synchronizes-with (3)
}
```

#### 1.2 å†…å­˜åºçš„å½¢å¼åŒ–è¯­ä¹‰

**å®šä¹‰ 4.2**: **å†…å­˜åºå…³ç³»**

```rust
#[derive(Clone, Copy, Debug)]
pub enum MemoryOrdering {
    Relaxed,  // æ— åŒæ­¥çº¦æŸ
    Acquire,  // è·å–è¯­ä¹‰ï¼šåç»­æ“ä½œä¸èƒ½é‡æ’åˆ°å‰é¢
    Release,  // é‡Šæ”¾è¯­ä¹‰ï¼šå‰é¢æ“ä½œä¸èƒ½é‡æ’åˆ°åé¢  
    AcqRel,   // è·å–-é‡Šæ”¾ï¼šä¸¤ç§è¯­ä¹‰ç»“åˆ
    SeqCst,   // é¡ºåºä¸€è‡´ï¼šå…¨å±€çº¿æ€§åº
}

// å½¢å¼åŒ–è¯­ä¹‰
impl MemoryOrderingSemantics {
    fn happens_before(op1: &AtomicOperation, op2: &AtomicOperation) -> bool {
        match (op1.ordering, op2.ordering) {
            // Release-AcquireåŒæ­¥
            (MemoryOrdering::Release, MemoryOrdering::Acquire) 
                if op1.location == op2.location => true,
                
            // SeqCstæ“ä½œå»ºç«‹å…¨åº
            (MemoryOrdering::SeqCst, MemoryOrdering::SeqCst) => {
                op1.global_timestamp < op2.global_timestamp
            }
            
            _ => false,
        }
    }
}
```

### 2. æ— é”æ•°æ®ç»“æ„

```rust
// Michael & Scotté˜Ÿåˆ—ç®—æ³•
pub struct LockFreeQueue<T> {
    head: AtomicPtr<Node<T>>,
    tail: AtomicPtr<Node<T>>,
}

struct Node<T> {
    data: Option<T>,
    next: AtomicPtr<Node<T>>,
}

impl<T> LockFreeQueue<T> {
    pub fn enqueue(&self, item: T) {
        let new_node = Box::into_raw(Box::new(Node {
            data: Some(item),
            next: AtomicPtr::new(ptr::null_mut()),
        }));
        
        loop {
            let tail = self.tail.load(Ordering::Acquire);
            let next = unsafe { (*tail).next.load(Ordering::Acquire) };
            
            // æ£€æŸ¥tailæ˜¯å¦ä»ç„¶æŒ‡å‘å°¾èŠ‚ç‚¹
            if tail == self.tail.load(Ordering::Acquire) {
                if next.is_null() {
                    // å°è¯•é“¾æ¥æ–°èŠ‚ç‚¹
                    if unsafe { (*tail).next.compare_exchange_weak(
                        next, new_node, Ordering::Release, Ordering::Relaxed
                    ).is_ok() } {
                        break;
                    }
                } else {
                    // å¸®åŠ©æ¨è¿›tailæŒ‡é’ˆ
                    let _ = self.tail.compare_exchange_weak(
                        tail, next, Ordering::Release, Ordering::Relaxed
                    );
                }
            }
        }
        
        // æ¨è¿›tailæŒ‡é’ˆ
        let _ = self.tail.compare_exchange_weak(
            self.tail.load(Ordering::Acquire), 
            new_node, 
            Ordering::Release, 
            Ordering::Relaxed
        );
    }
}
```

## ğŸ”” æ¡ä»¶å˜é‡è¯­ä¹‰

### 1. ç­‰å¾…å”¤é†’æœºåˆ¶

#### 1.1 Mesaè¯­ä¹‰ vs Hoareè¯­ä¹‰

```rust
// Mesaè¯­ä¹‰ï¼šè¢«å”¤é†’åéœ€è¦é‡æ–°æ£€æŸ¥æ¡ä»¶
pub struct MesaCondvar {
    waiters: Mutex<VecDeque<ThreadId>>,
}

impl MesaCondvar {
    pub fn wait<T>(&self, guard: MutexGuard<T>) -> MutexGuard<T> {
        let mutex = guard.mutex_ptr();
        drop(guard); // é‡Šæ”¾é”
        
        // åŠ å…¥ç­‰å¾…é˜Ÿåˆ—
        {
            let mut waiters = self.waiters.lock().unwrap();
            waiters.push_back(thread::current().id());
        }
        
        // é˜»å¡ç­‰å¾…
        thread::park();
        
        // é‡æ–°è·å–é”
        mutex.lock()
    }
    
    pub fn notify_one(&self) {
        let mut waiters = self.waiters.lock().unwrap();
        if let Some(waiter) = waiters.pop_front() {
            thread::unpark(waiter);
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šç”Ÿäº§è€…-æ¶ˆè´¹è€…
fn consumer_loop(buffer: &Arc<Mutex<VecDeque<Item>>>, not_empty: &Condvar) {
    loop {
        let mut buf = buffer.lock().unwrap();
        
        // Mesaè¯­ä¹‰ï¼šå¾ªç¯ç­‰å¾…
        while buf.is_empty() {
            buf = not_empty.wait(buf).unwrap();
        }
        
        let item = buf.pop_front().unwrap();
        drop(buf);
        
        process_item(item);
    }
}
```

#### 1.2 è™šå‡å”¤é†’å¤„ç†

```rust
// æŠ—è™šå‡å”¤é†’çš„æ¡ä»¶å˜é‡ä½¿ç”¨
pub struct SafeCondvar {
    inner: Condvar,
    spurious_wakeup_count: AtomicUsize,
}

impl SafeCondvar {
    pub fn wait_while<T, F>(&self, mut guard: MutexGuard<T>, condition: F) 
        -> MutexGuard<T>
    where
        F: Fn(&T) -> bool,
    {
        while condition(&*guard) {
            guard = self.inner.wait(guard).unwrap();
            
            // è®°å½•å¯èƒ½çš„è™šå‡å”¤é†’
            self.spurious_wakeup_count.fetch_add(1, Ordering::Relaxed);
        }
        guard
    }
}
```

## ğŸ“¡ é€šé“è¯­ä¹‰

### 1. æ¶ˆæ¯ä¼ é€’çš„çº¿æ€§ç±»å‹

#### 1.1 çº¿æ€§é€šé“ç±»å‹

```rust
// çº¿æ€§ç±»å‹çš„é€šé“ï¼šæ¯ä¸ªæ¶ˆæ¯åªèƒ½æ¶ˆè´¹ä¸€æ¬¡
pub struct LinearSender<T> {
    inner: mpsc::Sender<T>,
    consumed: Cell<bool>,
}

impl<T> LinearSender<T> {
    pub fn send(self, msg: T) -> Result<(), SendError<T>> {
        if self.consumed.get() {
            panic!("Sender already consumed");
        }
        self.consumed.set(true);
        self.inner.send(msg).map_err(|_| SendError(msg))
    }
}

// ä¼šè¯ç±»å‹ç¼–ç 
trait SessionType {}

struct Send<T, S: SessionType>(PhantomData<(T, S)>);
struct Recv<T, S: SessionType>(PhantomData<(T, S)>);
struct End;

impl SessionType for End {}
impl<T, S: SessionType> SessionType for Send<T, S> {}
impl<T, S: SessionType> SessionType for Recv<T, S> {}

pub struct TypedChannel<S: SessionType> {
    sender: mpsc::Sender<Box<dyn Any + Send>>,
    receiver: mpsc::Receiver<Box<dyn Any + Send>>,
    _session: PhantomData<S>,
}
```

#### 1.2 åå‹å’Œæµæ§åˆ¶

```rust
// å¸¦åå‹çš„å¼‚æ­¥é€šé“
pub struct BackpressureChannel<T> {
    buffer: VecDeque<T>,
    capacity: usize,
    senders_waiting: VecDeque<Waker>,
    receivers_waiting: VecDeque<Waker>,
    closed: bool,
}

impl<T> BackpressureChannel<T> {
    pub async fn send(&mut self, item: T) -> Result<(), SendError> {
        if self.closed {
            return Err(SendError::Closed);
        }
        
        // ç­‰å¾…ç¼“å†²åŒºæœ‰ç©ºé—´
        while self.buffer.len() >= self.capacity {
            let waker = poll_fn(|cx| {
                self.senders_waiting.push_back(cx.waker().clone());
                Poll::Pending
            }).await;
        }
        
        self.buffer.push_back(item);
        
        // å”¤é†’ç­‰å¾…çš„æ¥æ”¶è€…
        if let Some(waker) = self.receivers_waiting.pop_front() {
            waker.wake();
        }
        
        Ok(())
    }
    
    pub async fn recv(&mut self) -> Result<T, RecvError> {
        // ç­‰å¾…ç¼“å†²åŒºæœ‰æ•°æ®
        while self.buffer.is_empty() && !self.closed {
            poll_fn(|cx| {
                self.receivers_waiting.push_back(cx.waker().clone());
                Poll::Pending
            }).await;
        }
        
        if let Some(item) = self.buffer.pop_front() {
            // å”¤é†’ç­‰å¾…çš„å‘é€è€…
            if let Some(waker) = self.senders_waiting.pop_front() {
                waker.wake();
            }
            Ok(item)
        } else {
            Err(RecvError::Closed)
        }
    }
}
```

## ğŸš§ å±éšœè¯­ä¹‰

### 1. é›†ä½“åŒæ­¥æ¨¡å‹

```rust
// å¾ªç¯å±éšœï¼šæ”¯æŒå¤šè½®åŒæ­¥
pub struct CyclicBarrier {
    count: AtomicUsize,
    waiting: AtomicUsize, 
    generation: AtomicUsize,
    mutex: Mutex<()>,
    condvar: Condvar,
}

impl CyclicBarrier {
    pub fn new(count: usize) -> Self {
        Self {
            count: AtomicUsize::new(count),
            waiting: AtomicUsize::new(0),
            generation: AtomicUsize::new(0),
            mutex: Mutex::new(()),
            condvar: Condvar::new(),
        }
    }
    
    pub fn wait(&self) -> BarrierWaitResult {
        let _guard = self.mutex.lock().unwrap();
        let gen = self.generation.load(Ordering::Acquire);
        
        let waiting = self.waiting.fetch_add(1, Ordering::AcqRel);
        
        if waiting + 1 == self.count.load(Ordering::Acquire) {
            // æœ€åä¸€ä¸ªåˆ°è¾¾çš„çº¿ç¨‹
            self.waiting.store(0, Ordering::Release);
            self.generation.fetch_add(1, Ordering::AcqRel);
            self.condvar.notify_all();
            BarrierWaitResult::Leader
        } else {
            // ç­‰å¾…å…¶ä»–çº¿ç¨‹
            loop {
                if self.generation.load(Ordering::Acquire) != gen {
                    break;
                }
                let _guard = self.condvar.wait(_guard).unwrap();
            }
            BarrierWaitResult::Follower
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹ï¼šå¹¶è¡Œç®—æ³•çš„é˜¶æ®µåŒæ­¥
fn parallel_matrix_multiply(a: &Matrix, b: &Matrix, c: &mut Matrix, 
                           thread_id: usize, barrier: &CyclicBarrier) {
    let rows_per_thread = a.rows / num_threads();
    let start_row = thread_id * rows_per_thread;
    let end_row = (thread_id + 1) * rows_per_thread;
    
    // é˜¶æ®µ1ï¼šè®¡ç®—å±€éƒ¨ç»“æœ
    for i in start_row..end_row {
        for j in 0..b.cols {
            for k in 0..a.cols {
                c[i][j] += a[i][k] * b[k][j];
            }
        }
    }
    
    // åŒæ­¥ç‚¹ï¼šç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆé˜¶æ®µ1
    barrier.wait();
    
    // é˜¶æ®µ2ï¼šå¯ä»¥å®‰å…¨è¯»å–å…¶ä»–çº¿ç¨‹çš„ç»“æœ
    // ... åç»­å¤„ç† ...
}
```

## ğŸ”¬ ç†è®ºå‰æ²¿

### 1. é‡å­å¹¶å‘æ¨¡å‹

```rust
// é‡å­å¹¶å‘åŸè¯­çš„æ¦‚å¿µæ¨¡å‹
pub struct QuantumMutex<T> {
    state: QuantumState<MutexState>,
    data: UnsafeCell<T>,
}

#[derive(Clone)]
pub enum QuantumState<T> {
    Superposition(Vec<(T, f64)>), // çŠ¶æ€å’Œæ¦‚ç‡å¹…
    Entangled(Box<QuantumState<T>>, Box<QuantumState<T>>),
    Measured(T),
}

impl<T> QuantumMutex<T> {
    pub fn quantum_lock(&self) -> QuantumGuard<T> {
        // é‡å­æµ‹é‡ï¼šå¡Œç¼©åˆ°ç¡®å®šçŠ¶æ€
        let measured_state = self.state.measure();
        match measured_state {
            MutexState::Unlocked => {
                // è·å¾—é”ï¼Œè¿›å…¥ç»å…¸çŠ¶æ€
                QuantumGuard::Classical(ClassicalGuard::new(self))
            }
            MutexState::Locked(_) => {
                // è¿›å…¥é‡å­å åŠ ç­‰å¾…çŠ¶æ€
                QuantumGuard::Superposition(SuperpositionGuard::new(self))
            }
        }
    }
}
```

### 2. åŒºå—é“¾å¹¶å‘éªŒè¯

```rust
// åŒºå—é“¾çŠ¶æ€çš„å¹¶å‘ä¸€è‡´æ€§
pub struct BlockchainState {
    accounts: ConcurrentHashMap<Address, Account>,
    transactions: Vec<Transaction>,
    merkle_root: Hash,
}

impl BlockchainState {
    // å¹¶å‘äº¤æ˜“éªŒè¯
    pub async fn validate_transactions(&self, txs: &[Transaction]) 
        -> Result<ValidationResult, ValidationError> {
        
        // å¹¶è¡ŒéªŒè¯ï¼šæ£€æŸ¥äº¤æ˜“é—´çš„ä¾èµ–å…³ç³»
        let dependency_graph = self.build_dependency_graph(txs);
        
        // æ‹“æ‰‘æ’åºï¼šç¡®å®šå®‰å…¨çš„å¹¶è¡Œæ‰§è¡Œé¡ºåº
        let execution_order = dependency_graph.topological_sort()?;
        
        // åˆ†æ‰¹å¹¶è¡Œæ‰§è¡Œ
        for batch in execution_order.into_batches() {
            let futures: Vec<_> = batch.into_iter()
                .map(|tx| self.validate_transaction(tx))
                .collect();
                
            let results = join_all(futures).await;
            
            // æ£€æŸ¥æ‰¹å†…ä¸€è‡´æ€§
            self.verify_batch_consistency(&results)?;
        }
        
        Ok(ValidationResult::Valid)
    }
    
    // çŠ¶æ€é»˜å…‹å°”è¯æ˜çš„å¹¶å‘ç”Ÿæˆ
    pub async fn generate_state_proof(&self, addresses: &[Address]) 
        -> MerkleProof {
        // å¹¶è¡Œæ”¶é›†è´¦æˆ·çŠ¶æ€
        let account_futures: Vec<_> = addresses.iter()
            .map(|addr| async move {
                let account = self.accounts.get(addr).await?;
                Ok((addr.clone(), account.hash()))
            })
            .collect();
            
        let account_hashes = join_all(account_futures).await;
        
        // å¹¶è¡Œæ„å»ºé»˜å…‹å°”æ ‘
        MerkleTree::build_concurrent(account_hashes).await
    }
}
```

## ğŸ“Š æ€§èƒ½åˆ†æ

### 1. å¹¶å‘åŸè¯­æ€§èƒ½å¯¹æ¯”

```rust
use std::time::Instant;
use std::sync::{Arc, Mutex, RwLock};
use std::thread;

// æ€§èƒ½åŸºå‡†æµ‹è¯•
#[cfg(test)]
mod benchmarks {
    use super::*;
    
    #[test]
    fn benchmark_mutex_contention() {
        const NUM_THREADS: usize = 8;
        const OPERATIONS_PER_THREAD: usize = 100_000;
        
        let data = Arc::new(Mutex::new(0i64));
        let start = Instant::now();
        
        let handles: Vec<_> = (0..NUM_THREADS).map(|_| {
            let data = Arc::clone(&data);
            thread::spawn(move || {
                for _ in 0..OPERATIONS_PER_THREAD {
                    let mut guard = data.lock().unwrap();
                    *guard += 1;
                }
            })
        }).collect();
        
        for handle in handles {
            handle.join().unwrap();
        }
        
        let duration = start.elapsed();
        let final_value = *data.lock().unwrap();
        
        println!("Mutex benchmark:");
        println!("  Final value: {}", final_value);
        println!("  Duration: {:?}", duration);
        println!("  Ops/sec: {:.0}", 
                (NUM_THREADS * OPERATIONS_PER_THREAD) as f64 / duration.as_secs_f64());
    }
    
    #[test]
    fn benchmark_rwlock_readers() {
        const NUM_READERS: usize = 16;
        const NUM_WRITERS: usize = 2;
        const OPERATIONS: usize = 50_000;
        
        let data = Arc::new(RwLock::new(vec![0i32; 1000]));
        let start = Instant::now();
        
        // å¯åŠ¨è¯»è€…çº¿ç¨‹
        let reader_handles: Vec<_> = (0..NUM_READERS).map(|_| {
            let data = Arc::clone(&data);
            thread::spawn(move || {
                for _ in 0..OPERATIONS {
                    let guard = data.read().unwrap();
                    let _sum: i32 = guard.iter().sum();
                }
            })
        }).collect();
        
        // å¯åŠ¨å†™è€…çº¿ç¨‹
        let writer_handles: Vec<_> = (0..NUM_WRITERS).map(|i| {
            let data = Arc::clone(&data);
            thread::spawn(move || {
                for j in 0..OPERATIONS {
                    let mut guard = data.write().unwrap();
                    guard[j % guard.len()] = i as i32;
                }
            })
        }).collect();
        
        for handle in reader_handles.into_iter().chain(writer_handles) {
            handle.join().unwrap();
        }
        
        let duration = start.elapsed();
        println!("RwLock benchmark: {:?}", duration);
    }
    
    #[test]
    fn benchmark_atomic_operations() {
        use std::sync::atomic::{AtomicI64, Ordering};
        
        const NUM_THREADS: usize = 8;
        const OPERATIONS: usize = 1_000_000;
        
        let counter = Arc::new(AtomicI64::new(0));
        let start = Instant::now();
        
        let handles: Vec<_> = (0..NUM_THREADS).map(|_| {
            let counter = Arc::clone(&counter);
            thread::spawn(move || {
                for _ in 0..OPERATIONS {
                    counter.fetch_add(1, Ordering::Relaxed);
                }
            })
        }).collect();
        
        for handle in handles {
            handle.join().unwrap();
        }
        
        let duration = start.elapsed();
        let final_value = counter.load(Ordering::Relaxed);
        
        println!("Atomic benchmark:");
        println!("  Final value: {}", final_value);
        println!("  Duration: {:?}", duration);
        println!("  Ops/sec: {:.0}", 
                (NUM_THREADS * OPERATIONS) as f64 / duration.as_secs_f64());
    }
}
```

### 2. å¯æ‰©å±•æ€§åˆ†æ

```rust
// å¯æ‰©å±•æ€§æµ‹è¯•æ¡†æ¶
pub struct ScalabilityTest {
    name: String,
    thread_counts: Vec<usize>,
    operation_count: usize,
}

impl ScalabilityTest {
    pub fn run<F>(&self, test_fn: F) 
    where
        F: Fn(usize, usize) -> Duration + Sync + Send,
    {
        println!("Scalability test: {}", self.name);
        println!("Threads\tTime(ms)\tOps/sec\tSpeedup");
        
        let baseline_time = test_fn(1, self.operation_count);
        
        for &thread_count in &self.thread_counts {
            let time = test_fn(thread_count, self.operation_count);
            let ops_per_sec = self.operation_count as f64 / time.as_secs_f64();
            let speedup = baseline_time.as_secs_f64() / time.as_secs_f64();
            
            println!("{}\t{:.2}\t{:.0}\t{:.2}x",
                    thread_count,
                    time.as_millis(),
                    ops_per_sec,
                    speedup);
        }
    }
}

// ä½¿ç”¨ç¤ºä¾‹
fn test_mutex_scalability() {
    let test = ScalabilityTest {
        name: "Mutex Contention".to_string(),
        thread_counts: vec![1, 2, 4, 8, 16, 32],
        operation_count: 1_000_000,
    };
    
    test.run(|thread_count, ops| {
        let data = Arc::new(Mutex::new(0i64));
        let ops_per_thread = ops / thread_count;
        
        let start = Instant::now();
        
        let handles: Vec<_> = (0..thread_count).map(|_| {
            let data = Arc::clone(&data);
            thread::spawn(move || {
                for _ in 0..ops_per_thread {
                    let mut guard = data.lock().unwrap();
                    *guard += 1;
                }
            })
        }).collect();
        
        for handle in handles {
            handle.join().unwrap();
        }
        
        start.elapsed()
    });
}
```

## ğŸ”— äº¤å‰å¼•ç”¨

### ç›¸å…³è¯­ä¹‰å±‚

- **[åŸºç¡€è¯­ä¹‰å±‚ - å†…å­˜å®‰å…¨](../01_ownership_borrowing/04_memory_safety_semantics.md)** - å¹¶å‘å†…å­˜å®‰å…¨ä¿è¯
- **[æ§åˆ¶è¯­ä¹‰å±‚ - å‡½æ•°è¯­ä¹‰](../03_control_flow/02_function_formal_semantics.md)** - å¹¶å‘æ§åˆ¶æµ
- **[ç»„ç»‡è¯­ä¹‰å±‚ - æ¨¡å—è¯­ä¹‰](../10_modules/01_module_system_semantics.md)** - å¹¶å‘æ¨¡å—ç»„ç»‡
- **[è½¬æ¢è¯­ä¹‰å±‚ - å¼‚æ­¥è¯­ä¹‰](../06_async_await/02_async_await_semantics.md)** - å¼‚æ­¥å¹¶å‘æ¨¡å‹

### ç›¸å…³æ¦‚å¿µ

- **æ•°æ®ç«äº‰** â†” **å†…å­˜åº** - åŸå­æ“ä½œé˜²æ­¢æ•°æ®ç«äº‰
- **æ­»é”æ£€æµ‹** â†” **é”åº** - å…¨å±€é”æ’åºé¢„é˜²æ­»é”
- **æ´»é”é¿å…** â†” **é€€é¿ç­–ç•¥** - æŒ‡æ•°é€€é¿å’ŒéšæœºåŒ–
- **ä¼˜å…ˆçº§åè½¬** â†” **ä¼˜å…ˆçº§ç»§æ‰¿** - å®æ—¶ç³»ç»Ÿçš„ä¼˜å…ˆçº§å¤„ç†

---

**æ–‡æ¡£å®Œæˆåº¦**: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

**ç†è®ºæ·±åº¦**: â­â­â­â­â­ (ä¸“å®¶çº§)
**å®è·µæŒ‡å¯¼**: â­â­â­â­â­ (å®Œæ•´å·¥ç¨‹æ¡ˆä¾‹)  
**æ•°å­¦ä¸¥è°¨**: â­â­â­â­â­ (å®Œæ•´å½¢å¼åŒ–)
**åˆ›æ–°ä»·å€¼**: â­â­â­â­â­ (å‰æ²¿ç†è®ºé›†æˆ)
