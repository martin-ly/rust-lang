# ğŸ” Rustæ€§èƒ½åˆ†æå·¥å…·é›†æˆæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

**æ–‡æ¡£ç±»å‹**: æ€§èƒ½å·¥ç¨‹æŒ‡å—  
**é€‚ç”¨ç‰ˆæœ¬**: Rust 2021 Edition+  
**åˆ›å»ºæ—¥æœŸ**: 2025å¹´1æœˆ27æ—¥  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ27æ—¥  
**è´¨é‡ç­‰çº§**: ğŸ† **å·¥ä¸šçº§æ ‡å‡†**

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

- é›†æˆä¸»æµæ€§èƒ½åˆ†æå·¥å…·
- å»ºç«‹å®Œæ•´çš„æ€§èƒ½åˆ†æå·¥ä½œæµ
- æä¾›å¯è§†åŒ–çš„æ€§èƒ½åˆ†æç»“æœ
- å®ç°è‡ªåŠ¨åŒ–çš„æ€§èƒ½ç›‘æ§

## ğŸ› ï¸ æ€§èƒ½åˆ†æå·¥å…·é“¾

### 1. ç³»ç»Ÿçº§æ€§èƒ½åˆ†æå·¥å…·

#### 1.1 Perf - Linuxæ€§èƒ½åˆ†æå™¨

```bash
# å®‰è£…perf
sudo apt-get install linux-tools-common linux-tools-generic

# åŸºæœ¬ä½¿ç”¨
perf record -g ./target/release/my_program
perf report

# å®æ—¶åˆ†æ
perf top

# ç»Ÿè®¡ä¿¡æ¯
perf stat ./target/release/my_program
```

**Rusté›†æˆ**:

```rust
use std::process::Command;

fn run_perf_analysis(program_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    let output = Command::new("perf")
        .args(&["record", "-g", "-o", "perf.data", program_path])
        .output()?;
    
    if output.status.success() {
        let report = Command::new("perf")
            .args(&["report", "-i", "perf.data"])
            .output()?;
        
        Ok(String::from_utf8_lossy(&report.stdout).to_string())
    } else {
        Err("Perf analysis failed".into())
    }
}
```

#### 1.2 Valgrind - å†…å­˜åˆ†æå·¥å…·

```bash
# å†…å­˜æ³„æ¼æ£€æµ‹
valgrind --leak-check=full --show-leak-kinds=all ./target/release/my_program

# å†…å­˜ä½¿ç”¨åˆ†æ
valgrind --tool=massif ./target/release/my_program
ms_print massif.out.* > memory_report.txt
```

**Rusté›†æˆ**:

```rust
use std::process::Command;

fn run_valgrind_analysis(program_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    let output = Command::new("valgrind")
        .args(&[
            "--leak-check=full",
            "--show-leak-kinds=all",
            "--track-origins=yes",
            "--verbose",
            "--log-file=valgrind.log",
            program_path
        ])
        .output()?;
    
    Ok(String::from_utf8_lossy(&output.stderr).to_string())
}
```

### 2. Rustä¸“ç”¨æ€§èƒ½åˆ†æå·¥å…·

#### 2.1 Criterion.rs - åŸºå‡†æµ‹è¯•æ¡†æ¶

```toml
# Cargo.toml
[dependencies]
criterion = { version = "0.5", features = ["html_reports"] }

[[bench]]
name = "my_benchmark"
harness = false
```

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_function(c: &mut Criterion) {
    c.bench_function("my_function", |b| {
        b.iter(|| {
            // è¢«æµ‹è¯•çš„å‡½æ•°
            black_box(my_function())
        });
    });
}

criterion_group!(benches, benchmark_function);
criterion_main!(benches);
```

#### 2.2 Flamegraph - ç«ç„°å›¾ç”Ÿæˆ

```toml
# Cargo.toml
[dependencies]
flamegraph = "0.4"
```

```rust
use flamegraph::{self, Flamegraph};

fn generate_flamegraph<F, T>(operation: F) -> Result<T, Box<dyn std::error::Error>>
where
    F: FnOnce() -> T,
{
    let flamegraph = Flamegraph::new()?;
    
    let result = flamegraph.report(|_| {
        operation()
    });
    
    // ç”ŸæˆSVGç«ç„°å›¾
    result.report(&mut std::fs::File::create("flamegraph.svg")?)?;
    
    Ok(result.data)
}

// ä½¿ç”¨ç¤ºä¾‹
fn main() -> Result<(), Box<dyn std::error::Error>> {
    let result = generate_flamegraph(|| {
        // éœ€è¦åˆ†æçš„ä»£ç 
        expensive_operation();
    })?;
    
    println!("Flamegraph generated successfully");
    Ok(())
}
```

#### 2.3 Iai - æŒ‡ä»¤çº§åŸºå‡†æµ‹è¯•

```toml
# Cargo.toml
[dependencies]
iai = "0.1"
```

```rust
use iai::{black_box, main};

fn fibonacci(n: u64) -> u64 {
    match n {
        0 => 1,
        1 => 1,
        n => fibonacci(n - 1) + fibonacci(n - 2),
    }
}

fn iai_fibonacci_benchmark() -> u64 {
    black_box(fibonacci(black_box(20)))
}

main!(iai_fibonacci_benchmark);
```

## ğŸ“Š æ€§èƒ½ç›‘æ§æ¡†æ¶

### 1. è‡ªå®šä¹‰æ€§èƒ½ç›‘æ§å™¨

```rust
use std::time::{Duration, Instant};
use std::collections::HashMap;
use std::sync::Mutex;

#[derive(Debug, Clone)]
struct PerformanceMetric {
    name: String,
    total_time: Duration,
    call_count: u64,
    min_time: Duration,
    max_time: Duration,
    avg_time: Duration,
}

struct PerformanceMonitor {
    metrics: Mutex<HashMap<String, PerformanceMetric>>,
}

impl PerformanceMonitor {
    fn new() -> Self {
        PerformanceMonitor {
            metrics: Mutex::new(HashMap::new()),
        }
    }
    
    fn measure<F, T>(&self, name: &str, operation: F) -> T
    where
        F: FnOnce() -> T,
    {
        let start = Instant::now();
        let result = operation();
        let duration = start.elapsed();
        
        self.record_metric(name, duration);
        result
    }
    
    fn record_metric(&self, name: &str, duration: Duration) {
        let mut metrics = self.metrics.lock().unwrap();
        let metric = metrics.entry(name.to_string()).or_insert(PerformanceMetric {
            name: name.to_string(),
            total_time: Duration::ZERO,
            call_count: 0,
            min_time: Duration::MAX,
            max_time: Duration::ZERO,
            avg_time: Duration::ZERO,
        });
        
        metric.total_time += duration;
        metric.call_count += 1;
        metric.min_time = metric.min_time.min(duration);
        metric.max_time = metric.max_time.max(duration);
        metric.avg_time = metric.total_time / metric.call_count;
    }
    
    fn get_report(&self) -> Vec<PerformanceMetric> {
        let metrics = self.metrics.lock().unwrap();
        metrics.values().cloned().collect()
    }
    
    fn export_to_json(&self) -> Result<String, Box<dyn std::error::Error>> {
        use serde_json;
        
        let report = self.get_report();
        let json = serde_json::to_string_pretty(&report)?;
        Ok(json)
    }
}

// å…¨å±€æ€§èƒ½ç›‘æ§å™¨
lazy_static::lazy_static! {
    static ref GLOBAL_MONITOR: PerformanceMonitor = PerformanceMonitor::new();
}

// æ€§èƒ½ç›‘æ§å®
#[macro_export]
macro_rules! monitor {
    ($name:expr, $expr:expr) => {
        GLOBAL_MONITOR.measure($name, || $expr)
    };
}
```

### 2. å†…å­˜ä½¿ç”¨ç›‘æ§

```rust
use std::alloc::{alloc, dealloc, Layout};
use std::sync::atomic::{AtomicUsize, Ordering};

struct MemoryTracker {
    allocated: AtomicUsize,
    deallocated: AtomicUsize,
}

impl MemoryTracker {
    fn new() -> Self {
        MemoryTracker {
            allocated: AtomicUsize::new(0),
            deallocated: AtomicUsize::new(0),
        }
    }
    
    fn track_allocation(&self, size: usize) {
        self.allocated.fetch_add(size, Ordering::Relaxed);
    }
    
    fn track_deallocation(&self, size: usize) {
        self.deallocated.fetch_add(size, Ordering::Relaxed);
    }
    
    fn current_usage(&self) -> usize {
        self.allocated.load(Ordering::Relaxed)
            .saturating_sub(self.deallocated.load(Ordering::Relaxed))
    }
    
    fn reset(&self) {
        self.allocated.store(0, Ordering::Relaxed);
        self.deallocated.store(0, Ordering::Relaxed);
    }
}

// å…¨å±€å†…å­˜è·Ÿè¸ªå™¨
lazy_static::lazy_static! {
    static ref MEMORY_TRACKER: MemoryTracker = MemoryTracker::new();
}

// è‡ªå®šä¹‰åˆ†é…å™¨
struct TrackingAllocator;

unsafe impl std::alloc::GlobalAlloc for TrackingAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let ptr = alloc(layout);
        if !ptr.is_null() {
            MEMORY_TRACKER.track_allocation(layout.size());
        }
        ptr
    }
    
    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        dealloc(ptr, layout);
        MEMORY_TRACKER.track_deallocation(layout.size());
    }
}

#[global_allocator]
static ALLOCATOR: TrackingAllocator = TrackingAllocator;
```

## ğŸ” æ€§èƒ½åˆ†æå·¥ä½œæµ

### 1. è‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•

```rust
use std::process::Command;
use std::fs;
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
struct PerformanceTest {
    name: String,
    command: String,
    expected_duration: Duration,
    memory_limit: usize,
}

#[derive(Debug, Serialize, Deserialize)]
struct PerformanceResult {
    test_name: String,
    actual_duration: Duration,
    memory_usage: usize,
    success: bool,
    error_message: Option<String>,
}

struct PerformanceTestRunner {
    tests: Vec<PerformanceTest>,
    results: Vec<PerformanceResult>,
}

impl PerformanceTestRunner {
    fn new() -> Self {
        PerformanceTestRunner {
            tests: Vec::new(),
            results: Vec::new(),
        }
    }
    
    fn add_test(&mut self, test: PerformanceTest) {
        self.tests.push(test);
    }
    
    fn run_all_tests(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        for test in &self.tests {
            let result = self.run_single_test(test)?;
            self.results.push(result);
        }
        
        self.generate_report()?;
        Ok(())
    }
    
    fn run_single_test(&self, test: &PerformanceTest) -> Result<PerformanceResult, Box<dyn std::error::Error>> {
        let start = Instant::now();
        
        let output = Command::new("cargo")
            .args(&["run", "--release"])
            .current_dir(&test.command)
            .output()?;
        
        let duration = start.elapsed();
        let memory_usage = MEMORY_TRACKER.current_usage();
        
        let success = output.status.success() 
            && duration <= test.expected_duration
            && memory_usage <= test.memory_limit;
        
        Ok(PerformanceResult {
            test_name: test.name.clone(),
            actual_duration: duration,
            memory_usage,
            success,
            error_message: if success { None } else { 
                Some(String::from_utf8_lossy(&output.stderr).to_string()) 
            },
        })
    }
    
    fn generate_report(&self) -> Result<(), Box<dyn std::error::Error>> {
        let report = serde_json::to_string_pretty(&self.results)?;
        fs::write("performance_report.json", report)?;
        
        // ç”ŸæˆHTMLæŠ¥å‘Š
        self.generate_html_report()?;
        
        Ok(())
    }
    
    fn generate_html_report(&self) -> Result<(), Box<dyn std::error::Error>> {
        let mut html = String::new();
        html.push_str("<html><head><title>Performance Test Report</title></head><body>");
        html.push_str("<h1>Performance Test Report</h1>");
        html.push_str("<table border='1'><tr><th>Test</th><th>Duration</th><th>Memory</th><th>Status</th></tr>");
        
        for result in &self.results {
            let status = if result.success { "âœ… PASS" } else { "âŒ FAIL" };
            html.push_str(&format!(
                "<tr><td>{}</td><td>{:?}</td><td>{} bytes</td><td>{}</td></tr>",
                result.test_name, result.actual_duration, result.memory_usage, status
            ));
        }
        
        html.push_str("</table></body></html>");
        fs::write("performance_report.html", html)?;
        
        Ok(())
    }
}
```

### 2. æŒç»­é›†æˆé›†æˆ

```yaml
# .github/workflows/performance.yml
name: Performance Tests

on: [push, pull_request]

jobs:
  performance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          
      - name: Install perf
        run: |
          sudo apt-get update
          sudo apt-get install -y linux-tools-common linux-tools-generic
          
      - name: Run benchmarks
        run: cargo bench
        
      - name: Generate flamegraph
        run: |
          cargo install flamegraph
          cargo flamegraph --bench my_benchmark
          
      - name: Run performance tests
        run: cargo run --bin performance_tests
        
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: |
            target/criterion/
            flamegraph.svg
            performance_report.html
            performance_report.json
```

## ğŸ“ˆ å¯è§†åŒ–åˆ†æ

### 1. æ€§èƒ½å›¾è¡¨ç”Ÿæˆ

```rust
use plotters::prelude::*;

struct PerformanceVisualizer {
    data: Vec<PerformanceMetric>,
}

impl PerformanceVisualizer {
    fn new(data: Vec<PerformanceMetric>) -> Self {
        PerformanceVisualizer { data }
    }
    
    fn generate_execution_time_chart(&self, filename: &str) -> Result<(), Box<dyn std::error::Error>> {
        let root = BitMapBackend::new(filename, (800, 600)).into_drawing_area();
        root.fill(&WHITE)?;
        
        let max_time = self.data.iter()
            .map(|m| m.avg_time.as_micros() as f64)
            .fold(0.0, f64::max);
        
        let mut chart = ChartBuilder::on(&root)
            .caption("Function Execution Times", ("sans-serif", 30))
            .x_label_area_size(40)
            .y_label_area_size(60)
            .build_cartesian_2d(
                0..self.data.len(),
                0.0..max_time,
            )?;
        
        chart.configure_mesh().draw()?;
        
        chart.draw_series(
            self.data.iter().enumerate().map(|(i, metric)| {
                let color = if metric.avg_time.as_micros() > 1000 {
                    RED
                } else if metric.avg_time.as_micros() > 100 {
                    YELLOW
                } else {
                    GREEN
                };
                
                Rectangle::new(
                    [(i, 0), (i + 1, metric.avg_time.as_micros() as f64)],
                    color.filled(),
                )
            }),
        )?;
        
        root.present()?;
        Ok(())
    }
    
    fn generate_memory_usage_chart(&self, filename: &str) -> Result<(), Box<dyn std::error::Error>> {
        // å†…å­˜ä½¿ç”¨å›¾è¡¨å®ç°
        Ok(())
    }
}
```

### 2. å®æ—¶æ€§èƒ½ç›‘æ§

```rust
use tokio::time::{interval, Duration};
use std::sync::Arc;

struct RealTimeMonitor {
    monitor: Arc<PerformanceMonitor>,
    interval: Duration,
}

impl RealTimeMonitor {
    fn new(monitor: Arc<PerformanceMonitor>, interval: Duration) -> Self {
        RealTimeMonitor { monitor, interval }
    }
    
    async fn start_monitoring(&self) {
        let mut interval = interval(self.interval);
        
        loop {
            interval.tick().await;
            
            let report = self.monitor.get_report();
            self.display_current_metrics(&report);
            
            // æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
            self.check_performance_thresholds(&report);
        }
    }
    
    fn display_current_metrics(&self, metrics: &[PerformanceMetric]) {
        println!("\n=== Performance Metrics ===");
        for metric in metrics {
            println!(
                "{}: {:.2?} avg, {} calls, {:.2?} total",
                metric.name,
                metric.avg_time,
                metric.call_count,
                metric.total_time
            );
        }
        println!("===========================\n");
    }
    
    fn check_performance_thresholds(&self, metrics: &[PerformanceMetric]) {
        for metric in metrics {
            if metric.avg_time > Duration::from_millis(100) {
                eprintln!("âš ï¸  Performance warning: {} is slow ({:.2?})", 
                         metric.name, metric.avg_time);
            }
        }
    }
}
```

## ğŸ¯ æ€§èƒ½åˆ†ææ£€æŸ¥æ¸…å•

### âœ… å·¥å…·é…ç½®

- [ ] å®‰è£…å¹¶é…ç½®perf
- [ ] è®¾ç½®valgrindç¯å¢ƒ
- [ ] é…ç½®criterionåŸºå‡†æµ‹è¯•
- [ ] å®‰è£…flamegraphå·¥å…·
- [ ] è®¾ç½®æ€§èƒ½ç›‘æ§æ¡†æ¶

### âœ… åˆ†ææµç¨‹

- [ ] ç¡®å®šæ€§èƒ½ç“¶é¢ˆ
- [ ] é€‰æ‹©åˆé€‚åˆ†æå·¥å…·
- [ ] æ”¶é›†æ€§èƒ½æ•°æ®
- [ ] åˆ†ææ€§èƒ½ç»“æœ
- [ ] ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

### âœ… æŒç»­ç›‘æ§

- [ ] è®¾ç½®æ€§èƒ½åŸºå‡†
- [ ] é…ç½®è‡ªåŠ¨åŒ–æµ‹è¯•
- [ ] å»ºç«‹å‘Šè­¦æœºåˆ¶
- [ ] å®šæœŸæ€§èƒ½å®¡æŸ¥
- [ ] æ€§èƒ½å›å½’æ£€æµ‹

## ğŸ¯ åº”ç”¨åœºæ™¯

### 1. WebæœåŠ¡æ€§èƒ½åˆ†æ

```rust
use actix_web::{web, App, HttpServer, HttpResponse};

async fn analyze_web_performance() {
    let monitor = Arc::new(PerformanceMonitor::new());
    
    HttpServer::new(move || {
        App::new()
            .app_data(web::Data::new(monitor.clone()))
            .route("/api/data", web::get().to(monitored_handler))
    })
    .bind("127.0.0.1:8080")
    .unwrap()
    .run()
    .await
    .unwrap();
}

async fn monitored_handler(
    monitor: web::Data<Arc<PerformanceMonitor>>,
) -> HttpResponse {
    monitor.measure("api_data_handler", || {
        // å¤„ç†é€»è¾‘
        expensive_operation();
        HttpResponse::Ok().body("Data processed")
    })
}
```

### 2. æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½åˆ†æ

```rust
use sqlx::PgPool;

async fn analyze_database_performance(pool: &PgPool) {
    let monitor = Arc::new(PerformanceMonitor::new());
    
    let result = monitor.measure("database_query", || {
        // æ•°æ®åº“æŸ¥è¯¢
        sqlx::query!("SELECT * FROM users WHERE active = true")
            .fetch_all(pool)
    });
    
    println!("Query performance: {:?}", monitor.get_report());
}
```

### 3. ç®—æ³•æ€§èƒ½åˆ†æ

```rust
fn analyze_algorithm_performance() {
    let monitor = Arc::new(PerformanceMonitor::new());
    
    let data = generate_test_data(10000);
    
    let result = monitor.measure("sorting_algorithm", || {
        let mut sorted_data = data.clone();
        sorted_data.sort();
        sorted_data
    });
    
    let report = monitor.get_report();
    println!("Algorithm performance: {:?}", report);
}
```

## ğŸ¯ æ€»ç»“

æ€§èƒ½åˆ†æå·¥å…·é›†æˆæ˜¯æ€§èƒ½å·¥ç¨‹çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œé€šè¿‡ç³»ç»Ÿæ€§çš„å·¥å…·é“¾é›†æˆï¼Œæˆ‘ä»¬èƒ½å¤Ÿï¼š

1. **å…¨é¢ç›‘æ§**: ä»ç³»ç»Ÿçº§åˆ°åº”ç”¨çº§çš„å…¨é¢æ€§èƒ½ç›‘æ§
2. **ç²¾ç¡®åˆ†æ**: ä½¿ç”¨ä¸“ä¸šå·¥å…·è¿›è¡Œç²¾ç¡®çš„æ€§èƒ½åˆ†æ
3. **å¯è§†åŒ–å±•ç¤º**: é€šè¿‡å›¾è¡¨å’ŒæŠ¥å‘Šç›´è§‚å±•ç¤ºæ€§èƒ½æ•°æ®
4. **æŒç»­æ”¹è¿›**: å»ºç«‹æŒç»­çš„æ€§èƒ½ç›‘æ§å’Œæ”¹è¿›æœºåˆ¶

é€šè¿‡æœ¬æŒ‡å—çš„å®è·µï¼Œæ‚¨å°†èƒ½å¤Ÿå»ºç«‹å®Œæ•´çš„æ€§èƒ½åˆ†æä½“ç³»ï¼Œä¸ºRuståº”ç”¨çš„æ€§èƒ½ä¼˜åŒ–æä¾›å¼ºæœ‰åŠ›çš„æ”¯æ’‘ã€‚
